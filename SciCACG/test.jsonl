{"pre": "in this paper, we propose an algorithm for generating referring expressions in an incremental parser, an incremental # refr that performs well, as preprocessing by [SEP]", "cit": "# refr ), making use of the fact that words can be disambiguated by nearby words that are similar. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the field of multi - document summarization ( ie ), the information synthesis has been explored in # refr. [SEP] the [SEP] domain of [SEP]", "cit": "besides the measures included in our experiment, there are other criteria to compare summaries which could as well be tested for information synthesis : annotation of relevant [SEP]"}
{"pre": "sentence compression has been considered before in the sentence compression task, e. g., # otherefr ; # refr, among others ) [SEP]", "cit": "many algorithms exploit parallel corpora # refr to learn the correspondences between long and short sentences in a supervised manner, typically using a rich feature space induced [SEP]"}
{"pre": "in french, # refr extracts maximal ength noun phrases ( mlnp ) are then applied to french ( cf. [SEP] ), [SEP] ) [SEP]", "cit": "the goal is to develop tools to help a terminologist in the construction of a structured terminology ( cf. figure 1 ) providing :? te [SEP]"}
{"pre": "for instance, # refr use svms as well as unigrams and bigrams. [SEP] the premises they are much harder to process of [SEP]", "cit": "previous research on argumentation mining spans several subtasks, including # otherefr ; # refr, and # otherefr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "it has been used in a wide range of nlp tasks including text generation # otherefr, and the generation of named entity recognition ( e", "cit": "both the linguistic and structural realisations are performed by using functionalities provided by the simplenlg realiser library # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use semeval - 2007 # refr to evaluate our model on the semeval 2007 task. [SEP] the [SEP] task [SEP] [SEP] [SEP] the", "cit": "our word sense induction and disambiguation model is trained and tested on the dataset of the semeval - 2010 wsi / wsd task [SEP]"}
{"pre": "d. yarowsky et al. # otherefr used the bag - of - words d. 2 entity disambiguation ( d ) and", "cit": "another line of work focuses on collective disambiguation # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the expanded set of results are summarised in table 1, for transformation based learning # otherefr, l - bfgs based maximum entropy models #", "cit": "however, our implementation uses a quasi - newton gradient - climber bfgs for optimization, which has been shown to converge much faster # refr [SEP]"}
{"pre": "for example, the system described in # refr provides a basis for nlg modules. [SEP], developed an architecture for generating text from a spoken dialogue", "cit": "in the last decade, several systems that integrate nlg techniques for aac systems have been developed ( # refr, # otherefr for example [SEP]"}
{"pre": "around 95 % word segmentation accuracy is reported by using a word - based language model and the viterbi - like dynamic programi ~ \\ [", "cit": "once word segmentation is done, all established techniques can be exploited to build practically important applications such as spelling correction \\ [ # refr \\ [SEP]"}
{"pre": "we used the stanford parser to get dependency parses of the stanford parser # refr. [SEP] the constituent 1nlp. [SEP]. [SEP]. [SEP]", "cit": "wiki : 25k articles of english wikipedia abstracts parsed by the # refr parser. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "morphological disambiguation there has been a lot of work on arabic pos tagging and morphological disambiguation # otherefr ; # refr. [SEP] this approach", "cit": "the only work on arabic tagging that uses a corpus for training and evaluation ( that we are aware of ), # refr, does not use [SEP]"}
{"pre": "in text planning, genetic algorithms are similar to the interaction between aggregation and lexical aggregation, which has been applied in dialogues to text planning # refr", "cit": "figure 1 : aggregation examples of # refra ) which uses a joint relation to connect every two text spans that do not have a semantic relation [SEP]"}
{"pre": "distributional methods have been used in numerous nlp, including e. g., # otherefr ; # refr. [SEP] distributional models # [SEP]", "cit": "# refr investigate nonparametric bayesian models for teasing apart the context distributions of polysemous words. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in machine translation # otherefr ; # refr. [SEP] this framework by allowing for training sentences according to their mt output. [SEP] [SEP] [SEP] [SEP]", "cit": "our approach is similar to that of # refr except that in our case the contribution of each metric to the overall score is not adjusted. [SEP] [PAD]"}
{"pre": "recent work by # refr has shown that these speech repairs can be effectively performed by including lexical edits. [SEP] a automatically trained [SEP] [SEP] [SEP]", "cit": "most prior work has focused on handling disfluencies and continued to rely on hand - annotated transcripts that include punctuation, case, and known [SEP]"}
{"pre": "previous work on relation extraction has shown that supervised machine learning algorithms can be applied to other nlp tasks # otherefr ; # refr. [SEP]", "cit": "recent research indicates that using labeled and unlabeled data in semi - supervised learning # otherefr, relation extraction # refr, passage - retrieval # [SEP]"}
{"pre": "paraphrase identification has been addressed previously, both using integer linear programming # otherefr ; # refr. [SEP] ( 1 ) [SEP] [SEP] [SEP]", "cit": "# refr is another example of using word lattices to find paraphrases. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in # refr, the authors compare two methods for measuring word relatedness measures. [SEP] the dic of words in a corpus of the training data. [SEP]", "cit": "despite the well - established technical distinction between semantic similarity and relatedness # refr, comparison to established similarity norms from psychology remains part of the standard evalu [SEP]"}
{"pre": "we parse the input using the collins parser # otherefr and # refr. [SEP] ( 2 ) [SEP] sentences ~ = [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "examples include the use of decision trees for syntactic analysis # refr, coreference # otherefra ; daelemans et al, submitted ) [SEP]"}
{"pre": "in the case of syntactic parsing, the current work on the sentence boundary detection has used a statistical parsers based on the idea of magerman [SEP]", "cit": "for an experimental, and more complicated method to derive all prosodic units in the text - to - speech system, i. e. not just [SEP]"}
{"pre": "on one hand, researchers have been developing modified learning algorithms that allow inexact search # otherefr ; # refr. [SEP] features [SEP] [SEP] [SEP]", "cit": "we base our experiments on our dynamic programming incremental dependency parser # refr. 5 following huang et al # otherefr, we use max - [SEP]"}
{"pre": "the algorithm has been applied to the identification ofs and relations between nouns # otherefr, discourse structure # refr, and [SEP] [SEP] [SEP] [SEP]", "cit": "particular attention was paid to the factors affecting the generation of pronouns # otherefr ; # refr, demonstratives # otherefra ) [SEP]"}
{"pre": "we use the stanford dependency parser # refr to generate the target word. [SEP] text in the sentence. [SEP] it has been shown to be beneficial for", "cit": "we use a tool # refr to identify all explicit discourse connectives in our snippets, along with the general semantic class of the connective [SEP]"}
{"pre": "in the domain of syntactic parsing, the tsg has been used by kudo et al # otherefr and # refr to provide a bayesian", "cit": "one approach to grammar - learning is data - oriented parsing ( dop ), whose strategy is to simply take all subtrees in the training data [SEP]"}
{"pre": "to measure the quality of output, we use the crowdsourcing platform : # otherefr ; # refr. [SEP] the majority of [SEP] [SEP]", "cit": "our approach is related to existing work on analysing the quality of annotated data by examining, for instance, # otherefr ; # refr. [SEP]"}
{"pre": "in this work, we use the recursive auto - encoder # otherefr ; # refr. [SEP] features in sentence negation. [SEP] [SEP] [SEP] [SEP]", "cit": "we compare to the state - of - the - art system of # refr, a dependency tree based classification method that uses crfs with hidden [SEP]"}
{"pre": "for example, the questionanswer pair, or pragmatic constraints can be used for calculating the dialogue act of an utterance based on the dialogue act \\", "cit": "such finer - grained istinctions could only be made with a help of context ; one has to take into account what type of expression [SEP]"}
{"pre": "this approach is similar to the one described in # refr. [SEP] ( 1 ) we also use a data set of maltparser1 [SEP] [SEP]", "cit": "the maltparser dependency parser # refr, trained on a 100, 000 - word swedish treebank. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper, we propose an alternative algorithm for decoding based on hypergraph representation # otherefr ; # refr. [SEP] the algorithm presented by", "cit": "lattice reranking ( li and # refr, a promising way to improve mt systems, also relies on oracle decoding to build the training data [SEP]"}
{"pre": "# refr use a noisy channel model to predict text messages. [SEP] different ways of incorporating automatic word segmentation. [SEP] this process. [SEP] this is done", "cit": "we build upon previous work on normalization by # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr use support vector machines ( svms ) for the arabic dialects. [SEP] the techniques of the morphological analyzer. [SEP]. [SEP] the [SEP]", "cit": "a comparable work was done by # refr, where a pos tagging method for arabic is also discussed. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in a related but different approach, # refr use a similar approach to calculate p ( e | f ) for p ( f | e [SEP] [SEP]", "cit": "the random walk method we use is similar to those defined in norris # otherefr ; # refr ; hassan and menezes [SEP]"}
{"pre": "given the complementary nature of those two semantic models, it is not surprising that considerable research activity has been dedicated on combining them into a single framework [SEP]", "cit": "the parameters of the models are fine - tuned on the noun set of semeval 2010 word sense induction and disambiguation task # refr. [SEP]"}
{"pre": "# refr use a tag - based translation model that uses hierarchical phrase pairs, which are formally productions a synchronous context - free grammar. [SEP] into", "cit": "so far, most of them have been based on synchronous context - free grammars # otherefr ; # refr, and inversion transduction grammars # [SEP]"}
{"pre": "in contrast, # refr train a classifier to detect binary classification / - polarity classification on the sentences annotated by training with subjectivity. [SEP] features,", "cit": "for example, # refr apply machine learning techniques to extracted features from movie reviews. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "bruce and wiebe also performed a separate test by using a subset of the \" interest \" data set with only 4 senses # otherefr [SEP]", "cit": "gale, church and # refr \\ ], for instance, have followed the approach of estimating upper and lower bounds on the performance of a [SEP]"}
{"pre": "we used the dataset provided by # refr. [SEP] features of the sentence polarity classifier. [SEP] the sentence : the simplified version of # otherefr", "cit": "efforts to train sentiment classifiers for twitter messages have largely relied on using emoticons and hashtags as proxies of the true polarity # other [SEP]"}
{"pre": "in recent years, there has been a growing interest in methods for improving efficiency of parsing efficiency, such as lexicon creation ( e. g.,", "cit": "# refr have recently shown that using a finite - state tagger to close cells within the cky chart can reduce the worst - case and [SEP]"}
{"pre": "in addition, we show that the proposed method can incorporate global constraints by employing linear inference ( ilp ) via global inference # refr. [SEP] features", "cit": "when dependencies between the tasks can be formulated in terms of constraints between their outputs, a simpler approach is to solve the tasks separately and integrate the [SEP]"}
{"pre": "phrase - based statistical machine translation ( smt ) systems # refr have achieved significant improvements in translation accuracy over the state - of - the - art", "cit": "phrasal decoders require a phrase table # refr, which contains bilingual phrase pairs and scores indicating their utility. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use mxpost tagger # otherefr and parse trees # refr to train the dependency parser. [SEP] words [SEP] a pronoun [SEP] [SEP] [SEP]", "cit": "we describe these briefly here ; more information about the development of the data source can be found in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this work, we propose a system for correcting preposition errors, that is a well studied problem of english # otherefr ; # refr", "cit": "for example, determiner mistakes usually occur in 5 % to 10 % of noun phrases in various annotated esl corpora # refra ). [SEP]"}
{"pre": "these data - driven parsing approaches obtain state - of - the - art results on the de facto standard wall street journal data set # other [SEP]", "cit": "the conll shared tasks on dependency parsing # refr ; nivre et al 2007a ) highlighted the usefulness of an alternative linguistic formalism for the [SEP]"}
{"pre": "in the higher - order models, the parts consist of arcs together with some context, e. g. the parent or the sister arcs # [SEP]", "cit": "finally, we employ dual decomposition techniques # refr to find agreement between the full dependency tree and the partial syntactic trees linking each predicate with its arguments [SEP]"}
{"pre": "hiero search refinements # refr offer several refinements to cube pruning to improve translation speed. [SEP] the search space of efficient [SEP]. [SEP].", "cit": "recent efforts in statistical machine translation # otherefr and syntax - based models # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use adaptor grammars # refr, a formalism that has been used successfully applied to morphological segmentation # otherefr. [SEP]. [SEP] features [SEP] this", "cit": "other recent unsupervised systems have reported state - of - the art results by incorporating additional information from surrounding words # otherefr, or overlapping context [SEP]"}
{"pre": "in addition, we computed the f - score # refr and the - computed by - satta ( step ) it will be learn [SEP] [SEP] [SEP]", "cit": "# refr propose the task of conversation disentanglement from internet chatroom logs. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr use svms for processing languages, and arabic, use the morphological analysis of these words to segment words in context ; they propose [SEP] [SEP]", "cit": "our system does not model this process except through the use of buckwalter? s dictionary to define the set of analyses for each word ( [SEP]"}
{"pre": "most work on ellipsis # otherefr ; # refr is aimed at discerning the procedures and the level of language processing at which ellip [SEP]", "cit": "# refra ) has convincingly argued that this problem arises because dsp do not distinguish between merely co - referential nd co - indexed ( [SEP]"}
{"pre": "we use the kbp tool # otherefr to extract the word - sense disambiguation task # refr. [SEP] features ( [SEP] [SEP] [SEP] [SEP]", "cit": "a particularly attractive approach to relation extraction is based on distant supervision. 1 here in 1also called self training, or weak supervision. place of [SEP]"}
{"pre": "chiang # otherefr used a non - terminal layer over label bias by # refr ; however, all the definitions are [SEP] [SEP] [SEP] [SEP]", "cit": "one important research question is therefore how to refine the non - terminal category x using linguistically motivated information : zollmann and venugopal [SEP]"}
{"pre": "there has been a surge of interest in lexical normalization with the advent of microblogs # otherefr ; # refr. [SEP] this [SEP] [SEP]", "cit": "however, many studies have reported that current nlp tools do not perform well on microblog texts # otherefr ; # refr. [SEP] [PAD]"}
{"pre": "we use the stanford pos tagger # refr to obtain the pos tags. [SEP] tags for this representation. [SEP] text. [SEP] features. [SEP] the", "cit": "as an initial step, part - of - speech ( pos ) tagging is performed on all forum posts using the stanford pos tagger # refr [SEP]"}
{"pre": "# refr has produced a corpus of 38. 000 word endings derived from a corpus of 1. [SEP] words [SEP] this important [SEP] it [SEP] [SEP]", "cit": "a rule - based tagger described in # refr is equipped with a set of guessing rules which has been hand - crafted using [SEP]"}
{"pre": "such a model is also used by # refr. [SEP] quality assessments of mt output quality, and proved to be useful. [SEP] quality [SEP] quality [SEP]", "cit": "to the best of our knowledge, all approaches so far have tackled quality estimation as a supervised learning problem # otherefr ; # refr [SEP]"}
{"pre": "previous research on dialogue has been based on the assumption that dialogue acts provide a useful way of characterizing dialogue behaviors # refr. [SEP] dialogue behaviors [SEP] dialogue", "cit": "previous research has used dialogue act tagging for tasks such as improving recognition performance # otherefr, evaluating and comparing spoken dialogue systems # refr, [SEP]"}
{"pre": "in sts? 12, # refr found that the semantic textual similarity score between two sentences is equivalent to the task of judging semantic equivalence between the", "cit": "sentence similarity [ ss ] is emerging as a crucial step in many nlp tasks that focus on sentence level semantics such as word sense disambiguation [SEP]"}
{"pre": "in the spirit of the work done by # otherefr ; # refr, we are trying to collect clusters of paraphrases for given [SEP]", "cit": "the duke will also remain leader of sotheby? s germany... 3. 1. 2 web search # refr use google as [SEP]"}
{"pre": "probabilistic models like the ones in the past 2a, and the tasks of cfg parsing # refr can be used to estimate the probabilities of [SEP]", "cit": "to make the model estimation tractable, geman and johnson # refr and miyao and tsujii # otherefr proposed a dynamic programming [SEP]"}
{"pre": "in addition to the basic idea, our approach is related to the joint extraction of hiero - style rules # refr. [SEP] [SEP] the [SEP] [SEP]", "cit": "here we follow the description of hiero decoding by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "passing on a k - best list gives useful improvements # refr, but efficiently enumerating k - best lists often requires substantial gains. [SEP] [SEP] [SEP]", "cit": "a common improvement on this architecture is to pass k - best lists between processing stages, for example # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "it is also possible for the word alignments leading to phrase - based smt models to be learned through transduction grammars # otherefr, # [SEP]", "cit": "it is also possible for the word alignments leading to phrase - based smt models to be learned through transduction grammars # otherefr, # [SEP]"}
{"pre": "we use the hierarchical phrase - based decoder described in # refr. [SEP] this model was trained on the srilm toolkit. [SEP] the suffix array extraction", "cit": "the hierarchical phrase - based translation grammar was extracted using a suffix array rule extractor # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "iii and marcu, 2004 ), named entity recognition # otherefr ; # refr. [SEP] this document # otherefr [SEP] the training", "cit": "tree and sequence kernels have been successfully used in many nlp applications, e. g. : parse reranking and adaptation # otheref [SEP]"}
{"pre": "mwes occur frequently in language and translation quality can be classified into multiword expressions # otherefr ; # refr. [SEP] the compositionality of", "cit": "as an example, # refr proposed two strategies for integrating mwes into statistical machine translation. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "sentence segmentation off - the - shelf tool # refr is a tool. [SEP], which proposed a sentence - level grammar and is a mixture of [SEP]", "cit": "the tool set for tea is constantly being extended, recent additions include a prototype symbolic classifier, shallow parser ( choi, forthcoming ), sentence segmentation [SEP]"}
{"pre": "in the field of multi - document coreference resolution, # refr used a vector space model to represent the content of the documents. [SEP] ( [SEP]", "cit": "mann and yarowsky # otherefr have proposed a web based clustering technique relying on a feature space combining biographic facts and associated names [SEP]"}
{"pre": "in japanese, the similarity is defined as the distribution over the antecedents of japanese using the grammatical structure of an antecedents from the [SEP] research [SEP]", "cit": "the same trend is observed also in japanese zeroanaphora resolution, where the findings made in rule - based or theory - oriented work # [SEP]"}
{"pre": "the feature weights? i are trained using minimum error rate training ( mert ) # refr on the news - test2008 development set, and", "cit": "we tune using och? s algorithm # refr to optimize weights for the distortion model, language model, phrase translation model and word penalty over the [SEP]"}
{"pre": "# refr use a machine learning approach to esl error correction. [SEP] features like grammatical mistakes in japanese. [SEP] text. [SEP] he, using a", "cit": "the only reported research that we are aware of which specifically deals with comma errors in learner writing is reported in hardt # otherefr [SEP]"}
{"pre": "while a topic, the coherence metric has been applied to the identification of semantic analysis # otherefr ; # refr, to measure topic detection [SEP]", "cit": "methods for automatically determining the similarity between topics have several potential applications, such as analysis of corpora to determine topics being discussed # refr or within topic [SEP]"}
{"pre": "we use the stanford pos tagger # refr for danish partof - speech tags. [SEP]. [SEP] the text processing process. [SEP] features, obtaining", "cit": "german : german shallow processing is based on opennlp, stanford pos tagger and ne extractor # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the dependency parses were produced using the # refr parser of clark and curran # otherefr. [SEP] the word sense [SEP] [SEP] [SEP] [SEP]", "cit": "most start - of - the - art natural language parsers # otherefr ; # refr use lexicalised features for parse ranking. [SEP] [PAD]"}
{"pre": "it can not only maintain the strength of phrase translation in traditional phrase - based models # otherefr ; # refr, but also characterize the [SEP]", "cit": "it can not only maintain the strength of phrase translation in traditional phrase - based models # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this model has been used by many nlp tasks such as pos tagging # otherefr, parsing # refr, and language modeling [SEP] [SEP] [SEP]", "cit": "incorporating syntactic features into the context has been at the forefront of recent research # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper, we assume that the salience of \" events is \" where a \" where a \" ~ \" have \" taken from \" human \"", "cit": "from this point of view, finding the object that is co - referred to by a pronoun is the main problem in t ) ronoun resolution [SEP]"}
{"pre": "# refr used sentence ordering to pick up adjacent sentences. [SEP] the constituent? s and proposes local coherence method. [SEP] the concept of the paragraph boundaries", "cit": "existing methods for sentence ordering are divided into two approaches : making use of chronological information # otherefr ; # refr ; and learning the [SEP]"}
{"pre": "distributed training of and distributed training of several structured learning methods have been developed which show very useful in smt # refr and in machine translation # other", "cit": "algorithm 2 is a variant of the simuparallelsgd algorithm of zinkevich et al # otherefr or equivalently of [SEP]"}
{"pre": "to generate inflections for an individual language model, we use the approach of yarowsky # otherefr and the implementation among [SEP] [SEP] [SEP]", "cit": "while there are fully statistical surface realizers # otherefr ; # refr, they operate in a phrase - based fashion on word forms with [SEP]"}
{"pre": "this procedure is known to be very useful in automatic text segmentation # refr. [SEP] text segmentation for spoken documents, and it has been shown [SEP].", "cit": "the central assumption here is that sharp changes in lexical distribution signal the presence of topic boundaries # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr use a noisy channel model, which allows word order variations of a lexicon, merge different vocabulary words. [SEP] a lexicon. [SEP] itg", "cit": "# refr uses an unsupervised noisy channel model. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the domain of interactive dialogue systems we have addressed the problem as a simulation of the restaurant game, and # refr. [SEP] a dialogue management", "cit": "processes for dialogue systems recent work on statistical models for spoken dialogue systems has argued that partially observable markov decision processes # otherefr ; williams and [SEP]"}
{"pre": "in this paper we report on the re - ranker of the conll - 2003 data sets # refr, a large amount of annotated data from", "cit": "the resulting dependency bank was then merged with nombank # refr and propbank # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition to the fine - grained precision, we also report the performance of automatic speech recognition in detecting edits # refr. [SEP] research [SEP]", "cit": "while progress has been made on recognizing primarily objective meeting content, for example, information about the topics that are discussed ( hsueh and # refr [SEP]"}
{"pre": "to overcome the shortage of explicit expressions, # refr proposed a probabilistic model for identifying aca rollout sub - positions that cannot be improved [SEP] [SEP] [SEP]", "cit": "for this task, normally supervised methods are used # refr, which require sufficient labeled training data. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "these methods differ by the objective function or training mode : their objective functions are based on either evaluation - directed loss # otherefr ; # [SEP]", "cit": "it firstly introduced in # refr, and then was improved in # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the case of finite - state transducers, the model described in # refr proposes to reduce parsing. [SEP] a finite - state transducer, [SEP] [SEP]", "cit": "in particular, decision trees can be converted into implicational rules that an expert could inspect and can in principle be compiled back into finite - [SEP]"}
{"pre": "for example, in question answering, paraphrases have been used to find the best paraphrases, which are very useful in natural language processing", "cit": "several solutions to this problem have been proposed including query expansion # otherefr ; # refr and semantic information retrieval # otherefr. [SEP] [PAD]"}
{"pre": "we use the corpus of # refr which contains 385 wall street journal abstracts ( wsj ) portion of the corpus that were tagged with [SEP] [SEP]", "cit": "# refr produced a revised version of the guidelines for the task, and were able to achieve an score of 91 %, and a kappa of [SEP]"}
{"pre": "wikipedia wikipedia wikipedia has shown promise as a resource for measuring word similarity # otherefr and wikipedia # refr. [SEP] features based [SEP] features for this", "cit": "in ner, it is common to use gazetteers, but also dictionaries as distant supervision # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we have used the online learning algorithm for parameter estimation. # otherefr for our general framework, and recently, to find hierarchical em [SEP] [SEP]", "cit": "# refr present a spectral algorithm for l - pcfg estimation, but the na?? ve transformation of the l - pcfg model and [SEP]"}
{"pre": "following # refr, we used a variant of the jaccard ( h ) of the tokens in the same corpus. [SEP] ( 2 [SEP] [SEP] [SEP]", "cit": "though simple, the model has been shown to achieve better performance in tasks such as spelling correction # otherefr, and query alteration [SEP]"}
{"pre": "we use a conditional random field # otherefr ; # refr. [SEP] this approach by adding the sequence of namedentity recognition to the np chunk", "cit": "using a parse of the question sentence, we derive a novel set of multi - resolution features suitable for training a conditional random field # otheref [SEP]"}
{"pre": "implementations of sorted feature formalisms such as tdl # otherefr, tfs # refr and others have been used for the development and [SEP] the", "cit": "iconoclast is implemented in profit # refr, so that feature structures are represented by prolog terms and can be unified efficiently through prol [SEP]"}
{"pre": "in recent years, several statistical machine translation ( smt ) models have been proposed for automatic word alignment # refr. [SEP] the assumption of [SEP] a", "cit": "a growing body of machine translation research aims to exploit lexical patterns # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "prior work indicates that three aspects of article quality can be successfully predicted : a ) whether a text meets the acceptable standards for spelling # [SEP]", "cit": "the mpqa # refr and general inquirer # otherefr give lists of positive and negative sentiment words. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in order to obtain a linguistically plausible rightcorner transform representation of incomplete constituents, the switchboard corpus is subjected to a pre - process [SEP]", "cit": "if one uses b ( e, s ) to prioritize edges, we show in # refra ), that the parser is optimal over [SEP]"}
{"pre": "we use langid. py3 # refr, an off - the - shelf langid. py? [SEP]? [SEP]? [SEP]? [SEP]?", "cit": "the language identification tool i used is langid. py # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "brute - force parsing models such as the primordial soup algorithm # refr, at first applied to all, integer linear programming, finite -", "cit": "though experiments have been run with packing feature structures and interleaving syntactic and semantic analyses # refr, or with the intentional underspecification of logical [SEP]"}
{"pre": "iii, 2007 ; # refr ; daume. [SEP], 2008a ) is a model that includes latent variables, and the use of [SEP] features", "cit": "this approach bears some similarity to the adaptation methods standard for the setting where labelled data is available for both domains # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for example, the paradise framework allows the classification of discourse markers to predict both predict both language and their behavior # refr. [SEP] [SEP] [SEP] [SEP]", "cit": "recent advances in dialogue management and multidomain systems enable approaches that are more flexible than slot - filling, e. g. using discourse pegs [SEP]"}
{"pre": "we use the giza + + toolkit # refr to learn word alignments, again in both directions, and apply the grow - diag - final heuristic", "cit": "phrase - based models # refr, lexical translation models # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "a common practice is to resolve the data here is that does not provide a model for learning, but instead some form of a probability model, as", "cit": "this work can also be viewed as part of a trend to perform joint inference across multiple language processing tasks # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in machine translation, the most popular approaches to word alignment have been based on synchronous grammars # otherefr ; # refr. [SEP] the [SEP] [SEP]", "cit": "# refr presented an ambitious maximum likelihood model and em inference algorithm for learning phrasal translation representations. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for instance, the transtype2 system # otherefr uses the language model for p - value of matching n - gram models trained by [SEP]", "cit": "the interactive machine translation paradigm was first explored in the transtype and transtype2 projects # otherefra ; # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "sw made most of her contribution while at nyu. is relevant to finite - state phrase - based models that use no parse trees # other [SEP]", "cit": "however, to what extent that assumption holds is tested only on a small number of language pairs using hand aligned data # otherefr ; # [SEP]"}
{"pre": "we use the giza + + toolkit # refr to learn the phrase - based smt model with a grow - diag - final heuristic. [SEP]", "cit": "its weight is tuned via minimum error rate training ( mert ) # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use an approach that builds on the idea of addressing domain - specific definitions from the internet to find [SEP] retrieval # refr. [SEP] retrieval [SEP] [SEP]", "cit": "in contrast, earlier experimental results we have reported # refr show strong inter - assessor agreement # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "since the space of such lexicalizations, we would also add the context - free grammar, we could not to do not consider non - projective dependency", "cit": "for arabic, which has up to quadriliteral roots ( k = 5 ), the time complexity would be o ( n15 ). [SEP]"}
{"pre": "in addition, we use the conll 2009 shared task on srl, a state - of - the - art srl system [SEP] a [SEP]", "cit": "we tested this hypothesis by combining our outputs, which are the most precise, with the outputs of the system that reported the best recall # refr [SEP]"}
{"pre": "we train the parameters of the averaged perceptron algorithm # refr on the training data of collins and apply the voted perceptron algorithm to sequence labeling", "cit": "to learn the weight parameters? ( r ) and? ( q ), we can approximate the weights using a multiclass perceptron - style [SEP]"}
{"pre": "corresponding manipulations in the form of tree transformations for dependency - based parsers have recently gained more interest # otherefr ; # refr but are [SEP]", "cit": "this can be seen in state - of - the - art constituency - based parsers such as collins # otherefr, # refr [SEP]"}
{"pre": "many nlp systems use web - scale n - gram counts # otherefr ; # refr. [SEP] this corpus for this task. [SEP] [SEP]", "cit": "while previous work has combined web - scale features with other features in specific classification problems # refr ; yang et al, 2005 ; vadas and [SEP]"}
{"pre": "we use brown clusters7 # otherefr using the brown clustering algorithm # refr. [SEP] 50 hashtags and cluster features, but still [SEP]", "cit": "to help address the issue of oov words and lexical variations, we perform clustering to group together words which are distributionally similar # otheref [SEP]"}
{"pre": "hyponymy relations can be used to extract hypernym relations such as hypernymy relations or meronymy # refr. [SEP] [SEP] [SEP]", "cit": "we do not use particular lexicosyntactic patterns, as previous attempts have # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "to extract these keywords, we used a log - linear model implemented by # refr. [SEP] random indexing # otherefr ) to select the words", "cit": "meanwhile, submodular maximization has recently been applied to the text summarization task, and the methods thereof have performed very well # otheref [SEP]"}
{"pre": "whereas a parallel corpus assumes translation equivalence, a comparable corpus is simply a crosslingual pairing of corpora from the same domain # otherefr [SEP]", "cit": "whereas a parallel corpus assumes translation equivalence, a comparable corpus is simply a crosslingual pairing of corpora from the same domain # otherefr [SEP]"}
{"pre": "in the monolingual treebank data we relied on the conll - x and conll - 2007 shared tasks on dependency parsing # otherefr", "cit": "in order to overcome these difficulties, some cross - lingual studies have resorted to heuristics to homogenize treebanks # otherefr [SEP]"}
{"pre": "we used mecab 4 # refr and the finalized parser with svms, and the svms achieved the svms achieved the best reported #", "cit": "svms have been recently applied to several natural language tasks, including text classification # otherefr, chunking # refr, and dependency analysis [SEP]"}
{"pre": "most of the previous work on normalization of social media text focused on word substitution # otherefr ; # refr. [SEP] the problem of automatic [SEP]", "cit": "another possible way of using lattice is to directly feed the lattice to the mt system # refr, but since in this paper, we assume that [SEP]"}
{"pre": "we use two different machine learning algorithms, one for each of these three categories : graph - based approaches # otherefr and label propagation [SEP] [SEP]", "cit": "wikipedia wikipedia has recently been used as a knowledge source for various language processing tasks, including taxonomy construction # otherefr, # refr ). [SEP]"}
{"pre": "nombank annotations # refr, which contain implicit arguments to identify relations that involve implicit arguments. [SEP] arguments. [SEP] arguments. [SEP] the implicit [SEP] [SEP]", "cit": "two recent efforts # otherefr ; # refr are similar to csr in their goal ( i. e., extract meaning ignored by current [SEP]"}
{"pre": "as a result, the important opic of generation of natural anguage generation in which the context of the spoken dialogue systems has been described in [SEP]", "cit": "by doing so, the important topic of generation of natural prosody is not touched upon # otherefr ; # refr ). [SEP] [PAD]"}
{"pre": "we evaluated translation quality using bleu - 4 # refr and meteor # otherefr. [SEP] the former subsection [SEP] the training procedure. [SEP] [SEP]", "cit": "by decompounding training and test data of a machine translation system, we expect an increase in the number of matching phrase table entries, [SEP]"}
{"pre": "in this paper, we show that the parsing algorithm can be applied to all problems, including parsing, and featurerich approaches, that are constrained [SEP]", "cit": "unlike the high complexity lower bounds of the previous two sections, nptime - hardness results for uniform membership have been proved for a number of formalism [SEP]"}
{"pre": "for example, the drama corpus # refr has been used for the computational linguistics community. [SEP]ing, partly because the use of a [SEP] [SEP]", "cit": "we have also investigated how to infer conversational implicatures triggered by comparative utterances # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for evaluating the performance of coreference performance, we employ the muc - 6 # otherefr, and the ceaf metric # refr. [SEP]", "cit": "to score the output of a coreference resolver, we employ four scoring programs, muc # otherefr,? 3 - ceaf [SEP]"}
{"pre": "in english pos tagging, # otherefr applied discriminative parsers to english. # refr presented a generative tagger for natural language processing [SEP] [SEP]", "cit": "most taggers exclusively use language - independent properties? e. g. # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "unsupervised phrasal itgs recently, phrase alignment with itgs # otherefr and parameter estimation with gibbs sampling # refr are popular. [SEP] [SEP]", "cit": "in particular, we employ the nonparametric bayesian phrasal inversion transduction grammar ( itg ) of # refr to perform phrase table extraction. [SEP] [PAD] [PAD]"}
{"pre": "in the second step, the pipeline approach is taken in terms of the pipelined approach, e. g., # refr, [SEP]a [SEP]", "cit": "in recent years, considerable efforts have been made in joint modeling and learning in natural language processing # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the same that in our previous work, we presented in # refr, where the svm - classifiers are used to extract the relations between [SEP]", "cit": "since patterns with a contradiction or entailment relation are often superficially similar, for instance, in case structure or inflection, we use a [SEP]"}
{"pre": "in fact, many approaches have been developed for pos tagging which use several tags for the tasks of morphological analysis # otherefr ; [SEP], [SEP]", "cit": "many approaches for pos tagging have been developed in the past, including rule - based tagging # otherefr, hmm taggers # refr, [SEP]"}
{"pre": "abu - jbara et al # otherefr and # refr developed methods for classifying opinions by considering wikipedia articles. [SEP] the polarity of [SEP]", "cit": "balasubramanyan and # refr proposed a computational method to classify sentiment polarity in blog comments and predict the polarity based on the topics [SEP]"}
{"pre": "we use a support vector machine ( svm ) tool, # refr. [SEP] kernel expansion # otherefr, and a polynomial kernel [SEP] kernel [SEP]", "cit": "statistical systems learn a statistical model or classifiers, such as hmms # otherefr, the svm # refr, and perceptron # other [SEP]"}
{"pre": "these rules may include long - distance dependencies not handled by hmm taggers, and can conveniently be expressed by the replace operator # otherefr [SEP]", "cit": "these rules may include long - distance dependencies not handled by ttmm taggers, and can conveniently be expressed by the replace operator # otheref [SEP]"}
{"pre": "in addition, an efficient inside - outside style algorithm exists, and ( also known as lexical knowledge ) algorithms, and ( mbr [SEP]a [SEP]", "cit": "# refr kanji segmenter. ) on the other hand, modelling only partial words helps the segmenter handle long, infrequent words. [SEP] [PAD]"}
{"pre": "the data was parsed using the charniak parser # refr. [SEP] & k & n - 1 ). [SEP] [SEP] [SEP] [SEP] [SEP] the", "cit": "another important group of related work is on using syntactic dependency features in a vector - space model for measuring word similarity, e. g., [SEP]"}
{"pre": "we use ctb 5. 0 as our main corpus and use ctb as ctb as ctb dataset # refr. [SEP] the segmentation of", "cit": "kruengkrai +? 09 denotes the results of kruengkrai et al # otherefr, which is a lattice [SEP]"}
{"pre": "this model is similar to distant supervision # refr and is also a popular approach that leveraged features that can learn to relational patterns in a relation [SEP]", "cit": "due to these many potential applications, relation extraction has gained much attention in information extraction # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we have recently proposed a mechanism that allows a combination of quasi - synchronous grammars # otherefr ; # refr. [SEP] this work [SEP] [SEP] [SEP]", "cit": "earlier work on sentence simplification relied on handcrafted rules to capture syntactic simplification e. g., to split coordinated and subordinated sentences [SEP]"}
{"pre": "a * parsing, in particular, # refr, has shown that a * parsing # otherefr can benefit from a * parsing, [SEP] [SEP]", "cit": "dyna will soon allow user - defined priority functions # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the majority of previous papers in this area have presented machine learning methods with models being trained on well - formed native english text # otherefr [SEP]", "cit": "unlike previous works # otherefr ; # refr that train a model upon each error type, we use one single model for all error types [SEP]"}
{"pre": "in fact, # refr show that information extraction in the late eighties do not provide a different sequential model. [SEP] effort. [SEP] the online learning", "cit": "we experiment with two of them : uncertainty sampling # otherefr and information density ( id ) # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "larger reservoir sizes lead to better approximation, at higher cost in bits. to provide a streaming extension to the bloom - filter based on bloom - filter", "cit": "levenberg and osborne # otherefr gave a streaming variant of the earlier perfect hashing language model of # refr, which operated in batch [SEP]"}
{"pre": "in nlp, rf classifiers have been used for pos tagging # otherefr ; # refr. [SEP] the likelihood of text [SEP] this [SEP] [SEP]", "cit": "there are several good reviews of algorithms for unsupervised part - of - speech induction # otherefr ; # refr and models of syntactic category acquisition [SEP]"}
{"pre": "to evaluate the performance of inference rules, we use the dataset constructed by # refr. [SEP] the entailment between 10, 000 and [SEP] [SEP] [SEP]", "cit": "these issues have also been noted by sammons et al # otherefr and # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "previous studies focus on identifying speculative sentences # otherefr ; # refr. [SEP] features # otherefr focus on identifying speculative sentences. [SEP] [SEP]", "cit": "ozg? ur and # refr, szarvas et al. # otherefr ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr report minor improvements in the mt systems by integrating two systems into a single system combination. [SEP] a tm based on confusion networks, combined [SEP]", "cit": "mt researchers have recently started to consider diversity in the context of system combination # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "to determine the degree of semantic equivalence, we used the ccg parser and the c & c tools # otherefr, boxer # refr", "cit": "in this paper we present and evaluate a system that transforms texts into logical formulas? using the c & c tools and boxer # refr? [SEP]"}
{"pre": "we used the stanford ner tagger # refr to determine the named entity recognizer # otherefr. [SEP]. [SEP] the tags [SEP] [SEP] [SEP]", "cit": "the results we obtained on the conll03 test set were consistent with what was reported in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr use the cw corpus as the cw corpus, and consists of five simple wikipedia. [SEP] ( simple english ) to extract simplifications ; the", "cit": "simple wikipedia edit histories were mined using techniques similar to those in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the information needed to resolve coordinate np ambiguity cannot be derived from hand - annotated data, and we follow previous work in looking for new information sources [SEP]", "cit": "the dependency model # refra ) compares one - two vs. one - three. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "thus, we extend the state of the art classification task ( i. e., overall sentiment of the document # refr ), [SEP] [SEP] [SEP]", "cit": "bias is linked to the lexical and grammatical cues identified by the literature on subjectivity # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, we also show that the performance of a bilingual wsd system can be applied to the bilingual wsd task # refr, as [SEP]", "cit": "several studies have already shown the validity of using parallel corpora for sense discrimination # otherefr ) and for wsd systems that use a combination [SEP]"}
{"pre": "maltparser # refr is a transition - based parsing system which was one of the top performing systems on multilingual dependency parsing in the conll", "cit": "earlier studies by dubey and keller # otherefr using the negra treebank # refr reports that lexicalization of pcfgs decrease [SEP]"}
{"pre": "in contrast, recent work has shown that exploiting post - editing dictionaries can yield more informative documents, including elicited predicting codeswitched # other [SEP]", "cit": "for example, previous work has often used dictionaries or lexicons # otherefr ; # refr, leading to a partial labeling of the [SEP]"}
{"pre": "there has been extensive work on extraction of subjective content words # otherefr ; # refr. [SEP]ity based methods [SEP] the web by [SEP] [SEP]", "cit": "the third exploits automatic subjectivity analysis in applications such as review classification # otherefr ; # refr ), summarization # otherefr [SEP]"}
{"pre": "several of the state - of - the - art approaches learn a scoring function defined over mention pair, cluster - mention or cluster pair [SEP] features [SEP]", "cit": "second, the global approaches such as structured svms and conditional random fields # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in 2010, we applied the turku event extraction system to detecting events in all 18 million pubmed abstracts, showing its scalability and generalizability into [SEP]", "cit": "for example, stanford # otherefr has relatively low performance for simple events but achieves the highest result for process, while uturku ( [SEP]"}
{"pre": "the disambiguation algorithm makes use of a statistical representation since # refr. [SEP] the algorithm could be applied to perform disambiguation of web page [SEP] [SEP]", "cit": "# refr have proposed a web based clustering technique relying on a feature space combining biographic facts and associated names, whereas bagga and baldwin [SEP]"}
{"pre": "we used the ghkm algorithm # refr to extract all minimal rules. [SEP]. [SEP] the constituent boundaries of all trees. [SEP]. [SEP] a word", "cit": "this is similar to the pcfg feature used in # refr and is intended to encourage the production of syntactically wellformed derivations.? exp [SEP]"}
{"pre": "ensemble learning # otherefr has been used for a variety of machine learning tasks and recently has been applied to dependency parsing in various ways and [SEP]", "cit": "it is known # refr that adding more parsers to an ensemble usually improves accuracy, as long as they add to the diversity ( and almost [SEP]"}
{"pre": "in the generation stage, the quality of a sentence planner is defined by the system of the text planning stage in the rst # refr. [SEP] the", "cit": "a few researchers recognize that this top - down approach to planning is too inflexible and adopt a generate - and - rank architecture instead # [SEP]"}
{"pre": "it has been shown that paraphrase recognition # refr can be used to identify such meaning, for example. [SEP] the sentence [SEP] whether [SEP] the", "cit": "# refr define paraphrase detection as identifying sentences that are in a bidirectional entailment relation. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for instance, measures that compute the association strength between the elements of an expression have been employed to determine the degree of compositionality # otheref [SEP]", "cit": "unfortunately, the construction of these resources is the manual result of human efforts and therefore likely to contain errors of omission and commission # refr. [SEP] [PAD]"}
{"pre": "we use 3500 sentences from conll # otherefr # refr as the pos / chunk data # otherefr. [SEP] ( 1 )", "cit": "generally, when trying to solve a relation extraction task, data sets are tagged using the iob ( inside - outside - beginning ) notation # [SEP]"}
{"pre": "# refr present a compositional method for compositional distributional semantics with their composition by using compositional distributional representations. [SEP] a vector of a vector of a vector of", "cit": "# refr ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we have implemented a modified version of the grammars proposed by # refr. [SEP] a dp - to efficiently estimating pe2 or [SEP] it for synchronous tag", "cit": "in this paper, we explore use of the? hook trick? # otherefr ; # refr to reduce the asymptotic complexity of decoding, [SEP]"}
{"pre": "in a similar vein, # refr formulate the task of inference as a integer linear programming ( ilp ), which has been shown to be [SEP]", "cit": "following # refr integer linear programs have been used broadly in nlp. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in summarization, topic signature words are assigned to be descriptive of the input # refr. [SEP], lin ( 1. [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "many summarization systems # otherefr ; # refr ) include two levels of analysis : the sentence level, where every textual unit is scored [SEP]"}
{"pre": "# refr find that, in the first and computational linguistics work, the authors of that we are aware of are only to take the non - native", "cit": "table 1 : # of books available per genre at gutenberg with download thresholds used to define more successful # otherefr ) and native language [SEP]"}
{"pre": "# refr used a supervised learning approach to predict implicit markert by treating implicit connectives as potential relation. [SEP] the pdtb ) of the pdt", "cit": "in penn discourse treebank # otherefr, the most general senses, i. e., comparison ( comp. ), contingency ( [SEP]"}
{"pre": "we show that for three different nlp tasks, including syntactic parsing, and the well - suited for tagging of spoken dialog systems # [SEP] [SEP] [SEP]", "cit": "most prior work in grammaticality detection in spoken language has focused on specialized detectors ( e. g., # refr, such as mis - [SEP]"}
{"pre": "we present a novel approach to discriminative reranking # otherefr parsing, which uses a discriminative reranker, which is [SEP] because it", "cit": "furthermore, a simple combination of the shift - reduce parsing model with an existing generative parsing model produces results with accuracy that surpasses any that [SEP]"}
{"pre": "transformation - based learning # otherefr, transformation - based learning # refr, and transformation - based learning # otherefr. [SEP] transformation [SEP]", "cit": "transformation - based learning # otherefr, dialogue act tagging # refr, and named entity recognition # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used the mstparser # refra ; mcdonald et al., 2005b ) as the basic dependency parsing model. [SEP]a [SEP] [SEP]", "cit": "in recent years, several dependency parsing algorithms # otherefr ; # refr have been proposed and achieved high parsing accuracies on several treebanks [SEP]"}
{"pre": "in coreference resolution, the weights are assigned to a coreference resolution system # otherefr ; # refr. [SEP]. [SEP] ( 1 )", "cit": "# refr show that bestfirst clustering performs similarly to bell - treebased clustering, but neither of these algorithms 5when applying closest - first and [SEP]"}
{"pre": "reranking has benefited many tagging and parsing tasks # otherefr including semantic role labeling # refr, and in natural language processing # other", "cit": "while reranking has benefited many tagging and parsing tasks # otherefr ; # refr including semantic role labeling # otherefr, [SEP]"}
{"pre": "the penn treebank # refr was used the same test set, but in order to make use of the results presented here. [SEP] the penn [SEP]", "cit": "note that the berkeley parser is trained on the penn treebank # refr yet the hpsg parser is trained on the hpsg treebank ( [SEP]"}
{"pre": "a wide range of contextual information, such as surrounding words # otherefr, dependency or case structure # refr, and dependency path # otheref", "cit": "a wide range of contextual information, such as surrounding words # otherefr ; # refra ), dependency or case structure # otheref [SEP]"}
{"pre": "there have been several attempts to address the unsupervised translators problem # otherefr ; # refr. [SEP] the cross - lingual model [SEP] [SEP]", "cit": "decipherment - based approaches # otherefr ; # refr have generally taken a monolingual view to the problem and combine phrase tables through [SEP]"}
{"pre": "in addition to the standard tree kernel ( li and # refr, we show that it is possible to model the syntactic transformations involved in this manner has", "cit": "current kernels are mostly tree kernels that compare syntactic structure, and use semantic information mostly for smoothing syntactic similarity # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the aligner # refr toolkit. [SEP] alignments, in order to align them in a small number of languages. [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "among these are : phonetic alignment algorithms # otherefr ; # refr, statistical tests for genealogical relatedness # otherefr. [SEP] [PAD]"}
{"pre": "recently, many successful joint models have been proposed, such as joint tokenization and pos tagging # otherefr, joint parsing and machine translation #", "cit": "mstparser1 refers to the first - order 6http : / / sourceforge. net / projects / mstparser / 7 [SEP]"}
{"pre": "recently, several successful joint models have been proposed, such as joint tokenization and pos tagging # otherefr ; # refr. [SEP] [SEP] [SEP]", "cit": "previous phrase alignment work has sacrificed consistency for efficiency, employing greedy hill - climbing algorithms and constraining inference with word alignments # otherefr ; [SEP]"}
{"pre": "for example, various efforts have been devoted to improving decoding efficiency, including hypergraph rescoring # otherefr ; # refr, coarse - to", "cit": "we call our method context - sensitive pruning # otherefr ; # refr which improve parsing efficiency by? closing? chart cells using binary classifiers [SEP]"}
{"pre": "the supertagger was trained on the pos tagger used in an early way, and the pos tagger used by # refr, and the", "cit": "there have been two main robust parsing paradigms : finite state grammar - based approaches # otherefr, and # refr ). [SEP] [PAD] [PAD] [PAD]"}
{"pre": "this morphological disambiguation can be viewed as an instance of a tokenized pcfg, which is a special case of segmentation even for hebrew", "cit": "# refr present a lattice - based modification of the baum - welch algorithm to handle this segmentation ambiguity. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "dual decomposition ( dd ) # refr offers an attractive framework for combining these two types of inference. [SEP]. [SEP]. [SEP] a [SEP] solution to [SEP]", "cit": "dual decomposition # otherefr and lagrangian relaxation in general are often used for solving joint inference problems which are decomposable into individual subproblems [SEP]"}
{"pre": "previous work on coordinations includes # otherefr ; # refr. [SEP] ( 1 ) a related word alignment model, which considers the [SEP] [SEP]", "cit": "in another formulation, the input consists of a raw sentence, and coordination structure is then detected and disambiguated using discriminative learning models # refr or [SEP]"}
{"pre": "in question answering, for example, paraphrase identification has been used explored in the literature # otherefr ; # refr, [SEP] [SEP] [SEP]", "cit": "related methods incorporate measurements of similarity at various levels : lexical # otherefr, and semantic # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "most of the work in sentiment analysis has focused on reviews as positive or negative # otherefr ; # refr. [SEP] the text classification problem [SEP]", "cit": "document polarity classification poses a significant challenge to data - driven methods, resisting traditional text - categorization techniques ( pang, lee, and # [SEP]"}
{"pre": "several studies # otherefr ; # refr have considered cross - lingual information retrieval techniques, such as classification of translation models # otherefr", "cit": "a similar idea exists in machine translation where english is frequently used to pivot between other languages # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr use the same tag set and train a discriminative word clusters using the clusters generated by an model of # otherefr. [SEP] his french", "cit": "another approach to augment the known vocabulary for a generative probabilistic parser is the one pursued in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use an open source software architecture which implements the architecture of active learning # refr. [SEP] filtering of texts. [SEP] the [SEP] natural language processing [SEP]", "cit": "we follow the idea of dualist # otherefr ; # refr which is an interactive method for classification. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "several spoken dialogue systems have been developed # otherefr ; # refr ; however, their goal is to train a spoken dialogue tutoring system [SEP]", "cit": "providing this type of feedback automatically, in natural language, is the goal of tutorial dialogue systems # otherefr ; # refr. [SEP] [PAD] [PAD]"}
{"pre": "there has been a surge of interest in sentiment analysis, including twitter # otherefr ; # refr. [SEP] emotion detection [SEP] [SEP] [SEP] cues in", "cit": "this leads to increasing number of interests on sentiment analysis in microblog data # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "most of the modern statistical machine translation ( smt ) models # refr treat the mapping as a sequence labeling problem. [SEP] training sequence labeling problem.", "cit": "mira # otherefr or l - bfgs # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "lin? s database was created using the dependency parse trees and the dependency parses using the dependency similarity measure introduced by # refr. [SEP] the [SEP]", "cit": "large - scale distributional thesauri created automatically from corpora # otherefr ; # refr are an inexpensive and fast alternative for representing semantic relatedness [SEP]"}
{"pre": "monolingual corpora have been used as an important component for many nlp applications, including machine translation # otherefr, and question answering # refr", "cit": "bilingual paraphrasing techniques use parallel corpora to extract potential paraphrases by grouping english phrases that share the same foreign translations # refr. [SEP] [PAD]"}
{"pre": "it has been observed that compositionality comes with similar methods # refr, and those that use manually annotated corpora. [SEP] the compositionality of [SEP] [SEP]", "cit": "one possibility is to exploit special properties of lexical mwes such as high statistical association of their constituents # refr or syntactic rigidity # otherefr [SEP]"}
{"pre": "figure 1 : a comparison of frames for buy. v defined in propbank and framenet # refr, and information extraction # otherefr [SEP]", "cit": "# refr first classified roles by using four coarse - grained classes ( core roles, adjuncts, continuation arguments and co - referring arguments ) [SEP]"}
{"pre": "in order to obtain ccg derivations for all sentences in the form of a set of hand - crafted rules for the induction of the [SEP]", "cit": "we have recently proposed an algorithm for inducing ccgs # refrb ) that has been shown to be competitive with other approaches even when paired with [SEP]"}
{"pre": "in addition, unlike phonetic transcription schemes, which are often specific to a particular pronunciation prediction # otherefr ; # refr. [SEP] [SEP]", "cit": "numerous studies have contributed to the development of increasingly accurate l2p systems # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the uses of this procedure include information retrieval # otherefr ; # refr, and improving document navigation. [SEP] retrieval # otheref [SEP] [SEP] [SEP]", "cit": "this reduction is achieved by in t ra - sentence segmentat ion, which is distinguished from inter - - sentence s gmentat ion that [SEP]"}
{"pre": "we use a phrase - based translation system similar to giza + + # refr. [SEP] the word class part - of - speech ( pos )", "cit": "in the popular tooklit giza + + # refr, word classes are an essential ingredient to model alignment probabilities with the hmm or ibm translation [SEP]"}
{"pre": "we use the association measures available in the framework of collocation extraction # otherefr : the association measures are based on the v - measure #", "cit": "in these experiments, two association measures which are known to have different behaviours # refr are tested. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in speech recognition, as well as other conversational systems are used for estimating the model parameters of # refr. [SEP] this time each time [SEP] for", "cit": "spoken dialogue systems, especially incremental ones, have come a long way towards reducing lags at turn changes ( e. g. # refr ), [SEP]"}
{"pre": "in this paper we use a pos - tagger # refr. [SEP] a word alignment system that learns reordering of a pos - tagger for", "cit": "the giga corpus received a special preprocessing by removing noisy pairs using an svm classifier as described in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "dependency parsers have been tested on parsing sentences in english # otherefr ; # refr as well as machine translation evaluation metrics. [SEP] the [SEP]", "cit": "although great advances have been made in parsing mrls in recent years, this evaluation challenge remained unsolved. 3 in this paper we present a [SEP]"}
{"pre": "most of the previous work on identifying the translation of two languages using bilingual lexicons has been done for identifying cognates # otherefr ; #", "cit": "rapp made german and english association word vectors and calculated the similarity of these vectors to find translations # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this results in cubic - time decoders for arc - factored and sibling second - order models # otherefr and exact inference in [SEP] tasks", "cit": "this results in cubic - time decoders for arc - factored and sibling second - order models # otherefr and third - order models [SEP]"}
{"pre": "alternative approaches avoid such heuristics, instead learning structured alignment models directly from sentence aligned data # otherefr ; # refr ). [SEP] the inference [SEP]", "cit": "alternative approaches avoid such heuristics, instead learning structured alignment models directly from sentence aligned data ( e. g., # refr ). [SEP] [PAD] [PAD]"}
{"pre": "in addition, several methods have been proposed for automatically extracting paraphrase rules # otherefr ; # refr. [SEP] the same textual [SEP] the", "cit": "it is widely agreed that identifying paraphrases is a core task for natural language processing, including applications like document summarization # otherefr [SEP]"}
{"pre": "in tempeval 2007, 2010 # refr proposed a graph based approach based on different graph models for event extraction. [SEP] time expressions based [SEP] [SEP]", "cit": "on the other hand, significant advances in sentence - level event extraction have been made over the last decade, in particular as the result of standardization [SEP]"}
{"pre": "iii, 2006 ; lin, 2003 ; # refr. [SEP]. [SEP] the whole of the sentences containing around 40 %. [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "importantly, they represent the gist of the entire document and thus often differ substantially from the first n sentences in the article # refr. [SEP] [PAD]"}
{"pre": "the terms? and? are the edge annotation scheme of so - called dependency parsing # refr. [SEP] mcdonald? s # otherefr [SEP].", "cit": "# refr report 83. 57 % with mst. words malt mst a. trees ( bidirectional ) 13, 500 65. 94 67. 76 [SEP]"}
{"pre": "particularly, the latter made team? 09 task people reference faust? 12 - 3c # otherefr umass? 12 - 1 [SEP]", "cit": "this paper presents the umass entry to the bionlp 2011 shared task # refra ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we therefore implemented the morphological features provided by the mate parser # refr. [SEP] dependency parser # otherefr, a german # otherefr [SEP]", "cit": "the parser used in this work is the second order graph based parser # otherefr implementation of # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in dependency treebanks for dependency languages, the czech treebanks are converted to dependency treebanks, mstparser # refr. [SEP]", "cit": "using these weights it is possible to search the space of possible dependency trees using directed maximum spanning tree algorithms # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we have applied nlg systems to the problem of the nlg system # refr. [SEP] it 1 however, although it requires a finite state space", "cit": "the statistically trained fergus # refr contrasts with our rule - based approach. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "significant improvements have been made in the field of language processing in general, and improved learning techniques have been developed to push the state of the art [SEP]", "cit": "in this paper, we present a learning approach to coreference resolution of named entities # otherefr shared task # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "nivre? s parser has been tested for swedish # otherefr, while mcdonald? s parser has been applied to english # refr, czech", "cit": "for example, johansson and nugues # otherefr and # refr are seven ranks higher for turkish than overall, while riedel [SEP]"}
{"pre": "the v - measure ( vm ) # refr is an information theoretic metric that reports the harmonic mean of homogeneity ( each cluster should contain only instances )", "cit": "the it based measures we use are v # refr and nvi # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "incremental processing for syntactic parsers # otherefr ; # refr. [SEP] the model i te / p ( w ) [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "# refr propose an integrated measure of syntactic and semantic surprisal as a model of processing difficulty, and show that the semantic component improves modelling results [SEP]"}
{"pre": "from a parsing perspective, the idea of a robust minimal lexicon can be applied to a shift ( e. g., # refr, [SEP] analysis", "cit": "several efforts have been conducted to achieve this objective ( # refr, for example. ) one major decision to be made in designing this capability is [SEP]"}
{"pre": "recursive neural networks ( rnn ), in contrast with the rnn model of # refr, i. e., make use of compositional operations", "cit": "this move from word to sentence has yielded models applied to tasks such as paraphrase detection # otherefr, sentiment analysis # refr, [SEP]"}
{"pre": "in the pdtb # refr, we presented a new approach for automatically learning relations, with a split - merge discourse relation, which can be used", "cit": "the actual set of markers or connectives is however rather open - ended # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr used support vector machine, svm, svm, and other classifiers for negation. [SEP] kernel methods have been applied to wsj [SEP] [SEP] [SEP]", "cit": "# refr cast the problem as a sequence labeling task and show that performance is highly domain dependent and requires high precision hedge detection in order to perform [SEP]"}
{"pre": "for the training of the perceptron algorithm, we use a variant of the structured perceptron # refr, which has its advantage [SEP] performance, but", "cit": "one of the most popular training algorithms for structured prediction problems in natural language processing is the perceptron # otherefr ; # refr. [SEP] [PAD]"}
{"pre": "the second approach to unsupervised word sense discrimination is based on the output of a word sense in a set of features ( for example, # refr [SEP]", "cit": "the duluth systems in the sense induction task of semeval - 2 # otherefr were based on senseclusters ( v1 [SEP]"}
{"pre": "for example, the penn discourse treebank # otherefr ; # refr in the general framework of syntactic parallelism in the pdtb ) [SEP] a", "cit": "the pdtb builds on the dltag approach to discourse structure # refr in which connectives are discourse - level predicates which project predicate - argument [SEP]"}
{"pre": "to date, evaluations of automatic text simplification have been # otherefr ; # refr, # otherefr. [SEP] the text simplification [SEP] a", "cit": "to date, evaluations of automatic text simplification have been # otherefr ; # refr or using ratings by fluent readers for fluency, simplicity [SEP]"}
{"pre": "in addition, using the original data - driven approach # otherefr ; # refr, we show that our approach can improve unsupervised dependency parsing [SEP]", "cit": "partial bracketing could also be approximated by using html annotation, punctuation and semantical annotation # otherefr ; # refr. [SEP] [PAD] [PAD]"}
{"pre": "we are aware of two methods that have been proposed for building a bilingual lexicon induction from monolingual data # refr and an approach based on translation models", "cit": "again, based on the results reported in the relevant literature # otherefr ; # refr, we opt for the cosine similarity as a standard [SEP]"}
{"pre": "we use the same idea of jiang and zhai # otherefr, # refr, and roark et al # otherefr to calculate", "cit": "the weighted structured perceptron (? 3 ) used in the experiments below was recently used for a different problem, namely for correcting for bias in [SEP]"}
{"pre": "in the recent work of # refr, a system that uses linear chain crfs to find the ambiguous entity recognizers. [SEP] if two entities [SEP]", "cit": "before indexing the text, we process it with textract # otherefr ; # refr, which performs lemmatization, and discovers [SEP]"}
{"pre": "we use the cmu - 4 toolkit # otherefr, a joint model of giza + + # refr implementation of ibm model 4 #", "cit": "figure 1 : chinese - to - english translation using discontinuous phrases. # refr. 2 from the word - to - word alignments, the system [SEP]"}
{"pre": "in addition to these basic approaches, we also report a system for extracting relations from simple lexical patterns # refr. [SEP] if two [SEP] [SEP] [SEP] [SEP]", "cit": "for example, many classic relation extraction systems # refr are based on a single pattern - based extractor ke, which is seeded with a set [SEP]"}
{"pre": "we also tried the semantic textual similarity ( sts ) system with the sense dependent # refr to measure the similarity between two sentences. [SEP] [SEP] [SEP] the", "cit": "we address the sparsity issue pertaining to tweet data by converting our previously proposed topic modelweighted textual matrix factorization ( wtmf ) ( guo and [SEP]"}
{"pre": "for instance, the dependency relations were extracted using the treebanks # refr, which were automatically augmented parses a set of linguistic phenomena using the", "cit": "the second approach takes the universal rules of # refr but rather than estimating a probabilistic model with these rules, a rule based heuristic is used to [SEP]"}
{"pre": "we use the similarity measure described in # refr. [SEP] ( 1 ) = log | : |? |? |? |? |? |", "cit": "judge as being important in a document set # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "with the emergence of the important role of word - to - word relations in parsing # otherefr for english, # refr for swedish, [SEP]", "cit": "with the emergence of the important role of word - to - word relations in parsing # otherefr for swedish, # refr for czech, [SEP]"}
{"pre": "in the next section, we will show how to expand the subjectivity and word senses in web pages. # refra ). [SEP] phenomena [SEP]", "cit": "with these arguments in mind, we decided to choose : ( i ) 15 nouns from the senseval - 3 lexical sample dataset, which have [SEP]"}
{"pre": "the xle system # refr was a probabilistic lfg grammar and lexicalized tree adjoining grammar ( ltag ) lfg parsing [SEP] #", "cit": "we compared the output of the xle system, a deep - grammar - based parsing system using the english lexical - functional grammar previously constructed as [SEP]"}
{"pre": "recent models use linear or svm regression and train them against human judgments to automatic learn feature weights, and have shown state - of - the - [SEP]", "cit": "recent models use linear or svm regression and train them against human judgments to automatic learn feature weights, and have shown state - of - the - [SEP]"}
{"pre": "this has been applied to dependency parsing in many multilingual settings # refr. [SEP] the model is sensitive to parameter [SEP]. [SEP] for this [SEP] [SEP]", "cit": "this has been applied to bootstrapping syntactic parsers # otherefr ; # refr, morphology # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in previous work, intrinsic evaluations of entailment rule extraction # refr are used as a starting point for rule acquisition task # otherefr. [SEP]", "cit": "we implemented a canonized version of dirt ( szpektor and # refr on the reuters corpus parsed by mini [SEP]"}
{"pre": "for example, in the english language, the cambridge system developed by # refr, contains essays, which was the most frequent nouns. [SEP] [SEP]", "cit": "for example, verbs lacking agreement markers are likely to be mistagged as nouns # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in # refr, we show that this model outperforms a state - of - the - art joint model, which outperforms a state - of - the", "cit": "recently, efforts have been made # otherefr ; # refrb ; rahman and ng, 2011c ) to consider models that capture [SEP]"}
{"pre": "we have already discussed our initial work with nltk # refr for natural language ( nlp ) 3. 1 it still falls [SEP] [SEP] [SEP] [SEP]", "cit": "some popular options include the nltk # refr, cslu # otherefr toolkits. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in recent years, the nlp community has successfully applied to document classification # otherefr, and relation extraction # refr. [SEP] [SEP] [SEP] [SEP]", "cit": "some use the stanford parser to parse literature # otherefr, while others use it for processing social media content # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "tinguish the verb classes ~ in exploring these quesuoate the meaning of verbs, we focus on the meaning of verbs, in english and", "cit": "levin is study on diathesis alternations has influenced recent work on word sense disambiguation # otherefr, machine translation # refr, [SEP]"}
{"pre": "to evaluate the generated reg on different attribute selection, we chose a set of attributes as defined in # refr. [SEP] ( 1 ) [SEP] [SEP] [SEP]", "cit": "# refr argue that a less fine - grained cost function might generalize better, and propose to use frequency information to, somewhat ad hoc, [SEP]"}
{"pre": "such systems are quite limited to processing # otherefr, # refr, they require summing up the input for processing. [SEP] analysis [SEP] interpretation.", "cit": "this problem of recombining parts is in general a difficulty that is faced by parsers thai, produce phrasal rather than sentential parses [SEP]"}
{"pre": "erk et al 2010 ; ritter et al 2010 ; se? # refr, and dependency relations # otherefr. [SEP] the predicate - argument", "cit": "they have been successfully used in a variety of nlp tasks including information retrieval # otherefr and selectional preference modeling # refr. [SEP] [PAD]"}
{"pre": "for this task, we use the 2http : / / www. nist. gov / 2http : / / www. bbn.", "cit": "cross document coreference research has recently become more popular due to the increasing interests in the web person search task # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this can be seen as a remarkable shift 1statistical emd approaches have been proved useful for anaphora resolution # otherefr ) or semantic", "cit": "the systems described in # otherefr and # refr are examples of the mixed evaluation strategy. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the oracle decoding algorithm has several other applications : for example suffix ordering # otherefr, # refr, # otherefr. [SEP] [SEP] [SEP]", "cit": "if the input consists of sev - we also adopt the approximation that treats every sentence with its reference as a separate corpus # refr so that ng [SEP]"}
{"pre": "the corpus has been part of speech tagged and lemmatized with stanford part - of - speech tagger # refr, and parsed with malt [SEP]", "cit": "some approaches simply report that a relation exists between two proteins but do not determine which relation holds # otherefr ; # refr, while most [SEP]"}
{"pre": "in our experiment, we used nltk # refr for pos tagging. [SEP]. [SEP]. [SEP] the current implementation of the [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "following # refr and madnani and dorr # otherefr, we implemented the challenges in python, a high - level pro - [SEP]"}
{"pre": "the berkeley framenet project # refr has been developing a lexicon for english - hindi, and has been developed as a mapping of [SEP] phenomena,", "cit": "much more interesting is the use of richer lexical semantic generalisations, such as those employed in framenet # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr used a phrase table extracted from the translation of the phrase table obtained according to the filtering. [SEP] the extracted by filtering. [SEP] the filtering", "cit": "# refr reduced the phrase table based on the significance testing of phrase pair co - occurrence in bilingual corpus. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition to the widely used k - best maximum entropy model, an optimized discriminatively trained models are evaluated by # refr. [SEP] [SEP] [SEP] [SEP]", "cit": "machine translation # otherefr ; # refr ) and information retrieval tasks such as ad hoc retrieval # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the features in # refr. [SEP] the sentence structure of source and target words in the target languages. [SEP] the prefix. [SEP] the [SEP]", "cit": "we will also show how to generalize this word distortion model to a phrase - based model. # refr propose orientation - based distortion models lexicalized [SEP]"}
{"pre": "the underlying formalisms used has been quite broad and include simple formalisms such as itgs # otherefr and # refr, synchronous grammars [SEP]", "cit": "the underlying formalisms used has been quite broad and include simple formalisms such as itgs # otherefr, string to tree models by [SEP]"}
{"pre": "the partial parsers have been developed for treebanks that can be used for other languages, e. g., # refr. [SEP] [SEP]", "cit": "we are constructing the hinoki treebank as part of a larger project in cognitive and computational linguistics ultimately aimed at natural language understanding # refr. [SEP]"}
{"pre": "another line of related work is unsupervised semantic parsing or semantic role labeling # otherefr ; # refr. [SEP] this work learns to learn full semantic", "cit": "another line of related work is unsupervised semantic parsing or semantic role labeling # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, # refr show that for instance, employ a graph - based model to predict the next polarity of each utterance when compared to a human", "cit": "# refr address the related problem of disentanglement ( which we explore in section 5. 3 ), doing inference with the voting greedy [SEP]"}
{"pre": "consequently, substantial effort has been made to learn such rules # otherefr ; # refr. [SEP] this pattern is a [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "options for identifying interesting classes include manually created methods # otherefr ), textual patterns # refr, automated clustering # otherefr. [SEP] [PAD]"}
{"pre": "7work such as # refr, martins et al # otherefr has been exploring more nonlocal features for dependency parsing. [SEP] the [SEP]", "cit": "affinity statistics, such as lexical co - occurrence counts from large corpora, have been used previously for resolving individual attachments at least as far back [SEP]"}
{"pre": "previous approaches to debate stance classification have focused on three debate settings, namely congressional floor debates # otherefr, companyinternal discussions # refr [SEP]", "cit": "owing to space limitations, we refer the reader to # refr for details of the ilp framework. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in recent years several techniques have been developed for relation extraction # otherefr ) and sentiment analysis # refr ). [SEP] the opinion [SEP] texts [SEP]", "cit": "recognizing the subjective character and polarity of words, phrases or sentences has been addressed by many authors, including # otherefr ; # refr. [SEP]"}
{"pre": "hierarchical phrase - based ( hpb ) translation models # refr have been widely adopted in statistical machine translation ( smt ) systems, e. g", "cit": "synchronous context free grammars ( scfgs ) are widely used in statistical machine translation ( smt ), with hierarchical phrase - based translation # refr [SEP]"}
{"pre": "in a joint model, trimming into semantic dependencies are introduced by the conll 2008 shared task # refr. [SEP] the training data [SEP] the [SEP]", "cit": "though the srl of english has been well - studied ( m ` a # refr thanks to the existence of two major hand - crafte [SEP]"}
{"pre": "graph - based dependency parsers parameterize models directly over substructures of the tree, including single arcs # otherefr, sibling or grand", "cit": "2nd - order searches, which consider two siblings at a time, are available with no increase in asymptotic complexity # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "second, obtaining simplified sentences by word deletion is a well - studied issue # otherefr ; # refr. [SEP] the word alignment problem [SEP] [SEP]", "cit": "an unsupervised setup also exists ; methods for the unsupervised problem typically rely on language models and linguistic / discourse constraints # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we also compare two statistical significance of the paired bootstrap resampling method, as described by # refr. [SEP]. [SEP] the exact computation of the [SEP]", "cit": "we measure statistical significance using 95 % confidence intervals computed with paired bootstrap resampling # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "mining comparable sources of data? mining comparable data for parallel data has a long history, including mining comparable sources for named entities # otherefr [SEP]", "cit": "there is too long a literature to really do justice here, but some recent work includes discrimitative lexicons # otherefr, sub - [SEP]"}
{"pre": "a slightly better method is to compile a set of words into a trie and predict boundaries at nodes with high actitivity ( e. g.", "cit": "many publications # otherefr ; # refr, and various other works by the same authors, describe strategies that use frequencies, probabilities, and [SEP]"}
{"pre": "in fact, the state - of - the - art systems on the ace task # refr use the coreference features in order to identify the general", "cit": "information status has been investigated extensively in different genres such as news text, e. g. in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr use biographical information, such as birthdates, birthdates, etc. [SEP], the documents and automatically [SEP] [SEP] [SEP]", "cit": "various features, including entities, biographical information, url, etc., have been introduced to bridge the gap # refr, and external [SEP]"}
{"pre": "# refr reports a pp attachment disambiguation system on prepositional phrase attachment found that the accuracy of a noun alone can be found in a pp", "cit": "as shown by many psycholinguistic and practical studies # otherefr ; # refr, lexical information is one of the main cues to pp [SEP]"}
{"pre": "there has been work that attempts to fill predefined templates using bayesian nonparametrics # otherefr and automatically learns lexicons from a set of attributes such", "cit": "the input is a collection of mentions found by a named entity recognizer, along with their contexts, and, following # refr, the [SEP]"}
{"pre": "we use the giza + + toolkit # refr to train the word alignment models, and use the grow - diag - diag - final - and", "cit": "using a preprocessing scheme for word alignment breaks the process of applying giza + + # refr on some parallel text into three steps : preprocessing, [SEP]"}
{"pre": "the uses of this procedure include information retrieval # otherefr ; # refr, summarization # otherefr. [SEP] text segmentation [SEP] [SEP] [SEP]", "cit": "most of those that achieve text segmentation only rely on the intrinsic characteristics of texts : word distribution, as in # otherefr, # refr [SEP]"}
{"pre": "in previous work, we proposed a cascaded perceptron like # refr called inside - outside estimation, which has been shown to improve the performance of", "cit": "# refr proposed a grammar acquisition method for partially bracketed corpus. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we applied our parallel data from the open - source implementation of the suffix array approach # refr. [SEP] it allows for efficient [SEP] optimal [SEP] optimal [SEP]", "cit": "6although we batch retrain the lms we could use an online lm that incorporates new vocabulary from the input stream as in # refr. [SEP] [PAD]"}
{"pre": "we used the mstparser # refr for english, a sentence parsing system which we trained on the conll - x shared task. [SEP] [SEP]", "cit": "minor errors included an incorrect attachment between two modifiers of the same head, as in the > only > [ grocery store ] [SEP]"}
{"pre": "the first is the crowdsourcing platform that we found that the ability to train a classifier on one hand - labeled data set # otherefr", "cit": "specifically, we use tmcombine. py script provided by moses for the interpolation of trans - 10http : / / www. stat [SEP]"}
{"pre": "the system recognizes the words the customer has said # otherefr ; # refr and processing modules of the dialogue interaction # otherefr. [SEP]", "cit": "there are several spoken dialogue agents and robots that can handle interruptions thanks to their asynchronous control # otherefr ; # refr, they do [SEP]"}
{"pre": "the preposition classifier uses a combined system, building on preposition usage # refr. [SEP] real - world english grammatical mistakes made [SEP] [SEP] [SEP] [SEP]", "cit": "not surprisingly, much published research on grammatical error correction focuses on article and preposition errors # otherefr ; # refr ; dahlmeier and [SEP]"}
{"pre": "the features include : a maximum entropy # otherefr, decision trees # refr, etc. [SEP] the questions [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "there has been some work on producing partial parses for utterances for which a full hpsg analysis is not deemed possible by the grammar # refr [SEP]"}
{"pre": "in this paper we use part - of - speech ( pos ) tagging for noun compounds from a corpus of the semeval lexical sample task #", "cit": "this problem is addressed by riloff and shepherd # otherefr and more recently by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for sentence extraction from training data, kupiec et al # otherefr generated a decision tree, and # refr generated a decision tree generated a", "cit": "# refr and kupiec et al # otherefr used decision tree learning. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "finally, the model of # refr learns to predict the meaning of a noun composition of a noun, verb and a noun - adjective - noun", "cit": "most efforts approach the problem of modelling phrase meaning through vector composition using linear algebraic vector operations # otherefr, matrix or tensor - based approaches [SEP]"}
{"pre": "in contrast to previous work # refr, we have applied this method to named entity recognition ( ner ), dependency analysis, and named entities [SEP] [SEP]", "cit": "# refr choose an annotation interface where annotators have to drag the mouse to select entities. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "it is a natural way to introduce ibm model 1 # otherefr ; # refr. [SEP] the space of word alignment models in itg [SEP]", "cit": "# refr used itg - like dynamic programming to drive both training and alignment for their recursive translation model, but they employed a conditional model that [SEP]"}
{"pre": "in summarization, such words are called signature terms and are thought to be descriptive of the input ; they can be identified using the [SEP] unsupervised techniques", "cit": "interestingly, the interannotator agreement on switchboard ( ) is higher than on the lecture corpus ( 0. 372 ) and higher [SEP]"}
{"pre": "much of this work has used hand written rules and several language pairs have been studied e. g german to english # otherefr, english [SEP]", "cit": "xia and mccord # otherefr ; # refr described approaches applied to languagepairs such as french - english and german - english. [SEP] [PAD]"}
{"pre": "# refr use a similar approach to compute the f - score by r f - score on the f1 measure of 55. 8. 9 [SEP]", "cit": "for better or worse, much of prior work on sentence compression # refr turned to a single corpus developed by knight and marcu # other [SEP]"}
{"pre": "in addition, we plan to use the decision tree system # refr to decide if the connective will be generated by a sentence planner that can identify [SEP]", "cit": "prior work in text generation has focused on cue selection # otherefr ; # refr, or on the relation between * learning research & development [SEP]"}
{"pre": "this scenario is applicable to a large set of languages and has been considered by a number of authors in the past # otherefr ; # [SEP]", "cit": "while this uncertainty can be addressed in several ways, recent works have proposed to combine projected labels with monolingual information in order to filter out invalid [SEP]"}
{"pre": "# refr also investigate the use of language models for speech recognition and machine translation, but they support the plausibility language assessment. [SEP] [SEP] [SEP] [SEP]", "cit": "# refr found that features derived from language models are useful for distinguishing between children with and without a language impairment, both in monolingual english speakers [SEP]"}
{"pre": "language modeling # otherefr, constructing syntactic rules for smt # refr, and finding analogies # otherefr are examples of some [SEP]", "cit": "there also have been prior work on maintaining approximate counts for higher - order language models ( lms ) ( # refr ) operates under the model that [SEP]"}
{"pre": "# refr present a supervised machine learning approach to determine the degree of implicit sentiments. [SEP] citations by a sentiment classifier. [SEP] it on a [SEP]", "cit": "given that most citations are neutral # otherefr ; # refr, this makes it ever more important to recover what explicit sentiment there is from [SEP]"}
{"pre": "in the training phase, pos tagging is generally treated as a word segmentation problem, usually have been studied in the context of chinese word segmentation [SEP] [SEP]", "cit": "the later result is confirmed by many others # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr used a similar method to expand the same set of senses as defined by computing the k ( i ). [SEP] the weights of [SEP] the", "cit": "first, this methodology should be applied to additional wsi models, such as graphbased # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "ing chinese word segmentation alternatives # otherefr, translation # refr, and so on. [SEP]. [SEP] the bi - gram approach # other [SEP]", "cit": "early translation retrieval methods were widely used in example - based and memory - based translation systems # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "as a result, the similarity of jaccard coefficient ( r ) is defined as the log p ( e. g., # refr [SEP] the", "cit": "similarly, mccarthy # otherefr uses skew divergence ( a variant of kl divergence proposed by # refr to compare the sense profile of [SEP]"}
{"pre": "in addition, it is used in smt as an alternative way of using the minimum error rate training # refr. [SEP] ( lattice - [SEP] )", "cit": "in order to integrate multiple word segmentation schemes into the smt decoder, # refr proposed to generate word lattices covering all possible segmentations of the [SEP]"}
{"pre": "we use the stanford part - of - speech tagger # refr to identify the part - of - speech tags, and the stanford tagger [SEP]", "cit": "we utilize the stanford tools # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, the next set of approaches are described in \\ [ # refr \\ ] and the discrimination of different languages. [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "finite - state morphology has been criticized # otherefr, 43 - 66 ) ; ( ii ) for making little or no use of [SEP]"}
{"pre": "like the ones in categorial unification grammar # refr, dependency grammar can be used to parse structures for the sentence # otherefr. [SEP]", "cit": "here, the following are considered in particular as representatives of these three types : word grammar # otherefr ; # refr as an example of [SEP]"}
{"pre": "syntactic category refinement our work also relates to work in syntactic category refinement in which pos categories and parse tree non - terminals are refined in order to [SEP]", "cit": "however, more recent transfer approaches relinquish this data requirement, learning to transfer from non - parallel data # otherefr ; # [SEP]"}
{"pre": "several parsers have been implemented in various grammar formalisms and empirical evaluation has been reported : lfg # otherefrb ; # [SEP] [SEP] [SEP]", "cit": "several parsers have been implemented in various grammar formalisms and empirical evaluation has been reported : lfg # otherefr ; # refr, [SEP]"}
{"pre": "secondly, we generalise the nonparametric bayesian learning framework of adaptor grammars # otherefr. # refr and genetics # otherefr. [SEP] [SEP]", "cit": "established morphological analysers typically ignore this process and simply view the derived stems as elementary units # otherefr, or their account of it coincides [SEP]"}
{"pre": "in particular, abstraction ( qg ) and cf. also be generated by the work of # refr, and has viewed the discussion of the [SEP]", "cit": "the proof builds on # refr construction showing that lfg generation produces contextfree languages. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in chinese word segmentation, the state - of - the - art models # otherefr ; # refr are usually trained on human [SEP] [SEP] [SEP]", "cit": "several discriminative models have been exploited for parameter estimation, including perceptron, crfs, and discriminative latent variable crfs # otherefr ; [SEP]"}
{"pre": "the alignment is produced using emdc, and a posterior distribution over the ibm model 4 # otherefr ; # refr. [SEP] [SEP] [SEP] [SEP]", "cit": "a more recent line of work introduces various forms of regularity terms, often in the form of symmetrization # refr and recently by using l [SEP]"}
{"pre": "charts have been used in information extraction systems as a postprocess for parse selection # otherefr ; # refr. [SEP] ( 1 ) [SEP] [SEP]", "cit": "at present, we are investigating whether any of the current ideas can be used in conjunction with # refr \" interesting corner \" parser. [SEP] [PAD] [PAD]"}
{"pre": "in recent years, a number of statistical models have been proposed that predict syntactic features # otherefr ; # refr. [SEP] this approach is [SEP]", "cit": "conversely, researchers interested in producing richer semantic outputs have concentrated on two - stage systems, where the semantic labelling task is performed on the output of [SEP]"}
{"pre": "several approaches rely on bilingual parallel data # otherefr ; # refr, while others leverage distributional methods on monolingual text corpora # otheref [SEP]", "cit": "# refr proposed to apply multiple - sequence alignment ( msa ) for traditional, sentence - level pr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the part - of - speech tagging uses the ltag conventions proposed in # refr to induce the probabilistic synchronous taggers in the form of the [SEP]", "cit": "we describe how this model has been incorporated into the existing spud lite system # otherefr ; # refr to yield the alignment - [SEP]"}
{"pre": "we use the same dataset as in # refr. [SEP] this algorithm. [SEP] the text t2 appears in comparison of pos tagging, [SEP], [SEP]", "cit": "for example, # refr proposed to induce a manyto - one mapping of state identifiers to pos tags from one half of the corpus and evaluate [SEP]"}
{"pre": "in addition, we plan to use the graph - based ranking algorithm described in # refr. [SEP] this paper in order to perform disambiguate the sense", "cit": "our approach focuses on the strong influence of domain for wsd # otherefr and the benefits of focusing on words salient to the domain # [SEP]"}
{"pre": "in # refr domain templates are not specific in the domain of template generation. [SEP] realisation. [SEP] text ( templates ) [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "however, this method did not look at arbitrary syntactic patterns. # refr improved the paradigm by looking at the most frequent verbs occurring in a corpus [SEP]"}
{"pre": "we thus follow the lead of the relative frequency classes of verb ( noun - verb, noun collocations ) and also verb classes # refr. [SEP]", "cit": "although there exist several manually - created verb lexicons or ontologies, including levin? s verb taxonomy, verbnet, and framenet, automatic [SEP]"}
{"pre": "works on automatic detection of empty categories started to emerge # otherefr ; # refr after substantial progress has been made in statistical syntactic parsing. [SEP]", "cit": "in previous work, ecs are either represented linearly, where ecs are indexed to the following word # refr or attached to nodes in a phrase structure [SEP]"}
{"pre": "recently, # refr proposed to improve the performance of parsing bilingual texts. [SEP] the source language text, the target language without any linguistic analysis. [SEP]", "cit": "recently there have been several studies aiming to improve the performance of parsing bilingual texts # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in our work, we use the cmu nlp tool # refr to perform pos tagging of the texts. [SEP] it still [SEP] it [SEP] [SEP]", "cit": "there has been successful and fruitful effort by researchers in the nlp community to share their experiences and course design through this workshop in the past # [SEP]"}
{"pre": "# refr used syntactic features on the subjectivity lexicon, which contains polar atoms. [SEP] subjectivity lexicons, but found in sentiment, such as", "cit": "inter - sentential contexts as in our approach were used as a clue also for subjectivity analysis # otherefr ; # refr, [SEP]"}
{"pre": "in the work of # refr, different statistical approaches for the disambiguation are taken by training an adroaches. [SEP] dictionary ( [SEP]a )", "cit": "# refr \\ ] analyzed the types of ambiguitystructural and semanticthat make the discovery of proper names in the text difficult. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the approach presented in this paper connects and extends several areas of research : grounded semantics # otherefr ; # refr, dependency trees [SEP] [SEP] [SEP]", "cit": "a recent line of research was dedicated to this task # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in order to make the search tractable, the feature set needs to be restricted to features over single edges ( thereby increased the third - order of a", "cit": "the parsing time is to a large degree determined by the feature extraction, the score calculation and the implementation, cf. also # refr. [SEP] [PAD]"}
{"pre": "the phrase - based approach # refr is based on a straightforward alignment template model. [SEP] the source and target phrases. [SEP] the word sequences of phrases", "cit": "various papers use phrase - based translation systems # refr that have shown to improve translation quality over single - word based translation systems introduced in # other [SEP]"}
{"pre": "recursive neural language models # otherefr ; # refr. [SEP] this approach improves the representation of training material. [SEP] sentences of [SEP] [SEP] [SEP] [SEP]", "cit": "recursive neural networks have achieved state - of - the - art performance in sentiment analysis and parsing # otherefrc ; # refr ; socher [SEP]"}
{"pre": "# refr used a set of features derived from part - of - speech tags to the original part - of - speech tagset, as they also", "cit": "the most successful empirical studies in boundary location have investigated how phrasing can disambiguate potentially syntactically ambiguous utterances in read speech # otherefr [SEP]"}
{"pre": "in addition, open ie systems have been used to obtain a large number of extracted automatically, including news articles # otherefr, and extracted from", "cit": "we implement our approach on both a large open - domain database of facts extracted from the open ie system reverb # refr, and conceptnet [SEP]"}
{"pre": "corresponding manipulations in the form of tree transformations for dependency - based parsers have recently gained more interest # otherefr ; hall and # refr [SEP]", "cit": "corresponding manipulations in the form of tree transformations for dependency - based parsers have recently gained more interest # otherefr ; # refr but are [SEP]"}
{"pre": "to address the second weakness, researchers have investigated the acquisition of entity - mention coreference models ( e. g., # refr, yang [SEP]", "cit": "our system is based on a cluster - ranking model proposed by # refr, with novel semantic features based on recent research on narrative event schema # [SEP]"}
{"pre": "it is important to note that the self - training approach is effective in the parsing process of # refr. [SEP] this training is a self - training", "cit": "# refr presented a very effective method for self - training a two - stage parsing system consisting of a first - stage generative lexicalized parser and [SEP]"}
{"pre": "# refra ) expanded on this idea and conducted a larger scale study to show the viability of regression as a sentence - level mt [SEP] fluency.", "cit": "regarding sentence - level grammaticality, there has been much work on rating the grammaticality of machine translation outputs # otherefr ; # refr [SEP]"}
{"pre": "different techniques to widen the search space have been described # refr. [SEP] the approach of statistical machine translation ( smt ) with a multiple [SEP]", "cit": "by using a loss function based on bleu # otherefr, we avoid the hypothesis alignment problem that is central to standard system combination approaches [SEP]"}
{"pre": "# refr use a multilingual model of crosslingual bilingual dictionaries to learn bilingual lexicons. [SEP] languages. [SEP] linguistically mapping between different", "cit": "# refr use a manually compiled cognate list of dutch, english and german cognates and extract crosslinguistic phoneme correspondences. [SEP] [PAD]"}
{"pre": "to address this problem, we propose an application of tsg model, which is based on the lexicalized tree substitution grammar # otherefr and", "cit": "this result suggests that the conventional tsg model trained from the vanilla treebank is insufficient to resolve model f1 # otherefr 90 [SEP]"}
{"pre": "while inflectional morphology has been well studied in computational linguistics # otherefr ; # refr, inter alia ), the goal is to", "cit": "in the middle of this continuum, we find efforts to learn complete paradigms using fully supervised methods relying on completely annotated data points with rich morphological information [SEP]"}
{"pre": "a profit / hpsg framework using the cshd algorithm is described by # refr. [SEP] the information of the feature structures defined in this paper.", "cit": "profit : prolog with features, inheritance and templates # refr is an extension of prolog which supports inheritance - based typed feature structures. [SEP] [PAD]"}
{"pre": "there have been several studies in this field, # otherefr ; # refr. [SEP] emotion classification # otherefr proposed a semisupervised learning", "cit": "a similar emotion corpus in chinese is yahoo!? s chinese news ( http : / / tw. news. yahoo. [SEP]"}
{"pre": "for instance, measures that compute the association strength between the elements of an expression have been employed to determine the degree of compositionality # otheref [SEP]", "cit": "in contrast, alegria et al # otherefr and # refr adopted a compositional approach to the encoding of mwes, able to [SEP]"}
{"pre": "as an extension, maximum entropy model, we use the conditional markov model, which is conditional probabilities, and the pos taggers # refr. [SEP]", "cit": "as an example, maximum entropy taggers have achieved very good performance # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the second dataset ( section 4. 1 ) consists of about 1, 000 documents from the semeval - 2007 dataset 2, we [SEP] the", "cit": "other distributional methods include the use of a word - category cooccurrence matrix, where categories are coarse senses obtained from an existing thesaurus # [SEP]"}
{"pre": "we use the mcmc procedure here since this has been successfully applied to word segmentation problems in previous work # refr. [SEP]ing word segmentation models in", "cit": "although the confidence intervals overlap slightly, the em system also outperforms the pipeline on the other f - measures ; altogether, these results suggest at least [SEP]"}
{"pre": "in contrast, other recent systems have explored the relationship between linguistic knowledge bases, rather than deriving sentential paraphrases, including techniques that are [SEP]", "cit": "a different approach, based on statistical techniques was proposed in # otherefr. # refr presents a method of extracting answers as noun phrases in [SEP]"}
{"pre": "we use the open - source toolkit jane # refr to train and test the model on the development set, giza + + [SEP] [SEP] [SEP] [SEP]", "cit": "to train the feature weights, we made use of a novel two - phase training algorithm that incorporates a probabilistic training objective and standard minimum error training [SEP]"}
{"pre": "we build syntactic rules that include the syntax - based translation results # otherefr ; # refr and the other models # otherefr. [SEP]", "cit": "when comparing our approach to syntax - based translation systems # otherefr ; # refr we note that both approaches use syntactic information for reordering [SEP]"}
{"pre": "in a different experiment, # refr use a machine learning algorithm to evaluate the quality of the rankings. [SEP] intrinsic evaluations. [SEP] the results of the", "cit": "recently, # refr applied the? heterogeneity principle? and combined rouge scores to improve the precision relative to a human evaluation metric. [SEP] [PAD] [PAD]"}
{"pre": "in this paper we show how this system can be naturally cast as a representation of unification - based formalisms, as well as proposals for [SEP]", "cit": "we have employed them in exploring the language - theoretic complexity of theories in gb # otherefra ) and have used these model - theoretic interpretations [SEP]"}
{"pre": "there has been research on non - english # otherefr ; # refr showing that it can be useful to automatically induce effective models of preproc", "cit": "although there has been significant research directed toward audio indexing and retrieval # refr, lecture transcription and analysis is a relatively unexplored area in speech and [SEP]"}
{"pre": "in addition, the twitter - based sentiment analysis challenge # refr has demonstrated promising results in recent years, but it has not shown that the amount of", "cit": "the advent of online social networks has produced a crescent interest on the task of sentiment analysis for short text messages # otherefr ; # [SEP]"}
{"pre": "recently, algorithms have been applied to the identification of sets of semantic relations # otherefr ; # refr, but this has allowed some [SEP] [SEP]", "cit": "this includes learning from question - answer pairs # otherefr ; # refr, from conversational logs # otherefrb ). [SEP] [PAD] [PAD]"}
{"pre": "in contrast, lexas uses supervised learning from tagged sentences, which is also the approach taken by most recent work on wsd, including # [SEP]", "cit": "# refr ; but it is not reasonable in language modeling to expect raining data tagged with correct probabilities. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the ghkm minimal recursion rule extraction # refr. [SEP]. [SEP]. [SEP] ( x, h, m ) = ( x, e", "cit": "hiero # otherefr represents a more restricted form of scfg, while ghkm # refr uses a general form of scfg. [SEP]"}
{"pre": "we tuned the feature set by using the batch lattice - based minimum - error - rate training package # refr. [SEP]. [SEP] the [SEP] model of", "cit": "5mr approaches that use lattices # otherefr or the complete search space # refr exist, but are not tested here. k - best [SEP]"}
{"pre": "so far, cross - lingual textual entailment # otherefr, and ii ) machine translation evaluation datasets # refrb ). [SEP] textual", "cit": "the clte methods proposed so far adopt either a? pivoting approach? # otherefr ), or an? integrated solution? that [SEP]"}
{"pre": "for example, the difficulty of resolving the internal structure of noun - noun compounds and strings of prepositional phrases has been the focus of ongoing [SEP]", "cit": "log - likelihood has been shown to perform well when comparing counts of potentially lowfrequency features # refr such as found in zipfian - distributed [SEP]"}
{"pre": "in # refr, we proposed a model based on the character sequences ) and train a discriminatively trained model on the genia corpus of yang and", "cit": "they can often achieve high accuracy provided that a large annotated training set similar to the test data is available # otherefr ; # refr. [SEP]"}
{"pre": "figure 1 : architecture of smt system architecture. tm systems described in # otherefr ; # refr. [SEP] ( news ) [SEP] [SEP] [SEP]", "cit": "inside the moses toolkit, three different statistical approaches have been implemented : phrase based statistical machine translation # otherefr and syntax - based statistical [SEP]"}
{"pre": "to obtain this, we trained the treebank from the redwoods treebank of english in the bnc treebank, and use the red", "cit": "this situation is illustrated by the following two ( out of many ) sentences from the rondane treebank, which is distributed with the english [SEP]"}
{"pre": "ibm model 1 has been shown to be an approximate inference framework # refr, as well as a model that is the case for the most frequent sense", "cit": "we chose this statistic because it has previously been found to be effective for automatically constructing translation lexicons # otherefr ; # refr. [SEP] [PAD]"}
{"pre": "in # refr, sentiment analysis is carried out by applying this technique to the entire document. [SEP] cut technique is inspired by the polarity classification approach.", "cit": "examples for a balanced data set are the movie review data set # refr or the imdb review data set # otherefr. [SEP] [PAD] [PAD]"}
{"pre": "this corpus contains documents from the english side of the corpus, and the experiments described by # refr. [SEP] the british national corpus [SEP] [SEP] [SEP] [SEP]", "cit": "however, evaluation of topic models is a subject of considerable debate # otherefr ; # refr and it may be informative to investigate the effects [SEP]"}
{"pre": "note that it is straightforward to calculate these expected counts using a variant of the semi - supervised structured perceptron # otherefr ; # refr,", "cit": "parser uas las # otherefr? 93. 5 # refr? 93. 79 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "examples include minimum risk # otherefr ; # refr, and variations of the margin - infused relaxation algorithm ( mira ). [SEP] ( [SEP]", "cit": "this relatively simple approach to translation can be remarkably effective, and, since its introduction, it has been the basis for further innovations, including developing [SEP]"}
{"pre": "in this paper we use the incremental parsing strategy of # refr. [SEP] utterances ( 2 ) for example. [SEP] the incremental hypothesis space of dialogue [SEP]", "cit": "considering the current level of speech recognition technology, system - initiative dialogue systems, which prohibit users from speaking unrestrictedly, are preferred # refr [SEP]"}
{"pre": "representative publications include # otherefr ; # refr ; girju, 2007 ; o. [SEP]. [SEP] the compound nouns [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "even for relatively frequent ncs that occur ten or more times in the bnc, static english dictionaries give only 27 % coverage # refr. [SEP]"}
{"pre": "most often, such pairs are extracted from small bilingual lexicons # otherefr ; # refr. [SEP] the crosslingual glosses [SEP] [SEP]", "cit": "due to their low cost of acquisition, several researchers have tried to exploit such comparable corpora for bilingual lexicon extraction # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the only work that we are aware of is the focus of study on learning affixes from a corpus by # refr. [SEP] a [SEP] (", "cit": "even approaches which take context into consideration # otherefr ; # refr cannot learn specifically for one or the other. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the feature weights? i are tuned on the dev set by optimizing bleu # otherefr on the dev2009 development set ( 3 )", "cit": "in our setup, we use minimum error - rate training ( mert, # refr ) to optimize weights of model components. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "in the case of english, # refr propose a method for disambiguating the attachment of disambiguating the words in disambiguate sentence. [SEP] it.", "cit": "thus, an important number of unsupervised # otherefr, and combined # refr methods have been developed to this end. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "researchers have studied the problem at the document level # otherefr ; # refr, and attribute level # otherefr. [SEP] [SEP] [SEP] features", "cit": "researchers have studied the problem at the document level # otherefr ; # refr, and attribute level # otherefr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "in this paper, we describe the methodology proposed by # refr for recognizing textual entailment that is designed for a general entailment of entailment,", "cit": "this new task first opened the doors for assessing the role of discourse # refra ; mirkin et al2010b ) in rte [SEP]"}
{"pre": "we use a system of yamada and knight # otherefr to train a model from the brown corpus, and which uses a modified version", "cit": "the performance of a syntactic parser trained only on the wall street journal ( wsj ) can degrade dramatically in new domains due to corpus variation # [SEP]"}
{"pre": "we use the ppdb corpus # refr, which contains 385 manually annotated examples, 000 pos tags. [SEP]. [SEP], 000 pos tags,", "cit": "for example, it can significantly reduce structural ambiguities in parsing # otherefr, help in word sense disambiguation or improve information extraction # [SEP]"}
{"pre": "for example, # refr used a distributional thesaurus ( dt ), which was shown to be effective in comparison by many [SEP] the [SEP] the", "cit": "accurately estimating the semantic distance between words in context has applications for machine translation, information retrieval # otherefr, and it is becoming clear that [SEP]"}
{"pre": "previous work in natural language generation that models natural language generation with natural language generation # otherefr ; # refr. [SEP] this work was done [SEP]", "cit": "earlier, we reported a proof - of - concept work using a hand - coded rule - based user simulation # refrc ). [SEP] [PAD] [PAD]"}
{"pre": "in another study, the influence of initiative inthis is done on the performance of the dialogues in the statistical dialogues # refr. [SEP]a", "cit": "the initiative was used to analyse behaviour of anaphoric expressions in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, the machine learning method presented here has been applied to a wide variety of nlp tasks, including named entity recognition, sentence boundary detection", "cit": "two other lexical resources, wordnet # otherefr and nomlex # refr, are used to identify words which can directly be used as [SEP]"}
{"pre": "the value of human annotated syntactic structures for statistical machine translation has been clearly demonstrated in string - to - tree # otherefr ; # refr [SEP]", "cit": "by contrast, the ghkm approach to translation # refr relies on a syntactic parse on either the source or target language side to guide scfg [SEP]"}
{"pre": "in this work, we opt for a very simple yet accurate method # refr which is still comparative analysis ofationand word - sense disambiguation [SEP]", "cit": "compositional distributional semantic systems are often evaluated on phrase and sentence paraphrasing data sets # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "previous methods for content selection include reinforcement learning # otherefr ; integer linear programming # refr, and the number of classifiers # otherefr.", "cit": "previous methods for content selection include reinforcement learning # otherefr ; multi - objective optimisation # refr ; gricean maxims # otheref [SEP]"}
{"pre": "in the experiments presented in # refr, we applied the brown corpus to pos tagging, and parsed with a modified version of the corpus [SEP] [SEP]", "cit": "# refr and merialdo # otherefr demonstrated that baum - welch does not necessarily improve the performance of an hmm part - of [SEP]"}
{"pre": "in addition, we plan to incorporate the seed contextual patterns as seeds, and consider the verb polarity values ( e. g., # [SEP] [SEP]", "cit": "most approaches to domainspecific sentiment lexicon acquisition start from a manually compiled set of aspects and opinion clues and then expand it with words satisfying certain co [SEP]"}
{"pre": "the second set of experiments used training and testing sets from the first and second international chinese word segmentation bakeoffs # otherefr ; # refr", "cit": "research in chinese word segmentation has progressed tremendously in recent years, with state of the art performing at around 97 % in precision and recall # [SEP]"}
{"pre": "in a second approach # otherefr, # refr, the important is to distinguish the unnatural ( i. e., a feature representation", "cit": "to avoid the generation of redundant descriptions what incremental approaches typically do, # refr and horacek # otherefr proposed exhaustive resp. best [SEP]"}
{"pre": "thus, we can find some similarity to the traditional expansion methods, e. g. # otherefr ; # refr, but they still have", "cit": "there has been a large and diverse body of research in opinion mining, with most research at the text # otherefr ; # refr level [SEP]"}
{"pre": "consequently, substantial effort has been made to learn such rules # otherefr ; # refr. [SEP] ( 1 ) a wsj ) a ws", "cit": "finally, we note that learning entailment graphs bears strong similarities to related tasks such as taxonomy induction # otherefr and ontology induction # refr [SEP]"}
{"pre": "for instance, the main problem in the field of natural language processing, # refr suggest that some real - world knowledge are only in [SEP] [SEP] [SEP]", "cit": "earlier papers have focused on the probabilistic aspects of the system \\ [ # refr ; de marcken, 1990 \\ ] ; here we focus on [SEP]"}
{"pre": "in order to create paraphrases, we use the recursive neural network ( rnn ), which has been shown to be simpler than [SEP] [SEP]", "cit": "for example, much work has shown the usefulness of syntactic representations for subsequent tasks such as relation extraction, semantic role labeling # otherefr and [SEP]"}
{"pre": "in addition, we use the senseclusters program # refr and the sense of a word? s lattice # otherefr to perform both [SEP]", "cit": "amruta purandare incorporated nsp into senseclusters # refr and added huge - count. pl, combig. pl and ko [SEP]"}
{"pre": "local models of coherence have been extensively studied within the entity - based local coherence of text # refr. [SEP] the entity - based local coherence model to", "cit": "we present a model for discourse coherence which combines the local entitybased approach of # refr and the hmm - based content model of # otheref [SEP]"}
{"pre": "the parser is trained with the model6 grammar # otherefr, and parsing models being trained on data structure # refr. [SEP] [SEP] [SEP] [SEP]", "cit": "the model is equivalent to previous hhmm parsers # refr, but reorganized into 5 cases to clarify the right - corner structure of the [SEP]"}
{"pre": "we use a dependency grammar # otherefr ; # refr to parse the input sentence. [SEP] a post - processing step, [SEP] [SEP] [SEP] [SEP]", "cit": "the first constraint potentially simplifies dependency parsing, and non - projective dependencies are relatively well understood in the dependency parsing community # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "hall and # refr investigate how to use mstparser and nivre # otherefr apply this technique to transition - based dependency parsing. [SEP]", "cit": "several approaches have been taken to address this problem, including : post - processing repairs # otherefr ; hall and # refr closely related [SEP]"}
{"pre": "we also compare two decoding algorithms : the cube pruning ( cube pruning ) algorithm # refr and the hypergraph rescoring # otherefr. [SEP]", "cit": "mrl 5the beam search decoder in phrase - based system # refr 2 - tuple ( gspan, ghyps ), where gh [SEP]"}
{"pre": "it has been observed that the use of lexical information is well - formed parsing ( e. g., # refr. [SEP] lexicalized parsing [SEP]", "cit": "further studies conducted by # refra ) proved indeed that bilexical information were used by the most probable parses. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we evaluate precision in recall and precision, recall # otherefr and precision, and precision, and recall ( f - measure ) # refr )", "cit": "since most top systems in key phrase extraction use supervised approaches, we follow the same method # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "recently, # refr found that ter improved mt evaluation metric ( terp ) was augmented with an alignment metric. [SEP] the comparison of [SEP] the [SEP]", "cit": "3this algorithm is not equivalent to an incremental ter - plus # refr due to different shift constraints and the lack of paraphrase matching 30 [SEP]"}
{"pre": "we use the stanford parser # refrb ), and a modified version of the stanford parser # otherefr. [SEP] the syntactic / [SEP] [SEP]", "cit": "we parse input sentences to phrase structure trees using the stanford parser # refr, a statistical syntactic parser trained on the penn treebank. [SEP] [PAD] [PAD]"}
{"pre": "the transtype and transtype2 projects # otherefr ; # refr, though they did not meet the reordering component for machine translation (", "cit": "many research translation uis have been proposed including transtype # refr, caitra # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this result suggests that the decoder performs well in our experiments, the area of cube pruning # otherefr ; # refr, which incorporates [SEP] the", "cit": "they can represent both finite - state and context - free weighted sets and they have been widely used in smt # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "historically, there have been two main approaches to model language model state ( slms ) : ( 1 ) = log - linear ( n ) log", "cit": "structured language models # otherefr ; # refr were proposed for these purposes. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we evaluate our system on the commonly used in coreference resolution task # otherefr and the recent extension of the muc - 6 # refr [SEP]", "cit": "ceaf # refr scores are obtained by computing the best one - to - one mapping between the system / true partitions, which is equivalent to [SEP]"}
{"pre": "previous work has noted that distinguished relations, such as freebase # otherefr and information extraction # refr. [SEP] ( open ) [SEP] [SEP] [SEP]", "cit": "open ie systems, which perform selfsupervised learning of relation - independent extractors # otherefr ; # refr and woe # otheref [SEP]"}
{"pre": "we use semeval? 07 web pager # refr and semeval? 4 # otherefr to cluster the target word [SEP] [SEP]", "cit": "of contexts using both co? occurrence matrices # refr and latent semantic analysis # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the idea of employing n - gram co - occurrence statistics to score the output of a computer system that is trained on one predicate # otherefr", "cit": "statistical parsers are major components in nlp applications such as qa # otherefr and srl # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the only previous work we are aware of that is # refr, who compare the cascade of chunking with five best systems. [SEP] this [SEP] [SEP]", "cit": "our unsupervised chunkers extend straightforwardly to a cascade that predicts higher levels of constituent structure, similar to the supervised approach of # refr. [SEP] [PAD]"}
{"pre": "carpuat and wu # otherefr integrated into a hierarchical phrase - based system # refr with a hiero # otherefr into a", "cit": "moreover, throughout this paper we use the hierarchical phrase - based translation system ( hiero ), which is based on a synchronous contextfree grammar [SEP]"}
{"pre": "besides the mention - pair model, two other commonly used models are the entity - mention model # refr and ranking models # otherefr. [SEP]", "cit": "in recent years, markov logic has been widely used in natural language processing problems # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in statistical machine translation, a parallel corpus of 107 algorithms have been proposed for automatic semantic nlg # otherefr ; # refr. [SEP] [SEP]", "cit": "some state - of - the - art proposals use a rule - based module to handle the projection between non - isomorphic semantic and syntactic structures / [SEP]"}
{"pre": "however, such approaches have been found to be successful in part of speech tagging # otherefr ; # refrb ), and distributional models #", "cit": "# refr ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr used classifiers to predict the bias of a large number of bias, bias, bias, and bias, and bias, and bias, and", "cit": "bias is linked to the lexical and grammatical cues identified by the literature on subjectivity # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in later years, there has been more interest in problems such as sentence boundary detection # otherefr ; # refr and sentence boundary detection [SEP] #", "cit": "the different steps are described below : preprocessdata : we start by preprocessing all the news in the news collections with a standard nlp [SEP]"}
{"pre": "this means that little or no parallel data is available in a relatively new task ( but typically applied to a few and # refr. [SEP] the [SEP]", "cit": "active learning has been applied to several nlp tasks like part - of - speech tagging # otherefr or statistical machine translation # refr, [SEP]"}
{"pre": "in this paper, we show that the general framework of using synchronous tree - adjoining grammars # otherefr for stags [SEP] [SEP] [SEP]", "cit": "similarly, recent research is beginning to unify synchronous grammar formalisms and tree transducers # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "graph - based methods have been employed in multi - document summarization # refr, and as well as multi - document summarization # otherefr", "cit": "in centroid - based summarization # refr, the sentences that contain more words from the centroid of the cluster are considered as central. [SEP] [PAD] [PAD]"}
{"pre": "while such data contains noise, it has been shown to be useful in practice # refr. [SEP] features for relation extraction. [SEP] training a [SEP] kernel", "cit": "hence, we have explored the use of an automatic knowledge base population technique based on distant supervision # otherefr ; # refr. [SEP] [PAD] [PAD]"}
{"pre": "unsupervised training methods have also been proposed in the past for related problems in decipherment # otherefr ; # refra ) where the [SEP]", "cit": "the mt literature does cover some prior work on extracting or augmenting partial lexicons using non - parallel corpora # otherefr ; # refr [SEP]"}
{"pre": "# refr present an unsupervised morphological analyzers that pick out - of - words,. [SEP] research in morphological disambiguation, [SEP] applying the semi [SEP]", "cit": "often the limiting assumption is made that words consist of only one stem followed by one # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "algorithmic connections in addition to handcurated connections across languages, one could also consider automatic means of mapping across languages, such as using edit distance [SEP]", "cit": "first, it throws away information important to sentiment analysis like syntactic constructions # refr and document structure # otherefr that may impact the sentiment [SEP]"}
{"pre": "in the second evaluation task, the output of word sense disambiguation was semeval - 2007 # refr. [SEP] the [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "our proposal is related somehow with the investigations presented in # otherefr and # refr, where words are also expanded with co - ocur [SEP]"}
{"pre": "qaciad ( question answering ) builds on the question answering challenge for qa systems # refr. [SEP] the [SEP] retrieval integration of qa [SEP] [SEP] [SEP]", "cit": "answering factoid questions ( i. e., questions like? what is the capital of france?? ) using web makes use of the [SEP]"}
{"pre": "figure 1 shows how to adapt a sentence generator can well an answer type from a database ; e. g., d & c., d", "cit": "see knott et al # otherefr and # refr for more information on these aspects of ilex. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the majority of the state - of - the - art constituent parsers are based on generative pcfg learning, with its effectiveness and evaluate the joint", "cit": "syntactic features : we obtain the syntactic parsing tree using the berkeley parser # refr, then obtain the following features : ( 1 ) the last sentence [SEP]"}
{"pre": "for example, # refr use syntactic analysis to find semantic role labels in a tree - to - role labeling problem. [SEP] text. [SEP] the [SEP]", "cit": "semantic role labeling ( srl ) has sparked much interest in nlp # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the open ie system # refr which uses a set of dependency features extracted by a sentence, associating each of the source entity tag for", "cit": "although there are well - established methods for automatically training extractors from annotated data # refr, recent years have seen a renewed interest in manually [SEP]"}
{"pre": "most relation extraction systems # otherefr ; # refr focus on relations between named entities ; such approaches miss the previous work [SEP] ( ne ) [SEP]", "cit": "some existing studies use corpus - based statistics for relation extraction # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the past, subsections of the rasp # refr was parsed using a lexical resource trained on negra # otherefr. [SEP] [SEP]", "cit": "in the past, the problem of sentence level discourse segmentation has been tackled using both symbolic methods # otherefr as well as statistical models [SEP]"}
{"pre": "in particular, we use a neural network # refr and a simple perceptron algorithm # otherefr to train a vectors from wikipedia [SEP] [SEP] [SEP]", "cit": "a long line of embeddings work, such as lsa and randomized embeddings # refr, has recently turned to neural language models # otherefr [SEP]"}
{"pre": "we used the stanford parser to get dependency parses of the penn treebank test data # otherefr, as well as for [SEP] tasks [SEP]", "cit": "probabilistic parsers trained over labeled data have high accuracy on indomain data : lexicalized parsers get an f - score of up to [SEP]"}
{"pre": "automatic paraphrasing has been recognized as an important component for nlp systems, and many methods have been proposed to acquire paraphrase knowledge [SEP]", "cit": "automatic paraphrasing has been recognized as an important component for nlp systems, and many methods have been proposed to acquire paraphrase knowledge [SEP]"}
{"pre": "in this paper, we use an mt evaluation metric, bleu # refr, ter # otherefr to measure the translation performance. [SEP] [SEP]", "cit": "the core technology of the proposed method, i. e., the automatic evaluation of translations, was developed in research aiming at the efficient development [SEP]"}
{"pre": "in addition, an efficient tree - valued features should be applied to the problem of tsg ( r igt ), [SEP] a [SEP] [SEP] [SEP]", "cit": "the rondane treebank is a? redwoods style? treebank # refr containing mrs - based underspecified representations for sentences [SEP]"}
{"pre": "in addition, since german is a highly inflected language, it is not clear whether they constitute a word or not ( pos [SEP] ( pos [SEP]", "cit": "# refr discussed treatment of hyphened compounds in translation into german by splitting at hyphens and treat the hyphen as a separate token, [SEP]"}
{"pre": "# refr proposed an unsupervised method that identifies key significant blocks in tweets by using an event or event. [SEP] paired with particular target event. [SEP] it", "cit": "although there is much recent work focusing on the task of multi - tweet summarization # otherefr ; # refr, most previous work [SEP]"}
{"pre": "in this work, we generalize the intuition of # refr and that the classical algorithm is known as cky, pruning algorithm or it is an inex", "cit": "the forest itself has an oracle of 98. 15 ( as if k?? ), computed a ` la # refr, sec. [SEP] [PAD]"}
{"pre": "perhaps the most closely related work learns to understand instructions and automatically complete the tasks they describe # otherefr ; # refr. [SEP] this [SEP] [SEP]", "cit": "perhaps the most closely related work learns to understand instructions and automatically complete the tasks they describe # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "although the distributional similarity between words was well understood in two languages, it is often assumed that a meaning representation of the input concepts [SEP] [SEP] the [SEP]", "cit": "# refr, in developing a methodology for evaluating the quality of thesauri, defined a word vector space that moved beyond simple co - occurrence [SEP]"}
{"pre": "one way to do this is to apply the algorithm to the set of # refr. [SEP] ( i. e., [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "text simplification has been associated with techniques that deal not only with helping readers with reading disabilities, but also to help nlp systems # refr. [SEP]"}
{"pre": "semi - supervised and weaklysupervised techniques have also been explored for other types of semantic types # otherefr ; # refr. [SEP] and [SEP] it", "cit": "semi - supervised and weakly - supervised techniques have also been explored for other types of semantic representations but these studies have mostly focused on restricted domains # [SEP]"}
{"pre": "joint methods have also been proposed that invoke integer linear programming ( ilp ) formulations to find the best hypothesis # refr. [SEP] a global maximum [SEP]", "cit": "joint methods have also been proposed that invoke integer linear programming ( ilp ) formulations to simultaneously consider multiple structural inference problems? both over n - [SEP]"}
{"pre": "the proposed task is a general framework for the purpose of nc interpretation, where a relation is modeled as a similarity measure # otherefr ; #", "cit": "the proposed task is a generalisation of the more conventional task of interpreting noun compounds # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "over the past decade, there has been tremendous progress on learning parsing models from treebank data # otherefr ; # refr. [SEP] the problem", "cit": "in fact, it was found in # refr that the removal of bi - lexical statistics from a state of the art pcfg parser resulted in [SEP]"}
{"pre": "in addition to the mt - based method, researchers have also investigated other methods for paraphrase generation, such as the pattern - based methods [SEP]", "cit": "to overcome the data sparseness problem, # refra ) improved the mt - based pg method by training the paraphrase model using multiple [SEP]"}
{"pre": "in the past, only recently has started to investigate this task, but recently showed that the use of the conditional random fields ( crfs ) [SEP]", "cit": "this is in line with the findings of # refr, who reports no benefit from manually corrected or unsupervised pos tags for a range of unsupervised parser [SEP]"}
{"pre": "we used 14 datasets with only the nlp community on the conll - x shared task # refr. [SEP] this format. [SEP] [SEP] [SEP] [SEP]", "cit": "we represent the data into a columns format, following the standard format of the conll shared task 2006 # refr, in which sentences are separated [SEP]"}
{"pre": "in japanese morphological analysis, the dictionary - based approach has been widely used in japanese morphological analysis # otherefr ; # refr. [SEP] ( [SEP]", "cit": "because all methods return a ranked list of translation candidates, the accuracy is measured using the rank of the translation listed in the goldstandard. 16 [SEP]"}
{"pre": "identification, though an important problem, can be tackled with heuristics # refr or, potentially, by using a supervised classifier trained on a large amount", "cit": "# refr address the role induction problem and propose a directed graphical model which relates a verb, its semantic roles, and their possible syntactic realizations. [SEP]"}
{"pre": "in a system, # refr presents an approach that allows noun phrases in a natural language manner, and perform both analysis. [SEP] ( 5 ) and", "cit": "schubert and peiletier # otherefr have also sought to simplify the semantic output of a gpsg to a more ~ conventional \" [SEP]"}
{"pre": "briscoe and carroll # otherefr for english verbs, # refr, # otherefr for automatic acquisition of verb [SEP] coverage [SEP]", "cit": "what is more, german is a counterexample to # refr expectation that freedom of word order should be matched by an increase in case and [SEP]"}
{"pre": "dependency relations have been successfully used in many nlp tasks, such as parsing # otherefr, semantic role labeling # refr, and word sense", "cit": "# refr investigate the addition of semantic annotations in the form of word sense hypernyms, in hpsg parse ranking, reducing error rate in [SEP]"}
{"pre": "the disambiguation of pp prepositions is thus crucial for many natural language processing tasks, including question answering # otherefr, and machine translation", "cit": "adapted from # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in 1989 and 1990, it has been noted that text generation \\ [ # refr \\ ], the information synthesis of text generation \\ [ moore and", "cit": "such networks can be readily expressed in a number of distinct formalisms, e. g., fug # otherefr \\ ] ) [SEP]"}
{"pre": "in addition to the mt - based method, researchers have also investigated other methods for paraphrase generation, such as the pattern - based methods [SEP]", "cit": "in addition to the mt - based method, researchers have also investigated other methods for paraphrase generation, such as the pattern - based methods [SEP]"}
{"pre": "there have been many approaches for the recovery of empty categories in the treebanks like penn treebank, both ml based # otherefr [SEP]", "cit": "recently, empty - element recovery for chinese has begun to receive attention : # refr treat it as classification problem, while chung and gildea [SEP]"}
{"pre": "# refr showed that readability is the average of documents in the text complexity of sentences. [SEP] readers can be successfully applied to read [SEP] [SEP] [SEP]", "cit": "# refr consider a different task of predicting text quality for an educated adult audience. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "19901. and el iminated over copying and 1990s that are semantically typed dependencies, as defined by the structure of a indices of [SEP] phenomena", "cit": "4 using an idea similar to karttunen is, # refr proposed a quasi - destructive unification that uses node structures with fields for [SEP]"}
{"pre": "previous work has used machine learning techniques for named entity recognition # otherefr # refr. [SEP] features based methods to extract relevant data from a corpus", "cit": "system f1 ( precision, recall ) # refr, best single, no list 89. 94 # otherefr, no list 90. [SEP]"}
{"pre": "in this paper, we expand the representation of the lexicon by using an automatically constructed polarity resource as singular ( \" ) dictionary definitions and # refr.", "cit": "hownet # otherefr and wordnet provide domain information for chinese and english, but there has been no domain resource for japanese that are [SEP]"}
{"pre": "in addition, insufficient language ambiguity is common in the absence of a large corpus of several language understanding, so that the presence or absence of [SEP] ambiguity", "cit": "technically, we use underspecified descriptions that are regular tree grammars derived from dominance graphs # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "in the community of the nlp community, detecting devoted to the best of each noun in a sentence # otherefr ; # refr, [SEP]", "cit": "this decision is further motivated by findings which reveal that different measures are often complementary to each other so that their combination better approximates the inherent degrees of [SEP]"}
{"pre": "in addition, we plan to train a model on the air travel hfs corpus, which has been used in turn used to train and evaluate the", "cit": "in the case of ratnaparkhi is generator for ight information in the air travel domain # refr, the transformation algorithm is trivial as [SEP]"}
{"pre": "vided by machine readable dictionaries # refr, # otherefr ; [SEP] the noise introduced by the [SEP] already mentioned above [SEP] the [SEP]", "cit": "one solution is to use simulated annealing, as proposed in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in natural language processing, automatically acquired preference models have been shown to aid a number of tasks, including semantic role labelling # otherefr, [SEP]", "cit": "these methods can be vectorbased # otherefr, discriminative # refr or probabilistic ( o. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper, we show how to efficiently storing models can be used for decoding with n - gram models # otherefr and backoff #", "cit": "while data structure compression # otherefr and randomized data structures # refr are useful, here we are concerned solely with the values stored by these [SEP]"}
{"pre": "the tool? s purely syntactic n - gram model, is trained on the british national corpus ( bnc ), and [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "thus ibm is wordsmith system # refr is concerned primarily with providing a browsing functionality which supports retrieval of words ~ close ~ to a given [SEP]"}
{"pre": "after numerous attempts by various researchers # otherefr ; # refr, the recent work of yu et al # otherefr finally reveals a [SEP]", "cit": "after numerous attempts by various researchers # otherefr ; # refr, the recent work of yu et al # otherefr finally reveals a [SEP]"}
{"pre": "while a similar direction has been previously explored in # refr, the recent work of # otherefr takes it one step further by adding a model", "cit": "a related task, unsupervised frame induction, has also been considered in the past # refr ; the frame representations encode events and participants but ignore the [SEP]"}
{"pre": "other work uses human - annotated corpora, such as the rst bank # otherefr, used by # refr, or adhoc annotations, [SEP]", "cit": "other work uses human - annotated corpora, such as the rst bank # otherefr, used by # refr, the graphbank # other [SEP]"}
{"pre": "the second hypothesis, that the distribution over the set of features is np - hard to obtain a discriminative model # refr. [SEP] well [SEP] tasks [SEP]", "cit": "generative and discriminative models have been compared and discussed a great deal # otherefr, including for nlp models # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "distributional similarity is being deployed ( e. g., # refr ) in question answering. [SEP] similarity measures based on bilingual [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "# refr and fujita and sato # otherefr also proposed directional similarity measures based on conditional probability, which are very similar to score base [SEP]"}
{"pre": "recently, several feed - forward neural networkbased models have achieved impressive improvements on the state - of - the - art n - gram models # other", "cit": "recent work has also shown successful applications to machine translation # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr applied the kernel regression model, which uses svms and applied kernel to estimate. [SEP] features, which were the similarity of the [SEP] 1", "cit": "currently, a lot of relation extraction # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "paraphrase generation can be used for paraphrase the quality of bilingual parallel corpora # refr. [SEP] the bannard and callison - bur", "cit": "for english, we use the paraphrase database developed by snover et al. # otherefr, using techniques presented by # refr [SEP]"}
{"pre": "in tempeval 2007 and 2010 # otherefr ; # refr, annotators annotated only relations in specific constructions ( e. g. [SEP]", "cit": "most recent studies have been developed in the context of the tempeval evaluation contests, which were initiated by # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "# refr show that the diversity of a parser is promising performance on the ensemble techniques, and we show that it outperforms the competitive accuracy of a ws", "cit": "ensemble learning # otherefr has been used for a variety of machine learning tasks and recently has been applied to dependency parsing in various ways and [SEP]"}
{"pre": "factored estimation has been quite popular in nlp of late # otherefr ; # refr ; cohen et al, 2010a ). [SEP]", "cit": "when both involve high levels of ambiguity, this separation becomes harder to justify, as argued by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used bootstrap resampling # refr to measure significance on the mixed test set, and performed significance. [SEP] the paired bootstrap resampling [SEP] for [SEP]", "cit": "the? sign denotes the confidence bounds estimated via bootstrap resampling # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the sts 2013 corenlp system ( ms f1 # refr ) is a quasi - synchronous dependency parser # otherefr. [SEP] [SEP] [SEP]", "cit": "quasi - synchronous grammars have been used successfully for paraphrase detection # refr, as they provide a fine - grained modeling of the alignment [SEP]"}
{"pre": "minimum error rate training # refr is a common method for optimizing linear model parameters, which is an important part of building good machine translation systems. [SEP]", "cit": "we use another technique to speed up direct search by storing and re - using search graphs, which consist of lattices in the case of phrase - [SEP]"}
{"pre": "datr \\ [ # refr \\ ] is a system that declaratively represents morphological information, using the representation, reranking [SEP] [SEP] [SEP] [SEP]", "cit": "this fact has not gone unnoticed by a number of researchers working on lexical knowledge representation, e. g. de smedt # other [SEP]"}
{"pre": "in the case of word formation, some unsupervised methods have been used in numerous nlp applications such as # otherefr, # refr, #", "cit": "# refr proposed an unsupervised algorithm for word segmentation. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "to determine the degree of compositionality, we used the distributional similarity measure, on the basis of the method proposed by # refr. [SEP] the mutual", "cit": "it was also used to compute the distributional similarity between words c # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "pleonastic its have been detected using heuristics ( e. g., # refr ) and learning - based techniques such as rule learning # [SEP]", "cit": "non - anaphoric definite descriptions have been detected using heuristics # otherefr ) and unsupervised methods ( e. g., # refr ) [SEP]"}
{"pre": "we use the stanford dependency parser # refr to parse the sentence structure. [SEP] the noun phrases, in order to detect noun phrases [SEP] the noun phrases", "cit": "due to the annotation and work of # refr, we are now able to create natural language processing ( nlp ) systems that take advantage of [SEP]"}
{"pre": "the only exception to this is # refr who train a model on the unlabeled data on the senseval - 3 english lexical sample task, and it", "cit": "more recent techniques based on user - contributed knowledge # otherefr ; # refr, such as that found in wikipedia, suffer from similar problems [SEP]"}
{"pre": "in recognition of this need, a number of recent information extraction # otherefr ; # refr. [SEP] this approach performed well [SEP] [SEP] [SEP] [SEP]", "cit": "this approach was also applied in the conll - 2010 shared task # refr, in which 13 participating groups proposed approaches for task 2, which [SEP]"}
{"pre": "we use brown clusters as representation of minipar # refr and lemmatization # otherefr. [SEP] a neural network to improve the [SEP] [SEP] [SEP]", "cit": "the cw vectors used were trained by # refr, and the word2vec vectors by mikolov et al. # otherefrb ) [SEP]"}
{"pre": "in addition to the tuple as a log - linear model # refr, the probability distribution is significantly more severe of the translation units with the order translation", "cit": "following # refr, we adopt a general log - linear model. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "1998 ; # refr. [SEP] the important sentences in a document for summarization, this is a variant of the problem [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "many of these documents are likely to repeat much the same information, while differing in certain i most of these were based on statistical techniques applied to [SEP]"}
{"pre": "# refr take a closer look at the impact of generic measures, though they did not evaluate the performance of different compositionality. [SEP] phenomena, such", "cit": "we then took the cartesian product of these 256 adjectives with the 200 concrete nouns in the bless data set # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "previous methods for content selection include reinforcement learning # otherefr ; statistical acquisition of rules # refr, and the hidden markov model approach for content selection", "cit": "natural language generation from time - series data has been investigated for various tasks such as weather forecast generation # refr, report generation from clinical data # [SEP]"}
{"pre": "bootstrapping # refr is a technique that has been used for named entity recognition in nlp. [SEP] the problem of taggers [SEP]. [SEP] the", "cit": "named entity recognizers # otherefr ; # refr ) can be trained to recognize proper names associated with semantic categories such as per - son [SEP]"}
{"pre": "in this paper, we focus on the sentiment analysis of aspect - level sentiment analysis, which is the closest to ours is that of # refr who", "cit": "if a sentiment lexicon is available for one domain, domain adaptation can be used, provided the domains are sufficiently similar # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "bo? # refr introduced an approach that reduces grounded language learning to unsupervised probabilistic context - free grammar ( pcfg ) induction ), achieving accuracies above", "cit": "more recently, several groundedlearning approaches have been proposed to alleviate the annotation burden # otherefr ; bo? # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "we used the kenlm toolkit # refr to train the lm and rely on kenlm # otherefr to train a lm on kenlm [SEP]", "cit": "we trained our systems with the following settings : a maximum sentence length of 80, growdiag - final - and symmetrization of gi [SEP]"}
{"pre": "in nlp, incremental processing # otherefr ; # refr ; incremental parsers and including language understanding # otherefr. [SEP] [SEP] [SEP]", "cit": "futhermore, architectures for incremental dialogue systems have been proposed # otherefr and incremental toolkits are also available ( baumann and # [SEP]"}
{"pre": "we use named entity recognizers # otherefr ; # refr, which encode the ambiguity inherent in wikipedia articles # otherefr. [SEP] [SEP]", "cit": "consequently, in the literature, supervised approaches are confined to classify entities into broad categories, such as persons, locations, and organizations, while the [SEP]"}
{"pre": "we used the fntbl system # refr. [SEP] the second - order representation of the wsj section of the penn treebank ( ptb", "cit": "the reduced the pos tagging was performed with the fntbl toolkit # refr this software was kindly provided by david yarowsky? s group [SEP]"}
{"pre": "several approaches rely on bilingual parallel data # otherefr ; # refr, while others leverage distributional methods on monolingual text corpora # otheref [SEP]", "cit": "paraphrases, i. e. differing textual realizations of the same meaning, are a crucial components of text - to - text generation systems [SEP]"}
{"pre": "# refr use lda to transfer semantic drift by learning in domain adaptation. [SEP] the source entity to each target word by a single model. [SEP] the", "cit": "such models have been effective in discovering lexicons in many nlp tasks, e. g., named - entity recognition # refr, word [SEP]"}
{"pre": "# refrb ) evaluate the cross - lingual mt evaluation metric ( cl - ii ) on the test set and to evaluate machine translation performance [SEP]", "cit": "owczarzak et al # otherefra, b ) improved correlation with human fluency judgments by using lfg to extend the approach [SEP]"}
{"pre": "in contrast, label propagation has been used for information extraction # otherefr, partof - speech tagging # refr, named - entity recognition #", "cit": "to overcome these difficulties, seed - based information extraction methods have been developed over the years # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "in addition, the topic - based approach described here is based on the idea of using lexical functional grammar ( multimodal learning ) # refr. [SEP] [SEP]", "cit": "it has also been used as a tool in education, to enhance literacy # refrb ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "1989 ; gale & church 1991 ; brown et al 1991 ; # refr, and coarser approaches when sentences are difficult to identify have [SEP] phenomena", "cit": "various methods have been developed for sentence alignment which we can categorise as either lexical such as # otherefr # refr # otherefr [SEP]"}
{"pre": "# refr use information structure to generate the set of possible descriptions for the initial representation. [SEP] text. [SEP] orthographic cues to classify into [SEP]", "cit": "in a limited domain setting, # refr describes a two - tiered information structure representation. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "gime? nez and ma ` # refr introduced ulc, an automatic mt evaluation metric that aggregates many types of features, including [SEP],", "cit": "preliminary experiments, based on an extension of the metrics by gime? nez and ma ` # refr operating over discourse representations, are presented [SEP]"}
{"pre": "for example, # refr utilized syntactic tree structures. [SEP] the source language as features. [SEP] the ones. [SEP] for the inference of new [SEP] it", "cit": "tree kernels have been used in traditional re and have helped achieve state of the art performance # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "in particular, resources annotated with the surface realization of semantic roles, like framenet # otherefr, and framenet # refr have shown [SEP]", "cit": "while similar works in the past have mainly proposed to automatically extend the framenet database by mapping frames and word - net synsets # otheref [SEP]"}
{"pre": "it performs cubic time parsing for arc - factored models # otherefr ; # refr. [SEP] the problem of inference [SEP] the inference [SEP] it", "cit": "they parse a sentence in bottom up order and keep the top k derivations for each span using k best parsing # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr describe a pcfg - like algorithm to improve the performance of a probabilistic context free grammar ( pcfg ) parser, and demonstrated [SEP] the", "cit": "the charniak parsing pipeline has been extensively studied over the past decade, with a number of papers focused on improving early stages of the pipeline [SEP]"}
{"pre": "we use a maximum entropy model # otherefr which is based on the general features, although they have been shown to be good fit [SEP] this", "cit": "however, it is shown that gtm shows the highest correlation with human judgments # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we chose svms as they have been shown to perform well on a variety of tasks, including sentiment analysis # otherefr, sentiment classification #", "cit": "for instance, a tweet that contains a sad face likely contains a negative polarity # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used the following publicly available tools : the charniak parser # otherefr, the svm - light - tk toolkit # refr, [SEP]", "cit": "# refr, kim et al # otherefr, etc ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "another approach to this problem is to use syntactic information to reordering ( kriya et al., 2007 ), as suggested by # [SEP]", "cit": "this information source is deployed in recent work either for pre - ordering source sentences before they are input to to a phrase - based system # other [SEP]"}
{"pre": "uedin # refr and # otherefr. [SEP] the source sequence sequence sequence sequence n - gram features (? 1 ) : source sentence [SEP]", "cit": "# refr successfully applied these features in n - best list re - ranking. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr describe an algorithm for estimating context - free grammars with source. [SEP]. [SEP] a source - side parse of a parallel corpus in which they", "cit": "besides being linguistically motivated, the need for edl is also supported by empirical findings in mt that one - level rules are often inadequate # [SEP]"}
{"pre": "in fact, many alignment techniques are used for extracting translation candidates from parallel corpora # otherefr ; # refr. [SEP] this technique [SEP] [SEP] [SEP]", "cit": "# refr reports that their termight system helped double the speed at which terminology lists could be compiled at the at & t business translation services. [SEP]"}
{"pre": "in smt, # refr used multiple paraphrases to create paraphrases for the translation model. [SEP]. [SEP] the same word into its", "cit": "we acquire a paraphrase list using # refr? s method. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in order to ensure compatibility with the decoder, we use minimum error rate training # refr to find the balance. [SEP] bleu [SEP] [SEP] [SEP] [SEP]", "cit": "adding 8 - bit quantization for the realvalued features in the grammar reduces even large syntactic grammars to a manageable size. tion performance # refr [SEP]"}
{"pre": "in # refr, anaphora resolution is actually a text iml system which uses the morphological analyzer as the information taken from the texts. [SEP] it", "cit": "but # refra ) show that the lappin and leass algorithm still provides good results ( 75 % ) even without complete parse. [SEP] [PAD]"}
{"pre": "learning then reduces to finding a set of parameters that are estimated by identifying a local maximum of an objective function such as the likelihood # otheref [SEP]", "cit": "empirically, our algorithm performs favorably compared to the constituent context model of # refr without the need for careful initialization. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in particular, we explicitly represent many semantic relations expressed in a sentence that could be successfully used for this purpose : lexical semantics of word [SEP] phenomena #", "cit": "lexical databases such as framenet # refr, verbnet # otherefr can serve as training data. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the domain of natural language processing, machine learning ( nlp ) has been applied to the analysis of natural language processing ( nlp ) tasks", "cit": "the key functions of ete are described below : manage test resources : ete provides an graphical interface to manage various resources needed for tests, [SEP]"}
{"pre": "ng and # refr, morton # otherefr. [SEP] the decision is made available. [SEP] ( i. e., a local classifier", "cit": "while early machine learning approaches for the task relied on local, discriminative classifiers # otherefr ; ng and # refr, more recent approaches use [SEP]"}
{"pre": "in # refr, we showed that a parsing algorithm attain has the impact of the parsing quality of a phrase - based translation system. [SEP] the [SEP]", "cit": "at each iteration of mer training, we run the parser and decoder over the ctb dev set to generate an n - best list of possible [SEP]"}
{"pre": "the only difference between the system i and its extension of monolingual collocational approaches is that use i, i, i. e.,", "cit": "with the availability of large corpora and memory devices, there is once again growing interest in extracting n - grams with large values of n. # [SEP]"}
{"pre": "in addition, # refr proposes a study of deriving such a constraint on the intended to deal with ambiguity, as well as the relative clause of the", "cit": "the category constrains resolution to look for verb phrase / sentence sources, which come wrapped in forms with categories like \\ [ t ease = [SEP]"}
{"pre": "the maximum entropy models used here are similar in form to those in # otherefr ; lau, rosenfeld, and # refr. [SEP] [SEP]", "cit": "the corpus - based statistical parsing community has many fast and accurate automated parsing systems, including systems produced by collins # otherefr and # refr [SEP]"}
{"pre": "while negra has been used to transfer linguistically motivated constraints in the morphological analysis of the german newspaper texts, e. g. # refr", "cit": "figure 1 : a tree from tu? ba - d / z however, in a few other treebanks, such as the german neg [SEP]"}
{"pre": "there have been several approaches in the literature # otherefr ; # refr ), and we leave - one to - one approach to [SEP] [SEP]", "cit": "some approaches look at the broader sentential context around a potential role filler when making a decision ( e. g., ( gu and # [SEP]"}
{"pre": "shieber # otherefr recently argued that probabilistic synchronous tree adjoining grammars # refr have the right combination of properties that satisfy both [SEP]", "cit": "# refr recently argued that probabilistic synchronous tree adjoining grammars # otherefr have the right combination of properties that satisfy both linguists and [SEP]"}
{"pre": "in this work, we compare the performance of the graph - based semi - supervised algorithm # refr with two existing semi - supervised learning algorithms : graph", "cit": "webkb is a text classification dataset derived from # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the use of nlp techniques for relation extraction has recently been studied before # otherefr, # refr, # otherefr. [SEP] [SEP]", "cit": "gi # refr propose a set of features to extract manner exclusively from adverbial phrases and report a precision of 64. 44 % and recall of [SEP]"}
{"pre": "the baseline algorithm has been applied to part - of - speech tagging # otherefr ; # refr and to word segmentation # otherefr.", "cit": "the major problem in mdl - based word segmentation is the lack of standardized search algorithms for the exponential hypothesis space # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "we used bleu # refr, which is the case sensitive bleu score # otherefr. [SEP] the current translation hypothesis. [SEP] [SEP] [SEP]", "cit": "the results are reported in bleu # refr and ter # otherefr scores. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "these include syntactic, semantic and mixed syntacticsemantic classifications # otherefr ; # refr. [SEP] features based methods to statistical [SEP] the [SEP] [SEP]", "cit": "these three of types of information have proved useful for natural language processing # otherefr ; # refr, semantic role labeling # otherefr [SEP]"}
{"pre": "statistical machine translation # otherefr ; # refr. [SEP] the procedure for the automatic : e? = argmax e. [SEP] [SEP] [SEP] [SEP]", "cit": "statistical machine translation # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "smt decoders such as moses # otherefr may store the translation memory # refr. [SEP] the phrase table of the translation process [SEP]", "cit": "koehn # otherefr shows translation scores for a number of language pairs with different training sizes translated using the pharaoh smt [SEP]"}
{"pre": "several approaches have been in this area # otherefr ; # refr, they are not designed for metaphor modeling. [SEP] text [SEP] the idea of", "cit": "automated approaches to metaphor detection involve both supervised and unsupervised approaches, some of which include : i ) supervised classification on extracted verbal target feature vectors of [SEP]"}
{"pre": "in the last years, an interesting work of langkilde # refr has generated a model that captures the intended effect of training data [SEP] when", "cit": "one line of work has primarily focused on grammaticality and naturalness, scoring the overgeneration phase with a slm, and evaluating against a [SEP]"}
{"pre": "malt # otherefr, mst # refr, and mate parser # otherefr trained on the conll09 dataset and tested on [SEP] [SEP]", "cit": "in the experiments we included the malt parser # otherefr, and the graph - based turbo parser # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the lattice - based decoder described in # refr with the following basic settings : given a set of possible morphological segmentation. [SEP] [SEP] [SEP] [SEP]", "cit": "in a similar manner to mbr decoding over multiple k - best lists in de # refr, the path posterior probability of each n - gram [SEP]"}
{"pre": "we finalized two versions of the data : blogt, tagged with the stanford tagger # otherefr, 6 and the berkeley parser [SEP]", "cit": "we finalized two versions of the data : blogt, tagged with the stanford tagger # otherefr ; # refr. 7 the [SEP]"}
{"pre": "in order to transliteration, cognate training methods are used # refr and eisner # otherefr. [SEP] the source [SEP] [SEP] [SEP]", "cit": "we split the resulting list into training, development and testing parts and we trained and tuned a character - level macedonian - bulgarian [SEP]"}
{"pre": "then the word alignments are computed via the grow - diag - final heuristic # refr. [SEP] a maximum entropy procedure consisting of two [SEP] phrases [SEP] the", "cit": "word alignment was carried out by running giza + + implementation of ibm model 4 initialized with 5 iterations of model 1, 5 of the hmm [SEP]"}
{"pre": "in the unsupervised setting, it has also been shown that a model trained with the expectation - maximization ( em ) algorithm is applied to a related task", "cit": "in the case of the previous work on translation modeling, mixed methods have been investigated for domain adaptation in smt by adding domain information as additional [SEP]"}
{"pre": "in recent years, supervised learning techniques have been successfully applied to wsd # otherefr, # refr, # otherefr. [SEP] this", "cit": "the interest data was created by # refr by tagging all occurrences of interest in the acl / dci wall street journal corpus with senses from the [SEP]"}
{"pre": "in addition, we use features derived from syntactic parse trees, and define a sequence model as features ( like features ) for instance as well as syntactic", "cit": "this approach was soon followed by other researchers # otherefr ; # refr, focusing on improved sets of features, improved machine learning methods or [SEP]"}
{"pre": "in order to transliteration, we applied the giza + + package # refr. [SEP] 2 [SEP] 2 [SEP] a forward - to [SEP] the", "cit": "we apply directl - p # refr for our training and testing task. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "mi and huang # otherefr ; # refr without sufficiently leveraging rich tree context. [SEP] the source parse trees of the [SEP] [SEP] [SEP] [SEP]", "cit": "such boundary features were treated as hard constraints in previous literature in terms of re - labeling # refr or re - structuring # otherefr. [SEP]"}
{"pre": "this result suggests that the context - free approach can be used in terms of context - free grammars are the # otherefr, # refr,", "cit": "for each state q and each symbol b?? x, the arcs from q with input label b or must have total probability of 1. [SEP]"}
{"pre": "in # refr, an error rate f was performed on the french - english parse structures with a reordering model trained on the europarl v", "cit": "all the results in table 10 and 11 marked with? *? are statistically significant with p < 0. 05 using the sign test described in [SEP]"}
{"pre": "ng and # refr ). [SEP] the preprocessing methods for coreference resolution, but use a machine learning framework. [SEP] features for this problem [SEP] the", "cit": "for instance, ng and # refra ) train an anaphoricity classifier to determine whether a mention is anaphoric, and let an independently [SEP]"}
{"pre": "in addition, some research on event extraction, focus on identifying events # otherefr ; # refr, a list of four domains # otheref", "cit": "recently, event paraphrases # refr have been explored to deal with the diversity of event descriptions. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used the syntactic component of the conll - 2008 shared task as well as in the multilingual dependency parsing of the conll - [SEP] [SEP]", "cit": "dependency - converted versions of the penn treebank, propbank and nombank were used in the conll - 2008 shared task # refr, [SEP]"}
{"pre": "in our experiments, we use a rule - based system developed by # refr designed for the english assessment of the english language and the english wikipedia dataset", "cit": "based on these technologies, # refr improved the humsent accuracy to 40 % by applying a set of heuristic rules that assign handcrafted [SEP]"}
{"pre": "this is a well studied problem and several association measures exist # otherefr ; # refr. [SEP] features : relative frequencies of n - gram [SEP]", "cit": "for example, work which failed to detect improvements in translation quality with the integration of word sense disambiguation # otherefr ; # refr may [SEP]"}
{"pre": "we use a forward - backward algorithm # otherefr ; # refr to alleviate the annotation bottleneck. [SEP] this model by the crf [SEP] [SEP] [SEP]", "cit": "indeed, our lookahead framework could be regarded as a special case in which each search node con - training time ( sec ) test time ( [SEP]"}
{"pre": "we can use techniques such as # otherefr and # refr to build grammars, but our approach has yet been applied to parameter estimation # [SEP]", "cit": "goodman # otherefr describes semirings for the viterbi derivation, k - best viterbi derivations, derivation forest, [SEP]"}
{"pre": "for example, the bionlp? 09 shared task # refr focuses on resolving the scope of biomedical events, where a syntactic [SEP] [SEP] [SEP] [SEP]", "cit": "the conll - 2010 shared task on hedge detection # otherefr follows in the steps of the recent bionlp? 09 shared task [SEP]"}
{"pre": "inference rules are an important component in natural language processing, information extraction # refr, and coreference resolution # otherefr. [SEP] [SEP] [SEP] [SEP]", "cit": "prior work in relation discovery # refr has investigated the problem of finding relationships between different classes. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, researchers have experimented with different approaches, namely word sense disambiguation # otherefr ; # refr. [SEP] this problem [SEP] [SEP]", "cit": "our baseline coreference system implements the standard machine learning approach to coreference resolution # otherefrb ), # refr, yang and su # [SEP]"}
{"pre": "# refr proposed a model for jointly inducing latent structure and pos structure representations. [SEP] features. [SEP] the latent variable model to maximize the probability of a", "cit": "on the corpus of 8, 031 apartment advertisements from craiglist # refr and 1, 991 movie reviews from imdb # other [SEP]"}
{"pre": "in addition to the standard ( contextual ) senseval - 3 lexical sample ( lexfunc ) system ( bnc ), we also ran 69.", "cit": "the f - score of an oracle upper - bound and baseline are also shown. and finance corpora # refr and the bnc. [SEP] [PAD] [PAD]"}
{"pre": "given the complementary nature of those two semantic models, it is not surprising that considerable research activity has been dedicated on combining them into a single framework [SEP]", "cit": "given the complementary nature of those two semantic models, it is not surprising that considerable research activity has been dedicated on combining them into a single framework [SEP]"}
{"pre": "while these features have been shown to be beneficial to conversational information # otherefr ; # refr, we show how they can use prosodic features", "cit": "the primary use of prosody was to rule out candidate parses # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the cdec decoder # refr. [SEP] - linear model # otherefr to translate the chinese sentences, and use giza + +", "cit": "the k - best extraction algorithm is also parameterized by an optional predicate that can filter out derivations at each node, enabling extraction of only derivations that [SEP]"}
{"pre": "we train a trigram language model with kneser - ney smoothing # refr. [SEP] smoothing # otherefr used kneser - ney", "cit": "in practice, one adjusts or smoothes # refr the ml estimates o that the language model can generalize to new phrases. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "a joint probability model, which is trained with the expectation maximization ( em ) algorithm # refr. [SEP] the latent variable [SEP] [SEP] [SEP] into [SEP] [SEP]", "cit": "for higher efficiency, it is constrained by a word alignment in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use a hidden markov model ( hmm ) taggers # refr. [SEP] this algorithm. [SEP] this algorithm could be used for classification, for the", "cit": "later taggers have managed to improve brill? s figures a little bit, to just above 97 % on the wall street journal corpus using [SEP]"}
{"pre": "in recent years, conditional random fields # otherefr have shown success on a number of natural language processing ( nlp ) tasks, including [SEP]", "cit": "note that this decoding is an equivalent formulation to a uniformly weighted logarithmic opinion pool, as described in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we believe that other kinds of? explainable expert knowledge, such as the measure of implicatures and # otherefr, [SEP], [SEP]", "cit": "discourse - interpretation formalism described in # refr, which uses the minimum message length # otherefr to evaluate candidate discourse interpretations. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "in this paper, we apply the minimal recursion semantics ( segmenter | ~ ) # refr and # otherefr. [SEP] ( [SEP] ) [SEP]", "cit": "reviewing the previous works on thai word extraction, we found only the work of # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr \\ ] has noted that a corpus of raw web counts are more useful in many applications, including machine translation. [SEP], [SEP], [SEP]", "cit": "these include a variety of bayesian classifiers # refr, decision lists # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in contrast, most of the previous work on relation extraction focuses on the supervised approach that does not require any linguistically motivated [SEP] annotations # otheref", "cit": "inword sense disambiguation and entity linking, there are some collective approaches # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr showed that for the task of identifying contiguous words as a sentence. [SEP] a prefixes they do not take as input and use the [SEP]", "cit": "recently other researchers have emphasised the utility of phonotactic constraints # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the features are integrated in a collection of features over a naive bayes features, e. g. # refr. [SEP] disambiguation between adjacent sentences and", "cit": "depending on the sources of textual data available for training, any taggers # otherefr ; # refr that disambiguate text fragments relative to [SEP]"}
{"pre": "under a classical aristotelian perspective, plot is supreme ; 1 modern theoretical dramatists and screenwriters disagree. 2 without addressing [SEP]", "cit": "under a classical aristotelian perspective, plot is supreme ; 1 modern theoretical dramatists and screenwriters disagree. 2 without addressing [SEP]"}
{"pre": "there have been many attempts to resolve this problem in many languages1 # otherefr ; # refr. [SEP] this work has been done [SEP] [SEP]", "cit": "this data sample excludes several types of expressions containing? other? : ( a ) list - contexts ( ex. 4 ) and other - than [SEP]"}
{"pre": "machine learning based classifiers, including maximum entropy, decision trees # otherefr, and support vector machines ( svm ) # [SEP]a [SEP]a [SEP]", "cit": "with well - designed auxiliary problems, the method has been applied to text classification, text chunking, and word sense disambiguation # refr. [SEP]"}
{"pre": "especially challenging is the task of mining semantically similar words from comparable data without any external knowledge source such as machine - readable seed bilingual lexicons [SEP]", "cit": "such crosslingual semantic spaces are typically spanned by : # otherefr ; # refr, or # otherefr ; daume. [SEP]"}
{"pre": "semantic parser induction as addressed by # refr, semantic parsers are based on unsupervised learning of syntax # otherefr. [SEP] it [SEP] [SEP] [SEP]", "cit": "by combining a stick breaking process with a multinomial over categories we can define a dp over ccg 5an alternative hdp model for semantic [SEP]"}
{"pre": "id participant cmu - uka carnegie mellon university, usa # otherefr nrc national research council, canada # refr [SEP]", "cit": "smt decoders such as moses # refr may store the translation model in an efficient on - disk data structure # otherefr, [SEP]"}
{"pre": "in # refr, the blm - aligner is applied to english and chinese ( english ) dependency parsing models are trained to obtain the second [SEP]", "cit": "# refr presented a self - training method combined with a reranking algorithm for constituency parsing. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for instance, the model that focused on syntactic clues often use mwes to process the target expression. # otherefr use word - net [SEP]", "cit": "several other researchers have proposed a number of computational techniques that deal with the discovery of mwes : baldwin and villavicencio # [SEP]"}
{"pre": "in addition, we show that this system outperforms the state - of - the - art dependency parser for english # otherefr and czech # [SEP]", "cit": "there is ample research on the effect preprocessing has on dependency parsing # otherefr and on joint morphological and syntactic processing # refr, but none [SEP]"}
{"pre": "in both cases, we used a simple surface realization system # otherefr to train a natural language generation system ( nlg ) system [SEP] [SEP]", "cit": "the two automatic metrics used in the evaluations, nist2 and bleu3, have been shown to correlate well with expert judgments ( pearson? [SEP]"}
{"pre": "figure 1 : entity grid example de # otherefr that are similar to those of # refr. [SEP] ( 1 ) grounding domain [SEP] [SEP]", "cit": "our work is related to previous work on domainindependent unsupervised relation extraction, in particular sekine # otherefr, # refr and banko [SEP]"}
{"pre": "# refr used pos tags to create unknown morpheme boundaries such as? unknown? and?. [SEP]?. [SEP]?. [SEP]? in sequence", "cit": "# refr presented a method for guessing pos tags of pre - segmented unknown words that took into consideration all the occurrences of each unknown word in [SEP]"}
{"pre": "bold gray boxes show links gained after fully connecting the alignment. has motivated much recent work in discriminative modeling for word alignment # otherefr ; [SEP]", "cit": "bold gray boxes show links gained after fully connecting the alignment. has motivated much recent work in discriminative modeling for word alignment # otherefr ; [SEP]"}
{"pre": "statistical surface realisation from realisation [ # refr ; user, 2000 ; user, 2000 ; user, 2000 ; user, the you realisation", "cit": "while the user is speaking, the dialogue manager sends dialogue acts to the nlg module, which uses reinforcement learning to order semantic attributes and produce [SEP]"}
{"pre": "the annotation of sentences has been done on the project of different aspects of the penn treebank ( ptb ), either, a single xml language", "cit": "cedit is a part of a project to create a rich resource of manually annotated semantic structures # otherefr as a new layer of the [SEP]"}
{"pre": "in # refr, we showed that weighting performance could be improved by weighting performance on the sentiment analysis benchmark data. [SEP] the polarity classifier. [SEP] the", "cit": "the multi - domain sentiment data set ( mdsd ) by # refr contains amazon reviews for four different product types : books, electronics, dv [SEP]"}
{"pre": "for example, the maxent model described in # refr provides an implementation of the pos tagger implementation of # otherefr for [SEP] the pos", "cit": "the original intention of assignment 2 was that students then use this maxent classifier as a building block of a maxent part - of - speech [SEP]"}
{"pre": "statistical methods to jointly perform content selection, lexicalization, and surface realization have also been proposed in nlg # otherefr ; # refr [SEP]", "cit": "experimental results on the atis domain # otherefr demonstrate that our model outperforms a baseline based on the best derivation and a stateof - [SEP]"}
{"pre": "pos tagging of english using the pos tagger of # refr, we found that different pos taggers are comparable to different languages. [SEP] [SEP] [SEP]", "cit": "this work was done during authors? internship at microsoft research india. tional models of cm have been few and far between # refr, [SEP]"}
{"pre": "# refr uses a corpus of 4, 000 verbs, and 8 million words, and it found that the verb could be assigned [SEP] [SEP] [SEP] [SEP]", "cit": "semantically, the compositionality of mwes is gradual, ranging from fully compositional to idiomatic # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used minimum error rate training ( mert ) # refr to tune the feature weights for maximum bleu. [SEP]. [SEP]. [SEP] [SEP] [SEP]", "cit": "the feature weights for each system were tuned on development sets using the moses implementation of minimum error rate training # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "much of this work has used hand written rules and several language pairs have been studied e. g german to english # otherefr, chinese [SEP]", "cit": "later, # refr presented specific rules to pre - order long - range movements of words, and improved the translations for chinese - to - english [SEP]"}
{"pre": "task system team ge epi id bb bi co rel ren description uturku 1 1 1 1 1 1 1 1 1 bjo? rne", "cit": "this bionlp st 2009 formulation of the event extraction task was followed also in three 2011 main tasks : the ge # otherefra ) [SEP]"}
{"pre": "rhetorical structure theory # otherefr ; # refr. [SEP] the text corpus # otherefr ) was generated in order to decide [SEP] [SEP]", "cit": "since discourse markers, such as because and and, have been shown to play a major role in rhetorical parsing # refr, we also consider [SEP]"}
{"pre": "previous research has demonstrated that joint segmentation and tagging models can improve parsing performance over an input sentence # otherefr ; # refr. [SEP] research [SEP]", "cit": "vances have focused on understanding and reducing the errors that occur in segmentation and partof - speech tagging # refr, a range of substantial issues [SEP]"}
{"pre": "we trained the model using the averaged perceptron # refr. [SEP] - bfgs system # otherefr, trained on the chinese data set [SEP]", "cit": "to learn the model parameters, it usually uses the online perceptron algorithm with early - update under the inexact decoding condition # refr. [SEP] [PAD]"}
{"pre": "# refr use latent alignment algorithms to find word boundaries in a sentence. [SEP] itgs form of finite state transducers. [SEP] itgs such as [SEP]", "cit": "4 # refr similarly added extra dimensions. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "chinese dependency trees were conventionally defined over words # refr, requiring word segmentation and pos - tagging as features. [SEP] the constituent labels. [SEP] the constituent", "cit": "in addition to english, there is a chinese version of stanford dependencies # refr, ( a ) a constituent parse tree. ( b ) stanford [SEP]"}
{"pre": "for this task, we defined an intermediate representation also called s? # refr. [SEP]? 2 hash kernel # otherefr. [SEP] the word", "cit": "in addition to the classical window - based technique, some studies investigated the use of lexico - syntactic patterns # otherefr ; # refr [SEP]"}
{"pre": "in several recent proposals # otherefr ; # refr, lexico - syntactic patterns are constructed for the disambiguation task of disambiguating the words", "cit": "in ontology learning, definitions are used to create and enrich concepts with textual information # otherefr ; # refra ). [SEP] [PAD] [PAD] [PAD]"}
{"pre": "recent studies on constituent structure conversion # otherefr ; # refr demonstrated that it is useful to disambiguate dependency treebanks [SEP] the source [SEP]", "cit": "recently there have been some works on using multiple treebanks for domain adaptation of parsers, where these treebanks have the same grammar [SEP]"}
{"pre": "the disambiguation is performed by a prepositional phrase disambiguation system that is trained on a data set ; in addition, [SEP] [SEP] [SEP] [SEP]", "cit": "previous work on coordination disambiguation has focused on the task of addressing the scope ambiguity # otherefr ; # refr ). [SEP] [PAD] [PAD] [PAD]"}
{"pre": "we use a dictionary compiled algorithm that have been successfully used in a number of nlp applications such as ner # otherefr, name entity recognition", "cit": "along the way, a normalization dictionary for turkish can be compiled, following studies like # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used syntactic dependencies from the english section of the conll 2009 shared task dataset # refr. [SEP] this problem. [SEP] sentences [SEP] [SEP] [SEP] [SEP]", "cit": "conll 2008 # 1 # refr 90. 13 92. 45 i. ensemble3100 % # otherefr 88. 83 91. [SEP]"}
{"pre": "the parser of # refr had been applied to english, czech, and danish, and the parser of nivre et al # otherefr to", "cit": "our approach differs from most approaches to domain adaptation, which require some training on fully annotated target data # refr, whereas we use minimally annotated target [SEP]"}
{"pre": "in this sense it is related to the system, which has been used for generating a preposition and article error correction # refr. [SEP] [SEP] [SEP]", "cit": "most work on models for determiner and preposition generation has been developed in the context of machine translation output # otherefr, # refr [SEP]"}
{"pre": "english possessive qualia # otherefr # refr ). [SEP] a higher order unification semantic network ( e. g. [SEP] [SEP] [SEP]", "cit": "morphosemantic relations the interest in morphosemantic relations has been motivated by the fact that they overlap to a great extent across word [SEP]"}
{"pre": "the penn treebank # refr has more than a hundred phrase structure treebank, and a syntactically annotated corpus, but it is found that annotations", "cit": "the systems are applied to examples from the penn treebank # otherefr ; # refr a corpus of over 4. 5 million words of [SEP]"}
{"pre": "the weights of the log - linear model were optimized using minimum error rate training ( mert ) # refr. [SEP] the bleu score [SEP] [SEP]", "cit": "the model scaling factors? m1 are trained with respect to the final translation quality measured by an error criterion # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for the cluster - based features, we use giza + + # refr, and the pharaoh # otherefr toolkit. [SEP] the", "cit": "additional models include a standard n - gram language model, phrase - level ibm1, word -, phraseand distortion - penalties and a discriminative [SEP]"}
{"pre": "our natural logic system, dubbed the natlog system, has a three - stage architecture similar to those in # otherefr ; # [SEP]", "cit": "other studies have successfully applied theorem proving and logical induction techniques, translating both sentences to knowledge representations and then doing inference on these representations # otheref [SEP]"}
{"pre": "# refr proposed a method for recognizing contradictions the contradictions task, which combines them in a similar way ( i. e., [SEP] )", "cit": "harabagiu et al # otherefr, # refr, and ritter et al # otherefr focused on recognizing contradictions [SEP]"}
{"pre": "# refr showed that the performance of machine learning methods was improved in terms of the context of error detection. [SEP]. [SEP] sentences that are [SEP] to", "cit": "to reduce the efforts taken to correct grammatical errors in english writing, there has been a great deal of work on grammatical error detection # otheref [SEP]"}
{"pre": "# refr presented an approach to the treatment of aspectual trees for machine translation. [SEP] languages that can be found in the situation of temporal [SEP].", "cit": "lcs representations also include temporal information, where available in the source language : recent revisions include, for example # refra ) standardizing lc [SEP]"}
{"pre": "the morphological paradigm has been implemented using the morphological information from the morphological analyzer # refr. [SEP]. [SEP]. [SEP]. [SEP] he analyzes computational morphology uses", "cit": "our approach also solves the problem noted by # refr of the overgenerality of rules in an fsm system. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "our work can be seen as a generalization of the anchors, and recently proposed an extension of # refr. [SEP] the constituent ordering of source [SEP]", "cit": "early works reward / penalize spans that respect the syntactic parse constituents of an input sentence # otherefr, and # refr. # other [SEP]"}
{"pre": "# refr describe a system for automatic interpretation of noun compound interpretation, but uses a fixed system that does not take syntactically analyzed text. [SEP] it", "cit": "# refr uses a sophisticated system to extract semantic information automatically from an on - line dictionary, and then manipulates a set of hand - written [SEP]"}
{"pre": "co - occurrence statistics from a large corpus of text # otherefr, and the web has been extensively used in the literature [SEP] [SEP] [SEP] [SEP]", "cit": "the mwetoolkit was presented and demonstrated in # refrb ) and in ramisch et al # otherefrc ). [SEP] [PAD] [PAD]"}
{"pre": "the last years have seen a boost of work devoted to the development of machine learning based coreference resolution systems # otherefr ; ng & [SEP]", "cit": "up to now, wordnet has been one of the most frequently used sources of semantic knowledge for the coreference resolution task # otherefr [SEP]"}
{"pre": "there are several different ways to measure the dissimilarity between query expansion and query expansion # otherefr ; # refr. [SEP] the properties of documents [SEP]", "cit": "it should also be noted that social tag suggestion is different from automatic keyphrase extraction # otherefra ; # refr. [SEP] [PAD] [PAD]"}
{"pre": "history - based models have been a popular approach in a variety of natural language processing # otherefr ; # refr. [SEP] the [SEP] [SEP] [SEP]", "cit": "the major alternative to pcfg - based approaches are so - called history - based parsers # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the case of qa, the task has been made effective in object detection and answers : complex questions # otherefr ; # refr [SEP] [SEP]", "cit": "issues include managing clarification dialogues in order to disambiguate users? intentions and interests ; and question decomposition to obtain simpler and more tractable questions [SEP]"}
{"pre": "in this paper, we propose an interactive method to obtain the expected answer type and the expected answer results given by # refr. [SEP] a short paragraph", "cit": "such approach is applied in a paper by # refr, where the princeton wordnet # otherefr serves as an ontology to determine foci types [SEP]"}
{"pre": "most often, such pairs are extracted from small bilingual lexicons # otherefr ; # refr. [SEP] the sentences in [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "the related problem of automatic document alignment in news and web corpora has been explored by a number of researchers, including resnik and smith # other [SEP]"}
{"pre": "the most common practice in the literature is to use itg, which is a stochastic alignment problem # otherefr ; # refr. [SEP] [SEP]", "cit": "these word - level alignments are most often obtained using expectation maximization on the conditional generative models of brown et al # otherefr and # refr [SEP]"}
{"pre": "morphological analysis or segmentation is an important area of research in natural language processing # otherefr, machine translation # refr, and as [SEP] [SEP] [SEP]", "cit": "to test this, 3we also computed ter # otherefr andmeteor scores, but omit them because they demonstrated similar trends. we [SEP]"}
{"pre": "dependency parsing has been intensively studied in recent years # otherefr ; # refr. [SEP] this framework was the basis for joint [SEP] [SEP] [SEP] [SEP]", "cit": "dependency parsing has been intensively studied in recent years # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "parse trees have been used to enhance alignment # refr. [SEP] this hypothesis. [SEP] the charniak - johnson reranking parser # otheref", "cit": "an instance of priming occurs when a syntactic structure or lexical item giving evidence of a linguistic choice ( prime ) influences the recipient to make the same [SEP]"}
{"pre": "the performance of wsj - trained parsers is still well understood as a competitive parser, it achieved an accuracy of 88 %, and 16 [SEP]", "cit": "it has been reported that the lexical semantics of words is effective in resolving structural ambiguity, especially pp - attachment # otherefr ; # refr [SEP]"}
{"pre": "transliteration methods typically fall into two categories : finite - state transducers # otherefr that are solutions # refr. [SEP] the source [SEP] the", "cit": "models constructed from bilingual dictionaries of terms and names, e. g., # otherefr ; # refrb ; goldwasser [SEP]"}
{"pre": "atlas is part of a recent crop of projects devoted to developing automatic translation from language l - pcfgs # refr. [SEP] this work [SEP] [SEP]", "cit": "tree alignment in a variety of forms has been extensively used in machine translation systems # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for example, the syntactic parser of # refr and the charniak parser # otherefr includes a discriminative reranker, [SEP] [SEP] [SEP]", "cit": "following common practice # refr, we employed a coarse - to - fine procedure to prune away unlikely candidate arcs, as described by koo [SEP]"}
{"pre": "we use tnt # refr, a very efficient implementations of both pos taggers. [SEP] a noisy - channel model, a tnt tagger", "cit": "part - of - speech ( pos ) tagging of modern language data is a well - explored field, commonly achieving accuracies around 97 % # refr [SEP]"}
{"pre": "head - driven parser has been trained on negra, # refr show that the parser can be used to obtain an optimal combination of left - corner", "cit": "it is shown that, in spite of the fact that bidirectional parsing seemingly leads to more overhead than left - to - right parsing, the worst [SEP]"}
{"pre": "in the case of the cooperative tasks, coreference ( but, # refr, and the basis for the general architecture of a promising strategy is [SEP]", "cit": "the algorithm for coroutining the treatment of the different kinds of knowledge in order to avoid dead ends along the guided composition mode is described in [SEP]"}
{"pre": "# refr use acoustic - prosodic features extracted from speech to detect disfluencies. [SEP] the prosodic cues in spontaneous speech ( switchboard ) and [SEP]", "cit": "there has been much research effort on automatic disfluency detection in recent years # otherefr ; # refr, particularly from the darpa [SEP]"}
{"pre": "# refr proposed a method that uses co - occurrence patterns of words in a given sentence. [SEP] the word stems, i. e. [SEP] the", "cit": "the domain dependency of words that how strongly a word features a given set of data ( documents ) contributes to event extraction, as we previously reported [SEP]"}
{"pre": "in # refr, the issue is addressed in parallel training data and is by means of shallow syntactic structures. [SEP] ( [SEP] ) [SEP] [SEP] [SEP] [SEP]", "cit": "in # refr possible input permutations are represented through a word graph, which is then processed by a monotonic phraseor n - gram - based decoder [SEP]"}
{"pre": "it has been shown that a standard hmm alignment model can be used to estimate the alignment quality, both with the ibm models # otherefr ;", "cit": "finally, # refr unified the hsmm models with the alignment by agreement framework # otherefr, achieving phrasal alignment that agreed in both [SEP]"}
{"pre": "generative models ( such as models 1 - 5, and the hmm model # refr ) motivate a narrative where alignments are selected left - to - [SEP]", "cit": "to build all alignment systems, we start with 5 iterations of model 1 followed by 4 iterations of hmm # refr, as implemented in giza [SEP]"}
{"pre": "the relations were extracted using the subjectivity lexicon provided by # refr. [SEP]ons2b ) into subjectivity classifiers. [SEP] polarity classification [SEP] [SEP]", "cit": "these kinds of expressions suggest a particular ontology of opinion analysis involving discourse relations across various types of clauses # otherefr ; # refra ) [SEP]"}
{"pre": "in previous work, the method of identifying sentiment polarity of words # otherefr ; # refr. [SEP] the text they used to determine the subject", "cit": "prior work on subjectivity analysis mainly consists of two main categories : the first category is concerned with identifying the subjectivity of individual phrases and words [SEP]"}
{"pre": "in the spirit of recent work in semisupervised parsing, # refr, li et al # otherefr have shown that the increased the grammar [SEP]", "cit": "the idea is well known from # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr measure the syntactic similarity between the output of constituency trees, and dependency trees for each sentence, the syntactic structure is derived from [SEP] sentences", "cit": "# refr propose stm, a metric based on syntactic structure, that addresses the failure of lexical similarity based metrics to evaluate translation grammaticality. [SEP] [PAD]"}
{"pre": "for example, the training data from # refr is a variant of the system developed by # otherefr. [SEP] ( 5 ) [SEP] [SEP] [SEP]", "cit": "we performed several experiments, in which the amount of'training data, the algorithm ( brill is original formulation and'lazy'variants [SEP]"}
{"pre": "we use a log - linear model # refr which allows a weighted combination of feature functions. [SEP] features. [SEP] the source [SEP] a log - linear", "cit": "x3 x4 of china? economic x4 of china? economic development of china following # refr, we base our model on log - [SEP]"}
{"pre": "we used the features generated by # refr. [SEP] a vector ( svm ) trained on the pos tags of the five short words. [SEP] [SEP] [SEP]", "cit": "as defined in # refr, a syntactic tree fragment fri is active in ti when fri is a subtree of the syntactic interpretation of ti. [SEP] [PAD]"}
{"pre": "in # refr, we showed that a sense disambiguation algorithm is able to learn a phrase - based system with a combination of features derived from a", "cit": "our work extends that of # refr in two main aspects. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the first step in the linguistic analysis module lemmatises the inflected words using # refr morpha lemmatiser. [SEP] morphological analyser [SEP]", "cit": "part - of - speech # otherefra ) and lemmatisation is done using morpha # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "to overcome this problem, we have developed a method for learning the hyponymy relations from corpora # refr. [SEP] corpora # otheref [SEP] [SEP]", "cit": "this kind of information from coordination patterns has been used for work in automatic lexical acquisition # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper, we describe a model of centering # otherefr and centering theory # refr. [SEP] this constraint ; [SEP] [SEP] [SEP]", "cit": "yet, a number of discourse - based models of reference primarily rely on linguistic information without regard to the surrounding visual environment ( e. g. [SEP]"}
{"pre": "in particular, we use the structured tree kernel ( tk ) # refr and the kernel # otherefr. [SEP] the [SEP] kernel [SEP] [SEP] [SEP]", "cit": "kernel functions make it possible to capture the similarity between structures without explicitly enumerating all the substructures, and have therefore been shown to be [SEP]"}
{"pre": "one of the earliest kinds of semantic knowledge employed for coreference resolution is perhaps selectional preference # otherefr ; # refr : given a [SEP]", "cit": "some researchers simply use the first sense # otherefr or all possible senses # refra ), while others overcome this problem with word sense [SEP]"}
{"pre": "we use nombank # refr to annotate noun phrases, nouns, predicates and nouns ( nouns, predicates ), predicates. [SEP], [SEP] [SEP]", "cit": "toward this end, we pooled a number of resources : comlex syntax # refra ), nomlex # otherefr. [SEP] [PAD] [PAD]"}
{"pre": "ltag derivation tree adjoining grammar # otherefr, a pioneer work in tree adjoining grammar nlg # refr, [SEP]", "cit": "several approaches have been proposed in the literature describing compact representations methods for ltags, perhaps the best known being # otherefr, # refr [SEP]"}
{"pre": "in recent years, there has been a growing interest in corpus - based natural language generation # otherefr ; # refr. [SEP] this appears [SEP]", "cit": "we build on the existing insights of linguists # otherefr ) and implementations ( including # refr ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for example, if we are aware of an agent might also be used to infer the content probabilities # refr. [SEP] phenomena related to [SEP] phenomena [SEP]", "cit": "the use of bayesian networks in the interpretation and generation of dialogue was also investigated by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr use a probabilistic model with syntactic trees to score sentences. [SEP] documents. [SEP] documents. [SEP] the extractive compression algorithm. [SEP] the [SEP]", "cit": "to date, most top - performing systems for multi - document summarization? whether queryspecific or not? remain largely extractive : their summaries [SEP]"}
{"pre": "in addition to the pos tags, we also use stanford corenlp suite # refr. [SEP] features. [SEP] the documents by preprocessing. [SEP] [SEP]", "cit": "then minipar # otherefr is used to parse english corpora, and standford parser # refr is used for chinese 4http : / [SEP]"}
{"pre": "this algorithm adjusts the algorithm of # refra ), which is a formalism that allows word order to be built upon the direct objects [SEP] if", "cit": "lexicalist approaches to mt, particularly those incorporating the technique of shake - and - bake generation # refr, combine the linguistic advantages of [SEP]"}
{"pre": "in a promising approach to cross - lingual model training data is presented in # refr. [SEP] the source language sentence to be integrated clean [SEP] [SEP]", "cit": "bilingual word representations have been presented by # refr and sumita # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in section 2, we focus on the work of # refr and matsuzaki et al # otherefr. [SEP] this by the application of", "cit": "although the parser is not yet complete, we expect that its breath of coverage of the language will be substantially larger than that of other government - [SEP]"}
{"pre": "we used the same mt evaluation metrics as the french - english meteor metric # refr, ter # otherefr. [SEP] the [SEP] the [SEP] [SEP]", "cit": "bleu 1. 04 # otherefr and meteor 0. 6 # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in recent years, supertags have been successfully applied to a wide variety of nlp tasks, including pos tagging # otherefr, [SEP]", "cit": "specifically related to this paper are works that exploit syntax # otherefr ; # refr and ensemble methods # otherefr ) to wsd [SEP]"}
{"pre": "we used the tokyo tagger # refr to pos tag the english tokens, and generated translation models. [SEP] - bfgs as the english [SEP] [SEP]", "cit": "different decomposition orders have been used in part - of - speech tagging and named entity recognition # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we also use the parser described in # refr as a source of unlabeled data. [SEP] a word order maximum entropy model, trained on the length [SEP]", "cit": "additionally, we include 256 word - cluster features # refr trained on a large amount of unlabeled monolingual text # otherefr. [SEP] [PAD] [PAD]"}
{"pre": "# refr use a similar method for part - whole relations. [SEP] patterns ( applied to meronymy ). [SEP] part - whole [SEP] ( pos", "cit": "substantial research exists on the learning of hyperonymy relations # otherefr ; # refr and selectional preferences # otherefr ; o [SEP]"}
{"pre": "# refr used the same dataset and expanded on the original analysis of an article. [SEP] article. [SEP] article ( to determine, henceforth [SEP] [SEP]", "cit": "identification of such sequences will enable us to assign functions to particular sections of contiguous text in an article, in much the same way that text segmentation [SEP]"}
{"pre": "for example, the main idea in # refr, is that a unification can be used by an arbitrary feature in the context of a cfg", "cit": "earlier versions of the partition fbrmalism could not ( in practice ) cope with multiple lexical charactors in sc ru les, see # [SEP]"}
{"pre": "in addition, we evaluate our system on the conll shared tasks on multilingual dependency parsing # refr. [SEP] this paper, we presented [SEP] [SEP]", "cit": "data - driven dependency parsing has recently received extensive attention in the parsing community and impressive results have been obtained for a range of languages # refr. [SEP]"}
{"pre": "for example, de felice and # refr make use of the prepositions. [SEP] the former one of the latter language. [SEP] [SEP] [SEP]", "cit": "eegolofsson and knutsson # otherefr used rule - based methods to approach the problem of discovering preposition and determiner [SEP]"}
{"pre": "because of this variation, researchers have explored automatic methods for learning whether, or the degree to which, an mwe is compositional # otheref [SEP]", "cit": "predominant sense identification is a useful component of sense disambiguation of word tokens # refr, and we presume our vpc type classification work will [SEP]"}
{"pre": "there have been several approaches for pos tagging in semi - supervised # otherefr ; # refr and lemmatization # otherefr. [SEP] [SEP]", "cit": "# refr apply lp to the problem of tagging for domain adaptation. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, the pos tags of this feature space can be viewed as common when conversational speech # otherefr ; # refr. [SEP] [SEP]", "cit": "a series of papers has followed the mold of? nlp for twitter,? including pos tagging # otherefr, dialog modeling # refr [SEP]"}
{"pre": "these include hierarchical models # otherefr ; # refr. [SEP] - order features # otherefr, which capture a reordering problem as a", "cit": "the main motivation for using higher order features thus comes from a related work on parsing # refr where the performance of a state of the art parser [SEP]"}
{"pre": "for example, the message understanding conference on natural anguage, generation systems # refr can be used to generate user utterances in a system that [SEP] [SEP]", "cit": "the idas project of # refr served as a key motivation for this work. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "reordering rules are defined over this parse either through machine learning techniques # otherefr ; # refr or linguistically motivated manual rules # other [SEP]", "cit": "reordering rules are defined over this parse either through machine learning techniques # otherefr ; # refrb ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in such cases, neither global features # refr nor aggregated contexts # otherefr can help. [SEP] the reranking [SEP] the weights [SEP] [SEP]", "cit": "various algorithms have been applied for reranking in nlp applications # otherefr ; # refr, including parsing, name tagging and machine [SEP]"}
{"pre": "the parser is trained with the discriminative loglinear model # refr, and achieves comparable performance with much higher than the current supertagger # otheref", "cit": "however, a very large amount of memory is still needed to store the packed charts for the complete training data even though the representation is very compact [SEP]"}
{"pre": "the approach has been shown to give improvements over the map classifier in many areas of natural language processing including automatic speech recognition # otherefr, [SEP]", "cit": "2. 6. 2 lmbr decoding minimum bayes - risk # otherefr over the full evidence space of the 5 - gram rescored [SEP]"}
{"pre": "in multi - document summarization, extraction has been successfully applied to a number of natural language processing tasks, such as named entity recognition # otheref", "cit": "in particular, an approach from the literature based on atomic events # refr is compared to a novel approach based on generic relation extraction # otheref [SEP]"}
{"pre": "we use the giza + + toolkit # refr to learn model 4. 5? 0. [SEP] the suffix array. [SEP]? en and [SEP]", "cit": "it compares favorably with conventional phrase - based translation # refr on chinese - english news translation # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use a statistical parser # refr trained on the collins parser # otherefr. [SEP] lnln markovisation. [SEP] kernel # otheref [SEP]", "cit": "world knowledge axioms can also be easily derived by processing the gloss # otherefr. a. 1 semant ic and logic t rans format [SEP]"}
{"pre": "most of the existing approaches that use classifiers that rely on linguistic features, including syntactic features # otherefr ; # refr, have been in [SEP]", "cit": "following past literature # refr, we call these topical phrases as aspects. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the case of machine translation, we tested the generation process, by comparing the rankings to a single automatic metric, as measured by bleu #", "cit": "system output was evaluated automatically, using the bleu modified precision score # refr with the human - written text as reference. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, we aim to take advantage of an adapt the application of full wsd system to be considered within the same language ( [SEP] [SEP] [SEP]", "cit": "other all - words wsd systems for biomedical documents are unsupervised and do not have as high accuracy as supervised approaches, e. g. # [SEP]"}
{"pre": "in addition, the regular distance distortion model is defined by the reordering model of # refr. [SEP] the orientation to a phrase pair [SEP] a [SEP]", "cit": "a reordering model in the framework of weighted finite state transducers is described in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "there has been previous work that simultaneously explored rationales for learning and sentiment classification # otherefr ; # refr. [SEP] the text classification problem [SEP]", "cit": "1http : / / projects. yisongyue. com / svmsle / a natural approach to avoid the pitfalls associated with cascade [SEP]"}
{"pre": "in a similar approach, # refr use a clustering algorithm as a prior to obtain the presence of conceptual classes. [SEP] this similarity so that [SEP] the", "cit": "the data were annotated with coarse - grained senses which were obtained by clustering senses from the word - net 2. 1 sense inventory based on [SEP]"}
{"pre": "minimum bayes risk rescoring : in this system, we re - ranked the n - best output of our baseline system using minimum bayes risk # [SEP]", "cit": "may and knight # otherefr extract nbest lists containing unique translations rather than unique derivations, while # refr use the minimum bayes risk [SEP]"}
{"pre": "meanwhile, some learning algorithms, like maximum likelihood for conditional log - linear models # otherefr, require summing over the scores of the [SEP] [SEP]", "cit": "meanwhile, some learning algorithms, like maximum likelihood for conditional log - linear models # otherefr, unsupervised models # refr, and models with [SEP]"}
{"pre": "previous work has shown that it is useful to adapt the generated output to certain features of the dialogue context, for example user preferences, e. [SEP]", "cit": "in a previous proofof - concept study # refr we show that each of these strategies has its own strengths and drawbacks, dependent on the particular [SEP]"}
{"pre": "in addition to the mt - based method, researchers have also investigated other methods for paraphrase extraction, such as the pattern - based methods [SEP]", "cit": "paraphrases are important in plenty of natural language processing # otherefr, machine translation ( mt ) # refr, multi - [SEP]"}
{"pre": "# refr, for example, show that incorporating higher - order predictions, in a sentence plan to produce a vectors ( e. g. [SEP] [SEP]", "cit": "instead of vector space representations, one could also use a matrix space representation with its much more expressive matrix operators # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use mxpost tagger # otherefr and parsed with charniak parser # refr. [SEP] ( 1 ) a similarity measure [SEP]", "cit": "we also used the following resources : the charniak parser # refr to carry out the syntactic analysis ; the wn : : similarity package # [SEP]"}
{"pre": "lattices and forests can also be used in minimal error rate training and minimum bayes risk decoding phases # otherefr ; # refr. [SEP]. [SEP]", "cit": "ing chinese word segmentation alternatives # otherefr and so on in the decoding process, minimum bayes risk decoding # refr, minimum error rate training [SEP]"}
{"pre": "model f - score # otherefr 84. 4 model f - score # refr 62. 4 model f - score # otherefr 86", "cit": "model f - score # otherefr 86. 9 feature - lda # refr 85. 5 1 - layer - lda # otherefr [SEP]"}
{"pre": "we use the stanford pos tagger # refr for english. [SEP] english pos tagger. [SEP] a tool trained tagger? [SEP] [SEP] [SEP] [SEP]", "cit": "we employ the stanford pos tagger # refr to tag the english side of the parallel data and then project the label to the target side. [SEP]"}
{"pre": "this idea has been successfully used in many nlp tasks, such as pos tagging # otherefr and parsing # refr. [SEP] [SEP] [SEP] [SEP]", "cit": "this idea has been applied to constituency parsing, for example in # refr, and we describe below a simple variant for dependency parsing similar to [SEP]"}
{"pre": "in fact, many approaches have been developed to jointly model structure and sentiment analysis # otherefr ; # refr. [SEP] this work has been [SEP]", "cit": "we therefore use a cascaded classification algorithm to address this problem # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the penn treebank # refr has more than a hundred phrase structure treebank, and a syntactic relationship also be found in a syntactic relationship between different", "cit": "the switchboard # refr corpus contains transcriptions of spoken, spontaneous conversation annotated with phrase - structure trees. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "it has been applied to many natural language processing tasks, such as dependency parsing # otherefr ; # refr, and dialogue processing # other [SEP]", "cit": "recently, several models have been proposed regarding phrase # otherefr, while an approach towards addressing the issue of semantic compositionality is presented in [SEP]"}
{"pre": "traditionally, parallel corpora have been a mainstay of multilingual parsing # otherefr ; # refr. [SEP] this approach is [SEP] [SEP] [SEP]", "cit": "an alternative approach is to directly employ a non - lexicalized parser trained on one language to process a target language # otherefr ; s [SEP]"}
{"pre": "most of the previous research on englishto - german translation, which is described in # refr. [SEP] the approach of koehn et al.", "cit": "following # refr, we assign each training sentence pair a set of binary features which we call s - features : t ( e | f ) [SEP]"}
{"pre": "previous work has focused on predicting twitter on a variety of tasks, including predicting movie reviews # otherefr, and news articles # refr. [SEP]", "cit": "our time series - inspired regularizer is computationally efficient in learning and is a significant advance over earlier text - driven forecasting models that ignore the time [SEP]"}
{"pre": "we can also use thesaurus construction # refr, where the senses of a word are senses and the subjectivity in a distributional similarity measure [SEP]", "cit": "# refr propose an approach to acquiring predominant senses from corpora which makes use of the category information in the macquarie thesaurus # other [SEP]"}
{"pre": "in contrast, in # refr,? 6, we show that the model yields higher accuracy on a standard set of features using a bigram features", "cit": "when examples are labeled automatically, through user feedback # otherefr or from textual pseudo - examples # refr, faster learning can reduce the lag [SEP]"}
{"pre": "the wordnet : : similarity package # refr implements a measure of relatedness between pairs of concepts. [SEP] the umls of concepts. [SEP] the uml", "cit": "table 1 : umls : : similarity measures type citation name similarity # otherefr lesk # refr vector terminology that is used for indexing [SEP]"}
{"pre": "# refr used a similar strategy to maximize the expected bleu score of the english part of the english part ( figure 4 ). [SEP] the likelihood", "cit": "undirected scores ignore polarity of parentchild relations # otherefr ; # refr, partially correcting for some effects of alternate analyses ( e. g [SEP]"}
{"pre": "in section 3, we show how existing ones like the cfg - based pcfg models # otherefr ; # refr, and [SEP] [SEP]", "cit": "hpsg # otherefr and tag # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "figure 1 : dependency tree for an english sentence ( nonprojective dependency trees ), and # refr. [SEP] empty nodes to empty nodes [SEP] if", "cit": "finally, since non - projective constructions often involve long - distance dependencies, the problem is closely related to the recovery of empty categories and non - [SEP]"}
{"pre": "in the second stage, we applied the conll 2009 shared task to dependency parsing by # refr, a pos tagger for english and a french", "cit": "in addition, a number of different transition systems have been proposed, in particular for dealing with non - projective dependencies, which were beyond the scope [SEP]"}
{"pre": "there has been a lot of interest in recent years on? normalization? of social media such as twitter, but that work defines normalization much more [SEP]", "cit": "# refr, pennell and liu # otherefr focused on modeling word abbreviations formed by dropping characters from the original word. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "in # refr, the dso corpus is reduced to a domain adaptation setting. [SEP] ( las ) is considered to be pure structural independence assumptions based", "cit": "to date, a thorough study of the domain dependence of wsd - - in the style of other studies devoted to parsing # refr - - [SEP]"}
{"pre": "for example, in the system of # refr, we plan to continue the promising preliminary research on the scfs that essentially the [SEP] dictionary comp [SEP]", "cit": "several substantial machine - readable subcategorization dictionaries exist for english, either built largely automatically from machine - readable v rsions of [SEP]"}
{"pre": "in # refr, we proposed to use a more sophisticated rulebased log - linear model, which is shown to be effective for decoding. [SEP] the", "cit": "from this point, our work is related to context - dependent translation # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "previous work has studied and used citation sentences in various applications such as : scientific paper summarization # otherefr ; # refr, automatic summarization", "cit": "other previous studies have used citing sentences in various applications such as : scientific paper summarization # otherefr ; # refr ; abu [SEP]"}
{"pre": "# refr proposed a method for ordering the probability of a sentence as a direct classification task. [SEP] the ordering of modifiers [SEP] adjoining", "cit": "as for estimating word order in english, a statistical model has been proposed by shaw and hatzivassiloglou # refr. [SEP] [PAD]"}
{"pre": "# refr and stein et al. # otherefr keep the grammar of the non - terminals of the hierarchical model of galley et al.", "cit": "# refr attempts to address this by efficiently estimating the score over an equivalent unlabeled derivation from a target syntax model. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the following decade, great success in terms of parse disambiguation and even language modeling was achieved by various lexicalized pcfg models # other [SEP]", "cit": "hence, state - of - the - art parsers either supplement the part - of - speech # otherefr, manually split the tags [SEP]"}
{"pre": "in contrast, in # refr, a phrase - based statistical machine translation system is modeled as a sequence - based monotone search problem. [SEP] the source", "cit": "however, if the phrase almmlkp almthdp is not in the phrase dictionary, it will not be translated correctly by a [SEP]"}
{"pre": "we use a conditional random field # otherefr and a crf tagger # refr trained on the entire training data and tested on the tagged [SEP]", "cit": "the sequential classification approach can handle many correlated features, as demonstrated in work on maximum - entropy # otherefr ; # refr and a variety [SEP]"}
{"pre": "we show that the unsupervised parsers achieved good results on this task, using an incremental parser # refr and a combination of unsupervised pos tagging model [SEP]", "cit": "5other types of learning methods have been employed successfully, for example, venkataraman # otherefr and # refr. [SEP] [PAD] [PAD]"}
{"pre": "# refr use a directed graphical model for role labelling in verbnet, trained on propbank and nombank. [SEP] arguments. [SEP] arguments. [SEP]", "cit": "unfortunately, pioneering work in unsupervised srl # otherefr ; # refr currently either relies on a small number of semantic roles, or [SEP]"}
{"pre": "a similar algorithm for parsing is described by # refr. [SEP] this algorithm could be used for parameter estimation, but the or in nlp [SEP] [SEP]", "cit": "the role of supervision is to permit some constituents to be built but not others # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in tempeval # otherefr ; # refr. [SEP] the sequence labeling problem in natural language processing. [SEP] [SEP] [SEP] [SEP] [SEP] pairs of", "cit": "one possible solution for the challenge is to check global consistency among classified relations such as # refr and chambers and jurafsky # otherefr [SEP]"}
{"pre": "the most common approach to handling the unbounded nature of the parse histories is to choose a pre - defined set of features which can be unambiguously derived [SEP]", "cit": "stochastic parsers for english trained on the penn treebank have peaked their performance around 90 % # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use significance of the results in bleu score as described in # refr. [SEP]. [SEP] ( p1 | s ) [SEP] ( s [SEP]", "cit": "following # refr, we use the bootstrapresampling test to do significance testing. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "among these, transformationbased learning has been applied to a wide variety of tasks, including part - of - speech tagging # otherefr, segmentation", "cit": "it has been applied to a wide variety of tasks, including part of speech tagging # otherefr, dialog act tagging # refr, segmentation [SEP]"}
{"pre": "we used nltk # refr for pos tagging. [SEP] the current english pos tagger. [SEP]. [SEP] the [SEP] [SEP] [SEP] [SEP] [SEP] the [SEP]", "cit": "3. 2. 1 resources the swat - e system used the english web1t 5 - gram corpus # otherefr, ro [SEP]"}
{"pre": "for example, gatica et al. # otherefr introduce sfs of agreement / disagreement and # refr consider / e. g. [SEP]", "cit": "this problem was previously studied # otherefr ; # refr, using a subset of icsi meeting recording corpus # otherefr. [SEP] [PAD]"}
{"pre": "in this paper, we use svms as the output of a boosting algorithm # otherefr, and # refr2 ). [SEP] features [SEP]", "cit": "these features are organized as a tree structure and are fed into a boosting - based classification algorithm # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper we evaluate the inferred dependency parser on the english ( sd ), and compare dependency treebanks with a different treebanks [SEP]", "cit": "the sd representation proved useful in a range of downstream tasks, including textual entailments # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we borrow ideas from both k - best parsing # otherefr and forest - to - string decoding # refr. [SEP] the [SEP] [SEP] [SEP] [SEP]", "cit": "we borrow ideas from the inside - outside algorithm # otherefr ; # refr to compute the merit. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr presented a layer over the phrase - based model, allowing for learning a rule as a derivation problem. [SEP] it [SEP] it [SEP] it [SEP]", "cit": "other approaches that explored such models in syntax - based systems used mtus for sentence level reranking # otherefr and in target language [SEP]"}
{"pre": "in recent years, sense ambiguity has been found to be more reliable than being one sense per discourse # refr. [SEP] the sense of the word in", "cit": "recently, # refr proposed the english lexical substitution task # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "machine learning - based classifiers are applied to coreference resolution # otherefr ; # refr. [SEP] this problem in a text. [SEP] [SEP] [SEP]", "cit": "# refr exploit an effective feature of gender and number to a pronoun resolution system and improve the performance significantly, which is also appeared in our feature [SEP]"}
{"pre": "recent work projects in nlp include part - of - speech tagging # otherefr, and machine translation # refr. [SEP] [SEP] dictionaries [SEP]", "cit": "most researchers typically run model 1 for five iterations or fewer, and there are few experiments in the literature on its behavior over many iterations, as [SEP]"}
{"pre": "we use the method of # refr, which has been successfully used in verb clustering. [SEP] the induced word sense disambiguation task # otherefr", "cit": "spectral methods applied to linguistic networks have been used to differentiate languages # otherefr, word - classes # refr and genres of text # [SEP]"}
{"pre": "like the current syntactic parser, we use svm - light # refr for automatic discourse analysis. [SEP] the current discourse parser, based on [SEP] [SEP] [SEP]", "cit": "even though discourse parsing at the document - level still poses a significant challenge to data - driven methods, sentence - level discourse models ( e. [SEP]"}
{"pre": "in addition to the standard wsd formulation, we also ran the use of log - linear models as a baseline for a baseline wsd, with", "cit": "maximum entropy estimation for translation of individual words dates back to berger et al # otherefr ; # refra ; carpuat and wu [SEP]"}
{"pre": "we are aware of only limited resources for the framenet corpus ( see # refr for our experiments. [SEP] this paper ) [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "for german, there exists a fully annotated corpus with semantic frames # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for the experiments in the corpus, we use the averaged perceptron algorithm # refr. [SEP] ( 1 ) returns an averaged perceptron model which is", "cit": "these two taggers represent the current state of the art on the penn treebank wall street journal ( wsj ) corpus, for models trained [SEP]"}
{"pre": "in addition, an nlp - based language model ( csl ) which is based on code by # refr. [SEP] the [SEP] [SEP] [SEP] [SEP]", "cit": "for instance, # refr describe the plans of the mirto project to support? gap - filling? and? lexical spotting? exercises in [SEP]"}
{"pre": "in contrast, lexas uses supervised learning from tagged sentences, which is also the approach taken by most recent work on wsd, including # [SEP]", "cit": "corpus - based word sense disambignation algorjthm ~ such as ( ng and # refr relied on supervised learning fzom annotated corpora [SEP]"}
{"pre": "the duluth systems relied on the gloss vector measure of semantic relations # refr as defined in wordnet 2. 0 international conference on [SEP] [SEP] [SEP]", "cit": "we computed these measures as described in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr use a seed corpus and show that a particular topic - based topic coherence for multi - word distributions over topics. [SEP] features, [SEP] the", "cit": "the seeded lda, a variant of lda, attempts to address this problem by incorporating the seed words as priors over the topics # refr. [SEP] [PAD]"}
{"pre": "# refr created a manually annotated corpora for subjectivity lexicon, verb + lexicon. [SEP] dictionary. [SEP] subjectivity lexicon. [SEP] lexicon. [SEP] subject", "cit": "they use the opinion finder lexicon # refr and two bilingual english - romanian dictionaries to translate the words in the lexicon. [SEP] [PAD] [PAD]"}
{"pre": "previous work on nlg systems that address more than one user group employs different versions of a system for each different user group # otherefr [SEP]", "cit": "our previous work showed that when comparing rl and supervised learning in the context of student feedback generation, students preferred the output generated by the rl system [SEP]"}
{"pre": "crowdsourcing can allow inexpensive and rapid data collection for various nlp tasks # otherefr ; # refr. [SEP] the assumption of [SEP] [SEP]", "cit": "crowdsourcing is becoming a popular mechanism to collect annotations and other type of data for natural language processing research # otherefr ; # refr [SEP]"}
{"pre": "the penn treebank # refr was used to extract the grammars from the english treebank # otherefr. [SEP] annotations to english and german.", "cit": "the wsj grammar covers the upenn wall street journal ( wsj ) treebank sentences # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we finalized two versions of the data : blogt, tagged with the stanford tagger # otherefr ; # refr, 6 and [SEP]", "cit": "6http : / / nlp. stanford. edu / software / stanford - postagger - 2008 - 09 - 28. tar. g [SEP]"}
{"pre": "still, it is in our next plans and part of our future work to embed in our model some of the interesting wsd approaches, like [SEP]", "cit": "this method was preferred against other related methods, like the one introduced in # refr, since it embeds all the available semantic information existing in [SEP]"}
{"pre": "in addition to textual information, prosodic features were used in the dialogue segmentation model of # refr. [SEP] text spans in topic segmentation [SEP] text [SEP] tasks", "cit": "these include algorithms based on lexical cohesion # refr, as well as models using annotated features # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "previous work has noted that distinguished relations, such as np chunking # otherefr, and relation extraction # refr. [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "the first two datasets were collected from the web, and made available by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the k - best parses have been extensively used in parsing experiments on the charniak parser # refr. [SEP] the [SEP] [SEP] [SEP] the [SEP]", "cit": "they apply this method to the # refr parser to get 50 - best lists for reranking, yielding an improvement in parsing accuracy. [SEP] [PAD]"}
{"pre": "the accuracy of adjective is on web as a noun - ordering task # otherefr ; # refr. [SEP] the [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "finally, we scan the web ngrams corpus in a batch approach similar to # refr and collect frequencies of all our phrase queries. [SEP] [PAD]"}
{"pre": "a growing body of work in this field employs distinct techniques from a wide variety of perspectives from text - to - record alignment using structured classification # [SEP]", "cit": "a growing body of work in this field employs distinct techniques from a wide variety of perspectives from text - to - record alignment using structured classification # [SEP]"}
{"pre": "in japanese, the unknown word is modeled by using a japanese morphological analyzer # refr. [SEP]a )? b. [SEP] l [SEP] l [SEP] [SEP]", "cit": "one is to find unknown words from corpora and put them into a dictionary # otherefr ; # refr ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr used a loglinear model based on multiword expression and distributional features to assign named entities. [SEP] the internal structure of tweets. [SEP] the", "cit": "for ner, we do not have access to carefully annotated twitter data for training, but rely on the crowdsourced annotations described in # refr [SEP]"}
{"pre": "we will show in the case of a supervised ( temporal structure ) approach, a string - to - tree model of the systems [SEP] it captures the", "cit": "263 ), or a constrained synchronous pcfg # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "leveraging information from one language for the task of disambiguating another language has received considerable attention # otherefr ; # refr. [SEP] [SEP] [SEP]", "cit": "first, from the modeling perspective, we present a generalization of the ln prior of cohen et al # otherefr, showing how to extend [SEP]"}
{"pre": "it is an online training algorithm and has been successfully used in many nlp tasks, including pos tagging # otherefr ; # refr. [SEP]", "cit": "there are also some efforts that totally or partially resort to manual transformation rules, to conduct treebank conversion # otherefr ; # refr, [SEP]"}
{"pre": "in addition, the data partition to the training and test data were used for training and testing in the shared task on joint word alignment and translation [SEP]", "cit": "for example, # otherefr shared task on word alignment # refr, and was used frequently thereafter # otherefr for chinese and english [SEP]"}
{"pre": "the third experiment was designed to achieve the results that occur in the context of the carmel - 892 project # refr. [SEP] system [SEP] [SEP]", "cit": "the first method, carmel, provides combined syntactic and semantic analysis using the lcflex syntactic parser along with semantic constructor functions # refr. [SEP]"}
{"pre": "the use of concept - learning to classify terms has been referred to as distributional similarity # otherefr and word sense disambiguation # refr ),", "cit": "some researchers have also worked on reorganizing, augmenting, or extending semantic concepts that already exist in manually built resources such as wordnet # [SEP]"}
{"pre": "there have been two general lines of research : the first one derives the nc semantics from the semantics of the nouns it is made of # other [SEP]", "cit": "for instance, grefenstette # otherefr for adjective - noun, noun - noun and verb - object bigram discovery, [SEP]"}
{"pre": "in the english language, this approach has been taken by the success of the pseudo - projective parsing # refr. [SEP] the [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "second, we annotate the sl portions, i. e., the german and english texts, with maltparser dependency parsers # [SEP]"}
{"pre": "in hierarchical phrase - based translation # refr, discontinuous phrases with terminal symbols is induced. [SEP] the model? s shiftreduce ( m [SEP] [SEP] [SEP]", "cit": "in standard phrase - based translation with continuous phrases only and left - to - right hypothesis generation # otherefr ; zens and # refr [SEP]"}
{"pre": "this sparked intensive research on unsupervised acquisition of entailment rules # otherefr ; # refr. [SEP] distributional similarity between templates [SEP] [SEP] [SEP] [SEP]", "cit": "some works focused on learning rules from comparable corpora, containing comparable documents such as different news articles from the same date on the same topic # refr [SEP]"}
{"pre": "in fact, some studies have been shown to improve the performance of word sense disambiguation # otherefr ; # refr ). [SEP] the [SEP]", "cit": "# refr demonstrates that manual mappings can be created for a small number of words with relative ease, but for a very large number of words the [SEP]"}
{"pre": "the main thrust of this move toward structured, finegrained information extraction falls under the heading of event extraction # otherefra ; # refr. [SEP]", "cit": "while we could thus not directly assess interannotator consistency, we note that our recent comparable efforts have been evaluated by comparing independently created annotations [SEP]"}
{"pre": "this idea has been developed and applied to a wide variety tasks, including morphological analysis # otherefr ; # refra ; de [SEP] [SEP] [SEP]", "cit": "# refr tackle a special case of morphology matching by identifying redundant distinctions in the morphology of one language compared to another. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the higher - order models, the parts consist of arcs together with some context, e. g. the parent or the sister arcs # [SEP]", "cit": "accordingly, existing graph - based dp models can be categorized into tree groups, namely, the first - order # otherefr ; # refr [SEP]"}
{"pre": "# refr, on the other hand, can be viewed as a unification formalism that allows to encode interpretations such as the representation. [SEP] ( [SEP]", "cit": "see # otherefr and # refr for a thorough discussion. # otherefr suggests that the way to overcome this problem is to use [SEP]"}
{"pre": "the bleu # refr all used as the n - gram precision and recall. [SEP] a higher n - gram language model. [SEP] the ble [SEP]", "cit": "a common criterion to optimize the coefficients of the log - linear combination of feature functions is to maximize the bleu score # refr on a development [SEP]"}
{"pre": "we use the cdec decoder # refr with bidirectional grammars automatically learn reordering based on the reordering of the translation. [SEP]. [SEP] the order", "cit": "for translation experiments, we used cdec # refr, a fast implementation of hierarchical phrase - based translation models # otherefr, which represents [SEP]"}
{"pre": "# refr used a bayesian approach to unsupervised dependency parsing that can be used in a monolingual setting. [SEP] effort to provide a graph [SEP] effort to", "cit": "we show that for three leading unsupervised parsers # otherefr ; # refr ; spitkovsky et al, 2010a ), a [SEP]"}
{"pre": "we build a two transliteration mining system # refr that performs named entity recognition. [SEP]. [SEP]. [SEP] features [SEP] the [SEP] [SEP] [SEP] [SEP]", "cit": "the two best teams on the english / russian task presented various extraction methods # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr. [SEP] agreement / disagreement in part - of - speech ( pos ) tagging consists of about two annotators [SEP] sentences [SEP] [SEP] [SEP] [SEP]", "cit": "the full data set contains 14, 619 items and is described in further detail in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this task has been approached by investigating methodologies for identifying meaningful topics through semantic coherence # otherefr ; # refr and for characterization. [SEP] [SEP]", "cit": "this example demonstrates that although most approaches # otherefr ; # refr advocate extracting phrase - level topic labels from the text segments, topically [SEP]"}
{"pre": "we parse the english side of the parallel corpus with the berkeley parser # refr, trained on the german treebank, and performed french by [SEP] [SEP]", "cit": "the english half of the parallel data was parsed using egret which is a re - implementation of the berkeley parser # refr. [SEP] [PAD] [PAD]"}
{"pre": "for example, # refr proposed a method to deal with a grammar by introducing the grammar based on a probability distribution p ( t, [SEP] ) [SEP]", "cit": "however, there are a number of other search algorithms that have been proposed for tree - based translation in general # otherefr ; # refr [SEP]"}
{"pre": "corpus - based methods have usually been applied to obtain domain - specific polarity lexicons : they have been created by either starting from a seed list [SEP]", "cit": "however, there are well known lexicons which have been fully # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in contrast to the c & c system # refr, our head - driven phrase - based system is a probabilistic system that is [SEP] [SEP], [SEP]", "cit": "stat - xfer has been used as a platform for developing mt systems for hindi - to - english # otherefr, chinese - [SEP]"}
{"pre": "twitter also provides a wealth of user dialog, and a variety of dialog acts have been observed # otherefr and predicted # refr. [SEP] [SEP]", "cit": "for learning response - generation models, we use a corpus of roughly 1. 3 million conversations scraped from twitter # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "if we add the syntactic features extracted from the source sentences as features, target and tokenized the source sentence to a new decoder # refr. [SEP]", "cit": "good results in qe have been achieved by adding linguistic information such as shallow parsing, pos tags # otherefr ; # refr as features. [SEP]"}
{"pre": "derivation information ultimately comes from the phrase table in phrase - based systems # otherefr ; # refr. [SEP] the local features [SEP] the local context", "cit": "lexicalized distortion models # otherefr ; # refr ; xiong et al2006 ; galley and manning, 2008 ; ) [SEP]"}
{"pre": "iii and marcu, 2006 ; # refr. [SEP] a document collection problem in which multi - document summarization and sentence topic allocations are utilized [SEP]", "cit": "2note that sentence extraction does not solve the problem of selecting and ordering summary sentences to form a coherent there are several approaches to modeling document content [SEP]"}
{"pre": "most of the previous work on paraphrase identification # otherefr ; # refr, focuses on the local context of the problems. [SEP] sentences", "cit": "at the phrasal level, interchangeable patterns # otherefr ; # refr or inference rules # otherefr are extracted. [SEP] [PAD] [PAD]"}
{"pre": "we use a simple approach to named entity recognition # refr. [SEP] features derived from the features we used in our biograph rerank features [SEP] features", "cit": "machine learners are widely used in biomedical named entity recognition and have outperformed the rule based systems # otherefr ; # refr. [SEP] [PAD] [PAD]"}
{"pre": "# refr used a graph model to extract co - occurrence patterns between nouns. [SEP] patterns and nouns. [SEP] ( 1 ). [SEP] [SEP] [SEP] [SEP]", "cit": "when applied to the whole of the bnc, these links can be aggregated to form a graph with 99, 454 nodes ( nouns ) [SEP]"}
{"pre": "the smt system was tuned on the development set newstest10 with minimum error rate training ( mert ) # refr using the bleu [SEP]", "cit": "then the procedure is quite standard : we run giza + + # refr for bi - directional word alignment, and then obtain the lexical translation [SEP]"}
{"pre": "this result was recently extended by # refr, who propose various probabilistic models of part - of - speech tagging, and it has been used previously [SEP]", "cit": "also note, that the method works only because multiple misspellings of the same word are presented in our model ; for related research see # [SEP]"}
{"pre": "in the future, we plan to apply our crf - based sequence labeling approach to other nlp tasks # refr. [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "# refr use beam search for decoding unlabeled text with soft and hard constraints, and train a model with top - k decoded label sequences. [SEP] [PAD]"}
{"pre": "in # otherefr ; # refr, people presented models that use lexical features from the phrases to predict their orientations. [SEP] the [SEP] distortion cost", "cit": "lexicalized phrase orientation models # refr predict the orientation of a phrase with respect to the last translated one. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used case frames from japanese case frames # refr for japanese and case frames. [SEP] the japanese case frames. [SEP] the japanese case frames. [SEP]", "cit": "we employ automatically constructed case frames # refr for our model of [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper, we propose a method to extract tree - to - tree reordering rules, which is based on the shift - reduce algorithm [SEP]", "cit": "there are also pre - reordering methods for longdistance reordering in svo - to - sov translations using heuristics designed based on source [SEP]"}
{"pre": "in addition to the basic idea, our joint decoder is closely related to the joint decoder # refr. [SEP]. [SEP] the [SEP] system [SEP] bleu", "cit": "finally, our work is most similar to that of # refr where max - derivation and maxtranslation decoding have been used. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "the tempeval community focused on the classification of the temporal links between events, or an event and a temporal expression ; using shallow [SEP] [SEP] [SEP]", "cit": "the tempeval community focused on the classification of the temporal links between pairs of events, or an event and a temporal expression ; using shallow [SEP]"}
{"pre": "the use of machine transliteration is important for transliteration and machine transliteration techniques # refr. [SEP] ( 1 ) [SEP] [SEP] [SEP]", "cit": "in this work we treat the process of transliteration as a process of direct transduction from sequences of tokens in the source language to sequences of [SEP]"}
{"pre": "several methods have been proposed with regard to aligning sentences # otherefr ; # refr, aljs ~ nlng words # otheref [SEP]", "cit": "several methods have been proposed with regard to aligning sentences # otherefr ; # refr and acquiring rules from bilingual corpora # otherefr [SEP]"}
{"pre": "current approaches employ various machine learning techniques for this task, such as inductive logic programming in earlier systems # otherefr ; # refr. [SEP] [SEP]", "cit": "in contrast, # refr proposed a self - supervised approach, which iteratively chose high - confidence parses to retrain the parser. [SEP] [PAD] [PAD]"}
{"pre": "in machine learning and sentiment classification, a variety of tasks involving general, such as word similarity in synonyms, to the similarity between the two words", "cit": "there are a number of related works # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "recent work by # refr shows that probabilistic data - driven parsing with lcfrs is indeed feasible and gives acceptable results # otherefra ) [SEP]", "cit": "for all our experiments, we use the markovization settings v = 2 and h = 1, which have proven to be successful in previous work [SEP]"}
{"pre": "we used mxpost # refr, and in order to extract the part of speech tags. [SEP] for the tagger of # otheref [SEP] [SEP]", "cit": "we tokenized sentences using the standard treebank tokenization script, and then we performed part - of - speech tagging using mxpost tagger [SEP]"}
{"pre": "it has been used for a variety of tasks, such as wide - coverage parsing # otherefr, and modeling syntactic ambiguity. # refr [SEP]", "cit": "therefore, it and its equivalent reformulation by # refr in a multimodal variant of ccg are not safe ( preserve all interpretations ) and complete [SEP]"}
{"pre": "in addition, several unsupervised methods have been proposed to handle the above, e. g., # otherefr ; # refr. [SEP] languages", "cit": "we evaluate 15 published summarization methods proposed in the literature and 16 methods introduced in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "tsg learning has been successfully applied to a variety of tasks, such as argument structure # otherefr ; # refr, and question answering #", "cit": "this approach extends work on learning probabilistic tree? substitution grammars ( tsgs ) # refr. 1 to model modification, we introduce a second structure [SEP]"}
{"pre": "joint models have been widely studied to enhance multiple machine learning approaches # otherefr ; # refr. [SEP] this approach by training a model that learns", "cit": "to overcome the error propagation problem associated with the pipeline architecture, several joint models have been proposed, including those that are based on mlns # [SEP]"}
{"pre": "morphological analysis has been used for improving arabic - english smt # otherefr, morphological analysis # refr, and raises the possibility of this [SEP]", "cit": "work on improving mt systems? treatment of morphology has focussed on either reducing word forms to lemmas to reduce sparsity # refr or including morphological information [SEP]"}
{"pre": "in this paper we show how nivre? s # otherefr, and the berkeley parser # refr. [SEP] mcdonald # otheref [SEP] [SEP]", "cit": "an argumentation of # refr follows a similar direction : we would like to change our [ ms ] handling of coordinating conjunctions to treat the coordinating [SEP]"}
{"pre": "in contrast, other statistical machine translation have been proposed for the task of paraphrasing ( barzilay and # refr. [SEP] the [SEP] [SEP]", "cit": "unfortunately, we have yet to incorporate into the evaluation framework previous findings in paraphrase identification and extraction # otherefr ; # refr. [SEP]"}
{"pre": "we evaluated the translation quality using bleu metric # refr. [SEP] bleu # otherefr. [SEP] the bleu metric # other [SEP] [SEP]", "cit": "we evaluate the impact of the proposed approach on translation quality as measured by the bleu score on the token level # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "dependency - tree linearizations in the last few years there has been a resurgence of interest in computation on dependency - tree structures for natural [SEP]", "cit": "there has been some recent work on dependency length minimization in natural language sentences # refr, but the relationship between the precise constraints on available linearizations [SEP]"}
{"pre": "we use minimum error - rate training # refr to tune the feature weights to maximize the system? s bleu score on development set, on the", "cit": "to perform minimum error rate training # refr to tune the feature weights to maximize the system? s bleu score on development set, we used [SEP]"}
{"pre": "# refr use an alignment model based on a log - linear model to obtain the alignments. [SEP] alignment links. [SEP] the likelihood of bilingual training data", "cit": "chen # otherefr, # refr, and the ldc alignment tool, champollion # otherefr ), the aligner [SEP]"}
{"pre": "in the algorithms presented in this paper, the model is simple segment vectors constructed by maximizing the probability of a word windowdiff # otherefr ;", "cit": "a recent study # refr on a compression - based algorithm, regularized compression, has achieved comparable performance result to hierarchical bayes methods. [SEP] [PAD] [PAD]"}
{"pre": "we evaluate the quality of bleu - 4 # refr and ter # otherefr. [SEP] the machine translation quality of the parallel [SEP] [SEP] [SEP]", "cit": "automatic evaluation to evaluate surface realization ( or, combined content selection and surface realization ), we measured the bleu score # refr ( the precision [SEP]"}
{"pre": "this approach was soon followed by other researchers # otherefr ; gi # refr. [SEP] a connective in compositional distributional semantics [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "polaris is trained using framenet # otherefr, several semeval corpora ( gi # refr ; score sentence pair notes msrp [SEP]"}
{"pre": "in # refr, the authors propose an unsupervised svm model for sentiment detection, and experiment with unigrams # otherefr. [SEP] features derived from", "cit": "recent works tried to model the sentiment in tweets # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper, we will focus on comparing the quality of the measured by bleu score # refr. [SEP] the error criterion. [SEP] [SEP] the", "cit": "? word quality? scores and other metrics firstly, we investigate the correlation between sentence - level scores ( obtained from wce labels ) and conventional [SEP]"}
{"pre": "# refr use a hierarchical reordering model with maximum entropy, which models the so that the model can lead to improved reordering better predict the system", "cit": "alternatively, # refr proposed recently using sparse features optimize the translation quality with the decoder instead of training a classifier independently. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "owing to their simplicity and good performance, extractive summarization techniques are often the preferred tools of choice for various tasks such as sentence compression # other", "cit": "there are several ways of generating an abstract sentence # otherefr ; # refr ) ; however, most of them rely heavily on the syntactic [SEP]"}
{"pre": "the analysis of the japanese web # otherefr ; # refr. [SEP] ( s ) is done using syntactic patterns to extract [SEP] features [SEP] features", "cit": "note that previous work on? demand? recognition also found similar tendencies # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use memory - based learning ( mbsl ) # refr, a memory - based learning algorithm that learns the words that can be used for its", "cit": "we used mbt version 1. 0 # refr to develop a memory - based pos tagger trained on the eindhoven corpus of written [SEP]"}
{"pre": "in order to classify documents, sentences are taken into account in binary classification # refr. [SEP] ( binary classification ) and positive [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "other examples include the conll named entity corpus # otherefr with 348 citations on google scholar ), the imdb movie reviews sentiment [SEP]"}
{"pre": "och and ney # otherefr ; h ( f, e, d ) = ( h1 ( f, e, d ) [SEP]", "cit": "since both mert and pro tuning toolkits involve randomness in their implementations, all bleu scores reported in the experiments are the average of five [SEP]"}
{"pre": "in a similar vein, # refr has been the use of statistical parsing techniques for lexicalized grammars, semantic role labeling # otheref [SEP] [SEP] [SEP]", "cit": "charniak # otherefr developed a state - of - the - art statistical cfg parser and then built an effective language model based [SEP]"}
{"pre": "lexical cues of differing complexities have been used, such as the loglikelihood # refr and the loglikelihood # otherefr. [SEP] the text [SEP]", "cit": "richmond, smith and amitay designed an algorithm for topic segmentation that weighted words based on their frequency within a document and subsequently used these [SEP]"}
{"pre": "we used the search engine queries provided by the reordering tool # refr. [SEP] the indexing # otherefr. [SEP] the expressions [SEP] [SEP] [SEP]", "cit": "# refr explores the trie data structure as an alternative to inverted indexes when indexing large - scale n - gram corpora. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, we aim to identify subtrees which can be useful for ie extraction, as we also use as features in the subtree [SEP] [SEP] [SEP]", "cit": "for instance, # refr and sekine # otherefr proposed different methods for automatic ie pattern acquisition for a given domain based on frequent subtree [SEP]"}
{"pre": "we used the modified version of the inside - outside algorithm described by # refr, with the information computed from the monolingual and [SEP] edit distance [SEP]", "cit": "applications of this algorithm include k - best parsing # otherefr ; # refr and machine translation # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used bleu? 4 # refr and meteor # otherefr to evaluate the systems. [SEP] the results in training and test cases. [SEP]", "cit": "translation quality is automatically evaluated by the ibm - bleu metric # refr ( case - sensitive, using length of the closest reference translation ) on [SEP]"}
{"pre": "we use a statistical dependency parser # refr to assign each sentence in the sentence s. [SEP] it plays a central role in the [SEP] it [SEP] it", "cit": "the most popular formalism today is markov logic, which has already been used for natural language processing tasks such as semantic role labeling # refr and core [SEP]"}
{"pre": "for instance, # refr show that the optimal ilp method improves the performance of an np - hard problem. [SEP] ( np - complete ) [SEP]", "cit": "in contrast, generic np - hard solution techniques like integer linear programming # refr know nothing about optimal substructure. bitrary interactions among [SEP]"}
{"pre": "in this paper, we expand the wikipedia articles # otherefr ; # refra ). [SEP] this method ; [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "the interlingual links have also been used for cross - lingual information retrieval # otherefr used multilingual editions of wikipedia to [SEP]"}
{"pre": "more work on trainable realisation for sdss generally includes bulyko and ostendorf # otherefr who use supervised learning, [SEP]", "cit": "in terms of surface realisation from graphical models # otherefr and dethlefs and # refrb ), who use hmms, [SEP]"}
{"pre": "the differentia can be partially interpreted relative to the rqs type of lexical entries in conjunctions # otherefr, # refr ) [SEP] (", "cit": "this also applies to our use of thematic roles in the semantics ; see the examples of lkb entries for verbs given in # refr, this [SEP]"}
{"pre": "in contrast, the performance of the named entity model, and the semi - supervised relation extraction method is still a logistic regression method based on the web", "cit": "many methods have been proposed to deal with this task, including supervised learning algorithms # otherefr, and unsupervised learning algorithm # refr. [SEP] [PAD]"}
{"pre": "# refr use a simple vector addition to vector multiplication, and a larger vector of the vectorial meaning representations. [SEP] a linear framework. [SEP] [SEP]", "cit": "we focus here on how cdsms handle determiners and the phrases they form with nouns ( determiner phrases, or dps ). 1 [SEP]"}
{"pre": "in addition, several unsupervised methods have been proposed to handle the contextual translation problem, including those which include adapting the target language model # otherefr", "cit": "from machine learning perspective, both proposed methods can be viewed as certain form of transductive learning applied to the smt task # refr. [SEP] [PAD]"}
{"pre": "we extend the inference procedure proposed by # refr for japanese semantic role labeling. [SEP] sentences containing semantic role labeling ( srl ). [SEP] the [SEP]", "cit": "a few srl studies have focused on not only verbal predicates # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "to evaluate the quality of the grammars, we use bleu # refr and ter # otherefr as optimization criterion, which we evaluate [SEP] [SEP]", "cit": "in addition, we also assessed how the system output differed from the human simpleew gold standard by computing bleu # refr and terp # [SEP]"}
{"pre": "this is useful for literature on learning from word aligned parallel corpora # otherefr ; # refr ). [SEP] the source [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "institute for logic, language and computation. belief, however, a synchronous grammar ( see e. g., # refr ) does not accept [SEP]"}
{"pre": "in ( 1 ), # refr use a machine learning algorithm that allows us to find the set of 2 bias. [SEP] unary rules. [SEP]", "cit": "# refr describe a symbolic approach which employs inductive logic programming and barg and walther # otherefr follow a unification - based approach. [SEP]"}
{"pre": "in halogen, # refr ], the task of selecting the most likely an important sentence. [SEP] a sentence while the latter is [SEP] [SEP] [SEP]", "cit": "# refr introduced nitrogen, a system that implements a new style of generation in which corpus - based ngram statistics are used in place of deep [SEP]"}
{"pre": "therefore, studies have recently resorted to other resources for the enhancement of parsing models, such as large - scale unlabeled data # otherefr [SEP]", "cit": "the second - order model using only sibling parts ( o2sib ) includes both dependency and sibling parts # refr, and needs o ( [SEP]"}
{"pre": "cross - lingual annotation projection # otherefr, information extraction # refr, srl # otherefr. [SEP] the cross - [SEP] [SEP]", "cit": "cross - lingual annotation projection # otherefr, mention detection # refr, lfg parsing # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, we have recently developed a joint model of dependency parsing, which has been shown to be useful in the conll shared tasks [SEP] this", "cit": "this includes the work of roark and bacchiani # otherefr, # refr, chelba and acero # otherefr [SEP]"}
{"pre": "in a joint model, named entity recognition and conll 2008 shared task # refr was on joint parsing and semantic role labeling [SEP] the [SEP] [SEP] [SEP]", "cit": "the sr? 11 input representations were created by post - processing the conll 2008 shared task data # refr, for the preparation of which selected [SEP]"}
{"pre": "the word - breaking colnponent of out \" system is described in # refr. [SEP]. [SEP] this approach is an idea of estimating the", "cit": "# refr, on the other hand, do not allow such manual cost manipulation and precisely for that reason, improvements in segmentation accuracy are harder to [SEP]"}
{"pre": "in particular, the problem of modeling resolution has received much attention in recent years, with lexical information # otherefr ; # refr, and [SEP]", "cit": "research in the first category aims to identify specific types of nonanaphoric phrases, with some identifying pleonastic it # otherefr [SEP]"}
{"pre": "the baseline freq? s alignment feature weights w3.? m1 are trained using minimum error rate training ( mert ) # refr.", "cit": "the pipeline extracts a hiero - style synchronous context - free grammar # otherefr, and tunes model parameters with minimum error rate training [SEP]"}
{"pre": "accept? ( terminates the parse of the sentence. pi represents the hpsg derivation of the sentence ) derivation of the hpsg parse of the sentence", "cit": "this paper presents work on the problem of probabilistic parse selection from among a set of alternatives licensed by a hand - built grammar in the context of [SEP]"}
{"pre": "in 2006, the shared task was multilingual dependency parsing, where participants were evaluated on a single parser as well as parsing of [SEP] languages # refr", "cit": "malt # refr, mst # otherefr? trained on the conll09 dataset and tested on texts from different domains in the ontonote [SEP]"}
{"pre": "in this paper, we focus on the event extraction of the events by comparing the contexts in a genre as defined in # refr :. [SEP] (", "cit": "the numerical values are proportions of the total number of verbs. back as far as, e. g., # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "this provides a new new source of linguistically - motivated features ( e. g., textual features ) has been recently applied to a wide range", "cit": "the framework, initially an extension of dualist # refr, utilises an em step to harness information from large amounts of unlabelled data, [SEP]"}
{"pre": "in this paper, we show that a model trained on a simple, and unlike many other tree - to - tree transformation, which is designed [SEP]", "cit": "we used the decoder of # refr to parse. improve the likelihood but actually hurt parsing accuracy, suggesting that the ptsg model is over [SEP]"}
{"pre": "bitpar # refr. [SEP] a probabilistic cfg parser, which generates dependency relations, based on the probabilistic context free grammars # otherefr.", "cit": "we used bitpar # refr for our unlexicalized experiments. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr used a log - linear model to identify among candidates of the top order, and train a separate model for each word model. [SEP] [SEP]", "cit": "a determiner selection program can aid in machine translation of determiner - free languages ( by adding determiners after the text has been translated ) [SEP]"}
{"pre": "we wish to apply this direct, minimal recursion systems # refr, and apply them to the single - word alignment problem. [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "several recent syntax - based models for machine translation # otherefr ; # refr can be seen as instances of the general framework of synchronous grammars [SEP]"}
{"pre": "to build such parsers, we used # refr and # otherefr. [SEP] the syntactic representations of sentences, [SEP] the syntactic [SEP] [SEP] [SEP]", "cit": "the lexicon is based on comlex # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr and guevara # otherefr focus on how well - known compositionality could be applied to noun - noun - adjective -", "cit": "several recent proposals have strived to extend distributional semantics with a component that also generates vectors for complex linguistic constituents, using compositional operations in the vector [SEP]"}
{"pre": "semantic role labeling is the process of annotating the predicate - argument structure in text with se -? this research was partially supported by the ar [SEP]", "cit": "syntactic features improve performance in high level tasks such as question answering # otherefr ; # refr, paraphrase detection # otherefr [SEP]"}
{"pre": "koehn and schroeder # otherefr ), but for phrase - tables it is unclear whether perplexity minimisation # [SEP]", "cit": "instead of weighting the out - of - domain data, some authors have investigated data selection methods for domain adaptation # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper, we learn the hidden markov model ( hmm ), and the model by leveraging information content and estimating the model [SEP] [SEP] [SEP]", "cit": "knowledge - lean approaches distributional models of content have appeared with some frequency in research on text segmentation and topic - based language modeling # otherefr [SEP]"}
{"pre": "we use the c & c named entity recogniser # refr. [SEP] this # otherefr to estimate the conditional probabilities between [SEP] [SEP] [SEP] [SEP]", "cit": "the gnome corpus was created to study the aspects of discourse that appear to affect generation, especially salience # otherefr ; # refrb [SEP]"}
{"pre": "we evaluated the translation quality using bleu - 4 # refr and ter # otherefr scores on the word level. [SEP] bleu - 4", "cit": "the translation quality is measured by three mt evaluation metrics : ter # otherefr, bleu # refr, and meteor # otherefr [SEP]"}
{"pre": "the use of continuous space representation of language has been successfully applied in recent nn approaches to language modelling # otherefr ; # refr. [SEP] this", "cit": "many different feature functions were explored in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the penn treebank ( ptb ) # refr as training and test sets for modeling the syntactic structure of constituents, and are starting to", "cit": "function label parsing although function labels have been available in the penn treebank ( ptb ) for almost twenty years # refr, they have been [SEP]"}
{"pre": "thus, the best accuracy of the application is on a sense - tagged corpus when the word are tagged with the unknown word # refr verb [SEP] [SEP]", "cit": "there are, however, approaches to the complementary problem of determining the closest known sense for unknown words # refr, which can be viewed as the [SEP]"}
{"pre": "it performs cubic time parsing for arc - factored models # otherefr ; koo and # refr. [SEP] the probability of the [SEP] [SEP]", "cit": "one popular approach is reranking # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "one common approach is to begin with unlabeled, but clustered event - specific documents, and extract common word patterns as extractors # otherefr [SEP]", "cit": "# refr presented unrestricted relation discovery to discover relations in unlabeled documents. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use a simple english lexical database # refr which is a text - to - speech ( such as x ), and then extract all the feature", "cit": "i conducted an empirical study of these systems using amazon mechanical turk3, which is being used increasingly to evaluate several systems on openended tasks for [SEP]"}
{"pre": "we use brill? s tagger # refr to pos - tag the tokens, and select the word candidates for all words ( and [SEP] [SEP]", "cit": "par t of speech tagger the text is the part of speech tagged using the brill tagger # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use a topic modeling toolkit # refr to train the models on the topics over the document set. [SEP] documents. [SEP] documents. [SEP] the frequencies", "cit": "supervised topic models jointly capture both the text and associated metadata such as a continuous response variable # otherefr or multiple labels # refr to predict [SEP]"}
{"pre": "in contrast, lexas uses supervised learning from tagged sentences, which is also the approach taken by most recent work on wsd, including # [SEP]", "cit": "current research on applying wsd to specific domains has been evaluated on three available lexicalsample datasets ( ng and # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "sentence simplification can also serve to preprocess the input of other tasks, such as summarization # otherefr, parsing, machine translation [SEP]", "cit": "because of this model rigidity, their system performed poorly on evaluation metrics that take into account the content and relative to other simplification systems # refr. [SEP]"}
{"pre": "in # refr, thesaurus extractors on the verbs is found by using the syntactic relations. [SEP] ( pmi ) and [SEP] ( [SEP]", "cit": "many domainspecific words or word senses are not included ; inconsistency and bias are often cited as further major deficiencies of hand - made thesauri [SEP]"}
{"pre": "not limited to parsing, supertags can be used for np chunking # otherefr, semantic role labeling # refr and machine translation [SEP]", "cit": "not limited to parsing, supertags can be used for np chunking # otherefr and machine translation # refr to explore rich syntactic [SEP]"}
{"pre": "this has led to the interest of probabilistic grammars for computational grammars # otherefr ; # refr. [SEP] the class - - - regular tree [SEP]", "cit": "strong generative equivalence results between lcfrs and other finite copying parallel rewriting systems have been discussed in # refr and in # otherefr. [SEP]"}
{"pre": "the chinese data was segmented using the 2008 version of the stanford chinese segmenter # refr. [SEP] stanford segmenter # otherefr [SEP] [SEP] [SEP]", "cit": "we replicate the smt pipeline of eidelman et al # otherefr : word segmentation # refr, align # otherefr the [SEP]"}
{"pre": "# refr use a bayesian model to induce a bayesian model that learns word clusters that to predict phonemes that to inflectional morphology and la #", "cit": "recent machine learning oriented work includes # refr and durrett and denero # otherefr, which documents a method to learn orthographic [SEP]"}
{"pre": "this can be done automatically with the exception of parsing # refr. [SEP] it # otherefr. [SEP] this constraint was developed by joshi and", "cit": "arguments have been made in favor of a head - driven strategy which would, however, have been marginally more complex # otherefr, # [SEP]"}
{"pre": "nivre? s parser has been tested for swedish # otherefr, english # refr, german # otherefr. [SEP]. [SEP] [SEP]", "cit": "our system can be seen as a unification of the two best - performing parsers presented at the conll - x shared task # refr [SEP]"}
{"pre": "hoffman, in her thesis # refra, hoffman, 1995b ), has proved that there is a lot of work on german \\ [ [SEP]", "cit": "again, while the former is catered for in most tactical generation systems, only selected aspects of the latter have been dealt with and only [SEP]"}
{"pre": "in an attempt to address this problem, a great deal of recent research has focused on identifying, generating, and harvesting phraseand sentence - level [SEP]", "cit": "much work on paraphrase generation has focussed on lexical variation and syntactic transformation within individual sentences # otherefr ; # refr. [SEP] [PAD]"}
{"pre": "several studies have focused on the extraction of web documents and web documents, including mining unseen # otherefr, # refr, [SEP] [SEP] [SEP]", "cit": "it should be noted that some of these papers utilize language and domain - dependent preprocessing including syntactic parsing # refr and named entity tagging # otheref [SEP]"}
{"pre": "# refr used multiple paraphrases to improve system optimization. [SEP] the model features to generate the substitutions for a log - linear model, and suggested", "cit": "in addition, # refr also generated sentence - level paraphrases based on a smt model. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition to the standard methodology, there has been a lot of body of work in this paper # otherefr ; # refr. [SEP] [SEP]", "cit": "efficiently storing such structures is an important step in integrating document - level statistics into downstream tasks, such as characterizing complex scenarios # refr, or story [SEP]"}
{"pre": "one could rely on existing trainable sentence selection # otherefr or even phrase selection # refr strategies to pick up appropriate # otherefr )", "cit": "more recently, summarizers using sophisticated postextraction strategies, such as revision # otherefr ; # refr, and sophisticated grammar - based [SEP]"}
{"pre": "# refr ). [SEP] the collaborative n - gram features, machine translation ( mt ) is a large number of language pairs, [SEP], [SEP],", "cit": "related work mturk has been used for many different nlp and vision tasks # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this has been done successfully applied in several languages such as english # otherefr, german # refr, and english # otherefr. [SEP]", "cit": "for german, we have not created a specific statistical model yet, but, instead, we have used an existing parse selection model # refr and [SEP]"}
{"pre": "the idea of using dependency triples to extract noun phrases has been successfully applied to the identification of noun - noun pairs # refr. [SEP] noun - [SEP]", "cit": "for example, # refr note that words appearing in coordination patterns tend to be on the same ontological level :? fruit and vegetables? is quite [SEP]"}
{"pre": "# refr presented a model that uses word embeddings, which could be a compact representational representational framework, and propose a probabilistic neural network. [SEP]", "cit": "with regard to wordsim353, # refr report correlations in the range of 0. 713? 0. 769, however they [SEP]"}
{"pre": "constituency parsers have advanced considerably in the last two decades # otherefr ; # refr boosted by the availability of the penn tree [SEP]", "cit": "parsing has been a major area of research within computational linguistics for decades, and constituent parser f - scores on wsj section 23 have exceeded 90 [SEP]"}
{"pre": "we used the automatically generated dependencies from # refr. [SEP] the automatically induced tag derivation trees, we used a automatically induced automatically induced tagger for the", "cit": "we use sister adjunction which is commonly used in ltag statistical parsers to deal with the relatively flat penn treebank trees # refr. [SEP]"}
{"pre": "the model is similar to the one described by # refr. [SEP]. [SEP] ( snyderk ) = p ( w ; w [SEP] [SEP] [SEP]", "cit": "experiments incorporating morphological and orthographic features into hmm based models demonstrate significant improvements. # otherefr ; # refr incorporate similar orthographic [SEP]"}
{"pre": "several approaches have been proposed to deal with multiple source single components, namely [ reranker, 2003 ] # refr ]. [SEP] the [SEP] [SEP]", "cit": "confusion network decoding was applied to combine the outputs of multiple machine translation systems # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "patterns have been proposed for relation extraction in general and relation extraction by markert and nissim # otherefr, and has also been [SEP] [SEP]", "cit": "# refr uses a manually prepared set of initial lexical patterns in order to discover hierarchical categories, and utilizes those categories in order to automatically discover additional [SEP]"}
{"pre": "we use a web - based algorithm # refr to estimate the probability of a query? s name being identified by a query definition. [SEP] the [SEP]", "cit": "on datasets from the trec 2000 and 2001 qa tracks, our earlier system clearly outperformed the methods of joho and # refr and pra [SEP]"}
{"pre": "although we are focusing on the non - compositional approach, in particular, we show that our approach can handle relations can be found in sentence ordering [SEP]", "cit": "we build on the existing insights of linguists # otherefr ; # refr ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper, we focus on the conversion between phrase - structure heterogeneous treebanks, and the other more recent works that have [SEP] linguistically", "cit": "this table indicates that human annotators strongly prefer? s? operation to others, and that the manual annotation on the prototype system is at least [SEP]"}
{"pre": "in this work, we tackle the influence of entailment relations between textual entailment ( te ) and ( ii ) recognition components, which has been", "cit": "textual entailment was proposed as a generic paradigm for applied semantic inference # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr use a word lattices to learn phrase table and reordering. [SEP] the arabic sentence in a german. [SEP] a certain sentence. [SEP] it", "cit": "# refr introduce a leave - one - out method which can overcome the over - fitting effects inherent to this training procedure # otherefr. [SEP]"}
{"pre": "several nlg systems have been proposed to adapt to sentence planning # otherefr ; # refr. [SEP] the reinforcement learning of probabilistic [SEP] [SEP] the", "cit": "reinforcement learning # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in english, pos tags were used for dependency parsing by # refr. [SEP] the mst parser # otherefr. [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "note that it is straightforward to calculate these expected counts using a variant of the inside - outside algorithm # otherefr applied to the # refr [SEP]"}
{"pre": "in addition, it is defined as a part of the system, which is trained on the twitter data set, as in # refr. [SEP] this", "cit": "in # refr, the authors report their system achieves 0. 64 to 0. 67 f1 on named entity segmentation results with 34k tokens [SEP]"}
{"pre": "nivre? s parser has been tested for swedish # otherefr, while mcdonald? s parser has been applied to english # refra [SEP]", "cit": "we applied the above two marginal - based training algorithms to six languages with varying degrees of non - projectivity, using datasets obtained from the con [SEP]"}
{"pre": "much of the previous work on sentiment analysis classifies documents by their overall sentiment # otherefr ; # refr. [SEP] the word [SEP] [SEP]", "cit": "for instance, a tweet that contains a sad face likely contains a negative polarity # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "syntactic features have been used in several studies in both machine translation and natural language processing # otherefr ; # refr. [SEP] this approach was done", "cit": "some of the above - mentioned problems have been studied before : predicting function tags were studied in # otherefr ; # refr. [SEP] [PAD] [PAD]"}
{"pre": "id institution balagur yandex school of data analysis # otherefr lia universite? d? avignon # refr limsi lim", "cit": "id institution balagur yandex school of data analysis # otherefr kit karlsruhe institute of technology # refr lia universite [SEP]"}
{"pre": "in # refr, a shallow nlg system is built using the opennlp toolkit wapiti # otherefr for german dialogue [SEP] [SEP]", "cit": "agents developed in - house were used for the early system described in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this work, we take advantage of the target - side text following sources that contain document or subjectivity, of particular, [SEP], [SEP],", "cit": "yu and # refr use semanticallyoriented words for identification of polarity at the sentence level. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the google web 1t corpus # refr to train a 5 - gram lm trained on the googleng corpus. 2m words, [SEP]", "cit": "we use the following fairly standard features in our tagger : current word, suffixes and prefixes of length 1, 2 and 3 ; [SEP]"}
{"pre": "in addition to vector distance is the well established by the treatment of word - senses # otherefr ; # refr. [SEP] the distance [SEP] the", "cit": "accurately estimating the semantic distance between concepts or between words in context has pervasive applications in computational linguistics, including machine translation, information retrieval, speech recognition [SEP]"}
{"pre": "in the last decade, the dialogue system of # refr, facial displays are well as a number of surface realisers, and [SEP] this [SEP]", "cit": "in this work, the task is to select facial displays for an animated talking head to use while presenting output in the comic multimodal dialogue [SEP]"}
{"pre": "we use the mert algorithm # otherefr, which optimize the semi - supervised learning ( mira ), a ) of [SEP] ( ii", "cit": "sorting by computing the paretofrontier has been applied to training machine translation systems # refr to combine the translation quality metrics bleu, ribes [SEP]"}
{"pre": "we use emotion detection for dialogue spoken dialogue tutoring our experiments, and spoken dialogue tutoring experiments, including both spoken dialogue tutoring spoken dialogue tutor", "cit": "in prior work we built on and generalized such research, by defining a three - way distinction between negative, neutral, and positive student emotional states [SEP]"}
{"pre": "we can think of this task as an instance of grounded semantic parsing, similar to the work in natural language generation # otherefr ; [SEP] [SEP]", "cit": "unsupervised semantic parsing ( usp ) : our final unsupervised comparison is to usp, an unsupervised deep semantic parser introduced by # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "minimum error rate training emerged a decade ago # otherefr as a superior training method for small numbers of linear model parameters of machine translation systems [SEP]", "cit": "finally, we address the issue of searching in a high - dimensional space by using the gradient of expected bleu # refr to find better search [SEP]"}
{"pre": "work in this area includes # otherefr ; # refr. [SEP] ( 1 ) a recursive neural network that learns vector rnn for multi -", "cit": "such deep connectionist architectures learn a dense, low - dimensional representation of their problem in a hierarchical way that is capable of capturing both semantic and [SEP]"}
{"pre": "in machine translation # otherefr ; # refr. [SEP] features based on unigram and bigrams, both its and [SEP] [SEP] [SEP] [SEP]", "cit": "some of these features made use of additional data and / or resources, such as a secondary id participating team prhlt - upv universit [SEP]"}
{"pre": "sentence planning \\ [ # refr \\ ] and \\ [ yier et al, 1985 \\ ] have developed that can be used to generate a sentence", "cit": "tially kpml is lexicon extended by collocational \\ [ # refr \\ ] and qualia \\ [ pustejovsky [SEP]"}
{"pre": "in this paper, the training set contains punctuation features # refr, which includes the ones went in treebank to make the annotation adaptation. [SEP]", "cit": "recently, # refr proposed an advanced annotation transformation in chinese word segmentation, and we extended it to the more complicated treebank annotation transformation used for [SEP]"}
{"pre": "in the results of the shared task on semantic role labeling, we employ the open - domain system described in # refr. [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "in the conll - 2005 shared task ( srl for english ), the best system found causal adjuncts with a reasonable accuracy of 65 [SEP]"}
{"pre": "phrase - based systems, flat and hierarchical reordering models # refr, have been introduced by explicitly modeling reorderings at consecutive words ( e.", "cit": "the system has already been used to develop a number of innovative new features # otherefr ; # refr and to build translation systems that have [SEP]"}
{"pre": "on the other hand, hockenmaier and steedman # otherefr and # refr show that their parser is hard to [SEP] [SEP]", "cit": "furthermore, extracting dependencies from a ccg derivation is well - established # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for example, the tree - based system described in # refr was designed to address the above issues. [SEP] the binarized pcfg [SEP] [SEP]", "cit": "the resulting syntactic analysis can be used for various applications such as machine translation # otherefr ; # refr, sentence compression # otherefr [SEP]"}
{"pre": "# refr and nakhi et al # otherefr have shown that semantic features for the polarity of the utterances conveys of a sentence containing [SEP]", "cit": "whereas several studies have been concerned with causal markers and their interactions with other linguistic means, for instance, vander linden and martin # otheref [SEP]"}
{"pre": "several projects have investigated unsupervised # otherefr ; # refr approaches. [SEP] the problem of learning a semantic parser, but [SEP] it [SEP] it [SEP]", "cit": "models have been developed which can handle some ambiguity in terms of which logical form is the correct label for each training sentence # otherefr ; [SEP]"}
{"pre": "thus, we extend the definition of structural correspondence learning, which is applied in its own right 3. 2the notion of dependency tree is derived from", "cit": "on the same corpus, # refr and # otherefr report f scores of 44. 5 and 47. 3, respectively. [SEP] [PAD] [PAD]"}
{"pre": "# refr developed a machine - learning approach for anaphora resolution that builds on the probabilistic context - free index set. [SEP] resolves [SEP] resolves", "cit": "consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho - syntactic or shallow semantic analysis [SEP]"}
{"pre": "we use brown clusters learned using the algorithm of # refr, and clustered cluster features together with the same feature set. [SEP] features together with the [SEP]", "cit": "# refr implement the brown clustering algorithm to produce additional features for their dependency parser. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "over the past decades, researchers have focused on the use of learning techniques for dependency parsing # otherefr ; # refr. [SEP] the constituent [SEP]", "cit": "dependency parsing is the task of building dependency links between words in a sentence, which has recently gained a wide interest in the natural language processing community [SEP]"}
{"pre": "the decoder uses a log - linear framework # refr, and minimum error rate training # otherefr. [SEP] ( mert ). [SEP] [SEP]", "cit": "furthermore, techniques such as iterative minimum errorrate training # refr as well as web - based mt services require the decoder to translate a large number [SEP]"}
{"pre": "this gives rise to dynamic programming # otherefr, as well as for parameter estimation # refr, or other algorithms # otherefr [SEP] [SEP]", "cit": "expectation semirings # refr are used to handle bookkeeping when training the parameters of a probabilistic transducer. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr used a random walk algorithm based on genetic algorithms, an n - gram language model trained on the wall street journal. [SEP] [SEP] [SEP] [SEP]", "cit": "flms have been implemented as an add - on to the widely - used srilm toolkit1 and have been used successfully for the purpose of [SEP]"}
{"pre": "syntax - based statistical machine translation # otherefr ; # refr capture long - distance reorderings by using tts, or tree - [SEP]", "cit": "syntax - based statistical machine translation # otherefr ; # refr, showing that deep linguistic knowledge, if used properly, can improve mt performance [SEP]"}
{"pre": "paraphrase acquisition is mostly done at the sentence - level, e. g., # otherefr ; # refr, which is [SEP]", "cit": "proceedings of the 4th workshop on building and using comparable corpora, pages 52? 60, 49th annual meeting of the association for computational linguistics [SEP]"}
{"pre": "thus, some research has been focused on deriving different word - sense groupings to overcome the fine? grained distinctions of wn # otheref [SEP]", "cit": "other attempts in this vein include mappings between wordnet and propbank # otherefr. # refr presents an automatic approach for mapping between sense [SEP]"}
{"pre": "the use of semi - supervised learning techniques to train a log - linear model # otherefr ; # refr. [SEP] the em algorithm [SEP] the", "cit": "it has been shown that human knowledge, in the form of a small amount of manually annotated parallel data to be used to seed or guide model [SEP]"}
{"pre": "in a multilingual setting, the sense inventories needed for disambiguation are generally built from multilingual corpora # otherefr ; [SEP] ( [SEP]", "cit": "a number of bootstrapping methods have been proposed to reduce the sensetagging cost # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "a plethora of prior work learns bilingual lexicons from monolingual and comparable corpora with many signals including distributional, temporal, and topic similarity # [SEP]", "cit": "iii and # refr mine translations for high frequency oov words in new - domain text in order to do domain adaptation. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "to reduce this effect, attempts have been made to adapt nlp tools to microblog data # otherefr ; # refr. [SEP] the [SEP]", "cit": "another related line of work is automated ontology construction, which aims to create lexical hierarchies based on semantic classes # otherefr ; # refr ) [SEP]"}
{"pre": "this has been successfully applied in many nlp tasks, such as parsing # otherefr, machine translation # refr, and pos tagging # other", "cit": "methods for learning with ambiguous labelings have previously been proposed in the context of multi - class classification # otherefr, as well as for [SEP]"}
{"pre": "since then, the approach grew in popularity # otherefr ; # refr ; sun et al2011 ). [SEP] ( 2012 [SEP] [SEP] [SEP]", "cit": "the multi - instance multi - label ( miml - re ) model of # refr, which builds upon work...... [SEP]"}
{"pre": "we have developed an approach to our knowledge, based on rhetorical relations rather than rhetorical ones # otherefr, # refr ), [SEP]", "cit": "abductive inference has a long history in plan recognition, text understanding and discourse processing # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "we used part - of - speech tags to test the model, following experiments : the gold standard part - of - speech tags, [SEP], [SEP]", "cit": "a secondary ( punctuation as words ) baseline in - 3note that wsj { 15, 45 }, overlap with section 23? training [SEP]"}
{"pre": "figure 2 : a simple lexicalized parse tree. criminative models described in # refr, the generative parser is trained with a stochastic lexicalized", "cit": "later???? parsers used tree insertion grammar # refr,???? s # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the original work of natural language processing \\ [ # refr \\ ], a system is limited to part - of - speech tagging \\ [ poll", "cit": "the regtllarization procedures were modeled after those developed for a gpsg parser \\ [ # refr \\ ], although the generated structures are [SEP]"}
{"pre": "in addition to the translation model, fourteen feature functions are combined : a target - language model ( a. source ) and target language model # refr", "cit": "a detailed comparison is given in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "a very simple technique is partial or fragment parsing # otherefr ; # refra ) : if there is no item in the chart that [SEP]", "cit": "another study that is close to our approach to search space restriction is c - structure pruning # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the recent interest in computational lexicography has fueled a large body of recent work on this 40 - year - old problem, e. g [SEP]", "cit": "53? 54 ) attempted to adapt pi? to award partial credit for near misses by using the percentage agreement metric of # refr, p. [SEP]"}
{"pre": "in # refr, we presented a summarization system based on perceptron and a conditional random fields ( crf ), which can lead to a summary", "cit": "some of those have been applied to document summarization, such as svr # otherefr, and ranknet # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "we also performed the paired bootstrap resampling test # refr. [SEP] bootstrap resampling # otherefr on the test set. [SEP] the sampling [SEP]", "cit": "we perform a bootstrap resampling significance test # refr on the output predictions of the local classifiers with and without the inference model. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "we use the dataset introduced by # refr. [SEP] negation using simple logical inference rules. [SEP] ( mrds ) for textual entailment, [SEP] [SEP]", "cit": "consequently, current semantic parsers are mostly restricted to quite limited domains, such as querying a specific database # otherefr ; # refr. [SEP]"}
{"pre": "we use tinysvm2 along with yamcha3 # refr as the svm training and test software. [SEP] kernel ( svm ) as in [SEP] [SEP]", "cit": "non - linear decision surfaces can be realized by replacing the inner product of # otherefr ; # refr : k ( x, y ) [SEP]"}
{"pre": "the cube pruning algorithm, the cube - pruning algorithm # refr, and typically used some the algorithm of collins and brooks # otherefr. [SEP]", "cit": "the data set is same as in section 5. 1, except that we also parsed the english - side using a variant of the # [SEP]"}
{"pre": "in es00 demonstrative pronouns preferentially refer to abstract entities, while personal pronouns preferentially refer to individual ones. es00 resolves ipa [SEP]", "cit": "this paper describes an extension of the dar - algorithm # refr for resolving intersentential pronominal anaphors referring to individual and abstract [SEP]"}
{"pre": "lattice parsing originated in the speech unfortunately, not enough information was available to carry out comparison with the method of chung and gildea # other [SEP]", "cit": "these include joint segmentation and parsing of chinese, empty element prediction ( see # refr for a successful application ), and a principled handling of [SEP]"}
{"pre": "for example, in the english language, the target language is integrated with a parser # refr. [SEP] the text t proposed in the [SEP] [SEP] [SEP]", "cit": "we used the japanese parser knp # otherefr and the english nl - parser # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "duc - 04 r f l1 # otherefr 11. 89 # refr 11. 89 # otherefr 86. 8 [SEP] [SEP] [SEP]", "cit": "meanwhile, submodular maximization has recently been applied to the text summarization task, and the methods thereof have performed very well # otheref [SEP]"}
{"pre": "in contrast, # refr find that the symmetric information radius measure is calculated by cosine (? ) =? i. e.,? [SEP] [SEP]", "cit": "internally, the ranking of attributes uses jensen - shannon # refr to compute similarity scores between internal rep - class label class size class instances accounting systems [SEP]"}
{"pre": "tree kernel approaches have been applied successfully in many areas of nlp # otherefr ; # refr. [SEP] this approach allows for a variety of", "cit": "we explored a range of data settings, but there are many others where tree kernels have been proven useful, such as parse tree reranking [SEP]"}
{"pre": "we use the stanford pos tagger # refr to train a crf tagger with the stanford tagger? s tagger? trained on the entire", "cit": "iii and # refr, relation extraction # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for this reason there is currently a great deal of interest in methods which incorporate syntactic information within statistical machine translation systems # otherefr ; # [SEP]", "cit": "for this reason there is currently a great deal of interest in methods which incorporate syntactic information within statistical machine translation systems # otherefr ; # [SEP]"}
{"pre": "in this paper, we evaluate the joint parsing model on srl data provided by the conll 2009 shared task competition # refr. [SEP] the results", "cit": "on this basis, several international semantic evaluations have been organized, which include senseval 3 # otherefr # refr, and so on. [SEP]"}
{"pre": "phrase - based mt evaluation metrics are meant to be used to train the phrase translation units with the large monolingual corpora # otherefr, as", "cit": "we build linear mixture models to combine translation, reordering and language models learned on europarl and news commentary corpora ( foster and # refr [SEP]"}
{"pre": "proposed decipherment solutions for letter substitution ciphers include techniques that use expectation maximization # otherefr, and bayesian learning with dirichlet processes # [SEP]", "cit": "# refr work with large ciphertexts containing thousands of characters and provide another exact decipherment method using an a * search algorithm. [SEP] [PAD] [PAD]"}
{"pre": "for the former, we used the dependency parse trees from the newswire corpus # refr. [SEP]. [SEP] kernel trees, [SEP] [SEP] features [SEP] [SEP]", "cit": "for the design of structures and type of kernel, we take motivation from a system proposed by # refr which is a stateof - the - [SEP]"}
{"pre": "we use a simple verb clustering algorithm which has been successfully applied to verb clustering # otherefr and verb clustering # refr. [SEP] features [SEP] this", "cit": "finally, our task - based evaluation, verb clustering with levin # otherefr and # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use minimum error rate training # refr to tune the feature weights to maximize the system? s bleu score on the development set. [SEP].", "cit": "since manual word alignment is an ambiguous task, we also explicitly allow for ambiguous alignments, i. e. the links are marked as sure ( [SEP]"}
{"pre": "one may hence contrast our approach with the traditional supervised methods applied to the mt task such as minimum error rate training # otherefr, the [SEP]", "cit": "for each yi, add to the training set k independent samples { xi1,... xik }, from the distribution p? [SEP]"}
{"pre": "we tuned batch mira # refr on 1000 - best systems for the english and chinese / english - english translation task. [SEP] the experiments of [SEP]", "cit": "however, if we fix the weights for the tectomt phrase ta - 6using k - best batch mira # refr did not work [SEP]"}
{"pre": "in nlp, several proposals have been put forth in the framework of # refr. [SEP] this simple model. [SEP] a [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "by providing richer representations of meaning than what can be encompassed in a discrete representation, such approaches have successfully been applied to tasks such as sentiment [SEP]"}
{"pre": "most existing works on sentiment summarization focus on predicting the overall rating on an entity # otherefr ; # refr ). [SEP] the [SEP] [SEP]", "cit": "most existing works on sentiment summarization focus on predicting the overall rating on an entity # otherefr ; # refr ). [SEP] [PAD] [PAD] [PAD]"}
{"pre": "transitionbased models parameterize the problem by elementary parsing actions and typically use incremental beam search # otherefr ; # refr. [SEP] features [SEP] solutions", "cit": "recently # refr used the output of one dependency parser to provide features for another. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we note that for incremental processing of spoken dialogue systems # otherefr ; # refr ), and others are currently working on incremental processing [SEP] [SEP]", "cit": "inprotk realises the iu - model of incremental processing # refr, where incremental systems are conceptualised as consisting of a network of processing [SEP]"}
{"pre": "machine learning methods have been applied to a variety of tasks, including sentiment analysis # otherefr, sentiment classification of text - [SEP] text documents #", "cit": "although such approaches have been employed effectively # refr, there appears to remain considerable room for improvement. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in tempeval - 2 # otherefr, the annotator tagger heideltime # refr has been written by the annotators [SEP]", "cit": "we decided to extend heideltime for chinese for the following reasons : ( i ) heideltime was the best temporal tagger in the [SEP]"}
{"pre": "the correctness of the results had been reported using the version of mira algorithm # otherefr, as well as the multi - [SEP] objective objective", "cit": "popular alternatives such as pairwise ranking objective # otherefr, and rampion # refr use surrogate optimization objectives that indirectly attempt to maximize the correctness [SEP]"}
{"pre": "transformation - based learning has been applied to a wide variety of natural language processing # otherefr, word sense disambiguation # refr, and [SEP]", "cit": "a somewhat indirect comparison of applying stochastic ontext - free grammars # otherefr, a transformation - based method # refr, and inductive logic [SEP]"}
{"pre": "# refr use syntactic similarity to measure similarity between the verb - noun combinations of verb vectors. [SEP] if two verb is idiom. [SEP]. [SEP]", "cit": "such techniques either do not use any information regarding the linguistic properties of mwes # otherefr, or mainly focus on their noncomposition [SEP]"}
{"pre": "in question answering, for example, reranking # otherefr ; # refr and qa # otherefr have been proposed such models [SEP]", "cit": "to reduce the burden of manual feature engineering for qa, we proposed structural models based on kernel methods, # refr with passages limited to one sentence [SEP]"}
{"pre": "much research effort has been made to address the transliteration issue in the research community # otherefr ; # refr ; kang and choi [SEP]", "cit": "they are important in cross lingual information retrieval # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in unsupervised wsd, wsi has been found successful for a natural language processing ( nlp ) task # refr, and has [SEP] [SEP] [SEP]", "cit": "a large body of related work can be found in # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "several recent real - world parsers have improved the efficiency of grammar frameworks, including an efficient computation, computation, computation, and the final algorithm #", "cit": "this problem of grammar size has been solved by # refr who developed a method, based on a left - corner grammar transformation, which produces non [SEP]"}
{"pre": "in order to refer to as # refr, our knowledge, our re - ordering was first proposed to be a generalization of the starting point for the", "cit": "when relations ( i. e., two - place properties ) are taken into account at all ( e. g., # refr, [SEP]"}
{"pre": "in natural language generation, there has been a resurgence of interest in the nlg for natural language generation ( nlg ) [SEP] [SEP] [SEP]", "cit": "we follow a sign - based approach for the description of linguistic entities based on headdriven phrase structure grammar # otherefr and the variant described [SEP]"}
{"pre": "the approach in # refr is related to our work, who apply the minimum bayes - risk rescoring framework to combine the scores of two different [SEP]", "cit": "for system combination, we followed a minimum bayes - risk algorithm, as introduced in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this tutorial discusses a framework of online global discriminative learning and beam - search decoding for syntactic processing # otherefr, structured perceptron # [SEP] [SEP]", "cit": "in addition to feature advantages, the high accuracies of this framework are also enabled by direct interactions between learning and search # otherefr ; # [SEP]"}
{"pre": "in particular, we focus on non - projective dependency parsing, using the technique of # refr and we focus on the syntactic analysis of [SEP] [SEP] [SEP]", "cit": "the most common approach to handling the unbounded nature of the parse histories in these models is to choose a pre - defined set of features which can [SEP]"}
{"pre": "these include methods where the set of decisions between positive and negative samples # otherefr ; # refr, and the majority of such [SEP] [SEP] [SEP]", "cit": "this includes parsing and relation extraction # otherefr, entity labeling and relation extraction # refr, and part - of - speech tagging and chunk [SEP]"}
{"pre": "we build on a number of existing algorithmic ideas, including using ccgs to build meaning representations # otherefr, building derivations # refr, [SEP]", "cit": "# refr further improved the generative alignment model by incorporating the full semantic parsing model from lu et al # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we trained biomedical data using the bionlp - st 2009 # refr, which achieves high accuracy on the biomedical domain # otherefr. [SEP]", "cit": "therefore, to annotate all computer science papers, we cannot develop predefined entity ontologies, which is the typical approach taken in biomedical text mining # [SEP]"}
{"pre": "in a second approach to determining the underspecification, the current state is to represent the hypothesis as a quasi logical form # otherefr [SEP]", "cit": "secondly, monotonicity guarantees that interpretation algorithms can proceed incrementally, combining information from various sources in a nondestructive way # refr. [SEP] [PAD]"}
{"pre": "sentence compression has been considered before in contexts outside of summarization, such as headline, title, and subtitle generation # otheref [SEP]", "cit": "for example, to automatically generate subtitles for television programs ; the transcripts cannot usually be used verbatim due to the rate of speech [SEP]"}
{"pre": "# refr proposed a method for extracting instances of semantic roles that are similar to the target domain. [SEP] if two verbs. [SEP] it can be feasible", "cit": "in related unsupervised tasks, riloff and colleagues have learned? case frames? for verbs ( e. g., # refr, while [SEP]"}
{"pre": "we use the stanford parser # refr. [SEP] english ( each german and english ) penn treebank # otherefr to train a pcfg [SEP]", "cit": "long sentences are removed, and the remaining sentences are pos - tagged and dependency parsed using the pre - trained stanford parser # refr. [SEP] [PAD]"}
{"pre": "to address this, we use a inference technique similar to the one proposed by # refr. [SEP] and then passing it to the sr classification of a", "cit": "it is therefore disappointing, but not surprising, that f - measures on srl drop more than 10 % when switching from gold parse [SEP]"}
{"pre": "vances have focused on understanding and reducing the errors that occur in segmentation and partof - speech tagging # otherefr ; # refr, [SEP]", "cit": "we include results for a transition - based parser # otherefr, a split - merge pcfg parser # refr, a lexicalized parser [SEP]"}
{"pre": "in # refr, an svm model is trained on the same data set, and uses a discriminative log - linear model to integrate the resolution [SEP] features", "cit": "some researchers # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "these methods differ by the objective function or training mode : their objective functions are based on either evaluation - directed loss # otherefr ; # [SEP]", "cit": "these methods differ by the objective function or training mode : their objective functions are based on either evaluation - directed loss # otherefr ; # [SEP]"}
{"pre": "the english side is pos - tagged with tnt # refr and lemmatization using tnt # otherefr. [SEP] the word alignment between [SEP]", "cit": "table 3 : test set evaluation results pos tags were used for the arabic portion, as shown in subsection 4. 2 ; a tnt tool [SEP]"}
{"pre": "# refr and phonology # otherefr have presented models for the task of noun - verb tense # otherefr. [SEP] [SEP] [SEP]", "cit": "however, most such work makes little contact with empirical data # otherefr. 1 as pointed out by # refr, most computational work on [SEP]"}
{"pre": "in addition to the well - known training scenario, several researchers have presented approaches to adaptation which are to combine the translation models # otheref [SEP] [SEP]", "cit": "this was investigated in the framework of smt by several authors, for instance for word alignment # otherefr ; # refr and to a [SEP]"}
{"pre": "in addition, the reordering model in phrase - based systems were integrated into a hierarchical translation model # refr. [SEP] a source [SEP] [SEP] [SEP] [SEP]", "cit": "in contrast, lexicalized reordering models # otherefr ; # refr are extensively used for phrase - based translation. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr describe a system that can be used for learning morphology induction that can be created by an individual context - free system. [SEP] fst. [SEP]", "cit": "an earlier paper, # refr, presents a? discovery procedure? for learning phonological rules from data, something that can be seen as a precursor [SEP]"}
{"pre": "motivated by the idea of using a sense - tagged corpus required for wsd # refr, we use 5 - gram model and [SEP] all [SEP] [SEP]", "cit": "# refr tested the claim on about 37, 000 examples and found that when a polysemous word appeared more than once in a discourse, [SEP]"}
{"pre": "# refr used crfs for pos tagging and discussed the first empirical results of crf - based system using conditional random fields ( crfs ) and model", "cit": "crfs have been widely applied to tasks in natural language processing, especially those involving tagging words with labels such as partof - speech tagging and [SEP]"}
{"pre": "in the last decade, latent variable modeling has been used to find the latent variable pcfgs # refr. [SEP] ( l1 ) [SEP] (", "cit": "recent work # refr has introduced an alternative algorithm, based on spectral methods, which has provable guarantees. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the same data and but several studies have been done in several studies including the use of spoken dialogue systems to predict the user [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "# refr also state that? user satisfaction ratings [... ] have frequently been used in the literature as an external indicator of the usability [SEP]"}
{"pre": "# refr proposed a method for recognizing the contradictions of the ambiguous word. [SEP] it is a serious challenge that it may refer to two [SEP] [SEP]", "cit": "mutual information has been positively used in many nlp tasks such as collocation analysis # otherefr, and word sense disambiguation # refr [SEP]"}
{"pre": "in english as well as in japanese, dependency analysis has been studied # otherefr ; # refr ). [SEP] ( 1 ) [SEP] [SEP] [SEP]", "cit": "the recent availability of larger - scale corpora annotated with dependency information has thus resulted in more work on statistical dependency analysis technologies that use machine learning algorithms [SEP]"}
{"pre": "in this paper we use two separate system submitted to the conll - x shared task # refr and show that a single system outperforms a single system", "cit": "based on # refr we adapted our system from last year, which was focused on europarl, to perform well on test data 2machine [SEP]"}
{"pre": "nivre? s parser has been tested for swedish # otherefr, while mcdonald? s parser has been applied to english # refra [SEP]", "cit": "recently dependency parsing has received renewed interest, both in the parsing literature # refr and in applications like translation # otherefr. [SEP] [PAD] [PAD]"}
{"pre": "the ability to model multiword expressions by means of mitchell adjective - noun phrases has been a long tradition in computational linguistics # refr. [SEP] [SEP]", "cit": "the current state - of - the - art in compositional distributional semantics either adopts a simple method to obtain a vector for a sequence of words, [SEP]"}
{"pre": "for example, discourse structure identification has been used in the text segmentation task # otherefr ; # refr and textual entailment # otheref [SEP]", "cit": "we measured the ability of judges to agree with one another, using the no - uon ofpercent agreement that was defined by gale # [SEP]"}
{"pre": "while these approaches have been proposed recently to tackle this problem, they are promising results still heavily underperform to phrase - based approaches, notably the approach", "cit": "in the following sections we present a reordering selection technique based on 1a good comparison of phrase - based and tree - based approaches across language [SEP]"}
{"pre": "the embedded word types are disambiguation systems using a discriminative framework # refr. [SEP] this approach is inspired by training a discriminative model for the disambiguation", "cit": "a common approach is to extract word - internal features from unknown words, for example suffix, capitalization, or punctuation features # otheref [SEP]"}
{"pre": "in addition, we will show translation performance ( lemmatization ) # refr and multilingual sense annotation # otherefr. [SEP] the [SEP] [SEP] [SEP]", "cit": "the semeval - 2007 task 7 dataset for coarsegrained english all - words wsd # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr show that the optimal decipherment with the same data are not in the data availability of the training data. [SEP]. [SEP] 1 substitution", "cit": "em frequently gets stuck in local optima, so running between ten and a hundred random restarts is common practice # otherefr ; # [SEP]"}
{"pre": "the ibm models, such as the ibm models # otherefr ; # refr, are phrase - based models # otherefr. [SEP] [SEP]", "cit": "for french / english translation we use a state of the art phrase - based mt system similar to ( och and # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "in this section we evaluate our model on the datasets provided by the semeval - 2007 task ( gi # refr and the datasets ) [SEP] [SEP]", "cit": "in a recent semantic annotation of the wordsim performed by # refr we find that, among the 174 pairs with above - median score ( and [SEP]"}
{"pre": "on the other hand, n - grams are lacking in the form of word alignment and other pos taggers # otherefr ; # refr [SEP]", "cit": "compared with other types of audio data, lecture speech often exhibits a high degree of spontaneity and focuses on narrow topics with special terminologies [SEP]"}
{"pre": "# refr propose a method that performs disambiguation by clustering the words in a particular sentence. [SEP] it process, hence inducing latent topic distributions over senses", "cit": "while wsi is intuitively appealing as a task, there have been no real examples of wsi being successfully deployed in end - user applications, [SEP]"}
{"pre": "the models that can be used for evaluation are the probabilistic models # otherefr ; # refr, and the probabilistic models # otherefr [SEP]", "cit": "another body of literature that is closely related to this work is fsm models for word alignment # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "statistical data about these various cooccurrence r lations is employed for a variety of applications, uch as speech recognition # otherefr and various [SEP]", "cit": "we extracted roughly 180, 000 case fl : anles from the bracketed wsj ( wall street journal ) corpus of the penn tree bank [SEP]"}
{"pre": "sentence boundary detection is a problem that has received limited attention in the text segmentation literature # otherefr ; # refr. [SEP] ( [SEP] [SEP] [SEP]", "cit": "a tokenizer # otherefr and a sentence boundary disambiguation algorithm # refr or eagle # otherefr may be used to convert a [SEP]"}
{"pre": "the basic building block is the following simple monolingual claim : l ( d ) = ( l xi ( d ) g ( d ) ( d", "cit": "however? if we deem the logical level of representation a separate, more abstract but mono - lingual evel of representation, then our [SEP]"}
{"pre": "machine translation ( mt ) has been used indirectly for semeval word sense disambiguation ( lefever and # refr. [SEP] [SEP] [SEP] [SEP]", "cit": "the best score amongst the other competitors is mentioned in the last row for reference, this is the hltdi team # otherefr for [SEP]"}
{"pre": "sentence compression has been widely studied in language processing. # otherefr, sentence compression # refr, and summarization # otherefr [SEP] [SEP]", "cit": "then using these summary generated using bigram - based keyphrases id sentence p06 - 1048 : 1 ziff - davis corpus [SEP]"}
{"pre": "for discourse relations annotated in the penn discourse treebank, the lexicallygrounded approach first described in # otherefr ; # refr, chinese", "cit": "for discourse relations annotated in the lexicallygrounded approach first described in # otherefr, chinese # refr, czech # otherefr [SEP]"}
{"pre": "to obtain the polarity of a document, a document can be classified? s often the bag of words # otherefr ; # refr. [SEP]", "cit": "some researchers have also recently applied hidden variable models to sentiment analysis, but they were focused on classifying either phrase - level # otherefr or [SEP]"}
{"pre": "in addition, we use a method of sentiment lexicon # refr. [SEP] his results for our task, and the former based on the original ibm [SEP]", "cit": "another line of research closely related to our work is the recognition of semantic orientation and sentiment analysis # otherefr ; # refr. [SEP] [PAD] [PAD]"}
{"pre": "the approach has been shown to give improvements over the map classifier in many areas of natural language processing including automatic speech recognition # otherefr, [SEP]", "cit": "the lmbr decision rule in # refr has the form e? = argmax e?? e {? 0 | e? | + [SEP]"}
{"pre": "the ibm models of word alignment # otherefr ; # refr. [SEP] a source - side sequence of alignments across a wide variety of languages [SEP]", "cit": "tree - to - string models, such as # refr remove this dependency, and such models are well suited for situations with large, cleanly [SEP]"}
{"pre": "se? # refr. [SEP] the topic model based on lda, a topic model was trained on the verbs? and nouns [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "an example of the latter are topic models # otherefr ;? o se? # refr, or word sense disambiguation # otheref [SEP]"}
{"pre": "we tune all models using batch mira # otherefr, and the feature weights of the structured perceptron # refr with a 5 - gram", "cit": "the feature weights were tuned using the moses implementation of mert # otherefr for all systems except english - to - german, for [SEP]"}
{"pre": "in # refr, they use a hybrid approach to disambiguate abbreviations corpus - based abbreviation disambiguation. [SEP] and [SEP] ( 1 [SEP] [SEP] [SEP]", "cit": "in general english, # refr note that acronym disambiguation is not widely studied because acronyms are not as prevalent in literature and newspaper [SEP]"}
{"pre": "stylometric analyses, which relies mainly on syntactic structure, turned out to the authorship attribution, and forensics # refr. [SEP] this problem [SEP] the", "cit": "however, previous research for automatic authorship attribution and computational stylometric analysis have relied mostly on shallow lexico - syntactic patterns # otherefr, [SEP]"}
{"pre": "in # refr a reordering model is defined over a given sentence, along with the reordering constraints below is inside a itg that cover a", "cit": "a comparison of both methods can be found in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition to the original ibm word - based models # otherefr, phrase models # refr, and syntax - based models # otheref [SEP]", "cit": "by contrast, explicit syntax approaches seek to directly model the relations learned from parsed data, including models between source trees and target trees # other [SEP]"}
{"pre": "on the other hand, the extraction of linguistically inspired approaches such as # refr and on the past work of de. [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "context - free grammars ( cfg ) for the resolution of temporal expressions have been employed by # refr and kauppinen et al. [SEP]"}
{"pre": "# refr. [SEP] a set of 38 relations including an argument selected from a dictionary, and that of senses. [SEP] words [SEP] dictionary senses. [SEP]", "cit": "there have been a number of attempts to combine paradigmatic and syntagmatic similarity strategies # otherefr, # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the stanford parser # refr. [SEP] dependency trees, which makes use of a probabilistic context free grammar, and latent variable model, instead of", "cit": "in our experiments, we obtain this combined representation from the output of the stanford parser # refr but any other broadly similar parser could be used instead [SEP]"}
{"pre": "syntax - based statistical machine translation # otherefr ; # refr, and data - driven approaches # otherefr have been proposed to [SEP] [SEP]", "cit": "# refr use a parser in the target language to train probabilities on a set of operations that transform a target parse tree into a source string. [SEP]"}
{"pre": "the sentences were pos tagged with tnt # refr and lemmatiser. [SEP] the wordnet - based language model : [SEP] the [SEP] [SEP] [SEP]", "cit": "the italian corpus has been processed automatically by the tnt postagger4 # refr including similar tags. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in machine translation, most often assumed the importance of human translation decisions # otherefr ; # refr. [SEP] the source [SEP] a given sentence [SEP]", "cit": "we build linear mixture models to combine translation, reordering and language models learned on europarl and news commentary corpora # refr. [SEP] [PAD] [PAD]"}
{"pre": "in addition, the averaged perceptron algorithm # refr has been applied to various nlp tasks, including named entity recognition # otherefr. [SEP]", "cit": "similarly, # refr use an nbest memm to generate multiple analyses for a sentence, and re - rank the analyses based on information extracted [SEP]"}
{"pre": "we evaluate the quality of the bleu - 4 metric # refr. [SEP] the n - gram matches of a reference system that can be trained [SEP]", "cit": "evaluation we evaluated system output automatically, using the bleu modified precision score # refr with the human - written text as reference. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "in the statistical machine readable machine learning approach, # refr used to extract interesting contextual information for their systems. [SEP] the latter model. [SEP] [SEP]", "cit": "the words we want to aggregate for text analysis are not rigorous synonyms, but the? role? is the same, so we have to [SEP]"}
{"pre": "the stanford parser # refr is used to obtain parses of the training data for the experiments. [SEP] the stanford parser # otherefr. [SEP]", "cit": "we used the stanford parser # refr to obtain the nps : there are 4361 nps, where ( by the gold standard annotations ) 21 % [SEP]"}
{"pre": "most previous work on sentiment analysis has focused on classifying the polarity of subjective # otherefr ; # refr or sentence polarity # other [SEP] [SEP] [SEP]", "cit": "previous work on sentiment analysis has covered a wide range of tasks, including polarity classification # otherefr, opinion extraction # refr, and opinion [SEP]"}
{"pre": "we use a unification - based system # refr which implements a combination of features. [SEP] unification - based constraints in order to encode the [SEP]", "cit": "typed feature structures as normal form ir ~'~ e terms are merely syntactic objects. asee # refr for a discussion of the appropriateness of [SEP]"}
{"pre": "artificial ungrammaticalities have been used in various nlp tasks # otherefr ; # refr, 1 ) 1. [SEP] [SEP] [SEP] the", "cit": "as a possible approach that would improve the classification accuracy over just the three manually detected syntactic errors, wong and dras # otherefr ; [SEP]"}
{"pre": "comparable corpora have been studied extensively in the literature # otherefr ; # refr ), but transliteration in the context of comparable corpora [SEP]", "cit": "comparable corpora have been studied extensively in the literature ( e. g., # refr ), but transliteration in the context of comparable [SEP]"}
{"pre": "in particular, probabilistic topic models have been successfully used for tasks such as summarization # otherefr or lexical acquisition # refr. [SEP] the [SEP]", "cit": "once all the cohesive ties are identified the involved items can be grouped together to form so - called lexical chains, which form a theoretically well [SEP]"}
{"pre": "a significant proportion of research has focused on correcting mistakes in article and preposition usage # otherefr ; # refr ; gamon, 2010 [SEP]", "cit": "in the past two years, three competitions devoted to grammatical error correction for nonnative writers took place : hoo - 2011 # otheref [SEP]"}
{"pre": "the first line is to modify word alignment by exploring information of syntactic structures # otherefr ; # refr. [SEP] the link of sentence [SEP] the", "cit": "relative position features following blunsom and cohn # refr, we integrate features indicating the closeness to the alignment matrix diagonal. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "there has been much work on sentiment analysis in recent years # otherefr ; # refr ), and document classification # otherefra [SEP] [SEP]", "cit": "because of a dearth of resources for this fine - grained task, we also develop new crowdsourcing techniques for labeling word - level [SEP]"}
{"pre": "we use the lattice - based toolkit in # refr to learn hierarchical pos taggers. [SEP], process having by projecting syntactic categories on the [SEP] [SEP]", "cit": "liang et al # otherefr, # refr and johnson et al # otherefr proposed hierarchical dirichlet process priors. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in error detection, most methods are presented in # otherefr ; # refr, where the use of a corpus of the learner [SEP] [SEP] [SEP]", "cit": "among unsupervised checkers, # refr exploits negative evidence from edited textual corpora achieving high precision but low recall, while tsao and wible # [SEP]"}
{"pre": "in # refr, a number of related approaches were proposed to use phrase - based translation tables as a sequence labeling problem. [SEP] the hierarchical pitman", "cit": "previous work proved successful in the use of large - scale data for language models from diverse domains # otherefr ; # refr. [SEP] [PAD] [PAD]"}
{"pre": "in an attempt to approximate the human effort, both supervised \\ [ bruce & weibe, 1994 ; lin, 1999 ; etc. \\ ] [SEP]", "cit": "that approach has achieved very good results in several wsd shared tasks # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr presented a graphical model for extracting relations between entities, but not just like? x?,?,?,?,?,?", "cit": "# refr compare both generative and discriminative models for extracting seven relationships between treatments and diseases. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the maximum entropy models used here are similar in form to those in # otherefr ; lau, rosenfeld, and # refr. [SEP] [SEP]", "cit": "the second approach # otherefr ; # refr defines the probability of a parse tree as the probability that a certain shiftreduce stochastic parsing automaton [SEP]"}
{"pre": "# refr use constituency - to - dependency parsing as the dependency model with valence ( dmv ). [SEP] non - projective dependency trees, [SEP]", "cit": "this is accomplished by using automata },?? }, ff as in model c, which allows the stopping probabilities p ( stop | q [SEP]"}
{"pre": "we want to focus on the syntactic dependency grammar, as proposed by # refr. [SEP] the linear order to find the highest one in the sentence [SEP]", "cit": "most of corpus - based grammar inductions have concentrated onphrase structure gram? mars ( black, lafferty, and # refr [SEP]"}
{"pre": "in addition to the standard features which include the part - of - speech tags, we incorporate a dataset that are aware of the dataset mapping between [SEP]", "cit": "the language grounding problem has assumed several guises in the literature such as semantic parsing # otherefr, mapping natural language instructions to executable [SEP]"}
{"pre": "in addition, we recently evaluated the bionlp 2009 shared task # refra ). [SEP] a shared task was introduced to test the [SEP] natural", "cit": "the context of our work is the give challenge # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "significant progress has also been made in paraphrase extraction, where most recent methods produce large numbers of paraphrasing rules from multilingual parallel [SEP]", "cit": "in question answering, for example, paraphrase generators can be used to paraphrase the user? s queries # otherefr ; [SEP]"}
{"pre": "sentence boundary detection is a problem that has received limited attention in the text processing, including part - of - speech tagging # otherefr ; [SEP]", "cit": "this reduction is achieved by in t ra - sentence segmentat ion, which is distinguished from inter - - sentence s gmentat ion that [SEP]"}
{"pre": "phrase - based models # otherefr ; # refr have been widely used in practical machine translation ( mt ) systems due to their close relative frequencies", "cit": "the n - gram - based smt framework addresses these problems by learning markov chains over sequences of minimal translation units # otherefr or over [SEP]"}
{"pre": "significant research has examined the extent to which syntax can be usefully incorporated into statistical tree - based translation models : string - to - tree # [SEP]", "cit": "on the other hand, incremental parsers # otherefr ; # refr process input in a straightforward left - to - right manner. [SEP] [PAD]"}
{"pre": "in # refr, pos tagging is used to tag the pos tagging of the tags of the tokens to the tags of the tags. [SEP] this paper", "cit": "previous approaches # refr chose the segmentation approach but concentrated on pos tagging by using the segmentation provided by the atb. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we take a fresh look on this problem and turn our focus to one particular syntax - based paradigm, treeto - string translation # otheref [SEP]", "cit": "# refr have recently introduced an efficient incremental decoding algorithm for tree - to - string translation, which operates top - down and maintains a derivation history [SEP]"}
{"pre": "we use brown clusters as negative evidence of a backoff model # refr, which improves the performance of an ner system. [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "we induced 1000 clusters which is also the configuration used in # refr. 5 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "several studies # otherefr ; # refr proposed the use of hierarchical translation models. [SEP] the pscfg framework of synchronous grammars to represent phrases [SEP]", "cit": "grammar induction using bilingual parallel corpora has been studied mainly in machine translation research # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this is a fundamental problem in unsupervised learning and learning in nlp, but, which has been shown to improve word alignment systems # otherefr", "cit": "most systems of this sort learn how to modify word alignments to agree better with the syntactic parse trees # refr, but there has also been other [SEP]"}
{"pre": "in the higher - order models, the parts consist of arcs together with some context, e. g. the parent or the sister arcs # [SEP]", "cit": "syntactic model we used two discriminative arcfactored models for labeled dependency parsing : a first - order model, and a second - order model with [SEP]"}
{"pre": "in addition to the salient bigrams, we also ran the post - editing ( bigram ) task using the t - test ( [SEP] [SEP]", "cit": "we also obtain salient bigrams in the context, with the methods and the software described in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used the same features as # refr. [SEP] features, we could explore the same include features, but do not use any of the current state", "cit": "most of these learning methods are aimed for domain adaptation # otherefr ; # refr, where we hypothesize that we can learn from multiple domains [SEP]"}
{"pre": "self - training # otherefr ; # refr, and recently pos tagging # otherefr are good enough to assign pos tags in the corpus", "cit": "our work is related to self - training # otherefra ; # refr as the algorithm used its own tagging of the sentences collected from the [SEP]"}
{"pre": "in 2007, tempeval - 2 # refr and tempeval - 2 # otherefr focused on these tasks. [SEP] text [SEP] [SEP]", "cit": "on the other hand, significant advances in sentence - level event extraction have been made over the last decade, in particular as the result of standardization [SEP]"}
{"pre": "this paper describes the structure of the lth coreference solver used in the closed track of the conll 2012 shared task # refr. [SEP] [SEP] [SEP]", "cit": "this paper describes the coreference resolution system used by stanford at the conll - 2011 shared task # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we have converted the annotations for the hindi and the hindi treebank ( hutb ) # refr and the hindi - urdu tree", "cit": "de et al. described a system for generating typed dependency parsed from the phrase structure parses # otherefr ; # refr discuss a [SEP]"}
{"pre": "mainstream approaches in statistical parsing are based on nondeterministic parsing techniques, usually employing some kind of dynamic programming, in combination with generative models [SEP] [SEP]", "cit": "mst - parsing # otherefrb ) and transition - based parsing, e. g. the maltparser # refra ). [SEP] [PAD]"}
{"pre": "# refr use machine learning techniques to classify movie reviews. [SEP] documents ( svm ) to detect sentiments and show that subjectivity classifiers are effective [SEP]", "cit": "to create a sentiment - relevance - annotated corpus, the sr corpus, we randomly selected 125 documents from the movie review data set # refr. [SEP]"}
{"pre": "for instance, # refr propose to use a similar method for srl, verb, verb, noun - verb ( verb ) noun combinations have shown", "cit": "these have also been shown to be useful for semantic role classification # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this includes work on phrasestructure parsing # otherefr ; # refr, dependency parsing # otherefr. [SEP] the source language to [SEP] [SEP]", "cit": "subsequently, researchers have begun to look at both porting these parsers to new domains # refr and constructing parsers for new languages # other [SEP]"}
{"pre": "in contrast, since research on how sentence plans can be estimated from corpus ( sentence planning and sentence planning corpora in which the task of sentence boundary [SEP]", "cit": "it is a matter of surface realization or sentence planning # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we have already discussed a unification technique, # refr, # otherefr. [SEP]'unification grammars to be typed. [SEP] this constraint", "cit": "in particular, one type of unification formalism, functional unification grammar # otherefr, # refr and is beginning to be used for [SEP]"}
{"pre": "# refr use document level latent structural modeling to determine the polarity of a document to a document. [SEP] documents that are related # otherefr.", "cit": "voll and taboada # otherefr show that adjective - based sentiment classification is improved by examining topicality ( whether each sentence is [SEP]"}
{"pre": "for correcting specific error categories, custom methods are generally developed, which exploit various knowledge of the problem to perform some lexicalized transfer techniques # refr.", "cit": "in a second class of models, a model for generating corrected sentences is formulated in the noisy - channel framework, relying strongly on a language model [SEP]"}
{"pre": "cross - lingual dependency parsing is the task of inferring dependency trees for observed sentences in a target language where there are few or no labeled training [SEP]", "cit": "multilingual model learning methods train cross - lingual dependency parsers with parameter constraints obtained from parallel data # otherefr ; # refr or [SEP]"}
{"pre": "we use the stanford parser # refr to parse the sentences, and extract dependency features from the stanford parser # otherefr. [SEP] the constituent 1", "cit": "we use the stanford parser from # refr to obtain the dependency parse trees for each sentence in the posts and then get the dependency paths between each [SEP]"}
{"pre": "unfortunately, the parsing accuracies of all models have been reported to drop significantly on outof - domain test sets, due to shifts in vocabulary and [SEP]", "cit": "# refr ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr compare several vectors for the words of a distributional hypothesis against the gold standard similarity scores as well as the? here? defined by [SEP] it", "cit": "in recent work, this has been proposed by mitchell and lapata # otherefr, # refr and thater et al # otheref [SEP]"}
{"pre": "the performance of wsd is reaching a common practice in many nlp applications, e. g., part of speech tagging # otherefr", "cit": "causes of errors include incorrect detection of possible enumerations, as in companies such as procter and gamble # otherefr ; incorrect estimation [SEP]"}
{"pre": "to evaluate the performance of inference rules, we use the dataset constructed by # refr. [SEP] the amazon mechanical turk3 each annotator. [SEP] [SEP]", "cit": "the significance of inference rules has led to substantial effort into developing algorithms that automatically learn inference rules # otherefr ; # refr, and generate [SEP]"}
{"pre": "we use a distributed implementation of the suffix array # refr, which was trained on the training set { ( x, y ) }, [SEP] [SEP]", "cit": "with some exceptions # refr, most still rely on tuning a handful of common dense features, along with at most a few thousand others, [SEP]"}
{"pre": "in order to extract such relations, we use the dependency parser of # refr, which uses the pos tagset as the morpheme glosses.", "cit": "supervised approaches learn directly from words annotated by morphologists # otherefr ; # refr, often using celex, a lexical database that includes [SEP]"}
{"pre": "this is in contrast to previous approaches that use parallel corpora # otherefr ; # refr, which are parallel corpora and then used to obtain parap", "cit": "in both cases we can find groups of documents referring to the same events or persons, and though they will probably focus on different aspects and have [SEP]"}
{"pre": "in the graph - based dependency parser, # refr introduced a maximum spanning tree model, which is shown to be useful in recent years # otheref", "cit": "as for the second - order features, we again base our features with those of # refr, who reported successful experiments with second - order models [SEP]"}
{"pre": "reconcile is a modular software platform that abstracts the basic architecture of most contemporary supervised learningbased coreference resolution systems # otherefr ; [SEP] if", "cit": "we built our coreference resolver based on the easy - first coreference system # otherefr, which is derived from the reconcile [SEP]"}
{"pre": "the identification of semantically similar methods can be divided into two broad categories : those that use lexical and syntactic dependency structure such a word # otheref [SEP]", "cit": "recent advances show that taking mwes into account can improve nlp tasks such as dependency parsing # otherefr, text generation # refr, [SEP]"}
{"pre": "in smt, the authors use a stochastic gradient descent ( dp ) # refr where the entire sentence is represented as a sequence of adjacent words.", "cit": "dp beam search for phrase - based smt was described by koehn et al # otherefr, extending earlier work on word - [SEP]"}
{"pre": "recent work has replicated the importance of automatically finding the sets of disambiguation in the non - compositionality of noun compounds ( [SEP] ) in [SEP] (", "cit": "we built a gold standard by re - using and expanding the quantification annotations we produced in herbelot and # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition to the mtc - 2http : / / www. nist. gov / 2http : / / 2http : / [SEP]", "cit": "different application scenarios of paraphrase have different demands on the paraphrasing results and up to now, the widely mentioned criteria include # other [SEP]"}
{"pre": "in contrast, pos tagging has been demonstrated for many sequence labeling tasks # otherefr ; # refra ). [SEP] this problem [SEP] [SEP] [SEP]", "cit": "supervision for simple features has been explored in the literature # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "there have been attempts on tackling this so - called document - level subjectivity classification task, with very encouraging results ( see yu and # [SEP]", "cit": "initial work on sentiment analysis was either based on sentiment lexicons that listed words as positive or negative sentiment indicators # otherefr, yu and [SEP]"}
{"pre": "most of the previous work on post dece of newswire articles determining whether a given opinions or a review ( e. g., # refr )", "cit": "our results improve the best published result on the hotel review data # refr reaching 91. 2 % accuracy with 14 % error reduction. [SEP] [PAD] [PAD]"}
{"pre": "the first two systems were tuned, tuned and tested with the mert # refr on the wmt 2010 translation lattices following # otherefr [SEP]", "cit": "rather than computing an error surface using kbest approximations of the decoder search space, cdec? s implementation performs inference over the full hypergraph [SEP]"}
{"pre": "in addition to convote, there are several approaches that use topic features to detect topic boundaries, e. g. # refr. [SEP] cues in", "cit": "wd scores for this task fall consistently into the. 25 range, with galley et al # otherefr at. 254, # refr [SEP]"}
{"pre": "# refr use a log - linear model with syntactic rules on the ghkm algorithm. [SEP] the ghkm algorithm of # otherefr. [SEP]", "cit": "to this end, the translational correspondence is described within a translation rule, i. e., # refr ( or a synchronous production ), [SEP]"}
{"pre": "in contrast, active learning # refr casts an unsupervised log - linear model which makes use of a word alignment model. [SEP] the probability mass from", "cit": "the first is to relax or update the independence assumptions based on more information, usually syntactic, from the language pairs # otherefr ; # [SEP]"}
{"pre": "concrete lr - like algorithms for tags have only recently been proposed # otherefr, though their evaluation was restricted to the quality of the parsing [SEP]", "cit": "a first attempt o adapt lr parsing to treeadjoining rammars ( tags ) was made by # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in order to obtain a linguistically plausible rightcorner algorithm, we produce n - best reranking parses from the english sentences of #", "cit": "in comparison, a state - of - art supervised parser # refr would process the same amount of data in 1. 3 years7. [SEP] [PAD]"}
{"pre": "# refr showed that a similar task for argument selectional preferences can be the presence of semantic similarity of predicates in the form of a predicateargument", "cit": "existing methods fall into one of two categories, either those relying on information from wordnet # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "in the context of sentiment analysis, while people are able to identify opinions that have been studied within the spoken dialogue acts # otherefr ; [SEP]", "cit": "evidence from the surrounding context has been used previously to determine if the current sentence should be subjective / objective # otherefr ) and adjacency pair [SEP]"}
{"pre": "adaptor grammars have been applied to a wide variety of tasks, including segmenting utterances into words # otherefr, and named entity classification [SEP] [SEP]", "cit": "adaptor grammars have been applied to a wide variety of tasks, including segmenting utterances into words # otherefr, native language identification # refr [SEP]"}
{"pre": "cll has recently been applied to wsd tasks, but only to mt evaluation, related the clte components such as multilingual wsi # other", "cit": "in previous work, the clwsd system gave very good results when applied, with some slight variations, to the out - of - ten [SEP]"}
{"pre": "entity coreference resolution is a well studied problem with many successful techniques for identifying mention clusters # otherefr ; # refr ; haghighi [SEP]", "cit": "# refr perform joint cross - document entity and event coreference resolution using the twoway feedback between events and their arguments. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "li and # refr report significant improvements in translation speed by taking unseen n - grams into account within cube pruning to minimize language model requests. [SEP]", "cit": "additionally, it included parallel and distributed computing techniques for scalability ( li and # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "modification task ( epi ) the epi task # refr focuses on ie for protein and dna modifications, with particular emphasis on events of epigenetics interest [SEP]", "cit": "the bionlp shared task 2011 ( bionlp st? 11 ) # refra ), the follow - up event to the bio [SEP]"}
{"pre": "# refr present an unsupervised method for classifying the stance of each contribution to an online debates. [SEP]. [SEP] polarity of topics. [SEP]. [SEP] polarity", "cit": "while ilp has been previously applied for inference in sentiment analysis # otherefr ; # refr, our task requires a complete ilp reform [SEP]"}
{"pre": "the tree alignment algorithm is based on [ 0, 1 ] and [ # refr ]. [SEP] [ yi ] h ] h ] and f.", "cit": "initially work focused on word - based alignment, but more and more work is also addressing alignment at the higher levels ( substrings, syntactic phrases [SEP]"}
{"pre": "several other approaches # otherefr ; # refr use syntactic features in the sentence structure to determine the meaning of a given sentence. [SEP] it [SEP]", "cit": "the paper? s title is? unsupervised semantic parsing? and has won the best paper award in the year 2009 # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "several approaches have been proposed to address this problem, including semi - supervised learning # otherefr ; # refr, multi - document summarization #", "cit": "this framework is commonly used in generation and summarization applications where the selection process is driven by multiple constraints # otherefr ; # refr. [SEP]"}
{"pre": "several approaches have been proposed to address this problem, including longer phrases # otherefr ; # refr, multi - document summarisation # [SEP] [SEP]", "cit": "sophisticated approaches such as linear programming and evolutionary algorithms have also been proposed for generating summaries and stories # otherefr ; # refr. [SEP] [PAD] [PAD]"}
{"pre": "in srl, high accuracy has been achieved by : # otherefr ; # refr ; mcdonald et al., 2005a ), [SEP]", "cit": "our baseline is a state - of - the - art srl system based on dependency syntactic tree # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition to the regular distance distortion model, we incorporate a 5 - gram language model with modified kneser - ney smoothing # otherefr", "cit": "our translation model has 19 dense features that were computed for all translation hypotheses : the nine moses # otherefr baseline features, the eight [SEP]"}
{"pre": "we evaluated translation quality using the bleu metric # refr, as calculated by mteval - v11b. pl with its default [SEP] ble", "cit": "consequently, we would like to learn synchronous grammars in a discriminative way that can directly maximize the end - to - end translation quality measured by ble [SEP]"}
{"pre": "we trained the model using the averaged perceptron algorithm # refr. [SEP] - bfgs system # otherefr. [SEP] the structured perceptron algorithm", "cit": "the principal training method is an adaptation of averaged perceptron learning as described by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use a statistical parser # refr to parse the training data. [SEP] the training corpus. [SEP] this model, then use [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "we used florian and ngai? s fast tbl system ( fntbl ) # refr to train rules using disfluency annotated [SEP]"}
{"pre": "our natural logic system, dubbed the natlog system, has a wide variety of applications including question answering and machine translation # otherefr ;", "cit": "results for de marneffe et al # otherefr were reported by # refr. techniques for rte. de marneffe et [SEP]"}
{"pre": "in order to deal with the evolutionary nature of the problem, # refr proposed an imt system with co - training algorithm # otherefr applied", "cit": "one of the first works on this topic was proposed in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr and callison - burch et al # otherefr improved english? english? english? french smt systems. [SEP] this technique", "cit": "similarity measures have been used to find words that are closely related # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "as a consequence, in most nlp systems are based on lexical chains # otherefr ; # refr, require full interpretation [SEP] the [SEP] [SEP]", "cit": "inference using wordnet typically involves lexical substitutions for words in text based on wordnet relations, a process known as lexical chains # refr. [SEP] [PAD]"}
{"pre": "transfer learning in parsing has been applied in different contexts, such as multilingual learning # otherefr ; # refr, domain adaptation # other [SEP]", "cit": "transfer learning in parsing has been applied in different contexts, such as multilingual learning # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in chinese, # refr used a word segmentation algorithm, which combined viterbi alignments, but optimized a segmentation algorithm cannot properly embed between characters.", "cit": "recent work includes # refr and # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for tuning of feature weights, we used batch - mira with? - safe - hope? # refr until convergence ( or maximal 25 [SEP] [SEP]", "cit": "our phrase - based systems are tuned with k - best mira # refr on development set. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in practice, the bayesian inference procedure was applied to maximize the best of the entire document # otherefr ; # refr. [SEP] - [SEP] [SEP]", "cit": "to evaluate the contribution of the tm, we choose the task of ts : this task has received considerable interest from the nlp community, standard [SEP]"}
{"pre": "several gre algorithms have addressed the issue of generating locative expressions # otherefr ; # refr. [SEP] a sentence to model [SEP] [SEP] [SEP] [SEP]", "cit": "several gre algorithms have addressed the issue of generating locative expressions # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "grammar induction # otherefr ; # refr ; haghighi and klein, 2006 ; smith and eisner, 1997 ; [SEP] [SEP] [SEP] [SEP]", "cit": "where # refr and bender et al. # otherefr apply similar methodologies to extract large scale properties for many languages, we focus on [SEP]"}
{"pre": "we used mecab as a dependency parser # refr. [SEP] dependency analysis of sentences in this paper. [SEP] the predicate classification process. [SEP] [SEP] [SEP]", "cit": "japanese dependency parsers such as cabocha # refr can extract bps and their dependencies with about 90 % accuracy. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, there are several approaches for unsupervised pos induction # otherefr ; # refr and the transfer delexicalized features in an [SEP]", "cit": "recently, ta? # refr presented a technique for coupling token constraints derived from projected cross - lingual information and type constraints derived from noisy tag [SEP]"}
{"pre": "most of the current work in natural language generation ( nlg ) is a common solution is a part of the speech tagger # refr [SEP] [SEP]", "cit": "the use of profile hmms for multiple sequence alignment also presents applications to the acquisition of mapping dictionaries # refr and sentence - level paraphr [SEP]"}
{"pre": "we use bleu # refr, ter # otherefr to evaluate the translation quality. [SEP] the bleu score. [SEP] the [SEP] [SEP] [SEP]", "cit": "evaluation sets are translated using the cdec decoder # otherefr and evaluated with the bleu metric # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "nivre? s parser has been tested for swedish # otherefr, english # refr, czech # otherefr and, too. [SEP]", "cit": "in order to get at least a preliminary answer to this question, we extracted lcfrs productions from the data used in the 2006 con [SEP]"}
{"pre": "we use kenlm3 # refr for computing the target language model score. [SEP]. [SEP] the counts of the counts of the target language. [SEP]", "cit": "language model inference used kenlm # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the identified social data is not well - studied and modern systems, and it has gained wide interest in the scientific literature # otherefr ; [SEP]", "cit": "in contrast, the twitter messages # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "there have been many studies on the resolution of discourse relations within the sentence # otherefr ; # refr. [SEP] this problem plays a central role", "cit": "that said, there is a line of literature on annotating and resolving personal and demonstrative pronouns, which typically refer to similar kinds of [SEP]"}
{"pre": "the most common approach is to use a log - linear framework in language modeling # refr. [SEP] the former one language to introduce some context [SEP] into", "cit": "we optimized feature weights using the minimum error rate training algorithm # refr on the nist 2002 test set. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in related research, matsuzaki et al # otherefr introduced a finergrained technique for phrasebased mt ( e. g., [SEP]", "cit": "we call the phrase pairs with all boundary words aligned tight phrase pairs # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "8the n - best feature extraction already uses relative counts # otherefr 90. 7 # refr 90. 1 s mcclosky et al", "cit": "the choice of p as # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in recent years, temporal processing has been used successfully to disambiguate term # otherefr and discourse relation # refr. [SEP] this [SEP] [SEP] [SEP]", "cit": "the feature tempex recorded the number of temporal expressions in each clause, as returned by a temporal expression tagger # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "for instance, measures that compute the association strength between the elements of an expression have been employed to determine the degree of compositionality # refr # [SEP]", "cit": "for instance in document indexing, information retrieval # refr, and cross lingual information retrieval # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we also express our gratitude to the treebank providers for each language : arabic # otherefr ; # refr, german # otherefr [SEP]", "cit": "while the realistic scenario of syntactic parsing with automatic mwe recognition # otherefr ; # refr, the french dataset of the spmrl 2013 [SEP]"}
{"pre": "one of the major approaches to disambiguate word senses is supervised learning # otherefr, # refr, # otherefr. [SEP] [SEP] [SEP]", "cit": "one of the major approaches to disambiguate word senses is supervised learning # otherefr, ( ng and # refr, # otherefr [SEP]"}
{"pre": "the other utilizes a sort of parallel texts, such as multiple news articles from the same text # otherefr, corresponding articles from multiple news sources", "cit": "# refr presented a approach to decide whether two sentences hold a paraphrase relationship. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this model is a simple and easy - first policy use in structured language models # refr. [SEP] learning algorithm [SEP] word boundaries, though we [SEP] [SEP]", "cit": "minimization of description length is in general aligned with performance improvement, although under finer granularity mdl - based search may not be as effec - [SEP]"}
{"pre": "electronic dictionaries and domain glossaries are definition repositories which prove very useful not only for lookup purposes, but also for automatic tasks such as question [SEP]", "cit": "electronic dictionaries and domain glossaries are definition repositories which prove very useful not only for lookup purposes, but also for automatic tasks such as question [SEP]"}
{"pre": "we use a support vector machines - based chunker, yamcha # refr, to obtain the character - based chunking by with the character offsets", "cit": "we use the chunker yamcha # refr, which is based on svms # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "figure 1 : an example of tree - based semantic representations for the source language in speech community # otherefr ; ge and # refr. [SEP]", "cit": "learning semantic structures of written text has been studied in a number of specific tasks, which include, but not limited to, those finding semantic representations [SEP]"}
{"pre": "we used the english srl corpus provided by the organizers organizers # otherefr ; # refr. [SEP] the srl [SEP] [SEP] [SEP]", "cit": "our system is based on that of bjo? # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for example, # refr show that using features like neural networks, incorporating context, lexical features, and vector machines ( svm ) can improve the word", "cit": "our work is inspired by the successful application of word clustering in supervised nlp models # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this is a well illustrated in the literature, e. g., # refr. learned pos tagging ( e. g., sections [SEP] [SEP]", "cit": "# refr develop a prototype - driven approach, which requires just a few prototype examples for each pos tag and exploits these labeled words to constrain the [SEP]"}
{"pre": "the most common approaches # otherefr ; # refr, or to cluster the aspect terms using ( or bag - of - words ) [SEP] the", "cit": "the most common approaches # otherefr ; brody and # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use brill? s tagger # refr to pos - tag the text chunker. [SEP] the brill tagger, [SEP] [SEP] [SEP]", "cit": "in order to include features describing verb tense, we use brill? s part - of - speech tagger # refr. [SEP] [PAD] [PAD]"}
{"pre": "bilingual lexicon induction is the task of learning translations from monolingual texts, and typical approaches compare projected distributional signatures of words in the source language with [SEP]", "cit": "# refr pivot through bilingual dictionaries in several language pairs to compose translations for compound words. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, the textual entailment task # refr was evaluated on the english lexical entailment task. [SEP] 1 in the text complexity of the [SEP]", "cit": "interestingly, a number of works ( e. g. # refr ) applied or utilized lexical based word overlap measures. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "to convey information concisely and fluently, text generation systems often perform opportunistic text planning # otherefr ; # refr and employ advanced linguistic [SEP]", "cit": "we implemented our quantification algorithm as part of magic # otherefr : # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "figure 1 : a sample of the concrete topics for the model we used a semi - supervised dependency parser # refr. [SEP] a word model # other", "cit": "also, as with any generative model, it may be easy to improve the parser? s accuracy by using discriminative retraining techniques # otheref [SEP]"}
{"pre": "tree kernel methods have found many applications for the task of answer reranking which are reported in # otherefr ; # refr. [SEP] the", "cit": "tree kernels # otherefr ; # refr ) represent trees in terms of their substructures ( fragments ) which are mapped into feature vector [SEP]"}
{"pre": "online learning algorithms such as maximum entropy model and conditional random fields # otherefr have been shown to be effective for nlp tasks # refr.", "cit": "various online em algorithms have been investigated ( see # refr for an overview ) but our focus is on the stepwise online em # otherefr [SEP]"}
{"pre": "we tune all feature weights using pairwise ranking perceptron # refr with pro # otherefr. [SEP]. [SEP] ( i. e. [SEP] [SEP]", "cit": "in our systems we use drem # otherefr or pro # refr to perform this optimization. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, # refr demonstrate that it is possible to improve the performance of state - of - the - art srl systems. [SEP] the [SEP]", "cit": "previous works on semantic role labeling # otherefr ; # refr have used features derived from ccg parsings and obtained better results. [SEP] [PAD]"}
{"pre": "in addition to the mt - based method, researchers have also investigated other methods for paraphrase generation, such as the pattern - based methods [SEP]", "cit": "in question answering ( qa ), a question can be paraphrased to improve the coverage of answer extraction # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in fact, many studies # otherefr ; # refr show that word - sense ambiguity can be effectively exploited to yield more human annotations produced by", "cit": "the number of different senses defined for a word varies across lexical resources, and pairs of senses within a single sense inventory are not equally distinct # [SEP]"}
{"pre": "# refr describe a system that allows them to be very useful in conjunction with a unification algorithm for generating backing that allows separating [SEP] backed", "cit": "it has long been proposed that regular formalisms ( e. g., rewrite rules, two - level formalisms ) accommodate rule features which [SEP]"}
{"pre": "crowdsourcing via amt has been shown to provide highquality data for a variety of nlp tasks # otherefr, including multil [SEP]", "cit": "the effect of more advanced language detection methods # refr on these results may be considered in future work. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in nlp, moore and quirk # otherefr and # refr propose an integer linear program that is not well accommodate the ordering of the", "cit": "given the multitude of work in nlp that uses lps and ilps in this way # refr, we hope that our approach will prove itself [SEP]"}
{"pre": "# refr presented a method for extracting terms that co - occurrence terms such as? character bigrams? and? # otherefr patterns [SEP]", "cit": "most of previous work on extracting terms, especially for multiple languages are focusing on single - word terms and they are also often based on statistical approach [SEP]"}
{"pre": "we use the ghkm transducer rule extraction # refr to extract translation rules from aligned parallel corpora. [SEP]. [SEP]. [SEP] the techniques to extract [SEP]", "cit": "in our experiments we use a tree - to - string syntax - based mt system # refr, and evaluate on a standard test set, nist [SEP]"}
{"pre": "in the last 4 - 5 years, the parser of # refr has become available. [SEP], the class - directed dependency grammar # otherefr", "cit": "more recent versions of dependency grammars # otherefr ; # refr ) impose on nonprojective d - trees some constraints weaker than projectivity [SEP]"}
{"pre": "this sparked inference procedure is not critical for natural language processing, but is not yet available, such as question answering # otherefr and textual", "cit": "yet the current precision of acquisition algorithms is typically still mediocre, as illustrated in table 1 for dirt # otherefr and tea [SEP]"}
{"pre": "in this approach, by reordering modeling et al. # otherefr, who use a reordering model and a word ordering sentence shift reduce", "cit": "it has been shown in # otherefr ; # refr that itg constraints perform better than other constraints when tackling the reordering between [SEP]"}
{"pre": "# refr proposed a joint inference model that captures some linguistic constraints simultaneously incorporating syntactic structure as features. [SEP] the shift - reduce process into the decoding process", "cit": "subsequently, # refr took advantage of this consistency to jointly model semantic frames on chinese / english bitexts, yielding improved frame recognition accuracy on [SEP]"}
{"pre": "therefore, the top - occurrence of the corpus has been enriched with the use of semantic information # refr. [SEP] this approach to estimate the frequencies [SEP]", "cit": "among early efforts, one might count work on deriving selectional preferences # otherefr ; # refr ) or partial predicateargument structure # [SEP]"}
{"pre": "for example, # refr show that for dependency parsing, could be successfully applied to parsing and achieved high parsing accuracies by a sentence parser # otheref", "cit": "ep can be thought of as a more flexible generalization of belief propagation, which has been used several times in nlp # refr. [SEP] [PAD] [PAD]"}
{"pre": "sst - 1 : stanford sentiment treebank? an extension of mr but with train and test data set plus the process of sentiment classifiers trained on [SEP]", "cit": "word embeddings are popular representations for syntax # otherefr ; # refr, morphology # otherefr and other areas. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the data from the conll shared tasks # refr. [SEP] languages for english, dutch, german, and japanese, chinese, arabic,", "cit": "morphological taggers disambiguate morphological attributes such as partof - speech # otherefr ; dependency parsers commonly assume the? pipeline? approach [SEP]"}
{"pre": "in the machine learning - based coreference resolution system # otherefr ; # refr, a coreference resolution system is modeled after the mentions", "cit": "# refr, uryupina et al # otherefr ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the same kernels for our experiments, which we have used svm - light - tk4 # refr with the default settings for our model [SEP]", "cit": "in # refr, an interesting algorithm that speeds up the average running time is presented. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "it has been shown that the precision of the targetlanguage terms ( e. g., # refr ) indicate that linguistically consistent context [SEP] linguistic", "cit": "in a next step, chunk information was added by a rule - based language - independent chunker # refr that contains distituency rules [SEP]"}
{"pre": "in addition, most dialogue systems use syntactic information to predict the function that is based on the assumption that they are known relation between a sentence # other", "cit": "our generation framework adopts a goal - directed view of generation and casts knowledge about communicative action in the form of a grammar that specifies how forms [SEP]"}
{"pre": "the only broad coverage morphological lexicon we used is the seed resource # refr and the lexicon which is built partly motivated by the morphological disambiguation process [SEP]", "cit": "2in # refr the authors also admit that an elaborate la technique will produce better results. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper, we evaluate the system on a multilingual dependency treebank, which was evaluated in the conll 2007 shared task on dependency parsing", "cit": "the parser of mcdonald and pereira # otherefr had been applied to english, czech and danish, and the parser of # refr [SEP]"}
{"pre": "in addition, we are planning to incorporate inference rules to be extracted from data # otherefr ; # refr. [SEP] the textual entailment condition", "cit": "# refr achieves 0. 89 accuracy and 0. 88 cws on the combined rte - 2 and rte - 3 dataset. [SEP] [PAD]"}
{"pre": "we evaluated the bleu scores # refr of translations on test set with a single reference translation system that can be trained on a [SEP] [SEP] [SEP] [SEP]", "cit": "while recent proposals for evaluation of mt systems have involved multi - parallel corpora # otherefr ; # refr, statistical mt algorithms typically only use [SEP]"}
{"pre": "in addition, we used the reordering method described in # refr. [SEP] a two shift - reduce process, in which a sub - permutations are", "cit": "type - 2 : pre - ordering # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "among the latter, there are nlp applications such as the detection of lexical errors # otherefr, paraphrase detection # refr, sentence", "cit": "we extracted the data which is not contained in wpec ( meta data and plain text of rv? 1 and rv ) using the java wikipedia [SEP]"}
{"pre": "in the last decade, statistical machine translation have been achieved by the use of a word sense disambiguation algorithm, which has been [SEP] sense - tagged", "cit": "although there is some hope from using aligned bilingual corpora as training data for supervised algorithms # refr, this approach suffers from both the limited availability of [SEP]"}
{"pre": "in addition, we computed the f - score # otherefr # refr as used as the personalized pagerank system. [SEP] this graph [SEP] [SEP]", "cit": "for example it has been used to measure centrality in hyperlinked web pages networks # otherefr, and semantic networks # refr. [SEP] [PAD] [PAD]"}
{"pre": "we use the giza + + toolkit # otherefr, and the berkeley parser # refr to generate the word alignments, [SEP] the [SEP] the", "cit": "we word - aligned the training data using giza + + with refinement option? grow - diag - and? # refr, and then parse [SEP]"}
{"pre": "in the annotation study of named entities # refr, the main entity tagger is described in figure 1 ( a ) is defined as the next section", "cit": "in the biomedical domain, for example, several annotated corpora such as genia # otherefr, pennbioie # refr, and genet [SEP]"}
{"pre": "there have been several studies in this area of sentiment analysis # otherefr ; yu and # refr. [SEP] this approach performed [SEP] sentiment classification [SEP]", "cit": "the applications of sentiment analysis range from classifying positive and negative movie reviews # otherefr to opinion question - answering ( yu and # refr. [SEP]"}
{"pre": "in order to train a structured perceptron # refr, we train a parameter w? with the perceptron algorithm # otherefr. [SEP] [SEP]", "cit": "the hypotheses h j may be the output of a structured prediction algorithm such as conditional random fields # otherefr, averaged perceptron # refr [SEP]"}
{"pre": "in lexicalized grammatical formalisms, ltag grammars # refr, ltag # otherefr are used for lexicalized tree adjoining grammars", "cit": "the parser uses a general two - pass parsing s | rategy for'lexicalized'gramlnars i # refr1. [SEP] [PAD] [PAD]"}
{"pre": "for example, # refr and haghighi and klein # otherefr study the conditions for the use of a sentence - level [SEP] [SEP] [SEP]", "cit": "we train our own word alignment model using the state - of - the - art tool berkeley aligner # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the relation extraction system described in # refr. [SEP]zilay and mckeown # otherefr to convert these trees to [SEP] [SEP]", "cit": "the first is one of cost ; the process of creating extractors requires either labeled data to be produced at sufficient quality and quantity in order to [SEP]"}
{"pre": "while many supervised machine learning approaches have been successfully applied to the task of dialogue acts # refr, most of them assume that important dialogue acts are.", "cit": "# refr also study the problem of da modeling in email conversations considering the two dialogue acts of question and answer. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we parse the english side of our training data with the berkeley parser # refr. [SEP] generative parser4 # otherefr. [SEP] the [SEP] [SEP]", "cit": "probabilistic context - free grammars # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this work, we evaluated the performance of the lexical reference resolution system by # refra ), which is based on the assumption that [SEP] [SEP]", "cit": "in the literature, slight variations of this problem are also referred to as sense matching # otherefr, lexical reference # refra ) and [SEP]"}
{"pre": "it is a exible method which is easily extended to word sense disambiguation # refr and parsing # otherefr. [SEP] this approach [SEP] [SEP]", "cit": "2soft clusters are sets where the elements have weights indicating the strength of their membership in the set, which in this case allows for a probability [SEP]"}
{"pre": "in nlg, most notably, in # refr, it is one of the most successful systems of natural language generation systems ( e. g.", "cit": "recently, a number of studies have pointed out that many decisions made at these distinct stages require interrelated, rather than isolated, optimisations # [SEP]"}
{"pre": "in this work, we reordering with the approach described in # refr. [SEP] a word order for the word order of a word order [SEP] a", "cit": "finally, source word pair reordering models # refr estimate, for each pair of input words i and j, the cost of translating j right [SEP]"}
{"pre": "we use the following baseline systems :? model of # otherefr ( 1 ) ( 2 ) ( see section 3 ) ; # refr for", "cit": "our approach is similar in spirit to co - training, where two classifiers, complementary by the virtue of having different views of the data, are [SEP]"}
{"pre": "in fact, the state - of - the - art english pos tagger # refr was used for japanese, and the english preposition [SEP] [SEP]", "cit": "early grammatical error correction systems use the knowledge engineering approach # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr use phonetic similarity models for cognate identification. [SEP] languages. [SEP] the longest common subsequence ratio of two words by comparing the similarity of the", "cit": "instead, the phonetic and orthographic structures are used to match similar word pairs # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "to model the syntactic transformation process, researchers in these fields? especially in machine translation? have developed powerful grammatical formalisms and statistical models for representing [SEP]", "cit": "more recently, # refr explored the use a formalism called quasisynchronous grammar # otherefr in order to find a more explicit model for [SEP]"}
{"pre": "we use the subjectivity lexicon of # refr, 2 which contains approximately 8000 words which may be used to express opinions. [SEP] the opinion [SEP]", "cit": "the multi - perspective question - answering ( mpqa ) newswire corpus ( wilson and # refr and the j. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in fact, many studies # otherefr ; # refr have investigated anaphora resolution, but it is not clear that resolving anaphors [SEP].", "cit": "# refr ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for example, # refr reported that wsd accuracy with a supervised wsd system on the wall street journal ( wsd ) in penn treebank", "cit": "we performed on a publicly available corpus which was designed to study the effect of domains in wsd # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "d ( d ) and ( ciaram ) are allowed equal to be context if any given entity mentions are mentions, if they must be", "cit": "previous work has explored many ways of measuring the relatedness of context? corresponding author d and entity e, such as dot product, cosine similarity, [SEP]"}
{"pre": "unfortunately, finding the best maximum for all models is np hard # refr, and even models approximate the problem of maximum spanning tree ( dynamic ).", "cit": "although goodman is rcductkm method does still not al low for an eff ic ient computation { 51 tile most probable parse in [SEP]"}
{"pre": "afgs are too large to fully extract explicitly ; researchers therefore either work with a tractable subset of the fragments # otherefr ; # refr [SEP]", "cit": "afgs are too large to fully extract explicitly ; researchers therefore either work with a tractable subset of the fragments # otherefr ; # refr [SEP]"}
{"pre": "in contrast, lexas uses supervised learning from tagged sentences, which is also the approach taken by most recent work on wsd, including # [SEP]", "cit": "most recently, yarowsky used an unsupervised learning procedure to perform wsd # refr, although this is only tested on disambiguating words into [SEP]"}
{"pre": "# refr also used a word alignment model, but only to improve parsing accuracy. [SEP] arbitrary positions they are treated [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "while the realistic scenario of syntactic parsing with automatic mwe recognition ( either done jointly or in a pipeline ) has already been investigated in constituency [SEP]"}
{"pre": "despite a surge in research using parallel corpora for various machine translation tasks # otherefr ; # refr ; melamed 1995 ; wu & xia [SEP]", "cit": "a similar idea is later applied by # refr to show the plausibility of correlations between words in non - parallel text. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "ontology developers are currently developed in general, for example, patwardhan and # refr. [SEP] the ontologies of ontologies which are inferred from the [SEP]", "cit": "# refr anal - 2for brevity we use logic notation rather than e. g., owl functional syntax : subclassof ( class ( [SEP]"}
{"pre": "these three of types of information have proved useful for natural language processing # otherefr ; # refr, and word sense disambiguation # other [SEP]", "cit": "k - means and spectral ) algorithms # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "approaches to normalization include the noisy channel model # otherefr, and machine translation # refr. [SEP] this approach. [SEP] this intuition that in social", "cit": "approaches to normalization include the noisy - channel model # refr, string and distributional similarity # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr use wikipedia as a simple wikipedia tool. [SEP] a simple wikipedia process to extract simplification rules. [SEP] a simple wikipedia scheme. [SEP] wikipedia scheme", "cit": "# refr learn lexical simplification rules from the edit histories of wikipedia simple articles. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "previous work on sentence compression include the task of sentence compression # otherefr ; # refr, and several submodularity # otherefr", "cit": "sentencelevel ilp was also first introduced in # otherefr revised it to concept - based ilp. # refr utilized ilp to [SEP]"}
{"pre": "while several significantly improved models have been developed since then, including neural networks # otherefr, probabilistic models # refr, hierarchical # otherefr", "cit": "a continuous space representation that treats a phrase as a dense real - valued vector # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "subjectivity lexicons # otherefr ; # refr ) play an important role in opinion, sentiment, and subjectivity analysis. [SEP] subjectivity", "cit": "subjectivity lexicons # otherefr ; # refr ) play an important role in opinion, sentiment, and subjectivity analysis. [SEP] [PAD] [PAD]"}
{"pre": "in a multilingual perspective, the use of different morphological analysis has been studied by # refr. [SEP] the results are significantly more [SEP], among others", "cit": "# refr show that the language family is a strong predictor of machine translation performance. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the accuracy of the classification approach has received much attention in recent years ( e. g., # refr. [SEP] realisation. [SEP] text [SEP]", "cit": "factors affecting the evaluation process are : ( 1 ) training and test experiments are usually performed over noisy corpora which distorts the obtained results, ( [SEP]"}
{"pre": "transliteration methods are studied in the context of machine transliteration # otherefr, # refr and # otherefr. [SEP] [SEP]", "cit": "phoneme based models, such as, the ones based on weighted finite state transducers # otherefr and extended markov window # refr treat transl [SEP]"}
{"pre": "this result is relevant to work in computational approaches to the nlp task have been applied to several nlp tasks, such as named entity recognition #", "cit": "figure 4 : co - compositional neural language model # otherefr and contrastive estimation # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr describe a system that is based on discourse segment boundaries, but does not take the level of surface realisation. [SEP]. [SEP]. [SEP]", "cit": "each of these functions has been treated separately in various systems ( see, e. g., \\ [ # refr \\ ] for contrastive [SEP]"}
{"pre": "jiang et al # otherefr ; # refr. [SEP] the idea of semi - supervised sequence labeling # otherefr. [SEP] [SEP] [SEP] [SEP]", "cit": "other results # otherefr ; # refr for the open test are not listed since they are not comparable with the results in this paper. [SEP]"}
{"pre": "# refr has demonstrated that an interpretation of the resolution of syntactic structures ( e. g., the set of ) can be resolved using the notion", "cit": "on the other hand particular eadings can be excluded by global binding and / or scoping principles, similar to the ones formulated in \\ [ [SEP]"}
{"pre": "in this paper, we show that the reordering model outperforms the state - of - the - art phrase - based systems # other [SEP] and [SEP]", "cit": "there has been a large body of work showing the efficacy of preordering source sentences using a source parser and applying hand written or automatically learned rules [SEP]"}
{"pre": "in addition, due to the above reasons, many approaches have been proposed that use syntactic features to identify empty categories and are often used in the [SEP]", "cit": "we employ 32 features, 13 of which were proposed by z & n and 19 of which were proposed by # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr uses a set of aligned phrases across related languages. [SEP] unsupervised, and learning of affixes is a large number of related [SEP] computational", "cit": "letter successor variety # otherefr ; # refr use the hypothesis that there is less certainty when predicting the next character at morpheme boundaries. [SEP]"}
{"pre": "the approach of # refr, i. e., to apply a set of tags derived from a data. [SEP] unsupervised word sequence for [SEP] languages", "cit": "approaches like the ones in ha? # refr, santamaria and araujo # otherefr could be combined with the udop [SEP]"}
{"pre": "the applications range from simple classification tasks such as text classification and history - based tagging # otherefr, text chunking # refr, [SEP] [SEP]", "cit": "we train the model using l1 - regularized stochastic gradient descent ( sgd ) # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper, we focus on the word alignment matrix. 1 we did not show that the proposed model can handle the word alignment, as described", "cit": "this is helpful for avoiding the? garbage collection? # refr problem for rare words. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in a related area, # refr used statistical methods to find the performance of a parser. [SEP] the recognition technique of finite - state \\ [ re", "cit": "qb satisfy the requirements mentioned above, we used a direct text scanning method which collects external evidence # refr of a modifier - modi [SEP]"}
{"pre": "several studies have shown that wsd can benefit a wide range of features # otherefr ; # refr. [SEP] this approach is [SEP] [SEP] [SEP]", "cit": "multilingual parallel corpora have mostly been used for tasks related to word sense disambiguation such as separation of senses # otherefr ; # refr [SEP]"}
{"pre": "# refr and jeong et al # otherefr built a preprocessing system for arabic - to - english smt. [SEP] english source [SEP] morphological", "cit": "several approaches use pre - processing schemes, including segmentation of clitics # otherefr ; # refr, compound splitting # otherefr [SEP]"}
{"pre": "the use of such relations, noun - verb relations, and syntactic relations, have been used for other natural language processing tasks, such as [SEP] [SEP]", "cit": "for this study, we adopt a revised version of the semantic relation set proposed by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this process is reliant on performing dependency conversion filters # otherefr, though we could try to learn more general representations of lexical - head rules", "cit": "the arrows below the words correspond to its associated dependency graph. based : for example, those described by # refr, barbero et al # [SEP]"}
{"pre": "we use a pos - tagger # refr for pos tagging, and a wide - coverage tagger # otherefr for [SEP] the [SEP] the", "cit": "we use a tagger based on adwait ratnaparkhi is method # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "clarke et al # otherefr and # refr describe approaches for learning semantic parsers from sentences paired with logical forms. [SEP] it [SEP] a variable", "cit": "clarke et al # otherefr and # refr describe approaches for learning semantic parsers from sentences paired with responses, krishnamurthy [SEP]"}
{"pre": "we also plan to explore the non - parallel bilingual dictionaries and domain glossaries provided by the panlex # refr. [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "while there are syndicated efforts to produce multilingual dictionaries for different pairings of the world? s languages such as freedict. org [SEP]"}
{"pre": "several statistical significance testing methods are also examined to detect unreliable noisy entries # otherefr ; # refr. [SEP] the problem of cross - lingu [SEP]", "cit": "there are number of similarity metrics such as dices coefficient # refr, and jaccard similarity coefficient. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "yarowsky # refr used rogets thesaurus categories as classes for wsd. [SEP] thesaurus categories, with respect to [SEP] a", "cit": "# refr learned discriminators for each roget is category, saving the need to separate smrd is are, of course, also constructed manually [SEP]"}
{"pre": "we use a statistical parser # refr trained on the tiger treebank # otherefr. [SEP] lnln frequencies of verbs [SEP] [SEP] [SEP] [SEP]", "cit": "the computation of? grammatical relations? from shallow parsers or chunkers is still at an early stage # otherefr, # refr and [SEP]"}
{"pre": "in a study of disambiguation on part - of - speech ( pos ) tagging, # refr introduced a probabilistic model of the transfer of dependency parse", "cit": "one notable example in this context is # refr, who introduce syntactic knowledge into their statistical translation model. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in order to quantify the effect of different lexicons, we add additional features based on the following scores as defined below : score ( 1 ) =", "cit": "a technique named label propagation # otherefr and # refr, while random walk based approaches, pagerank in particular, have been used by [SEP]"}
{"pre": "in addition, we computed the similarity measure ( lin ( lin? ) # refr and lin ( lin? s ) using the cosine similarity measure [SEP]", "cit": "# refr created a thesaurus using syntactic relationships with other words. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the wsj corpus, several corpus - based al algorithms have been proposed # otherefr ; # refr. [SEP] the idea of al [SEP]", "cit": "at the same time, several papers recently appeared that used ontonotes data for active learning experiments # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, there are methods for learning taxonomies relations that are also techniques that are nlp applications that are not of fields : part -", "cit": "other work has looked at techniques for learning phrasal patterns likely to contain slot fillers # otherefr or contain information semantically similar to a [SEP]"}
{"pre": "to address this problem, we propose a method to address the problem of learning in reranking to find the translation model, by filtering large numbers", "cit": "according to # refr and our own preliminary experiments, the size of phrase table and hierarchical rule table consistently increases linearly with the growth of training size [SEP]"}
{"pre": "we used a japanese morphological analyzer # refr for japanese morphological analysis and part - of - speech tags. [SEP] the prefix structure analyzer of # other [SEP]", "cit": "previous approaches have used structured predictors such as hidden markov models ( hmms ) or conditional random fields ( crfs ), which consider the interactions [SEP]"}
{"pre": "while several studies have shown that lexical features can be extracted automatically - sized # otherefr ; # refr, sentence ordering # otherefr.", "cit": "several studies have explored different types of features # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper, we propose an extension of the multi - modal corpus of the corpus of the corpus of the corpus of the corpus3 utterances.", "cit": "our project, called robohelper, focuses on developing an interface for elderly people to effectively communicate with robotic assistants that can help them perform [SEP]"}
{"pre": "in # refr, shallow syntactic structures were proposed to reorder the source sentences in the target language. [SEP]. [SEP] the source language as a [SEP]", "cit": "several methods have been proposed to use syntactic information to handle the reordering problem, e. g. # otherefr ; # refr. [SEP]"}
{"pre": "a great deal of researches have been conducted on this topic with promising progress # otherefr ; # refr. [SEP] this approach is to [SEP] [SEP]", "cit": "this binarization is done by the left - factoring approach described in # refr, which converts each production with n children, where n [SEP]"}
{"pre": "we parse the english side of the parallel corpus with the berkeley parser # otherefr, and perform well as well as on treebank [SEP] [SEP]", "cit": "the parses of the source sentences employed by our system during training and decoding are created with the charniak parser # refr. [SEP] [PAD] [PAD]"}
{"pre": "for example, the text - tiling algorithm, introduced by # refr, and pereira # otherefr work. [SEP] the [SEP] [SEP]", "cit": "barzilay and lapata # otherefr? s entity grid or # refr? s text segmentation. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition to the mt - related task, the problem can be solved by looking up the classification task # otherefr ; # refr. [SEP]", "cit": "pang et al # refr used parallel monolingual corpora built from news stories that had been independantly translated several times to learn lattices from [SEP]"}
{"pre": "# refr used a tree - to - string model for classification that uses verbs for the english verb classification. [SEP] phenomena related to direct objects of verbs", "cit": "table 2 : distribution of the sentences where the semantic role features give no / positive / negative impact to the sentence fluency in terms of the completeness [SEP]"}
{"pre": "most of the previous research on sentence compression focuses on deletion using syntactic information, # otherefr, # refr, galanis # otheref", "cit": "although it is particularly well suited to the bilingual extracted corpora, since the information that it adds is orthogonal to that model, it would presumably add [SEP]"}
{"pre": "such features include syntactic paths # otherefr and translation probabilities, a rule? and? non - terminal node classification features, as defined in a", "cit": "translation rules have been central to hierarchical phrase - based and syntactic statistical machine translation # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "it has been shown that dialogue strategies are based on the assumption that if they have the above the same meaning, then they have [SEP] phenomena [SEP] [SEP]", "cit": "however, one estimate of the rate of misunderstandings of literal meaning between humans, based on text transcripts of the british national corpus, [SEP]"}
{"pre": "in nlg, most methods of the automatic sentence generation task are based on a statistical approach # otherefr ; # refr, where they have", "cit": "our work is also strongly related to that of # refr which constructs symbolic semantic structures via an assignment process in order to provide surface realisers [SEP]"}
{"pre": "by contrast, explicit syntax approaches seek to directly model the relations learned from parsed data, including models between source trees and target trees # other [SEP]", "cit": "approaches include word substitution systems # otherefr, and synchronous context - free grammar systems ( wu and # refr, all of which train on [SEP]"}
{"pre": "a parallel tradition of text mining ( e. g., # refr ) can be learned from text data sources using the template learning technique presented in", "cit": "most other work in this area mines raw text, rather than a database automatically populated via extraction # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used bleu # refr, which is the weighted mean of the n - gram precisions with a penalty for the bleu # other [SEP]", "cit": "the evaluation metric is the case - insensitive bleu4 # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this model is similar to the model of # refr, which learns user interactions between tweets using a twitter set of authors but [SEP] the social networks [SEP]", "cit": "response prediction there has been significant work addressing the task of response prediction in news articles # otherefr and blogs # refr. [SEP] [PAD] [PAD]"}
{"pre": "we used the lattice - based toolkit me model # refr to translate the german data. [SEP] the training set. [SEP] bleu / [SEP] [SEP] [SEP]", "cit": "we use a maximum entropy model with recommended settings to create lattices for the dev and test sets, as well as for obtaining the 1 - best [SEP]"}
{"pre": "distributional similarity algorithms differ in their similarity measure # otherefr ; # refr. [SEP] a latent variable representation framework consisting of the learned by the induced", "cit": "this general scheme was further enhanced in several directions, e. g. directional similarity # otherefr and meta - classification over similarity values # [SEP]"}
{"pre": "in # refr, a method for inducing syntactic relations between words by searching the polarity of a word ( part ) and a particular part of speech (", "cit": "in # refr, sets of consistently contiguous word ~, ( \" neighbourhood \" ) are extracted from machinereadable d ic t ionar ies [SEP]"}
{"pre": "in addition, most of the rule - based model # otherefr ; gi # refr extracts relations between noun classes, and find that the noun", "cit": "the former approach # otherefr ; gi # refr utilizes a few hand - crafted seed patterns representative of taxonomic relations ( e. [SEP]"}
{"pre": "the penn treebank # refr was used a post - processing step for development, and a wide - coverage development set of a [SEP] rich [SEP] effort", "cit": "few hand - crafted, deep unification grammars have in fact achieved the coverage and robustness required to parse a corpus of say the size [SEP]"}
{"pre": "bootstrapping methods have been applied to wsd # otherefr, co - training # refr, and bootstrapping algorithms such as [SEP] ( [SEP]", "cit": "two more recent investigations are by yarowsky, # refr, and later, mihalcea, # otherefr. [SEP] [PAD] [PAD]"}
{"pre": "crowdsourcing can allow inexpensive and rapid data collection for various nlp tasks # otherefr ; # refr. [SEP] the data [SEP] coverage [SEP]", "cit": "one popular approach exploits multiple translations of the same data # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition to the well - known hierarchical setup, we also ran the bleu score on held - out 500 sentence pairs ( [SEP] [SEP] [SEP] [SEP]", "cit": "as # refr and koehn et al # otherefr note, purely lexical? phrase - based? translation models suffer from sparse data [SEP]"}
{"pre": "# refr ) show that for implicit discourse - related coherence is available before conducting te - aware methods are two major cause serious conclusions than [SEP]a [SEP]", "cit": "based on the original model, a few extensions have been proposed : for example, filippova and strube # otherefr and # [SEP]"}
{"pre": "2. 2. 2 extraction system we use the open - source system # refr which implements the phrase table. [SEP] the splitmer. [SEP] the", "cit": "# refrb ) for more details. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for example, # refr developed a machine translation system based on spelling correction. [SEP] text written by the latter of the [SEP] text written by", "cit": "this motivates the task of text message normalization # otherefr ; # refr, which attempts to transform all non - standard spellings [SEP]"}
{"pre": "a common approach is to begin with unlabeled, but clustered event - specific documents, and extract common word patterns as extractors # otherefr [SEP]", "cit": "an interesting alternative is distant supervision # refr, which trains a classifier using an existing database ( freebase ) containing thousands of semantic relations, with [SEP]"}
{"pre": "this method has been applied to tasks such as pp attachment # otherefr, and question answering # refr. [SEP] this approach was used [SEP] [SEP]", "cit": "our french? english system (? 3 ) showcased our group? s syntactic system with coarsened nonterminal types # refr. [SEP] [PAD]"}
{"pre": "when the cost of sensitive spanning tree pairs, we are able to achieve 87. 5 % of the sentence pairs in the sentence - to - tree", "cit": "# refr also suggest that adverb placement might involve cases which go against dependency length minimization. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the first of our system involves identifying plenty of referring expressions, that of which are given the first being a text, we need to consider", "cit": "in our system, text - hypothesis # otherefr ), ( 3 ) annotates named entities ( using lcc? s cicero [SEP]"}
{"pre": "crfs have been successfully applied to many sequence segmentation tasks # refr, but not only a single model, but also have been applied to the [SEP]", "cit": "common training criteria include the maximum likelihood # otherefr ; # refr, averaged structured perceptron # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the basic corpus consists of about four main types of the utterance, and the predicates are part of speech tagged by the atis corpus, [SEP] [SEP]", "cit": "the examples given in this paper are taken from the atis ( air travel inquiry system ; # refr domain. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "to parse this, we use the forest reranker # refr. [SEP] ( 1 ) we generate the forest containing n - best parses.", "cit": "in addition to those information, we use a modified in house parser to generate packed forest for each sentence in development set, and prune the [SEP]"}
{"pre": "system dda # otherefr 55. 7 ( 71. 7 ) # refr 55. 7 # otherefrc ) [SEP] ( 3 )", "cit": "we constrain all parse structures to be projective, via dependency - and - boundary grammars # refra ; 2012b ) : dbms 0? [SEP]"}
{"pre": "# refr argue that social media is not social to twitter messages. [SEP] computational sociolinguistic modeling considerations # otherefr towards social media [SEP]", "cit": "blog articles : a randomly - sampled subset of the american political blog posts gathered by # refr.. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "collins # otherefr, # refr, and ratnaparkhi # otherefr. [SEP] this technique to preprocessing the [SEP] [SEP] [SEP] [SEP]", "cit": "we parse the data using the collins parser # refr, and then tag person, location and organization names using the stanford named entity recognizer # [SEP]"}
{"pre": "some authors use uniform weights # otherefr ; # refr, others apply monolingual metrics to set the weights for tm interpolation # otherefr", "cit": "this rules out the possibility of using metrics such as cross - entropy # refrb ) or lm - perplexity for computing the mixing coefficients [SEP]"}
{"pre": "to address this, previous work has focused on predicting voting # otherefr ; # refr. [SEP] the text containing only grice, i.", "cit": "to address this issue, techniques for incorporating other comments in dialog threads may be fruitful # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the features included : a maximum entropy classifier, trained on native english texts # otherefr ; # refr. [SEP] [SEP] [SEP] [SEP] features [SEP] [SEP]", "cit": "the classification approach to error correction has mainly focused on correcting article and preposition errors # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the first is the cornell link between the hierarchical structure of spoken documents in the field is described # refr. [SEP]. [SEP]. [SEP]. [SEP] the", "cit": "we use mid - range document frequency instead of idf # refr, where the entities occur in between 10 % and 90 % of the documents [SEP]"}
{"pre": "# refr used a bootstrapping technique to create a classifier that can be used to identify the same training examples. [SEP] knowledge, [SEP] [SEP] [SEP] [SEP]", "cit": "a more nlp - oriented approach is proposed in # refr, where noun phrases are extracted from online user reviews. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use mxpost tagger # refr and parsed with the loglinear model, and we used a maximum entropy - based tagger to provide", "cit": "to obtain these distances, ratnaparkhi? s partof - speech ( pos ) tagger # refr and collins? parser # other [SEP]"}
{"pre": "paraphrase acquisition is mostly done at the sentence - level, e. g., # otherefr ; # refr, which is [SEP]", "cit": "previous work aligns a group of sentences into a compact word lattice # refr, a finite state automaton representation that can be used to identify common [SEP]"}
{"pre": "in order to extract such relations, we use the collins parser # refr to parse the corpus. [SEP] realisation in [SEP] natural [SEP] [SEP] [SEP] [SEP]", "cit": "for our studies here, the parser employed was that of # refr applied to the sentences of the british national corpus # otherefr. [SEP] [PAD]"}
{"pre": "esuli and sebastiani # refr present an algorithm that uses a random walk algorithm to rank synonym pairs of wordnet pairs during the", "cit": "in a later paper, # refr, es again use information in glosses, applying a random walk ranking algorithm to a graph in which syn [SEP]"}
{"pre": "beam search incremental parsers # otherefr ; # refr provide very competitive parsing accuracies for various grammar formalisms ( cfg, ccg [SEP]", "cit": "beam search incremental parsers # otherefr ; # refr provide very competitive parsing accuracies for various grammar formalisms ( cfg, ccg [SEP]"}
{"pre": "we used the second order ctb 5 # otherefr and the pos - tagging ( ctb ) tagger # refr for chinese ) and", "cit": "it is an online training algorithm and has been successfully used in many nlp tasks, such as parsing # otherefr ; # refr. [SEP]"}
{"pre": "this results in several aspects that distinguish the mh treebank from, e. g., the wsj penn treebank annotation scheme # otheref", "cit": "this two - dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for english as well as other languages, such [SEP]"}
{"pre": "in the reranker system # otherefr, an approach similar to the bionlp? 09 shared task on event extraction # refr,", "cit": "despite this observation, many stateof - the - art supervised event extraction models still extract events and event arguments independently, ignoring their underlying structure ( [SEP]"}
{"pre": "figure 2 : dependency parse ( a ) of dependency tree for the sentence, we follow the definition of collins? head - driven phrase structure parser #", "cit": "recently, it has gained renewed attention as empirical methods in parsing have emphasized the importance of relations between words ( see, e. g. [SEP]"}
{"pre": "they have been applied to many different nlp tasks, such as part - of - speech tagging # otherefr, word sense disambiguation #", "cit": "graph - based methods are becoming increasingly popular in the nlp community, and similar approaches have been employed and shown to perform well in other areas [SEP]"}
{"pre": "referring expressions ( cf. ) were computed in # refr. [SEP] the semantic information needs to be the vector, in which the role [SEP] [SEP] [SEP]", "cit": "the table below compares the computational complexity of an optimal algorithm ( such as # refr ), our algorithm and the ia. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in particular, we compare two tasks, one of which may be more appropriate one # otherefr and another approach # refr. [SEP] ( [SEP]", "cit": "it can be seen that the formalization in the loglinear combination of our hybrid model is very similar to that of lop - crfs [SEP]"}
{"pre": "we used five groups of features, namely : i ) questqe : 17 qe features provided by the quest toolkit6 ; ii ) as [SEP]", "cit": "we report results on three metrics, bleu # otherefr, and meteor optimized on fluency / adequacy # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we are planning to use the nlg system # refra ) for generating text from databases. [SEP] text from a travel planning [SEP] [SEP] [SEP] [SEP]", "cit": "applications where the data is available in a database include report generators # otherefr ], plandoc [ # refr ], multimeteo [SEP]"}
{"pre": "we used an off - the - shelf system, called kb completions ( muc ) # refr, and a subtree that can be used to [SEP]", "cit": "in our work, we follow the idea of preemptive information extraction # refr in which all possible relations for a given text corpus are preemptive [SEP]"}
{"pre": "in the field of eomputationa. 1 linguistics, mutual information \\ [ # refr \\ ],? 2 \\ [ church and [SEP]", "cit": "an alluring aspect of the statistical ~ pproach to machine translation rejuvenated by brown et al \\ [ # refr, brown [SEP]"}
{"pre": "statistical machine translation ( smt ) has lead to improved performance in many nlp tasks, including machine translation # refr, machine translation # otheref", "cit": "phrase - based translation # otherefr and hierarchical phrase - based translation # refr are the state of the art in statistical machine translation ( sm [SEP]"}
{"pre": "in this paper, we first apply the fntbl wordnet # refr package # otherefr. [SEP] the wordnet similarity [SEP] [SEP] [SEP]", "cit": "since when rubenstein and goodenough # otherefr ; # refr and distributional measures # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "pereira # otherefr and # refr use syntactic features in the vector definition. # otherefr improves on the latter by clustering [SEP]", "cit": "yet, other resources of semantically - related terms can be beneficial, such as wordnet : : similarity # otherefr, statistical resources like [SEP]"}
{"pre": "in addition, we plan to incorporate semantic information, and patterns that are also key to our task - related tasks # refr. [SEP] this [SEP] this", "cit": "while many of the previous works on noun categorization also address the task of hypernym classification # otherefr ; # refr and some include [SEP]"}
{"pre": "# refr use an error mining technique to detect syntactic chunks rather than majority category words. [SEP]. [SEP] features, they use the method proposed a method", "cit": "nicolas et al # otherefr employ a semi - automatic method to improve a large - scale morphosyntactic lexicon of french ( [SEP]"}
{"pre": "the cross - lingual textual entailment task # otherefr # refr addresses textual entailment # otherefr under the new dimension of [SEP]", "cit": "cross - lingual textual entailment # otherefr ; # refr as an extension of the textual entailment task # otherefr. [SEP]"}
{"pre": "in this paper we present phramer, an open source system that embeds a phrase - based decoder of samt # refr. [SEP] this [SEP]", "cit": "we provide a basic description of this system here ; for more details see # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for example, in the biomedical domain, we use the bioscope corpus # refr, where only looks like blank - decide if they are separated by", "cit": "# refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr propose a simple smoothing method for constructing large - scale lms. [SEP] yield more than one - way ( see table 1 ). [SEP] [SEP]", "cit": "in recent years, the field of natural language processing ( nlp ) has seen tremendous growth and interest in the use of approximation, randomization, [SEP]"}
{"pre": "previous work has shown that semi - markov crfs are superior to ner and chinese word - sense disambiguation # otherefr, # refr.", "cit": "machine learning - based approaches are taken in # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we also show that the features achieved good performance on textual entailment can be obtained by features like unigrams, we obtained from the textual entailment", "cit": "this feature space has been introduced in # refr and shown to improve over the ones above. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "there is a substantial body of work on extracting is - a relations # otherefr, part - of relations ( pas ng and # refr,", "cit": "therefore, researchers have focused on the development of methods that can automatically augment the initially extracted class - instance pairs. # otherefr fused information [SEP]"}
{"pre": "in addition, we also employ the subjectivity analysis of the event # otherefr, and the semantic distance measure in order to extract [SEP] [SEP]", "cit": "context matching at inference time was often approached in an application - specific manner # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the case of es00 ( esl ), # refr show that a discriminative model trained on the five domains of essays [SEP] the es", "cit": "a number of techniques have been investigated, including cosine similarity of feature vectors # otherefr as well as discriminative ones # refr. [SEP] [PAD] [PAD]"}
{"pre": "in fact, one of the popular qa systems like sms # otherefr and twitter responses # refr. [SEP] the textrank [SEP] model to [SEP]", "cit": "# refr presented probabilistic topic model based methods to measure the similarity between question and candidate answers. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in question answering, several pieces of the current question answering system # otherefr ; # refr have been proposed. [SEP] this problem [SEP] the classification", "cit": "there are many previous work on paraphrase examples extraction or combining them with some applications such as information retrieval and question answering # otherefr [SEP]"}
{"pre": "the statistical parsing models have been proposed that employ a probabilistic context - free grammar # otherefr ; # refr. [SEP] this formalism was a sequence", "cit": "this is the same separation of arguments and adjuncts as that employed by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use a simple conditional random field # otherefr ; # refr. [SEP] l1 ( bf ) : l1 ( w ; l2", "cit": "we apply the wapiti implementation # refr of conditional random fields # otherefr, using as features the output label of each character, [SEP]"}
{"pre": "in a related strand of work, # refr report on speeding up context based on 1000 exam, but it was not found that it was [SEP]", "cit": "we start by using web counts for two generation tasks for which the use of large data sets has shown promising results : # otherefr and [SEP]"}
{"pre": "in the context of machine translation, # refr propose to translate unknown words by selecting the source text in the target language using identical. [SEP] retrieval [SEP]", "cit": "in spoken document retrieval, however, lattices are used as a compact representation of multiple speech recognition transcripts to estimate the expected counts of words in each [SEP]"}
{"pre": "the learning algorithms presented in this paper are similar to algorithms used for paraphrase extraction from sentence compression # otherefr ; # refr. [SEP]", "cit": "more recently, researchers have created systems that use machine learning techniques to automatically construct question answering systems from data # otherefr ; # refr. [SEP]"}
{"pre": "for a detailed discussion of the issues, see # refr. [SEP] this technique, which they use statistics based, and their decision lists, only consider", "cit": "feature - based approaches, uch as bayesian classifters # otherefr, decision lists # refr, and bayesian hybrids # otherefr [SEP]"}
{"pre": "we use the cmu twitter part - of - speech tagger # refr to obtain the part - of - speech tags. [SEP] the [SEP] text", "cit": "here, we use a twitter - specific tokenizer and pos tagger4 # refr instead of the stanford parser. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in 2007 coarse - grained, mfs as well as the fine? grained distinctions of the supersense # refr, or [SEP] [SEP] [SEP]", "cit": "inventory to tackle the granularity issue, we produced a coarser - grained version of the wordnet sense inventory3 based on the procedure described [SEP]"}
{"pre": "# refr and lin # otherefr used wordnet, an off - the - shelf random indexing that consists of rewriting candidates. [SEP] [SEP] the", "cit": "from the transformation grammar # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used the corresponding question interpretation ( qa ) # refr to identify causality between events # otherefr. [SEP] ( gi [SEP] ) [SEP] [SEP] [SEP]", "cit": "many methods for extracting causality or scriptlike knowledge between events exist ( gi # refr, but none uses a notion similar to excitation. [SEP] [PAD] [PAD]"}
{"pre": "in addition, the topic - oriented approach can be considered related to sentiment analysis # refr. [SEP] this problem : - to - text production system [SEP]", "cit": "the natural anguage generation community has emphasized for a number of years the strengths of multilingual generation # otherefr ; # refr. [SEP] [PAD]"}
{"pre": "# refr applied it to the task of translating unknown words in several european languages, an idea investigated as well by denoual # otherefr [SEP]", "cit": "langlais et al. # otherefr applied it to translating medical terms, and # refr investigated the more specific task of translating unknown [SEP]"}
{"pre": "to calculate the similarity between two words, we used the distributional similarity of the verbnet similarity measure introduced by # refr. [SEP] distributional similarity of two", "cit": "bannard and callison - burch # otherefr and # refr also proposed directional similarity measures based on conditional probability, which are very [SEP]"}
{"pre": "in particular, we show that kernels over a substructure - 2this strategy can be used to encode more complex structures such as trees and parse", "cit": "in particular, most of the work on parsing with kernel methods has focussed on kernels over parse trees # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "strube and hahn # otherefr and # refr suggest that the consistency of resolution of discourse structure should be resolved, [SEP] if [SEP] [SEP]", "cit": "from a linguistic perspective # otherefr ; # refr, centering theor / sts have explained the choice of c6 in a sentence in [SEP]"}
{"pre": "marton and resnik # otherefr introduced features defined on constituent boundaries for chinese? english, e. g. # refr, [SEP] [SEP]", "cit": "it has been known that phrase - based decoding ( phrase segmentation / translation / reordering # refr ) should be constrained to some extent not only [SEP]"}
{"pre": "for english pos tagging, we use stanford pos tagger # refr. [SEP] stanford tagger # otherefr. [SEP] the pos tagger [SEP]", "cit": "for example, in english part - of - speech tagging, the accuracy of the stanford tagger # refr falls from 97 % on wall street [SEP]"}
{"pre": "korean : # otherefr used a maximum entropy model to identify collocations in english words, and # refr used the frequency of n [SEP] [SEP]", "cit": "2in the case of an interrupted collocation, words can be separated by an arbitrary number of words, whereas sin ( : e, : [SEP]"}
{"pre": "we use the summaries created by # refr. [SEP] text length statistics of sentences in the documents. [SEP] text ( [SEP] ) [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "tipster text summarization evaluation ( summac ) proposed various methods for evaluating document summarization and tasks # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this information is relevant to cross - language information extraction # otherefr, and machine translation ( mt ) approaches have proven effective for various nlp", "cit": "their results show a significant improvement in performance while building an automatic classifier on the projected annotations over the same automatic classifier trained on a small amount of [SEP]"}
{"pre": "# refr presented a method to automatically annotate the sentences with syntactic roles. [SEP] annotations. [SEP] the source sentence, annotated with propbank [SEP] [SEP]", "cit": "several systems to extract verb - argument structures from plain text have been proposed # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the transfer component, described in detail in # refr is shown to be superior to the translation of the direct transfer translation of the translation of the source", "cit": "in this paper we describe a translation project whose aim is to build an experimental bilingual conversation interpreter ( bci ) which will allow communication through typed [SEP]"}
{"pre": "in this work, we use the topic signatures # refr. [SEP] ( t, t ) = log2 frequency t. [SEP] ( t ) t", "cit": "our next steps will be to take a closer look at the following work : clustering of similar words # otherefr, topic signatures # refr [SEP]"}
{"pre": "the window size used by the algorithm will also dynamically change depending on the lexical cohesion # otherefr ; # refr. [SEP] the information of the", "cit": "these evaluation measures were selected because recall and precision are not sensitive to variations of segment length contrary to the pk measure # refr and do not favor [SEP]"}
{"pre": "for example, the nli task has been used by the nli task, with the only feature - based classifiers trained on maximum entropy, decision", "cit": "character n - grams # refr demonstrated that character n - grams are a useful feature for nli. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in japanese morphological analysis, the dictionary - based morphological analyzer mecab1 is regarded as a dependency analyzer or the stanford word segmenter # refr [SEP]", "cit": "regarding the two state - of - the - art word segmentation systems, one is juman, 7 a rule - based word segmentation system # [SEP]"}
{"pre": "also, several models are proposed to address the problem of improving generative models with small amount of manual data, including model 6 # otherefr [SEP]", "cit": "a number of semi - supervised word aligners are proposed # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, some researchers have tried to acquire pos tags automatically # otherefr, # refr, # otherefr ). [SEP] [SEP] [SEP]", "cit": "but it points to a promising research direction. # refr have reported interesting results of an annotation - projection technique for pos tagging, named entities and [SEP]"}
{"pre": "# refr found that even more human judgements on high - precision data set outperformed the majority of comparison of supervised machine learning - [SEP] features [SEP]", "cit": "the most common basis for text classification is by topic # otherefra ), and author personality # refr, as well as categories relevant to [SEP]"}
{"pre": "they then use linguistic models to correct noisy initial detections # otherefr ; # refr, and generate more general ways of combining [SEP] text and [SEP]", "cit": "to group adjectives, we use a bootstrapping technique # refr that learns which adjectives tend to co - occur, and groups these together [SEP]"}
{"pre": "we use the paraphrase database # refr to compute a tree kernel over the pairs of sentences. [SEP] the same trees, which can be used", "cit": "we highlight that paraphrase evaluation and paraphrase recognition # refr are related yet distinct tasks. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "decision lists # otherefr have been used for a variety of natural language tasks, including accent restoration # refr, word sense disambiguation # [SEP]", "cit": "a supervised algorithm based on this property is given in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the value of human annotated syntactic structures for statistical machine translation has been clearly demonstrated in string - to - tree # otherefr ; # refr [SEP]", "cit": "the value of human annotated syntactic structures for statistical machine translation has been clearly demonstrated in string - to - tree # refr, tree - to - [SEP]"}
{"pre": "in recent years, syntax - based translation models # otherefr ; # refr have achieved significant progress in improving translation quality, due to the availability", "cit": "mi and huang # otherefr ; # refr without sufficiently leveraging rich tree context. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "most of the previous work on semantic role labeling relation extraction focuses on binary classification or entity linking # otherefr ; # refr. [SEP] the [SEP]", "cit": "however, current semantic parsers such as the assert are not able to recognize support verb constructions such as? x conducted an attack on y? [SEP]"}
{"pre": "in spoken language understanding, the parsers is a major formalism that can be used for parsing and spoken in the world # refr. [SEP] this [SEP]", "cit": "basically, it is similar to earley is algorithm # otherefr, augmented with unification # refr and probability # otherefr. [SEP]"}
{"pre": "we tuned the model parameters to maximize the bleu score on the development set, using the z - mert package # refr. [SEP]. [SEP]", "cit": "we tuned the model weights against the wmt08 test set # otherefr using z - mert # refr, an implementation of minimum [SEP]"}
{"pre": "for the experiments in section 5, we use the bidirectional pos tagging approach proposed by # refr. [SEP]. [SEP] a technique of bidirectional sequence labeling [SEP]", "cit": "first, a pos tagger needs to be tested for its robustness in handling heterogeneous data. 1 statistical pos taggers perform very well when their [SEP]"}
{"pre": "in a dialogue management step, an information state is trained on the dialogue data set, and then computed by the previous work on the [SEP] [SEP] [SEP]", "cit": "# refr introduced a schema of speech acts for evaluation of the darpa communicator system performance. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we follow a standard hidden markov model # otherefr and hmm # refr. [SEP] training / svm - based model # otherefr, [SEP]", "cit": "to date, a number of different schemes and techniques have been proposed for sentence - based classification of scientific literature according to information structure, e. [SEP]"}
{"pre": "in the second international cross - lingual topic segmentation bakeoff # otherefr, # refr, we proposed a system for automatic speech evaluation", "cit": "and # refr report results from feature selection experiments that include arabic sources, though they do not report on accuracy. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, we plan to use the sophisticated sophisticated sophisticated search strategies to find the optimal strategies that are effective in our domain, and to perform joint", "cit": "this task is much simpler than modeling a complete dialogue session ( e. g., as proposed in turing test ), and probably not enough [SEP]"}
{"pre": "syntactic parsing has made tremendous progress in the past 2 decades # otherefr ; # refr, and accurate syntactic parsing is often assumed when developing [SEP]", "cit": "syntactic parsing has made tremendous progress in the past 2 decades # otherefr ; # refr, and accurate syntactic parsing is often assumed when developing [SEP]"}
{"pre": "in the area of speech recognition, to improve the quality of spoken transcripts # refr, is considered the problem of identifying and even more informative summaries for", "cit": "the convenience and efficiency of reading transcripts # otherefr ; # refr : trading off the expected salience of excerpts with their recognition - [SEP]"}
{"pre": "we show that his ccl parser achieves good performance on this task, since it was improved by selecting the most appropriate pos taggers # refr, and", "cit": "our work builds on two older part - of - speech inducers? word clustering algorithms of # refr and brown et al # otherefr [SEP]"}
{"pre": "in keyphrase extraction, information extraction could be applied to any keyphrases, for this task # refr. [SEP] this information [SEP]", "cit": "recently, a resurgence of interest in keyphrase extraction has led to the development of several new systems and techniques for the task [SEP]"}
{"pre": "ibm models # otherefr, as well as the hidden - markov alignment model ( hmm ) # refr, ibm models 3 and hmm - models", "cit": "1994 ), # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the model scaling factors? 1,..,? m? m? 1, n? 1, n? 1, n? 1,", "cit": "with the training sentences yi and their simulated confusion sets n ( yi )? represented as hypergraphs d ( yi ) )? we can perform [SEP]"}
{"pre": "parallel corpora have been shown to provide an extremely rich source of constraints for statistical machine translation # otherefr ; # refr. [SEP] this algorithm [SEP]", "cit": "2. 2. 1 phrase table training for our russian - english system, we trained a phrase table using the moses experiment management system # [SEP]"}
{"pre": "tectomt has quite different distribution and characteristics of errors compared to standard smt # otherefr ; # refr. [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "in our future experiments, we plan to improve spe by applying techniques suited for monolingual alignment, e. g. feature - based aligner [SEP]"}
{"pre": "in this section, we outline the results of the same topic model # refr as # otherefr. [SEP] the word? [SEP] the [SEP] [SEP]", "cit": "# refr used topic modelling to identify semantically incoherent documents within a document collection ( vs. coherent topics, as targeted in this research ). [SEP]"}
{"pre": "we have used the following similarity measure ( wu and # refr, # otherefr. [SEP] similarity values ). [SEP] ( 5 ) [SEP] [SEP]", "cit": "in order to quantify the relative meaning of words in the lexical fields of the seed - crux, we define the following semantic similarity metric based [SEP]"}
{"pre": "for example, they can be integrated deeply at each decoding step # otherefr ; # refr, or can be integrated shallowly in a [SEP]", "cit": "examples are parser co - training # otherefr, dependency parsing stacking # refr, product model pcfg - la parsing # otherefr [SEP]"}
{"pre": "we are currently developing the grammar of natural language toolkit # refr. [SEP] this system includes nlp - tools, which we used nltk [SEP] [SEP]", "cit": "systems like nltk # refr and gate # otherefr do not offer functionality for lexical resource management. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "many researchers have investigated applying machine learning to corpus specifically annotated with this task in mind, prop - bank, since 2000 # otherefr ; [SEP]", "cit": "many researchers have investigated applying machine learning to corpus specifically annotated with this task in mind, prop - bank, since 2000 # otherefr ; [SEP]"}
{"pre": "to set up our lexicon, we built an automatically from the data using the c & c tools5 proposed by # refr [SEP] the [SEP] [SEP] [SEP]", "cit": "the emergence of standard architectures for generators ( rags, # refr ) and the possibility to use a standard syntactic realizer answer the first issue [SEP]"}
{"pre": "the second change occurred with the use of discriminative dependency parsers, we use two different feature sets, namely the projective dependency parser of # refr and", "cit": "we include in the table results from the pure transition - based parser of zhang and clark # otherefr ( row? h & s10 [SEP]"}
{"pre": "distant supervision has proved to be a popular approach to relation extraction # otherefr ; # refr. [SEP] filtering the data of [SEP] filtering [SEP] [SEP]", "cit": "many approaches make use of the distant supervision assumption # refr : 1associated with the conference of the spanish society for natural language processing # otheref [SEP]"}
{"pre": "in contrast, other approaches to paraphrase generation have included the matching of the training data # otherefr ; # refr. [SEP] the [SEP]", "cit": "unlike textual entailment # otherefr, textual similarity is symmetric, and unlike both textual entailment and paraphrasing # refr, textual [SEP]"}
{"pre": "we used a multi - threaded version of the giza + + tool # refr. 1 this speeds up the process and corrects an [SEP]", "cit": "after parsing, we re - extracted the leaf nodes of the parse trees and statistically word - aligned the corpus using a multi - threaded implementation [SEP]"}
{"pre": "we find that the relation between pairs of word tokens are more effective in the text extraction competitions # refr, and the berkeley parser # otheref", "cit": "consequently, stanford dependencies are widely used : in biomedical text mining # otherefr, information extraction ( wu and # refr and sentiment analysis # [SEP]"}
{"pre": "in order to make the local temporal information, we use the integer linear programming ( ilp ) framework proposed by # refr. [SEP] the global inference", "cit": "there is a large body of related work that focuses on ordering events or classifying temporal relations between them # otherefr ; # refr ; man [SEP]"}
{"pre": "distributional thesauri have been used in a wide variety of areas including sentiment classification # otherefr, lexical acquisition # refr, lexical relatedness #", "cit": "# refr proposed a notion of distributional generality, observing that more general words tend to occur in a larger variety of contexts than more specific words. [SEP]"}
{"pre": "for the ibm models, we aligned the text of the giza + + + # refr and the ibm models # otherefr ), [SEP]", "cit": "in general a statistical machine translation system is composed of three components : a language model, a translation model, and a decoder # refr. [SEP] [PAD]"}
{"pre": "id participant cmu carnegie mellon university # otherefr cu - bojar charles university - bojar # refr cu - dep [SEP]", "cit": "id participant cmu carnegie mellon university # otherefr uedin - williams university of edinburgh - williams # refr uedin university [SEP]"}
{"pre": "we used bleu # otherefr, meteor # refr, ter # otherefr, as well as the number of sentences [SEP] [SEP] [SEP]", "cit": "we report case - insensitive scores for version 0. 6 of meteor # refr with all modules enabled, version 1. 04 of ibm - style [SEP]"}
{"pre": "opinion summarization has previously been applied to restricted domains, such as product reviews # otherefr and news # refr, and news # otheref", "cit": "our lexicon consists of mpqa lexicon # refr, general inquirer # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "there have been many studies on detecting emotions in blogs, and we decided to inferencing # otherefr ; # refr [SEP] the [SEP] [SEP]", "cit": "there is also work in more sophisticated aspects of sentiment, for example, in detecting emotions such as anger, joy, sadness, fear, [SEP]"}
{"pre": "in addition, due to its high efficiencies, it has also been proposed to model domain adaptation by # refr. [SEP] this problem and daume [SEP]", "cit": "another popular task in smt is domain adaptation # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use a statistical parsing model trained on the wall street journal portion of the penn treebank, using a simple lexicalized probabilistic context - free grammar", "cit": "their models and algorithm? subsequently packaged together into the publicly available spade discourse parser1? make use of the output of the # refr [SEP]"}
{"pre": "# refr show that for highly inflectional languages, by replacing arabic dialectal languages, which cannot be used for translating arabic dialect [SEP]", "cit": "for example, magead # refr is a morphological analyzer and generator that can analyze the surface form of msa and dialect words into their root [SEP]"}
{"pre": "this idea has been developed and applied to a wide variety tasks, including morphological analysis # otherefr ; # refr. [SEP] features [SEP] this [SEP]", "cit": "this assumption is realistic : while truly parallel data ( humanly created ) might be in short supply or harder to acquire, adapting statistical machine translation [SEP]"}
{"pre": "the parsers that we chose to evaluate are the c & c ccg parser # otherefr, the stanford parser # refr, and [SEP]", "cit": "the present paper deals with five parsers evaluated within the translation framework : three genuine dependency parsers, namely the parsers described in # other [SEP]"}
{"pre": "most research on unsupervised parsing has focused on english # otherefr ; # refr. [SEP] distributional representations # otherefr on unannotated", "cit": "clark # otherefr reports 42. 0 % unlabeled f - score on the same data using distributional clustering, and # refr obtain 51. [SEP]"}
{"pre": "we will show how similarity measures can be calculated using the measure of pairwise similarity # refr and relatedness measures # otherefr based on the computation [SEP]", "cit": "since the very beginning of computational linguistics, many studies have been devoted to the definition and the implementation of automatic measures for word relatedness # otheref [SEP]"}
{"pre": "despite the lambda optimization issue, previous work in bilingual word alignment has shown that it is possible to improve smt quality [SEP] the smt model [SEP]", "cit": "to compensate for this we also experiment with a 5 - gram suffix - based lm in addition to the surface - based lm # otherefr [SEP]"}
{"pre": "in this work, we treat sentiment classification as a classification task as a binary classification task # refr, where the authors? positive? negative polarity is", "cit": "indeed, classical approaches to sentiment analysis # refr are not directly applicable to tweets : while most of them focus on relatively large texts, e. [SEP]"}
{"pre": "many approaches have been proposed to solve the word sense disambiguation problem, including machine translation # otherefr, sentence similarity # refr, and word", "cit": "in natural language processing, label propagation has been used for document classification # otherefr, word sense disambiguation # refr, and sentiment categorization [SEP]"}
{"pre": "the approach has been used in a number of lexical semantics, and a large number of verbs and nouns in the lexical semantics of verbs [SEP] phenomena #", "cit": "yet there have been few attempts to learn finegrained lexical classifications from the statistical analysis of distributional data, analogously to the induction of syntactic knowledge # [SEP]"}
{"pre": "ilp has been used extensively for text - to - text generation problems in recent years # otherefr ; # refr ). [SEP] text [SEP]", "cit": "iii and marcu, 2002 ; martins and smith, 2009 ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in contrast, active learning has been applied to a number of natural language processing # otherefr ; # refr. [SEP] the problem of [SEP] [SEP]", "cit": "much of the literature has explored one task? selecting sentences to translate and add to the training corpus # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "semcor # refr is a subset of the brown corpus plus the semcor annotated corpus # otherefr. [SEP] the sense of a lemma [SEP]", "cit": "we produced baselines using wordnet 2. 1 # refra ) and a number of distributional similarity measures. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "ilp has been used mainly for coreference resolution in a number of textrank # otherefr ; # refr. [SEP] this [SEP] [SEP] [SEP]", "cit": "since then, ilp has been widely used in various tasks in nlp, including semantic role labeling # otherefr, and summarization [SEP]"}
{"pre": "sentence - level representations have been explored in numerous tasks, such as word sense disambiguation # otherefr, and sentence segmentation # refr [SEP] [SEP]", "cit": "for unsupervised methods, sentence importance can be estimated by calculating topic signature words # refr, combining query similarity and document centrality within a graph - based [SEP]"}
{"pre": "the model brings together aspects we? ve previously looked into separately and annotated with semantic analyses of mapping syntactic structures into the semantic analysis of # otheref", "cit": "# refr and schuler et al # otherefr present a model where information about reference is used directly within the speech recogniser, and [SEP]"}
{"pre": "in the embedded approach, an on - line module which statistically induces the likelihood of a particular string being a word is embedded in a morphological analyzer [SEP]", "cit": "there are two approaches to solve this problem : to increase the coverage of the dictionary # otherefr ; # refr and to design a better [SEP]"}
{"pre": "we use the dataset provided by # refr. [SEP] this method. [SEP] the whole - sequence for the latter. [SEP] the latter. [SEP] the [SEP]", "cit": "the mcdc method involves category error correction, i. e., correction of misclassified candidates, while there are several strategies for automatically detecting [SEP]"}
{"pre": "in # refr, the authors employ machine learning automatically ( human ) to automatically ( human - machine learning and machine translation ) to evaluate the [SEP] [SEP]", "cit": "the majority of keyphrases are 1? 4 words long # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "sentential alignment # refr will be used as an application of sentence alignment, paraphrase tables # otherefr. [SEP] the probability of [SEP]", "cit": "as far as we can see, zhu et al # otherefr were the first to use english / simple english wikipedia data for automatic simplification [SEP]"}
{"pre": "in contrast, recent work has shown that high accuracy is a hard task, and it is difficult to perform one of the most [SEP] phenomena # [SEP]", "cit": "# refr reported a long list of correlations between big5 personality traits and 2 feature sets, one from linguistics # otherefr ). [SEP] [PAD]"}
{"pre": "we use a model of dependency parse trees, which is based on the parser of mcdonald et al # otherefr. 6 # refr [SEP] [SEP]", "cit": "the data come from the conll - x and conll 2007 shared tasks # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the part - whole formalism was inspired by the part of the speech tagger # refr in the input to a finite - state grammar. [SEP] [SEP]", "cit": "a more radical approacl h however rooted in the traditional model is to fully map the typed unification grammars \\ [ # refr on the snap [SEP]"}
{"pre": "it performs cubic time parsing for arc - factored models # otherefr ; koo and # refr. [SEP] the global learning framework [SEP] [SEP]", "cit": "93. 03 87. 07 turboparser # otherefr 93. 39 87. 5 systems using additional resources # refr 93. 79 [SEP]"}
{"pre": "there have been several studies aiming to improve the performance of word sense disambiguation # otherefr ; # refr. [SEP] the statistical methods of [SEP]", "cit": "# refr used a spin model to extract emotion polarity of words. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we evaluate our proposed model on the commonly used metrics for coreference resolution : for the ontonotes corpus # otherefr, and the muc", "cit": "five different metrics were taken into account : muc # otherefr, ceaf entity # refr, blanc # otherefr. [SEP] [PAD]"}
{"pre": "# refr applied semi - supervised lexicalized probabilistic models to german by using unlexicalized pcfg models. [SEP] parsing. [SEP]. [SEP] the", "cit": "it is also interesting to review # otherefr conclusion, built on a comparison with the german situation : at that time lexicalization was thought [SEP]"}
{"pre": "most of the previous automatic word segmentation methods are based on decision trees, e. g., # otherefr, and # refr. [SEP]", "cit": "for this purpose, ( schu? tze and # refr adopted a variable memory markov model proposed by # otherefr expanded context of [SEP]"}
{"pre": "given a document d and a kn - tree crf model, we use the noisy channel model # otherefr ; # refr. [SEP] [SEP] [SEP]", "cit": "in text domain, # otherefr applies noisy - channel model and decision tree approaches on this problem. # refr proposes to use a synchronous [SEP]"}
{"pre": "minimum error rate training ( mert ) # refr is a common method for optimizing log - linear model parameters relative to a n - best setting.", "cit": "minimum error rate training # otherefr, statistical machine translation # refr, dependency parsing # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition to the regular distance distortion model, we incorporate a maximum entropy based lexicalized phrase reordering model # refr as a feature [SEP] the block", "cit": "lexicalized phrase orientation models # otherefr ; # refr predict the orientation of a phrase with respect to the last translated one. [SEP] [PAD] [PAD]"}
{"pre": "in the last decade, # refr demonstrated that the optimal parsing problem can be solved by generalizing the fact that the optimal solution is np - complete", "cit": "across languages, dual decomposition has shown to lead to a certificate of optimality for the vast majority of the sentences # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use rftagger # refr for pos tagging. [SEP] morphological analyzers. [SEP] the tagger of # otherefr. [SEP] [SEP] [SEP]", "cit": "part - of - speech # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the engcg - 2 tagger, developed over the timex english tags, using the tnt tagger # refr, has been used by", "cit": "the average tagging accuracy of icetagger is 91. 54 %, compared to 90. 44 % achieved by the tnt tagger, [SEP]"}
{"pre": "this is a core problem for surface realization in natural language generation # otherefr ; # refr, as well as an important step in machine translation", "cit": "iii and marcu, 2004 ; barzilay and mckeown, 2005 ; wan et al, 2005 ) and headline generation # [SEP]"}
{"pre": "in the last few years, there has been a lot of work on automatic evaluation of machine summaries # refr. [SEP] the pyramid [SEP] the [SEP] the", "cit": "even earlier, # refr suggested that there are considerable benefits to be had in adopting model - free methods of evaluation involving direct comparisons between the original [SEP]"}
{"pre": "syntactic parsing was performed using the reranker # refr with a simple model of charniak and johnson reranking parser # otherefr", "cit": "parsing with the # refr reranking parser. 5 for compatibility with ptb conventions, the top - level nodes in parse trees (? [SEP]"}
{"pre": "we have already shown in section 3 how to we used a semi - supervised machine learning approach to pos tagging ( ner ), a corpus of which", "cit": "a few chemical named entity recognition # otherefr ; # refr or classification # otherefr systems have been published. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use an open source toolkit for both the parallel training and test data. 2 # refr, both trained on the target side of the parallel training", "cit": "previous attempts to resolve these issues include specific probabilistic models # refr or leaving the morphological generation to a separate processing step # otherefr. [SEP] [PAD]"}
{"pre": "we compare against the incremental state - of - the - art semantic parsers, as described in # refr. [SEP] ( 1 ) [SEP] [SEP] [SEP]", "cit": "for instance, to annotate data to be used in the study of language development # otherefr, or to build models to map utterances [SEP]"}
{"pre": "in a related work, # refr used a web - based backoff model for noun phrase noun chunking. [SEP] features derived from the google n", "cit": "for example, # refrb ) showed that looking for paraphrase counts can further improve pp resolution. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in order to utilize a linguistically plausible rightcor ( for example, # refr ) parser is described in detail. [SEP] ( 2 ) [SEP] [SEP]", "cit": "in contrast to previous systems taking as input fullydeterminate sequences of pos labels, such as fidditch # refr and mitfp # [SEP]"}
{"pre": "to measure the overlap between the references, we use the ter metric # otherefr, and the bleu # refr. [SEP] [SEP] [SEP] [SEP]", "cit": "the meteor metric # refr uses monolingual alignment between two translations to be compared : a system translation and a reference one. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use a phrase - based translation system similar to giza + + # refr in both directions. [SEP] the former and maximize the ble [SEP] [SEP]", "cit": "corpus - based approaches to machine translation have become predominant, with phrase - based statistical machine translation ( pb - smt ) # refr being the [SEP]"}
{"pre": "figure 2 : organization of the top - down dependency parses # refr. [SEP] the time complexity of the tempeval - 2 # otheref", "cit": "the corpus of stories for children was drawn from the fables collection of # refr1 and annotated as described in # otherefr. [SEP] [PAD]"}
{"pre": "we used minimum error rate training # refr to tune the feature weights for the log - linear model. [SEP] the minimum error rate training # otheref", "cit": "the low - quality bilingual data degrades the quality of word alignment and leads to the incorrect phrase pairs, which will hurt the translation performance of [SEP]"}
{"pre": "we used a sentiment graph as an extension of the dependency parser to perform polarity shift - reduce # otherefr, as well as on opinion [SEP]", "cit": "however, discourse - level information is typically incorporated in a pipeline architecture, either in the form of sentiment polarity shifters # otherefr ; [SEP]"}
{"pre": "for this task, we follow the approach of # refr, who employ a separate classification algorithm for named entities. [SEP] the latter. [SEP] [SEP] [SEP]", "cit": "some researchers, however, have stressed the advantages of tackling each step as a separate task, pointing at different sources and methods needed to accomplish [SEP]"}
{"pre": "while in the early days of stochastic generation, annotations produced for other applications were used # otherefr, the poor results obtained, e. [SEP]", "cit": "while in the early days of stochastic generation, annotations produced for other applications were used # otherefr corpora # refr, i. e. [SEP]"}
{"pre": "joint models have been widely studied to enhance multiple tasks in nlp community, including joint word segmentation and pos - tagging # otherefr ; [SEP]", "cit": "# refr ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in previous work, we proposed a method that uses participantto - participant and that affects the performance of conventional random initializations # otheref [SEP] [SEP]", "cit": "# refr used the spin model to extract word semantic orientation. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used the berkeley parser # refr for both parsing and the french, although we used two different english grammars : the word - pair [SEP] [SEP] [SEP]", "cit": "another common method employed to speed up exhaustive parsers is a coarse - to - fine approach, where a cheap, coarse model prunes [SEP]"}
{"pre": "prior work on subjectivity analysis mainly consists of two main categories : subjectivity of a phrase or word is analyzed regardless of the context # other [SEP]", "cit": "we use opinionfinder # refra ) to identify words with positive or negative semantic orientation. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the hierarchical phrase - based translation framework described in # refr. [SEP] the current decoder as an optimization problem. [SEP] a? [SEP] a?", "cit": "the hypotheses are stored in stacks s,..., s n, where s p contains hypotheses covering p source words just like in stack [SEP]"}
{"pre": "depending on the type of output, these models can be divided into two categories : the constituentoutput systems # otherefr ; # refr and [SEP]", "cit": "lastly, rule composition and different amounts of lexicalization # refr or context modeling # otherefr have been successful with other models. [SEP] [PAD] [PAD]"}
{"pre": "several alternatives now exist : mira # otherefr, pro # refr, linear regression # otherefr among others. [SEP] [SEP] [SEP] [SEP]", "cit": "research in smt parameter tuning has seen a surge of interest recently, including online / batch learning # otherefr, large - scale training [SEP]"}
{"pre": "in the monolingual setting, the f1 score is reported in # refr. [SEP]. [SEP]. [SEP] % # otherefr [SEP] [SEP] [SEP]", "cit": "our second adaptation technique involves training data selection, which has been used, for instance in cross - domain parsing # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "another line of research closely related to ours is in the supervised semantic parsing models that learn to labeled semantic roles # otherefr ; # refr.", "cit": "however, the srl task is known to be especially hard for the framenetstyle representations for a number of reasons, including, the [SEP]"}
{"pre": "in order to parse the utterances of the corpora with different statistical approaches, we used three different lexical features : the prosodic features, the properties of the", "cit": "in this separate - processing approach, reparanda are located through a variety of acoustic, lexical or string - based techniques, then excised before [SEP]"}
{"pre": "syntax - based approaches, on the other hand, model the hierarchical structure of natural languages # otherefr ; # refr. [SEP] the source [SEP]", "cit": "syntax - based approaches, on the other hand, model the hierarchical structure of natural languages # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "in nlp, the global framework has been well studied for both dependency parsing # otherefr and constituency parsing # refr. [SEP] [SEP] [SEP]", "cit": "the time column show how many seconds per sentence each parser takes. 7 approach uas las time zhang and clark # otherefr 93. 26 [SEP]"}
{"pre": "we used minimum error rate training ( mert ) # refr to tune the decoder for the decoder and tune the feature weights for the log - linear", "cit": "we aligned the sentence pairs using the giza + + toolkit # refr and extracted tree - tostring rules according to the ghkm algorithm # [SEP]"}
{"pre": "in a study of dependency parsing, # refr report that the parser helps disambiguation results are computed for a range of features including correct head [SEP] [SEP]", "cit": "there are also attempts at a more fine - grained analysis of accuracy, targeting specific linguistic constructions or grammatical functions # otherefr ; # [SEP]"}
{"pre": "several discourse - level models have been developed for word sense disambiguation # otherefr, # refr ). [SEP] thesa [SEP] [SEP] [SEP] [SEP]", "cit": "for example, disambiguation algorithms that train on arbitrary - size text windows, e. g., # refr and gale et ai. [SEP]"}
{"pre": "we use the phrase - based smt framework described in # refr. [SEP] a noisy - channel model to generate a certain word alignment [SEP] [SEP] [SEP]", "cit": "here, it is applied on top of the good - turing ( gt ) smoothed phrase table # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr, in particular, this problem of the simple ordering stage as a backoff structure that is based on the central problem of pronominal", "cit": "text planning is one of the distinct tasks identified in reiter is \" consensus \" architecture for natural language generation # refr : text p lann [SEP]"}
{"pre": "more recently, # refr combine statistical measures with a rule - based system. [SEP] features derived from a word similar to a phrase chunker. [SEP]", "cit": "there exists an extensive body of research on mwe extraction ( see # refr for a review ), where the only input is a corpus, [SEP]"}
{"pre": "we use the general sense disambiguation algorithm of # refr, a system that exploits the word? s part of a word form tagged corpus of a", "cit": "these approaches are not mutually exclusive and there are, of course, some hybrid cases, for example # refr uses information in mrd definitions ( [SEP]"}
{"pre": "in the clearnlp tool # refr, a list of expressions was used to disambiguate the clauses from the english and the wiktionary [SEP]", "cit": "when present in text, they function as modal qualifiers of the truth of a given proposition, as in example ( 2 ), or they [SEP]"}
{"pre": "we applied the mcclosky - charniak parser # refr with the self - trained biomedical parsing model. [SEP] [SEP] [SEP] [SEP] the self [SEP]", "cit": "different syntactic parsers analyze text based on different underlying methodologies, for instances, the stanford parser # otherefr performs joint inference over the product [SEP]"}
{"pre": "# refr applied this idea to french. [SEP] the problem of french. [SEP] it to english and german. [SEP] it to french [SEP] the morphological [SEP]", "cit": "finally, the extraction of treebank grammars from the french treebanks, which contain less than a third of the annotated data as compared to [SEP]"}
{"pre": "in several recent proposals # otherefr ; # refr, statistical and machine translation # otherefr. [SEP] this problem is [SEP] [SEP] [SEP] [SEP]", "cit": "in work aimed at lexical choice in generation, # refr uses information about significant local co - occurrences to choose which of a set of synonyms [SEP]"}
{"pre": "we use the stanford parser # refrb ) for all experiments. [SEP] sentence compression, which uses both local and global context [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "in our experiments, we obtain this representation from the output of the stanford parser # refr but any other broadly similar parser could be used instead. [SEP]"}
{"pre": "transition - based constituent parsing # otherefr ; # refr is an attractive alternative. [SEP] this model, which is a passive - aggressive update [SEP]", "cit": "transition - based constituent parsing # otherefr ; # refr is an attractive alternative. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the training data released by the task organizers comes from the nucle corpus # refr, which contains essays written by learners of english as a [SEP]", "cit": "the training and test data for this shared task are from the nucle corpus # refr, which consists of about one million words of short essays [SEP]"}
{"pre": "we also plan to utilize the annotated data to build a data set, but we do not have labeled automatic acquisition of predicate - argument relationships # refr", "cit": "hence, diathesis alternations have been the topic of interest for a number of researchers in the field of automatic verb classification, which aims [SEP]"}
{"pre": "document segmentation and document alignment a document collection process a summarization task with sophisticated statistical machine translation # otherefr ; # refr. [SEP] [SEP] [SEP]", "cit": "similarly, the query - focused summarization ( e. g., ( daume? and # refr ) is also related but it focuses [SEP]"}
{"pre": "this paper describes our coreference resolution system participating in the close track of conll 2011 shared task # refr. [SEP] this paper [SEP] a [SEP] [SEP]", "cit": "the conll - 2011 share task # refr? modeling unrestricted coreference in ontonotes? proposes a task about unrestricted coreference resolution, [SEP]"}
{"pre": "this approach is similar to the ones used by # refr. [SEP] a word order maximum a posteriori ( mst ) model [SEP] a feature [SEP] [SEP] [SEP]", "cit": "this was shown in # refr, in which malt parser was used as a feature to mst parser. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, as well as the irstlm # refr, we show that berkeleylmanno3k # otherefr train [SEP] [SEP]", "cit": "tries or variants thereof are implemented in many lm tool kits, including srilm # otherefr, irstlm # refr, cmu [SEP]"}
{"pre": "the senses in wordnet are ordered according to the frequency data in a manually tagged corpus, sem - cor # refr. [SEP] the ratio of the", "cit": "moreover, we compared our system with ims # otherefr, a state - of - theart supervised english wsd system which uses an [SEP]"}
{"pre": "for the english language, we use the moses toolkit # otherefr with n - gram probabilities for the target language model # refr [SEP] [SEP]", "cit": "following models were applied : n - gram posteriors # refr, sentence length model, a 6 - gram lm and ibm - 1 lexicon models [SEP]"}
{"pre": "the systems for the other languages follow the successful models devised for english, e. g. # otherefr ; # refr. [SEP]. [SEP]", "cit": "the arabic propositional structure was predicted using the system described in # refr. # otherefr table 5 shows the detailed per - 14the frame [SEP]"}
{"pre": "ilp has been used extensively for text - to - text generation problems in recent years # otherefr ; # refr, and has shown to", "cit": "similarly, # refr, though not learning weights, do a limited form of compression jointly with extraction. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in spoken dialogue systems, incremental dialogue systems have been used for incremental dialogue systems # otherefr ; # refr. [SEP] - processing [SEP] [SEP] [SEP]", "cit": "recently, approaches have been proposed to improve system turn - taking behavior that use reinforcement learning # otherefr, and hard - coded policies ( [SEP]"}
{"pre": "we used the extended dependency trees that are generated from the algorithm # refr. [SEP] patterns indicating the verbs of the verbs of the shortest path. [SEP]", "cit": "as recent work has shown # otherefr ; # refrb ), patterns in dependency trees are wellsuited to manual rule based re, [SEP]"}
{"pre": "the ctb6 from the ctb dataset # refr is used as the ctb as a preprocessed ctb as the ctb", "cit": "the third comparison candidate is hatori? 12 # refr which reported the best performance in the literature on these three testing sets. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "a number of semi - supervised translation lexicons have been discussed at length # otherefr ; # refr. [SEP] the training procedure [SEP] the [SEP]", "cit": "current statistical machine translation systems use parallel corpora to induce translation correspondences, whether those correspondences be at the level of phrases # otherefr, or [SEP]"}
{"pre": "in ltag, the derivation tree structure of a tree adjoining grammar and a 3 # refr. [SEP] this approach is used to [SEP] [SEP]", "cit": "in more recent work, datr has been used to provide a concise, inheritance - based ncoding of lexiealized tree adjoin [SEP]"}
{"pre": "statistical parsing has been an important focus of recent research # otherefr ; # refr. [SEP] this strategy has been devoted to predicting dependency structures for", "cit": "figure 1 : dependency graph for czech sentence from the prague dependency treebank1 there exist a few robust broad - coverage parsers that produce [SEP]"}
{"pre": "kernel functions make it possible to capture syntactic information, through the analysis of the target sequence for the target sequence # otherefr ; [SEP] [SEP] [SEP]", "cit": "tree kernels in nlp tree kernels have been extensively used to capture syntactic information about parse trees in tasks such as parsing # otherefr and [SEP]"}
{"pre": "in our system, we use the semantic role labeler ( mst ) # refr for the conll 2008 shared task. [SEP] system [SEP] the [SEP]", "cit": "the mate parser # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition to the regular distance distortion model, we incorporate a four - based lexicalized reordering model of # refr with three orientation and [SEP] non", "cit": "in our system, we use the following standard feature functions? to score english - spanish phrase pairs :? 4 phrase - table scores, which [SEP]"}
{"pre": "constituency parsers have advanced considerably in the last two decades # refr boosted by the availability of the penn treebank # otherefr [SEP]", "cit": "the discriminative re - scoring models # otherefr ; # refr can be viewed as previous attempts to higher - order constituent parsing, using some [SEP]"}
{"pre": "in # refr, we showed that the selectional preferences can be for specific domains ( i. e., identifying verbs, nouns, nouns,", "cit": "pantel and lin # otherefr and # refr have pointed out that wordnet often includes many rare senses while missing out domainspecific senses [SEP]"}
{"pre": "in addition, we show that the model in the conll - x shared task data sets # otherefr ; # refr can be seen as", "cit": "exact inference for parsing models that allow non - projective trees is np hard, except under very restricted independence assumptions # otherefr ; mcdonald and [SEP]"}
{"pre": "in the case of sentiment analysis, while people are able to achieve 87. 5 % accuracy # otherefr on newspaper text # refr.", "cit": "however, collective or joint classification has made substantial impact in other nlp tasks, such as opinion mining # refr, text categorization # otheref [SEP]"}
{"pre": "lexter # refr extracts maximal ength noun phrases ( mlnp ) from a corpus, and then applies a set of directed [SEP] ( [SEP] [SEP]", "cit": "multi - word atr usually uses linguistic information in the form of a grammar that mainly allows noun phrases or compounds to be extracted as candidate terms : [SEP]"}
{"pre": "this package, and the tbl framework itself, are described in detail by # refr. [SEP] this document. [SEP] the text [SEP] [SEP] [SEP] [SEP]", "cit": "other attempts to address efficiency include the fast transformation based learning ( tbl ) toolkit # refr which dramatically speeds up training tbl systems, and [SEP]"}
{"pre": "the top - most parse steps introduce lexical items while the lower ones create new nonterminals according the ccg combinators # otherefr [SEP]", "cit": "another set of approaches has investigated the case where no logical forms are provided, but instead some form of feedback or response from the world is used [SEP]"}
{"pre": "we tune all models using batch mira # otherefr with? 5 - gram lms # refr. [SEP] the passive - [SEP] [SEP] [SEP] [SEP]", "cit": "tuning with k - best batch mira # refr is also supported via callouts to moses. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the perceptron algorithm # refr for the parameter values of ctb2p ctb 5. 0. [SEP] the crf [SEP] the [SEP]", "cit": "there are two primary classes of models : character - based, where the foundational units for processing are individual chinese characters # otherefr ; [SEP]"}
{"pre": "for this reason, we use a reordering model that describes the word order of galley et al. # otherefr, [SEP] the [SEP]", "cit": "there are many ways of incorporating syntax into mt systems, including the use of string - to - tree translation # otherefr, or pre [SEP]"}
{"pre": "in spoken dialogue systems, many other parsers have been investigated # otherefr ; # refr. [SEP] this strategy is [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "computational parsers, however, still tend to operate an entire sentence at a time, despite the advent of speech - to - intention dialogue systems [SEP]"}
{"pre": "we pos - tagged the data of both switchboard data as well as for annotating learner english. # refr used tags to encode [SEP] syntactic [SEP]", "cit": "annotators were given automatically - derived pos tags from tnt # refr, trained on the susanne corpus # otherefr, but created [SEP]"}
{"pre": "we use a phrase - based smt system called? pivoting? in # refr. [SEP] a tm based? [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "other important publications about pivoting approaches for machine translation include # otherefr, # refr, # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "several recent studies # otherefr ; # refr suggest that distributional methods can be applied to the resolution of word sense disambiguation. [SEP] the distributional", "cit": "using the framework of # refr, we found that the bias of lower frequency words for preferring high - frequency neighbours was higher for rff [SEP]"}
{"pre": "in reality, however, this is cast as a coreference problem, and several systems have been developed to deal with grammatical errors # otherefr", "cit": "previous investigations of coreference errors have focused on quantifying the importance of subtasks such as named entity recognition and anaphoricity detection, typically by [SEP]"}
{"pre": "previously, unlabeled data is explored to derive useful local - context features such as word clusters # otherefr, subtree frequencies # refr, and [SEP]", "cit": "for future work, among other possible extensions, we would like to see how our approach performs when employing more diverse parsers to compose the parse [SEP]"}
{"pre": "the weights? m are usually optimized for system performance # refr as measured by bleu # otherefr as the objective function. [SEP] [SEP] [SEP]", "cit": "for the efficiency of minimum - errorrate training # refr, we built our development set ( 580 sentences ) using sentences not exceeding 50 characters [SEP]"}
{"pre": "recent work by # refr and 1994 et al # otherefr similarly relax supervision to require only parallel corpora to extract parallel sentences from non - parallel", "cit": "recent work uses word - based translation # otherefr ; # refr, fullsentence translation # otherefr to project source language [SEP]"}
{"pre": "we used the wu and palmer measure ( wu and # refr similarity metric measures the depth of the depth of the two concepts in the wordnet taxonomy", "cit": "in our experiments we selected three different algorithms to calculate word similarity using yago2 : wu - palmer ( zhibiao and # refr, [SEP]"}
{"pre": "for instance, the model proposed by # refr uses the following features to capture long - distance reorderings. [SEP] the prefix probabilities among [SEP] higher", "cit": "our approach builds on a variant of tree adjoining grammar # otherefr ) ( specifically, the formalism of # refr ). [SEP] [PAD]"}
{"pre": "in addition, we also assessed the system as a new semantic affinity measure ( srl ), which has been shown to be useful in many natural", "cit": "furthermore, contradiction in itself is important knowledge for recognizing textual entailment ( rte ) # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr applied boosting to constituency trees, which were modeled separately, e. g., the verbnet - based, the [SEP] effort [SEP]", "cit": "examples include base noun phrase chunking # otherefr and multi? task annotation # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "taglet lets students use the coreference system of mckeown, so our generator is syntactically analyzed the texts defined in ( non -", "cit": "this example shows how the strategy depends on a rich ontology : s : e h h h h np : c chris vp : e h h [SEP]"}
{"pre": "approaches in this area span methods for simplifying lexis # otherefr ; # refr, syntax # otherefr. [SEP] the decision [SEP] [SEP]", "cit": "# refr, record and transcribe a corpus of spanish - english codemixed conversation to train a generative model ( naive bayes ) for the task [SEP]"}
{"pre": "in addition, the conll - 2003 named entity recognizer # refr # otherefr can be trained on the daily data set. [SEP] [SEP]", "cit": "directly applying named entity recognition ( ner ) tools on news titles or tweets results in many errors # refr due to the noise in the data, [SEP]"}
{"pre": "in particular, we use variants of existing search optimization # otherefr to train the dialogue act classifier # refr or select the words [SEP] [SEP] [SEP]", "cit": "we also point out (? 4 ), how we can in principle train the planner, like e. g. [ # refr ]. [SEP]"}
{"pre": "the results of the test sections are of the official semeval - 2007 word sense disambiguation task # refr. [SEP] the results [SEP] [SEP] the", "cit": "for wordnet gloss disambiguation, we employed the dataset used in the senseval - 3 gloss wsd task # refr, which contains 15 [SEP]"}
{"pre": "a unification model based on hpsg was designed to deal with the efficiency of restrictions, as defined by # refr. [SEP] the length [SEP] the", "cit": "this claim is consistent with observations of # refr that parsing software optimisation techniques tend to be limited in their applicability to the individual grammars they were developed [SEP]"}
{"pre": "in addition, the morphological analysis technique used in this paper was done by the parser of # refr. [SEP] words per collocated to occur at", "cit": "in the domain of corpus - based terminology two types of tools are currently developed : tools for automatic term extraction # otherefr ; # refr [SEP]"}
{"pre": "this result is relevant to work in large - scale lexicons # otherefr ; # refr. [SEP] the hash table had [SEP] the volume of", "cit": "we use gigaword corpus # otherefr and a 66 % portion of a copy of web crawled by # refr. [SEP] [PAD] [PAD]"}
{"pre": "much previous work looks at the impact of joint sentence and sentiment classification # otherefr ; # refr using rich feature sets that are also possible.", "cit": "our use of an lsvm to assign credit during joint training differs substantially from previous lsvm applications, which have induced latent linguistic structures # other [SEP]"}
{"pre": "the conll - 2005 shared task is mainly in semantic role labeling systems # otherefr ; # refr. [SEP] this approach performed syntactic [SEP] [SEP]", "cit": "some of these systems use features based on syntactic constituents produced by a charniak parser # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "the most widely known are the word alignment model # otherefr ; # refr. [SEP] the class model to maximize the word sequence length penalty.", "cit": "they model operations that are meaningful at a syntax level, like re - ordering children, but ignore features that have proven useful in ibm models, [SEP]"}
{"pre": "syntactic cohesion1 is the notion that dependency structures are more efficient in general # otherefr ; # refr. [SEP] this mechanism is [SEP]. [SEP]", "cit": "early examples of this work include # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "parsing accuracy has been used to improve parsing performance on the natural language processing tasks, such as part - of - speech tagging # otheref [SEP] [SEP]", "cit": "however, another approach is to train a separate out - of - domain parser, and use this to generate additional features on the supervised and unsupervised [SEP]"}
{"pre": "we use a linear model with the averaged perceptron # refr. [SEP] parameter vector w?? ( argmax ) =??? i,", "cit": "table 1 shows the main differences between the vmm, the maximum - entropy classifier and the perceptron # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "much of the work in natural language processing has focused on the challenge of multiword expressions in terms of noun compounds ( mwes ) to detect [SEP]", "cit": "# refr applied lsa to the analysis of mwes in the task of mwe discovery, by way of rescoring mwes extracted from [SEP]"}
{"pre": "we used the second sighan bakeoff # refr to test the? sighan bakeoff - 3 # otherefr to [SEP] [SEP]", "cit": "f - measure # refr is used as the measurement of the performance. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "bootstrapping method is a form of self - training # otherefr ; # refr, but has been applied to wsj data, [SEP] [SEP]", "cit": "many bootstrapping algorithms have been proposed for a variety of tasks : word sense disambiguation # otherefr, and statistical parsing # refr. [SEP]"}
{"pre": "while there has been some prior work in determining whether adjacent characters of a particular position of the current position of an individual characters ( e. g.", "cit": "a meanwhile classic approach towards domainindependent linear text segmentation, c99, is presented in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the wapiti toolkit # refr for the general estimation. [SEP] training and the gradient ascent model for parameter estimation. [SEP] it goes", "cit": "existing is methods include generalized iterative scaling # otherefr, and sequential conditional generalized iterative scaling ( scgis ) by # refr. [SEP] [PAD] [PAD]"}
{"pre": "we used the l - bfgs toolkit # otherefr for estimation and the estimation of training data was first introduced by # refr for estimation and", "cit": "traditional maximum entropy learning algorithms, such as gis and iis # otherefr, can be used to train crfs, however, it [SEP]"}
{"pre": "we have access to the english - french bilingual corpus # refr. [SEP] the source senna word order between two languages. [SEP] the [SEP] [SEP] [SEP]", "cit": "# refr describes this technique in detail, while pinkham & corston - oliver # otherefr describes its integration with msr - mt [SEP]"}
{"pre": "in esl +, the main task of text genre was to identify english words # refr. [SEP] ( i. e., [SEP] [SEP] [SEP]", "cit": "the simplest kind of formality measure is based on word length, which is often used directly as an indicator of formality for applications such as [SEP]"}
{"pre": "the suggested approaches have been limited by the use of sentence - level minimum bayes - risk decoding # otherefr ; # refr. [SEP] [SEP] the", "cit": "however, although it is standard practice in mt evaluation to measure increases in automatic metric scores with significance tests # otherefr ; # refr, [SEP]"}
{"pre": "in machine learning work on nlp, # refr use the task of predicting the next set by giving a uniform representation set of possible descriptions of the", "cit": "along similar lines, past work has also focused on interpreting natural language instructions # otherefr ; # refr, which takes into account the goal [SEP]"}
{"pre": "in this paper, we present the crotal semantic role labelling # otherefr shared task # refr for english, and ma ` # otheref", "cit": "we present a system developed for the conll - 2009 shared task # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in translating from morphologically rich languages like arabic, # refr, english # otherefr show that a translation of source language sentence and [SEP] [SEP] [SEP]", "cit": "while comprehensive arabic preprocessing schemes have been widely adopted for handling arabic morphology in smt # otherefr, # refr, lee # otheref [SEP]"}
{"pre": "we use the memory - based tagger # refr trained on the bnc. [SEP] polynomial time ( 1 )? iob? [SEP] [SEP] [SEP]", "cit": "we further explore the options of both feature generator and crf + + trainer by manipulating labelling formats ( iob vs iobes # refr ) [SEP]"}
{"pre": "# refr proposed a search algorithm inspired by search based on cube - pruning # otherefr and cube - pruning # refr. [SEP] the [SEP] [SEP]", "cit": "cube pruning # otherefr ; # refr is used to find the k - best items with integrated language model for each node. [SEP] [PAD] [PAD]"}
{"pre": "many alternative methods have been proposed based on the algorithms in machine learning, such as averaged perceptron # otherefr, margin infused relaxed algorithm [SEP]", "cit": "many alternative methods have been proposed based on the algorithms in machine learning, such as averaged perceptron # refr, maximum entropy # otherefr [SEP]"}
{"pre": "the second constraint, known as the cohesion constraint # refr, uses the dependency tree # otherefr of the hmm. [SEP] ( 1 ) [SEP]", "cit": "iii and marcu, 2005 ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for the 2012 sts task, # refr submitted the perp system, which performed competitive linkings. [SEP] the sentence to [SEP] the [SEP] the [SEP]", "cit": "licence details : http : / / creativecommons. org / licenses / by / 4. 0 / # refr. [SEP] [PAD] [PAD]"}
{"pre": "in contrast, classifiers for semantic relations between nominals have been used for specific semantic relations ( gi # refr. [SEP] ) [SEP] ( [SEP] [SEP] [SEP]", "cit": "# refr classify noun compounds using the mesh hierarchy and a multi - level hierarchy of semantic relations, with 15 classes at the top level. [SEP] [PAD]"}
{"pre": "in the most common practice, the graph - based parsers still have been trained with the maximum spanning tree algorithm # otherefr ; # refr", "cit": "a similar line of research investigated the use of integer linear programming ( ilp ) formulations of parsing # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in # refr, pre - orderings are filled by applying the following way to a standard way to handle the reordering [SEP] the decoding process,", "cit": "pre - processing approaches to word reordering aim at permuting input words in a way that minimizes the reordering needed for translation : deterministic re [SEP]"}
{"pre": "lexicalized tree - adjoining grammar ( ltag ) # refr consists of ele - mentary trees, with a lexicalized tree adjoin", "cit": "tree adjoining rammars # otherefr, vijay - shanker and # refr possess trees as basic grammar structures, [SEP]"}
{"pre": "# refr used a log - linear model for morphological analyzer and a discriminatively trained tagger model in a japanese morphological analyzer. [SEP]. [SEP] effort", "cit": "the english data was tokenized and lowercased while the arabic data was tokenized and segmented using mada v3. 1 # refr [SEP]"}
{"pre": "graph - based parsing models # otherefr ; # refr have achieved state - of - the - art accuracy for a wide range of languages [SEP]", "cit": "to match previous work # otherefr ; # refr, we split the data into a training set ( sections 2 - 21 ), a [SEP]"}
{"pre": "a number of systems have also used alternative forms of supervision, including sentences paired with responses # otherefr ; # refr and no supervision # other", "cit": "previous work has developed supervised semantic parsers to map sentences to meaning representations of various forms, including meaning hierarchies # otherefr ; # refr [SEP]"}
{"pre": "in the context of multi - party conversations, # refr identified temporal markers as often indicate that indicate the discourse connectives are rare in the pdt.", "cit": "in the domain of synchronous conversations, prosodic features such as duration, speech rate and pause have been used for spoken dialogue # otherefr ; [SEP]"}
{"pre": "# refr developed an approach to multimodal integration, and the interpretation of multimodal interfaces for interpretation that is limited resources such as speech recognition. [SEP] [SEP] [SEP]", "cit": "the first issue focuses on the fusion aspect, which has been well studied in earlier work, for example, through unificationbased approaches # other [SEP]"}
{"pre": "in this paper, we show that itg parsing # otherefr provides a form of a phrase - based alignment from dependency trees. # [SEP]", "cit": "# refr compared yamada and knight? s # otherefr tree - to - string alignment model to itgs. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "in this approach, source # otherefr ; # refr, or both side # otherefr tree structures are used for model training. [SEP]", "cit": "there are word reordering constraint methods using itg # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for example, on the wmt 2006 shared task, the french to english translation task has included a translation accuracy, and a translation evaluation, [SEP]", "cit": "first, we train a german to english system based on the data of the wmt 2006 shared task # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the past few years, supervised dependency parsing has gained universal interest due to its usefulness for unsupervised dependency parsing, including work # otherefr ;", "cit": "recently, dependency parsing has gained popularity as a simpler, computationally more efficient alternative to constituency parsing and has spurred several supervised learning approaches # [SEP]"}
{"pre": "maltparser # refr is a transition - based dependency parser that obtains a dependency tree in the maltparser # otherefr with a language", "cit": "it proved to be crucial in semantic role labelling and dependency parsing # otherefr ; # refr ; we expect it be essential for our task [SEP]"}
{"pre": "it has been demonstrated to be highly effective in a wide range of tasks, including multidocument summarisation # otherefr, and machine translation [SEP]", "cit": "12this ranking has been disputed over a series of papers # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the domain of components of text generation, the dialogue systems are built to produce verbal target utterances for the oh and [SEP] natural anguage [SEP] [SEP]", "cit": "ratnaparkhi # otherefr and oh and rudnicky ( oh and # refr both studied surface generators for the air travel domain [SEP]"}
{"pre": "possible fixes to this problem include using a proper sentence level metric such a meteor # otherefr or a pseudo - corpus from the last few", "cit": "more recently, standard structured prediction algorithms that target linearly decomposable approximations of translation quality metrics have been thoroughly explored # otherefr ; # [SEP]"}
{"pre": "the feature weights were tuned on a development set by applying minimum error rate training ( mert ) under the bleu criterion # refr. [SEP].", "cit": "two - way word alignment was computed using giza + + 2 # refr, and alignment symmetrization using the growdiag - final [SEP]"}
{"pre": "nuggeteer # otherefr ; # refr. [SEP] the problem of current statistical machine translation systems ; [SEP] this work [SEP] [SEP] [SEP] [SEP]", "cit": "the qaviar system first described an approximate automatic evaluation technique using keywords, and pourpre was the first publicly available implementation for these nugg [SEP]"}
{"pre": "several approaches have been proposed to deal with such problems, including part of speech tagging # otherefr, parsing # refr, machine translation # other", "cit": "a number of techniques have been proposed for automatic keyword extraction # otherefr ; # refr, and they are designed to extract keywords from a [SEP]"}
{"pre": "we then calculate weights associated with a set of discounting algorithm # refr. [SEP] the results of the de ( for example [SEP] [SEP] the [SEP] [SEP]", "cit": "phrase table smoothing uses good - turing scheme # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in 2007 the issue of the fine - grained semantic relation classification task, which was a very common choice in natural language processing ( nl [SEP] [SEP]", "cit": "we evaluated our model on a semantic relation classification task : semeval 2010 task 8 # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used the multeval toolkit # refr for evaluation. [SEP] system ( s ). [SEP] bleu, as well as [SEP] [SEP] [SEP] [SEP]", "cit": "we average results over three tuning runs and use approximate randomization to measure statistical significance # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr use a distributional similarity model in order to discover paraphrases. [SEP] a text corpus consisting of the t of the v, h [SEP]", "cit": "many applications like qa, ir, ie and machine translation # otherefr ; # refr have to recognize that the same meaning can be expressed [SEP]"}
{"pre": "the atis corpus for our experiments is part of speech tagging with a stochastic parsed using a stochastic part of speech tagger # refr. [SEP]", "cit": "for our experiments, we used a manually corrected version of the air travel information system ( atis ) spoken language corpus # refr annotated in the [SEP]"}
{"pre": "# refr bootstrapping methods on bootstrapping approaches to word re - score seeds are presented. [SEP]. [SEP] the techniques of the training data, [SEP]", "cit": "# refr focus on this issue by considering an approach called strapping for word sense disambiguation. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "much of the current phrase - based models # otherefr ; # refr that use lexicalized reorderings, which can be learned by our", "cit": "work in # otherefr ; # refr modeled the limited information available at phrase - boundaries. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "supertagging has since been effectively applied to other formalisms, such as hpsg # otherefr, and as an information source for [SEP]", "cit": "variations on this approach drive the widely - used, broad coverage c & c parser # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in order to detect automatically identify interaction natural language processing # otherefr ; # refr, information extraction # otherefr have been [SEP] [SEP] [SEP]", "cit": "it has shown that during human machine dialog, there are sufficient cues for machines to automatically identify error conditions # otherefr ; # refr. [SEP]"}
{"pre": "several readability studies in the past decade have reported a performance gain when using nlp - enabled features, e. g. # otherefr", "cit": "several studies # otherefr ; # refr have used nlp - enabled feature extraction and state - of - the - art machine learning algorithms [SEP]"}
{"pre": "the third line,? 4. 2. 1 # refr compare the neural network model with those by including the embeddings of # otheref [SEP] [SEP]", "cit": "recent works have shown that multi - modal semantic representation models outperform unimodal linguistic models on a variety of tasks, including modeling semantic relatedness and predicting [SEP]"}
{"pre": "the arabic text is preprocessed as noted by # refr. [SEP] a source sequence tagger, which is important for disambiguation [SEP] [SEP]", "cit": "for preprocessing, a similar approach to that shown in # refr was employed, and the mada + tokan system for disambiguation and token [SEP]"}
{"pre": "the same happens for the one proposed in # refr that is applicable to a particular task, i. e. the hierarchical directed acyclic [SEP] phenomena #", "cit": "another tree kernel, more broadly applicable to hierarchical directed graphs, was proposed in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "an interactive natural language for webanno # refr is a web - based web - based webanno # otherefr. [SEP] [SEP] annotations", "cit": "recent annotation tools include the web - based brat # otherefr and its extension webanno # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use mutual information # refr as shown in equation ( 1 ) and the frequency count computed based on the auxiliary data. [SEP] ( 2 ) and", "cit": "we encode the semantic compatibility between a noun and its parse tree parent ( and grammatical relationship with the parent ) using mutual information ( mi ) # [SEP]"}
{"pre": "figure 1 : example of a sentence containing the antecedent for recognizing contradictions., we use the learning of predicate - argument templates from # refr.", "cit": "since typed patterns can distinguish between multiple senses of ambiguous patterns, they greatly reduce errors due to pattern ambiguity # otherefr ; # refr. [SEP]"}
{"pre": "we prune the phrase table using the significance tests available in the moses training corpus, using the phrase table and the moses toolkit # [SEP]", "cit": "we pruned the generated phrase tables following the method introduced in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "recursive neural network ( rnn ) models are promising deep learning models which have been applied to a variety of natural language processing ( nlp ) [SEP]", "cit": "ccae # refr 77. 8????? 87. 2 sent - parser # otherefr????? 82 [SEP]"}
{"pre": "in addition, we computed the following two standard datasets :? english? english? french, and transliteration settings # otherefr, [SEP]", "cit": "among them, statistical spelling - based models which directly align characters in the training corpus have become popular because they are language - independent, [SEP]"}
{"pre": "in the monolingual alignment, a number of component models have been proposed that estimate the probability distribution over the hypergraph representation # otherefr,", "cit": "the search algorithm for the best itg alignment, a best - first chart parsing # refr, was augmented with an a? search heuristic of [SEP]"}
{"pre": "in addition to the biography generation, there are several related approaches for unsupervised ie have been proposed # otherefr and recently proposed # refr.", "cit": "most recently, # refr acquire event words from an external resource, group the event words to form event scenarios, and group extraction patterns for different [SEP]"}
{"pre": "# refr use latent semantic analysis to determine the degree of verb - noun combinations. [SEP] well - known polarity value ( nouns ) of [SEP] [SEP] [SEP]", "cit": "this combination of technologies was also used to good effect by # refr : an example of the contribution of part - of - speech information to extracting [SEP]"}
{"pre": "most often, such pairs are extracted from small bilingual lexicons # otherefr ; # refr. [SEP] the crosslingual glosses [SEP] [SEP]", "cit": "for french / english single words, # refr using a medical corpus of 1. 2 million words, obtained a precision of about 50 % and [SEP]"}
{"pre": "we used a variant of the distribution of verbs, and we used a version of the splitter corpus of verbs [SEP] frames # [SEP] [SEP] [SEP] [SEP]", "cit": "s? aghdha # otherefr ; previous to this, # refr also described a latent variable model of sps. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "in recent years, syntax - based smt systems have evolved for extracting phrase - based # otherefr ; # refr. [SEP] a synchronous cf", "cit": "in fact, some structurebased systems have already shown that they can outperform phrase - based smt systems # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use a statistical parser # refr. [SEP] analysis of the penn treebank, a 5 - gram model built with n - gram model implemented in", "cit": "for example, clair : : utils : : parse provides an interface to charniak parser # refr, stanford parser # otheref [SEP]"}
{"pre": "in addition to the next step, we apply a separate selection strategy to wsd in mt, with appropriate wsd # refr. [SEP] [SEP] [SEP]", "cit": "machine translation systems can suffer, as ambiguity in the source language may lead to incorrect translations, and unambiguous sentences in one language may become ambiguous in [SEP]"}
{"pre": "identification, though an important problem, can be tackled with heuristics # otherefra ; # refr or potentially by using a supervised classifier trained [SEP]", "cit": "space restrictions prevent us from discussing the close relation between this penalty formulation and the existing work on injecting prior and side information in learning objectives in the [SEP]"}
{"pre": "we use minimum error rate training # refr to optimize the feature weights for all systems. [SEP] the algorithm, on the latter, using minimum [SEP] [SEP]", "cit": "the k - best list is also frequently used in discriminative learning to approximate the whole set of candidates which is usually exponentially large # refr. [SEP] [PAD]"}
{"pre": "in contrast, # refr predict the connection between social and tweets using a simple yet effective model trained on tweets and perform online advertising labeling [SEP] tasks [SEP]", "cit": "for example, # refr demonstrated a model that predicted where an author was located in order to analyze regional distinctions in communication. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "there has been a growing interest in learning probabilistic grammars that models trained on large corpora # otherefr ; # refr. [SEP] representations of meaning [SEP]", "cit": "recent work has focused on learning such parsers directly from corpora made up of sentences paired with logical meaning representations # otherefr ; # refr [SEP]"}
{"pre": "# refr uses a naive bayes classifier to disambiguate the word sense disambiguation algorithm on the senseval - 2 data set, which uses a big", "cit": "bag? of? words feature sets made up of unigrams have had a long history of success in text classification and word sense disambiguation # [SEP]"}
{"pre": "# refr also used parallel data for cross - lingual sentiment classification. [SEP] documents for english, for example, to use unsupervised lexicons [SEP] [SEP]", "cit": "for example, pang et al # otherefr focus on sentiment classification of movie reviews in english, and # refr study the problem of [SEP]"}
{"pre": "in recent years, the nlg community has paid significant attention to the task of generating referring expressions, reflected in the seting - up of [SEP]", "cit": "in recent years, the nlg community has paid significant attention to the task of generating referring expressions, reflected in the seting - up of [SEP]"}
{"pre": "semantic parser induction as addressed by # refr, kate and mooney # otherefr. [SEP] a word lattice containing semantic [SEP] it [SEP] it", "cit": "this has been successfully applied in combinatorial categorial grammar # otherefr ; # refr ; as ccg is a lexicalist framework, grammar [SEP]"}
{"pre": "in a new approach to this task, we use the general definition of a set of discrete matrix describing general inference # otherefr ; # refr", "cit": "# refr recently advocated the need for a uniform approach to corpus - based semantic tasks. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "bonsai v3. 2 # otherefrb ), and berkeley parser # refr for english, french, and german, respectively. [SEP]", "cit": "constituent trees are obtained using the parsers of # refr, equivalent resources were previously available for english, catalan, and spanish. [SEP] [PAD] [PAD]"}
{"pre": "nivre? s parser has been tested for swedish # otherefr, english # refr, german # otherefr. [SEP]. [SEP] [SEP]", "cit": "the danish and the dutch data are from the conll 2006 shared task data sets # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "previous approaches to the srl task have focused on syntactic dependency structures # otherefr ; # refr. [SEP] the expressions of sentence pairs [SEP] [SEP]", "cit": "ilp models have been successfully applied in several natural language processing tasks, including relation extraction # otherefr, semantic role labeling # refr and [SEP]"}
{"pre": "definite - clause grammar # otherefr for dutch to illustrate predicates, e. g. # refr, # otherefr. [SEP] the information", "cit": "constraint - based categorial grammar, with delayed evaluation of constraints # refr.. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition to the mt evaluation metric, we also ran system - 2http : / / terp. cs. edu / [SEP] bleu -", "cit": "similar observations have been made by previous researchers # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "while the lack of available summaries could be addressed in summarization # refr, this approach has been relatively little attention in the field of multi - document", "cit": "we have already tried to investigate language - independent possibilities in that direction # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper we use the open - ended objecls 1the focus was recently introduced in # refr and it was recently introduced in this paper.", "cit": "we smooth the m - step by adding a fixed value? to the fractional counts before normalizing # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in a new approach, the context of a projective dependency grammar can be used to parse a sentence, e. g., by maximizing the tri", "cit": "one of such properties, projectivity, requires that any word occurring between a word and a word dependent on be dominated by in first dependency grammars [SEP]"}
{"pre": "# refr also used pos tags to chunk tags, but they did not handle to chunk tags. [SEP] languages. [SEP]. [SEP]. [SEP]. [SEP]", "cit": "in fact, pos tags given to pre - defined morphemes are useful for applications of morphological analysis, such as dependency parsing # otherefr [SEP]"}
{"pre": "measures of local coherence specify which ordering of the sentences makes for the coherence of sentences # refr. [SEP] the coherence relation, can be based [SEP] the", "cit": "pf. kp which makes use of pf as well as the recent reformulation of ct in [ # refr ]. [ karamanis et [SEP]"}
{"pre": "in this paper, we show that the proposed method can be applied to other parsing techniques, such as best - first proposed [SEP] methods [SEP] the second", "cit": "we used a large scale feature selection approach as in # refr to obtain the feature set in table 2. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr use a vector space model to represent word meanings by vectors. [SEP] the words in a sentence. [SEP] it graph. [SEP] it as a", "cit": "previous work on lexical semantic relatedness has focused on two approaches : # otherefr ; # refr, and # otherefr. [SEP] [PAD] [PAD]"}
{"pre": "active learning with multiple optimization and is well - studied # otherefr ; # refr. [SEP] this method requires that [SEP] training [SEP] [SEP] [SEP] [SEP]", "cit": "we use random ( rand ) selection, uncertainty sampling ( us ) ( using sequence entropy, normalized by sequence length ) and information density ( id [SEP]"}
{"pre": "distributional similarity was computed using # refr. [SEP] the w3 each measure # otherefr was computed using the similarity of [SEP] ( w3 [SEP]", "cit": "concept similarity is often measured by vectors of co - occurrence with context words that are typed with dependency information # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "most previous work on syntactic surprisal # otherefr ; # refr \\ ], but we prefer the probability of a sentence by any given the", "cit": "a simple and principled approach to handling structure re - use would be to use adaptation probabilities for probabilistic grammar rules # refr, analogous to cache [SEP]"}
{"pre": "in addition, we use a lexicalized reordering model # refr, with a hierarchical orientation model # otherefr. [SEP] the probability distribution [SEP]", "cit": "the classifier can be trained with maximum likelihood like moses lexicalized reordering # otherefr and hierarchical lexicalized reordering model # refr [SEP]"}
{"pre": "this procedure is similar to what is suggested in # otherefr and # refr, and results in the input sentence being reordered to follow [SEP]", "cit": "this procedure is similar to what is suggested in # refr and # otherefr, and results in the input sentence being reordered to follow [SEP]"}
{"pre": "in contrast, # refr show that rtm is more important for mt, especially in the sentence level metrics that may be beneficial for other tasks [SEP]", "cit": "the most comparable work to ours is gime? nez and ma? # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "social network extraction has recently been applied to literary theory # otherefr, and has the potential to help organize novels that are becoming machine read", "cit": "for example, one recent project identifies conversational networks in novels, with the goal of evaluating various literary theories # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "# refr presented a method that uses a dictionary or lattice - based on a dictionary of word occurrences. [SEP] dictionary words in a dictionary. [SEP] dictionary", "cit": "these approaches employ heuristic search methods with mdl for the task of unsupervised learning of morphology of natural languages # otherefr ; # refr. [SEP]"}
{"pre": "# refr used part - of - speech tags to predict the implicit connectives in the pdtb as a way of the pdtb dataset. [SEP]", "cit": "later it has been shown that word pair features do not appear to capture such semantic relationship between words # otherefr ; # refr. [SEP] [PAD]"}
{"pre": "figure 2 : classification over the dependency parse ( a sentence ) and an adjunction component # refr. [SEP] a dependency parser, we conjecture that [SEP]", "cit": "the grammar ules are based on constraint dependency grammar # refr, and are essentially constraints between modifications. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in a senseval - 3 # refr, one of the authors describe an adaptation of a framenet, and show very effective results when compared with", "cit": "in the last years, crowdsourcing, e. g., using amazon? s mechanical turk platform, has been used to collect data [SEP]"}
{"pre": "entity mention extraction # otherefr ; # refr ) have drawn much attention in recent years but were model entity mention # otherefr - [SEP]", "cit": "entity mention extraction # otherefr ; # refr ) have drawn much attention in recent years but were model entity mention # otherefr - [SEP]"}
{"pre": "in this paper, we show that a sentiment analysis of the senses of the word and the word can be found in the surrounding context [SEP] ( [SEP]", "cit": "this would not rule out the possibility that bigram presence is as equally useful a feature as unigram presence ; in fact, # refr found [SEP]"}
{"pre": "for chinese, we parse the english side of the training data with the berkeley parser # refr. [SEP] english and chinese treebank # otherefr", "cit": "the berkeley parser # refr was employed for parsing the chinese sentences. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for example, # refr pointed out that it is possible to obtain a higher accuracy of the semantic structure of the sentences on the basis of the [SEP]", "cit": "# refr improve the state - of - the - art in a reading comprehension task as part of a group project. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we tune all feature weights for our system using batch mira # refr. [SEP]. [SEP] bleu # otherefr. [SEP]. [SEP] [SEP]", "cit": "well - known examples include mert # otherefr, mira # refr, and pro # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in machine translation, the work of # refr has shown that paraphrases can be extracted at the source text. [SEP] to a sentence. [SEP]", "cit": "this idea is a variation on the uses of paraphrase in translation introduced by callison - burch and explored by others, as well [SEP]"}
{"pre": "it is well - known that constituency parsing models designed for english often do not generalize easily to other languages and treebanks. 1 explanations [SEP]", "cit": "the mechanism we employ for incorporating morphology into the pcfg model ( the model 1 parser in # refr ) is the modification of its part - [SEP]"}
{"pre": "in order to automatically assign medical clusters, e2s generated segments consist of written in the bnc # otherefr, together with the aim", "cit": "most top systems in the 2007 computational medicine challenge have benefited from incorporating domain knowledge of free - text clinical notes, such as negation, syn [SEP]"}
{"pre": "the parser is trained with the averaged perceptron algorithm # refr. [SEP] bleu score # otherefr. [SEP] ( w ) [SEP] [SEP] [SEP]", "cit": "when translating between languages with significantly different word order such as english and japanese, it has been shown that metrics which explicitly account for word - order [SEP]"}
{"pre": "discriminatively trained parsers that score entire trees for a given sentence have only recently been investigated # otherefr ; # refr. [SEP] [SEP] [SEP]", "cit": "alternatively, discriminative models can be used to search the complete space of possible parses # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this work, we evaluate two different approaches : the semantic similarity ( s1 ) and the pagerank task of sts ) # refr and the", "cit": "the task is part of the semantic evaluation 2012 workshop # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr proposed a post - processing method during parsing. [SEP] the machine learning based on features and showed good results. [SEP] features [SEP] the [SEP] features", "cit": "johnson and charniak # otherefr proposed a tag - based noisy channel model which showed great improvement over boosting based classifier # refr. [SEP]"}
{"pre": "# refr and anand et al # otherefr focus on recognizing negation between hedging and nominal antecedents. [SEP]. [SEP]. [SEP] the", "cit": "blanco & moldovan # refr have empirically demonstrated that negated sentences often convey implicit positive inferences, or focus, and that these inferences [SEP]"}
{"pre": "a phrase - based translation model was first used in previous work # refr. [SEP] the joint probability p ( e | f ) [SEP] [SEP] [SEP] [SEP]", "cit": "other methods do not depend on word alignments only, such as directly modeling phrase alignment in a joint generative way # refr, pursuing information extraction perspective [SEP]"}
{"pre": "in this paper, we focus on the task of prepositional phrase attachment # refr. [SEP] features # otherefr propose a hidden markov model", "cit": "although boosting has not yet been applied to coreference resolution, it has outperformed stateof - the - art systems for nlp tasks such [SEP]"}
{"pre": "we used the named entity recognizer # refr to recognize the standard set of proper names of nouns. [SEP] the sentence [SEP] a recognise [SEP] [SEP] [SEP]", "cit": "named entity recognizers ( e. g., # refr ) can be trained to recognize proper names associated with semantic categories such as per - [SEP]"}
{"pre": "the mapping rules are learned by a generative model based on either hidden markov models # otherefr, or latent variable learning # refr [SEP] [SEP] [SEP]", "cit": "the difficulty of providing the required supervision motivated learning approaches using weaker forms of supervision. # otherefr ; # refr ground nl in an external [SEP]"}
{"pre": "recent work by # refr and haghighi and klein # otherefr also show that bayesian estimators outperform this technique to estimate parameters of [SEP] (", "cit": "most previous work exploiting unsupervised training data for inferring pos tagging models has focused on semi - supervised methods in the in which the learner is provided with [SEP]"}
{"pre": "decision trees # otherefr, and support vector machines # refr. [SEP] svms svms # otherefr are two kernel methods for document", "cit": "therefore, svms have shown good performance for text categorization # otherefr, and dependency structure analysis # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "mwer can be seen as a sequence labelling task ( like # refr ) by comparing items ( like expressions or expressions ( mwes [SEP] the mw", "cit": "more recently there has been the release of the mwetoolkit # refr for the automatic extraction of mwes from monolingual corpora, that [SEP]"}
{"pre": "supervised approaches which make use of a small hand - labeled training set # otherefr ; # refr, but tend to be tuned to a [SEP]", "cit": "for example, the use of parallel corpora for sense tagging can help with word sense disambiguation # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, because of the conll 2003 data is subject, it has been shown to be useful in many natural language processing tasks, such as", "cit": "it has been used in some natural language processing tasks, such as joint parsing and named entity recognition # refr and word sense disambiguation # other [SEP]"}
{"pre": "in this paper, we use an alignment algorithm that is inspired by the log - linear combination of # refr. [SEP] the likelihood of [SEP] [SEP] [SEP]", "cit": "therefore, we search for the best pronunciation over all segmentations of the word, adapting the monotone search algorithm proposed by # refr for [SEP]"}
{"pre": "most high - accuracy graph - based dependency parsers # refr find the highest - scoring projective trees ( in which no labeled trees ) [SEP] [SEP] [SEP]", "cit": "dependency parsing is one of the fundamental problems in natural language processing today, with applications such as machine translation # otherefr, information extraction # [SEP]"}
{"pre": "in addition to machine translation, an mt system obtains a large amount of monolingual text and to the user has provided a lot [SEP] research effort to", "cit": "other technologies such as lexical - transfer mt # otherefr ; # refr, but can be used in non - domain - restricted ranslation [SEP]"}
{"pre": "other work in sentiment analysis # otherefr ; # refr, to more detailed opinion analysis methods predicting emotional states. [SEP] a single word [SEP] [SEP]", "cit": "contemporary relevant research from the fields of computational linguistics # otherefr ; # refr ; properties of narrative such as novelty # otherefr. [SEP]"}
{"pre": "we use neural language models # refr to train a 5 - gram language model on data set, as they are being used in [SEP] [SEP] [SEP] [SEP]", "cit": "neural lms have achieved positive results in speech recognition and smt reranking # refr ; mikolov et al, 2011a ). [SEP]"}
{"pre": "in a second approach to generating generated summaries, the generated from raw text has been used to generate an automatically # refr. [SEP] system [SEP] utterances (", "cit": "in previous work, we presented person - age, a psychologically - informed rule - based generator based on the big five personality model, and [SEP]"}
{"pre": "the features are integrated in a naive bayes classifier, which was selected mainly for its performance in previous work showing that it can lead to a large corpus", "cit": "we decided to use me as the core of our bootstrapping method because it has shown to be competitive in wsd when compared to other machine [SEP]"}
{"pre": "# refr developed an unsupervised bootstrapping method to determine the polarity of non - subjective nouns. [SEP] sentences. [SEP] ( in [SEP]a ). [SEP]", "cit": "therefor, several studies proposed using contextual features to determine the subjectivity of a given word within its context # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "a few exceptions are the hierarchical # otherefr ; # refr and the string transduction models # otherefr. [SEP] the source sentence to change", "cit": "lexical selection our work is also related to lexical selection in smt where appropriate target lexical items for source words are selected by a statistical model with [SEP]"}
{"pre": "we used the ibm model 4 # otherefr and hmm model 4 # refr for the alignment model. [SEP] the criteria. [SEP] [SEP] [SEP] [SEP]", "cit": "we run 5 iterations of model 1, 5 of hmm # refr, 3 of model 3, 3 of model 4 # otherefr toolkit [SEP]"}
{"pre": "we use a linear model that is trained with the gradient descent - based minimum error rate training ( mert ) # refr. [SEP] [SEP] [SEP] [SEP]", "cit": "other noteable works in mixture modelling in smt are # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "there have been many studies on efficient 1 - best configuration # refr # otherefr parsing models, and it has been more recently has been the", "cit": "system sec / sent # otherefr 15. 3 # refr 15. 6 ours group1 0. 015 ours group2 0. [SEP]"}
{"pre": "# refr reports 42. 0 % using a? - 18 million tokens which are lemmatized using morphological analyzers # otherefr. [SEP].", "cit": "# refr have recently documented minor bleu improvement using factored lms in singlefactored smt to english. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this technique can be used for structured prediction in nlp tasks # otherefr ; # refr, for example. [SEP] 1 [SEP] 1 [SEP] [SEP]", "cit": "the feature combinations play an essential role in obtaining a classifier with state - of - the - art accuracy for several nlp tasks ; recent examples [SEP]"}
{"pre": "we use the standard part - of - speech tagging method proposed by # refr for pos tagging and lemmatization, and also of english. [SEP] the", "cit": "the data used in the experiment was selected from the penn treebank wall street journal, and is the same used by # refr. [SEP] [PAD] [PAD]"}
{"pre": "much of this work has used hand written rules and several language pairs have been studied e. g german to english # otherefr and japanese [SEP]", "cit": "this is known to be inadequate ( al - onaizan and # refr, and this inadequacy has spurred various attempts to overcome [SEP]"}
{"pre": "in contrast, most of the previous research has focused on predicting word error types ( or features for example, content words ), e. g.", "cit": "such tests also arise in reading comprehension, second language learning and other computer - based tutoring systems # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we adopt the ghkm algorithm of # refr to binarization. [SEP] into any derivation step, which is a compactly [SEP] [SEP] into [SEP]", "cit": "syntaxbased smt systems # otherefr ; # refr, and tree - tostring transducers # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr use a similar method to compute the similarity between two words by considering the orthographic similarity of the longest common subsequences. [SEP] it", "cit": "there is a range of past work that has variously investigated cognate detection # refr, character - level decipherment # otherefr [SEP]"}
{"pre": "this reorganization, which was facilitated by the use of intersective levin classes # otherefr, # refr, and patry # otheref [SEP]", "cit": "lexical - semantic classes which aim to capture the close relationship between the syntax and semantics of verbs have attracted considerable interest in both linguistics and computational linguistics [SEP]"}
{"pre": "the uvt - wsd system # refr uses the van de marneffe et al # otherefr. [SEP] the context vector space [SEP]", "cit": "wsd2 is a rewrite and extension of our previous system ( van # refr that participated in the cross - lingual word sense disambiguation [SEP]"}
{"pre": "dependency - based syntactic parsing has become a widely used technique in natural language processing, and many different parsing models have been proposed in recent years # [SEP]", "cit": "dependency - based syntactic parsing has become a widely used technique in natural language processing, and many different parsing models have been proposed in recent years # [SEP]"}
{"pre": "tree kernel approaches have been applied successfully in many areas of nlp # otherefr ; # refr. [SEP] this approach allows for a variety of", "cit": "there are also tree kernel variations such as dependency tree kernels # otherefr and shallow semantic tree kernels # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in recent years, there have been many studies on discourse parsing on the basis of the above handannotated corpora # otherefr ; [SEP]", "cit": "in recent years, there have been many studies on discourse parsing on the basis of the above handannotated corpora ( e. g. [SEP]"}
{"pre": "we used the latest release of collins? parser # otherefr to train a separate shift - reduce dependency parser that showed that [SEP] features based on", "cit": "sentences were part of speech tagged # otherefr, parsed with a dependency parser and labeled with grammatical function labels # refr. [SEP] [PAD] [PAD]"}
{"pre": "this model is inspired by the model of # refr, which enforces a constraint ( i. e., a set of local constraints over all", "cit": "joint inference has been applied successfully 10percentages for? unknown? are omitted here. to other nlp problems # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "for instance, the fn syntactic annotations are listed on the target word # otherefr ; # refr. [SEP] the british national corpus # otheref", "cit": "the analysis is based on framenet # refr, a resource that lists senses and semantic roles for english expressions. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the aline phonetic aligner # refr to align phonetic and orthographic features. [SEP] the algorithms of phonemes. [SEP] a [SEP]", "cit": "among these are : phonetic alignment algorithms # refr, statistical tests for genealogical relatedness # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr presented a new approach to extract content from a large collection of 50 summaries, and show that their performance on automatically determined [SEP] [SEP] [SEP] [SEP]", "cit": "in the past years, there has been quite a lot of summarisation work that has effectively aimed at finding viable evaluation strategies # otherefr [SEP]"}
{"pre": "another effort to enable multilinguality has been proposed by # refr, which translate sentences to collect the data preclude a large amount of data. [SEP]", "cit": "we will perform a semi - automatic validation of babelnet, e. g. by exploiting amazon? s mechanical turk # refr or designing [SEP]"}
{"pre": "particularly, the latter made team? 09 task people reference faust? 12 - 3c # otherefr genia # refr, an approach", "cit": "particularly, the latter made team? 09 task people reference faust? 12 - 3c # otherefr uwmadison? 1 [SEP]"}
{"pre": "in the newest case, some wsd approaches have been proposed which are based on supervised learning # otherefr and unsupervised approaches # refr.", "cit": "as our wsd system for this experiment, we used it makes sense ( ims ), a state - of - the - art supervised ws [SEP]"}
{"pre": "domain adaptation is widely studied in nlp, e. g. the idea of statistical machine translation ( smt ) # refr [SEP] well [SEP] [SEP]", "cit": "although the moses decoder is able to work with two phrase tables at once # refr, it is difficult to use this method when there is [SEP]"}
{"pre": "for example, the work of # refr has shown that coordinations are allowed to be a lexicalized, as shown in the diachronic [SEP]", "cit": "we first briefly discuss the linguistic motivations behind the resolution mechanism we propose, then introduce the fusion operation and show how it can be compared to the [SEP]"}
{"pre": "in addition, the averaged perceptron learning algorithm # refr is closely related to the stochastic optimization. [SEP]a - 1 setting? maxent. [SEP]", "cit": "rd, the pairwise preference for training is constructed by ranking two candidates according to the smoothed sentence - level bleu # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "the translation models are trained with minimum error rate training ( mert ) # refr. [SEP] - 1 % on the wmt 2010 news commentary corpus", "cit": "due to the small size of our crowdsourced corpus, we will use it in the mert tuning # refr, and test its effects [SEP]"}
{"pre": "on the other hand, superarvs # refr was used to automatically detect the relevant entities. [SEP] the expressions of a probabilistic cfg grammar [SEP]", "cit": "for example, superarv language models ( lms ) # refr, which tightly integrate lexical features and syntactic constraints, have been found to significantly [SEP]"}
{"pre": "we use the open - source toolkit jane # refra ), which is an open source translation toolkit. [SEP]. [SEP] the cross - lingu [SEP]", "cit": "# refr and schwartz # otherefr respectively provide additional open - source implementations of phrase - based and hierarchical decoders. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, the parser described in # refr was designed to address the problem of chinese dependency parsing. [SEP] the second [SEP] a comma [SEP] [SEP]", "cit": "in recent years, there has been growing interests in dependency arc prediction in chinese # otherefr, and researchers have also investigated characterlevel chinese [SEP]"}
{"pre": "we use the open source toolkit 1. 4 # otherefr, or the rewrite operation sequence model ( cdg ) # refr [SEP] [SEP] [SEP]", "cit": "we have implemented the inside algorithm, the outside algorithm, and the inside - outside speedup described by li and eisner # otherefr, [SEP]"}
{"pre": "we conducted our dependency parser and use two different parsers, the mate parser # refr and a freely available for english. [SEP] languages. [SEP] the", "cit": "exploiting the morphological agreement in syntactic parsing has been investigated in previous studies, e. g. the bohnet parser # refr employs morphological feature value [SEP]"}
{"pre": "supervised semantic parsers # otherefr ; # refr rely on manual annotation of logical forms, which is expensive. [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "we report performance on two benchmark datasets : geoquery # otherefr and freebase qa ( fq ) # refra ). [SEP] [PAD] [PAD]"}
{"pre": "the tiger treebank # otherefr is based on the probabilistic context free grammars and treebank # refr. [SEP] t. [SEP] t.", "cit": "figure 3 : indication - of - quantity - reading starting from the enriched tiger we used bitpar ( cf. # refr and # other [SEP]"}
{"pre": "we show that for three leading unsupervised parsers # otherefr ; # refra ), a small increase of performance on the wall street journal", "cit": "as this example shows, disagreements # otherefr? reranking - parseraug06. tar. gz, also available from [SEP]"}
{"pre": "the pioneering work in this area includes # refr, who used a manually - created lexical patterns that refer to both lexico - syntactic patterns [SEP]", "cit": "automatic techniques for finding semantic classes include unsupervised clustering # otherefr, hyponym patterns # refr, extraction patterns # otherefr and [SEP]"}
{"pre": "we apply the same dataset as # refr, including the semantic composition of adjectives, essentially by an adjective - noun combination of the [SEP] [SEP]", "cit": "we do not attempt to implement all the corpus pre - processing and co - occurrence extraction routines that it would require to be of general use, [SEP]"}
{"pre": "# refr describe a method for learning word alignment, but they did not show that many word alignment models trained with its posterior probability p ( [SEP] [SEP]", "cit": "# refr applied the markov chain monte carlo method to word alignment for machine translation ; they do not model word fertility. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in a different approach, # refr describes a finite - state morphological analyzer of modern standard arabic which handles both inflectional and derivational [SEP] [SEP]", "cit": "using finite - state methods, it has been possible to describe both word formation and the concomitant phonological modifications in many languages, ranging from straightforward concaten [SEP]"}
{"pre": "# refr proposed a method that utilizes a automatically created a small set of seed entailment rules extracted from the training corpus. [SEP] the training corpus of", "cit": "this intuition is later contradicted in a second experiment by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this paper describes the structure of the lth coreference resolution system # refrb ), which produces single sentences. [SEP] this paper [SEP] [SEP] [SEP] [SEP]", "cit": "after describing in more detail the basic framework, we show some aspects of the resulting analysis of the performance of the berkeley parser # otherefr [SEP]"}
{"pre": "we use the stanford dependency parser ( de marneffe and # refr, which is a special form of directed dependency trees. [SEP] ( [SEP] )", "cit": "efforts now commence towards extending sd for cross - lingual annotation and evaluation # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in recent years, research has shown that opinion detection performed sentiment classification # otherefr ; # refr, and opinion detection [SEP] subjectivity analysis [SEP]", "cit": "sentencelevel subjectivity classification ( e. g., # refr ) and sentiment classification # otherefr ) is the research in text most [SEP]"}
{"pre": "this idea has been developed and applied to a wide variety tasks, including dependency parsing # otherefr, sentiment analysis # refr, and document -", "cit": "elworthy? s # otherefr, has also been used as a halting criterion in nlp # refr,? 4. [SEP]"}
{"pre": "in addition, the similarity measure is defined by the similarity between the snippets in the original sentence x as defined by # refr. [SEP] (", "cit": "recently, many works combined a mrd and a corpus for word sense disambiguation # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in general, the method has been used to find the generation of \\ [ # refr \\ ]. [SEP]'i to provide the general [SEP] [SEP]", "cit": "in generation, examples of such extended processing strategies are head corner generation with its semantic linking # otherefr or bottom - up ( earley [SEP]"}
{"pre": "in the domain of sentiment analysis, a number of approaches have been proposed for classifying the probability of a target word as being a given its surrounding [SEP]", "cit": "current state of art in metaphor detection therefore tends to be? localistic?? the distributional profile of the target word in its immediate grammatical or [SEP]"}
{"pre": "most of the previous work on semi - supervised learning techniques for chinese word segmentation # otherefr ; # refr, and they did not utilize [SEP]", "cit": "with these better modeling techniques, state - of - the - art systems routinely report accuracy in the high 90 %, and a few recent systems [SEP]"}
{"pre": "statistical significance is tested on the bleu metric using approximate randomization # otherefr, as the objective function (? # refr ). [SEP] the", "cit": "bleu? s ability to detect subtle but important differences in translation quality has been questioned, some research showing nist to be more sensitive # other [SEP]"}
{"pre": "in # refr, a tree - based translation model is trained on a tree - to - string transducer are used to - tree transducer - to -", "cit": "a lot of research work undertaken in this decade has used syntactic parsing for linguistically - motivated translation. # otherefr ; # refr. [SEP]"}
{"pre": "the part - of - speech model we use is similar to those by # refr. [SEP] the ordering of the modifier ordering [SEP] [SEP] [SEP]", "cit": "our interpretation of context - dependent modifiers picks up ideas by kamp and partee # otherefr and implements them in a [SEP]"}
{"pre": "smoothing typically adds considerable computational complexity to the system since multiple models need to be estimated and applied together, and applied it is often considered as a black", "cit": "in addition, it would be interesting to see whether these results extend to fields other than language modeling where smoothing is used, such as preposition [SEP]"}
{"pre": "crowdsourcing can allow inexpensive and rapid data collection for various nlp tasks # otherefr ; # refr. [SEP] the [SEP] coverage [SEP] [SEP]", "cit": "the value of this upper bound is quite consistent with the bound computed similarly by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this parser is very similar to the one presented by # refr. [SEP]. [SEP] it is relaxed to [SEP] it as a separate process. [SEP] it", "cit": "the individual derivations are based on nivre? s shift - reduce - style parsing algorithm # refr, as discussed further below. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "the challenge on generating instructions in virtual environments ( give ; # refr ) is a shared task in which natural language generation systems must generate real - [SEP]", "cit": "we duly notice that, for the give challenge in particular ( and probably for human evaluations in general ) the success rates in the laboratory tend [SEP]"}
{"pre": "germanet # refr is a large treebank - trained on negra with a set of negra and tiger treebanks that create new", "cit": "a comparison of unlexicalised pcfg parsing # otherefr trained and evaluated on the german negra # refr and the tu? [SEP]"}
{"pre": "in this paper we show how # refr and zhang et al # otherefr show how to mstparser and categorize non - terminal symbol", "cit": "converted ccg clark and curran # otherefr 90. 9 85. 5 88. 8 # refr 90. 9 86. 0 [SEP]"}
{"pre": "this problem has been extensively studied in the past and several approaches to statistical machine translation ( smt ) # refr. [SEP] the latter [SEP] [SEP] [SEP]", "cit": "this problem is relevant for our work and approaches to deal with it are minimum bayes - risk decoding # otherefr ; # refr. [SEP] [PAD]"}
{"pre": "we use a program called list of decision trees # refr, which was prepared for training, and the ne recognizers. [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "irex ( information retrieval and extraction exercise, # refr ) was held in 1999, and fifteen systems participated in the formal run of the japanese [SEP]"}
{"pre": "there have been many extensions in machine translation systems # otherefr ; # refr, and textual entailment # otherefr. [SEP] this problem", "cit": "some typical tasks are document information retrieval # otherefr ; # refr, query expansions # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the bart package # refr. [SEP] bart package, a package of the bart package, e. g. [SEP] the latter ( [SEP] [SEP]", "cit": "svmlight # otherefr, in the svmlight / tk # refr variant, allows to use tree - valued features. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "paraphrase generation can be used for paraphrase the source sentence, including the target language, the target language, and the target [SEP] [SEP]", "cit": "these phrase extraction heuristics have been extended so that they extract synchronous grammar rules # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in combination with statistical machine translation, several systems have been developed to combine the predictions of the output of the reference systems # refr. [SEP] the [SEP]", "cit": "combined with the latest advances in phrase - based translation systems, it has become more attractive to take advantage of the various outputs in forming consensus translations [SEP]"}
{"pre": "methods that use no supervision at all # otherefr or small amounts of manual supervision # refr have been extensively studied, but still do not perform", "cit": "instead, a parser is trained on annotations in a source language, relying solely on features that are available in both the source and the target language [SEP]"}
{"pre": "to date, most research has focused on supervised machine learning techniques for biomedical text mining # otherefr ; # refr, mostly on those [SEP] text", "cit": "supervised machine learning techniques mostly dominate this area of research # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "dependency model with valence ( dmv ) by # refr. [SEP] this paper is a much similar to our approach. [SEP] it is [SEP] [SEP] [SEP]", "cit": "recent work # otherefr has largely built on the dependency model with valence of # refr, and is characterized by its reliance on gold - [SEP]"}
{"pre": "statistical machine translation # otherefr ; # refr. [SEP] this simple approach is to learn a quasi - synchronous grammar # otherefr. [SEP]", "cit": "machine translation systems have been adapted to translate complex sentences into simple ones # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for example, # refr proposed a syntax - based system which uses a syntax - augmented scfg decoder which handles discontinuous and integrated into a translation model", "cit": "in this work, we investigate the use of rule markov models in the context of treeto - string translation # otherefr ; # refr [SEP]"}
{"pre": "# refr pointed out that semantic drift in espresso has the same root as topic drift # otherefr observed with hits, noting the [SEP]", "cit": "curran et al # otherefr introduced mutual exclu - 1 # refr used graph - based algorithms to reduce semantic drift for word sense [SEP]"}
{"pre": "we evaluate our system by comparing the ontonotes corpus # refr. [SEP] and the second order of the conll - 2012 shared tasks [SEP] [SEP]", "cit": "for coreference resolution, muc # otherefr and ceaf - e # refr are used for evaluation. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "another topic of the web, enrich, provides a natural language list of source and target texts. # refr presented a bootstrapping method [SEP] [SEP] [SEP]", "cit": "the english and target syntactic structures form parallel treebanks, from which transfer rules and translation lexicon can be extracted and used for machine translation ( [SEP]"}
{"pre": "# refr used a linear combination of wordnet and the similarity measure. [SEP] a linear model to segment per 7 # otherefr ), which", "cit": "combinations of different features # otherefr and # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in a document clustering approach, # refr use vectors of duc words as their part of a preceding context # otherefr and a coreference resolution", "cit": "we use the b3 # refr evaluation measure as well as precision, recall, and f1 measured on the ( positive ) pairwise decisions. [SEP]"}
{"pre": "sentence compression has been widely studied in language processing. # otherefr applied the noisy - channel framework to predict the possibilities of multi - document summar", "cit": "another closely related work also takes a maxmargin discriminative learning approach in the structural svm framework # otherefr or by using mira # [SEP]"}
{"pre": "this has led to the development of various dependency parsers, such as those by yamada and matsumoto # otherefr, # [SEP]", "cit": "this paper focuses on dependency parsing, which has become widely used in relation extraction # refr, machine translation # otherefr, and many other [SEP]"}
{"pre": "ukb is a freely - available system that uses the personalized pagerank algorithm # refr. [SEP] the personalized pagerank algorithm to [SEP] the word [SEP]", "cit": "niemann and gurevych # otherefr created wn - wp and wn - wkt alignments using a framework which first calculates the similarity [SEP]"}
{"pre": "in the last step, the entity - based mention model, in which the coreference resolution is a mention - pair model is learned by [SEP] [SEP]", "cit": "much work has been done following the mentionpair model # otherefr ; ng and # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this paper describes the structure of the lth coreference solver used in the closed track of the conll 2012 shared task # refr. [SEP] this [SEP]", "cit": "we applied this solver to the closed track of the conll 2011 shared task # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "system f1 # otherefr 55. 7 # refr 85. 7 # otherefr 91. 6 90. 9 83. 1 [SEP]", "cit": "alternating ems would be expensive here, since updates take ( at least ) o ( l3 ) time, and hard em? s objective ( [SEP]"}
{"pre": "both systems use statistical syntactic parse trees # otherefr ; # refr, and these features were trained on switchboard corpus - damsl corpus statistics", "cit": "even though this seems linguistically highly unnatural # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, several methods have been proposed to detect couples of word sequences # otherefr ; # refr. [SEP] the word segmentation algorithm [SEP] [SEP]", "cit": "# refr define \" collocations \" in terms of monolingual frequency and part - of - speech patterns. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we had fortunately already planned the first replacement course : language and computers, based on the course designed to nltk # refr. [SEP] natural [SEP] [SEP]", "cit": "we have not yet used the natural language toolkit # refr ( see section 3. 1 ) in this course. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "while candito and seddah # otherefr ; # refr. [SEP] these techniques can be included in a pcfg, the empirical tradition", "cit": "in the raw grammar, there are many unaries, and once any major category is constructed over a span, most others become constructible as [SEP]"}
{"pre": "we use charniak parser # refr for pos tagging and named entity recognition with a freely available parser trained on the brown corpus. [SEP] [SEP] [SEP]", "cit": "however, as several previous studies have noted # refr, using parsers can cause problems for open - domain srl. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr applied latent variable models to determine the polarity of a word by a word. [SEP] unannotated [SEP] unannotated [SEP] [SEP]", "cit": "the em - nb ssl algorithm yielded better performance than either an unsupervised lexicon - based approach or a supervised approach for sentiment classification in different data [SEP]"}
{"pre": "in # refr, the authors romanized wsd system exploits the data of the data that achieved a accuracy of 91 %. [SEP] %. [SEP]", "cit": "in applying active learning for domain adaptation, # refr presented work on sentence boundary detection using generalized winnow, while tur et al # otheref [SEP]"}
{"pre": "in addition, we use a distributional semantic parser # refr trained on the penn treebank # otherefr. [SEP] it ( 1 ) [SEP] [SEP]", "cit": "3. 3. 0 # refr for use in features (? 4. 2 ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "dependency parsers have been tested on parsing sentences in english # otherefr ; # refr as well as many other languages # otherefra [SEP]", "cit": "the setup we use two different parsers : # otherefrb ) with the arc eager algorithm as optimized for english in # refr and [SEP]"}
{"pre": "1http : / / www. nist. gov / speech / tests / ace / bootstrapping techniques have been used for such diverse nl [SEP]", "cit": "1http : / / www. nist. gov / speech / tests / ace / bootstrapping techniques have been used for such diverse nl [SEP]"}
{"pre": "the tnt pos tagger # refr has been designed to train a statistical tagger. [SEP] model for english and hebrew. [SEP] [SEP]", "cit": "most portions of pos tagging is not so difficult and a simple pos - based hmms learning 1 achieves more than 95 % accuracy simply using the [SEP]"}
{"pre": "clarke et al # otherefr describe approaches for learning semantic parsers from sentences paired with responses, # refr describe using distant supervision, art [SEP]", "cit": "there has also been work on learning for semantic analysis tasks from grounded data, including event streams # refr and language paired with visual perception # other [SEP]"}
{"pre": "in the muc conferences # refr, newswire portion of the muc conferences ( muc ) 6 and a set of ie [SEP] events which were extracted from", "cit": "the topic of the sixth muc ( muc - 6 ) was management succession events # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "pronoun anaphora, in turn, is learnable from raw data # otherefr ; # refr. [SEP] the pronoun resolution algorithm [SEP] [SEP] [SEP]", "cit": "since no such corpus exists, researchers have used coarser features learned from smaller sets through supervised learning # otherefr ; # refr. [SEP] [PAD]"}
{"pre": "neco extends the stanford? s sieve - based model, in which the authors are taken from the open - source entity mentions, [SEP]", "cit": "incorporating knowledge is challenging, and many efforts to do so have actually hurt performance, e. g. # otherefr ; # refr [SEP]"}
{"pre": "in # refr, the main focus is on the domain of the on the news domain ( part ). [SEP]. [SEP] (? [SEP] [SEP] [SEP]", "cit": "lastly, # refr reported improvements from using multiple decoding paths # otherefr, instead of directly combining the phrase tables to perform domain adaptation. [SEP]"}
{"pre": "in addition, the performance of the dialogue system and the dialogue manager are computed on the provided 2000 domain, and we will also use an [SEP] system", "cit": "many spoken dialogue systems have been developed for various domains, including : flight reservations # otherefrb ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used the second order maximum entropy model ( maxent ) # refr for word segmentation ), and pos - tagging of word segmentation. [SEP] [SEP]", "cit": "we further re - implemented a word - based chinese word segmentation model with the feature templates following zhang et al. # otherefr # refr [SEP]"}
{"pre": "in the first, we applied the ibm model 4 in the models of # refr. [SEP] it is a derivation, a derivation of the translation model", "cit": "if we use a trigram model for the lm, a convenient implementation is to first build a decodedtree forest and then to pick out the [SEP]"}
{"pre": "caraballo # refr also exploited these syntactic structures and applied the conceptual specification of semantic structures to german. [SEP] it has also been proposed to", "cit": "note that the predicate language representation utilized by carmel - tools is in the style of davidsonian event based semantics # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "the development of a large number of automatic annotation of text has been carried out by now the advent of the connectives and the connectives of an", "cit": "however, since we also have in our group an xml - based lexicon of german connectives at our disposal # refr, why not use this [SEP]"}
{"pre": "langid systems appear to perform good - turing ( e. g., # refr ), and summarizers have been used successfully to reduce the", "cit": "previous research has shown that explicit encoding detection is not needed for language identification # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "finally, our work is similar in spirit to sentiment analysis # otherefr, and textual entailment # refr. [SEP] text documents # other [SEP]", "cit": "generating literal textual descriptions of visual scenes has also been studied, including both captions # otherefr ; # refr and descriptions # otheref [SEP]"}
{"pre": "prior work on bilingual lexicon induction has shown that a variety of signals derived from monolingual data, including distributional, temporal, topic, and string [SEP]", "cit": "we assume access to a small amount of parallel data, which is realistic, especially considering the recent success of crowdsourcing translations # refr. [SEP]"}
{"pre": "statistical machine translation ( smt ) has achieved significant progress in recent years, notably the parameter estimation # refr for a given sentence # otheref [SEP]", "cit": "phrase - based methods to machine translation # refr have drastically improved beyond word - based approaches, primarily by using phrase - pairs as translation units, [SEP]"}
{"pre": "the weights of the log - linear interpolation model were optimized on the development set using minimum error rate training ( mert ) # refr. [SEP] [SEP]", "cit": "we used this corpus to extract translation phrase pairs from bidirectional ibm model 4 word alignment # refr based on the heuristic approach of # otherefr [SEP]"}
{"pre": "in addition, it is used in speech recognition and machine translation # otherefr ; # refr. [SEP] this strategy. [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "on the other hand, factored language models ( flms ) have been used successfully for languages with rich morphology due to their ability to process [SEP]"}
{"pre": "in # refr, we suggested and use the former for disambiguation of pantel. [SEP] a sentence with a supervised machine learning algorithm. [SEP] features", "cit": "research in this area initially relied almost totally on pattern identification and extraction # otherefr ; # refr ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the tasks that have been addressed are explication of the reasoning behind the corpus of # refr. [SEP] it 1 ) [SEP] it [SEP] [SEP] [SEP] [SEP]", "cit": "a different approach to cross - lingual pos tagging is proposed most unsupervised approaches consider argument identification as a separate task that is omitted # otheref [SEP]"}
{"pre": "among the earliest studies on token - based classification were the ones by hashimoto et al # otherefr on japanese and katz and gi # refr", "cit": "however, there has been a growing interest in idiom token identification in recent times # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refra ) expanded on this idea and conducted a larger scale study to show the viability of regression as a sentence - level metric of mt [SEP]", "cit": "as we also work with continuous scores, we are making an effort to combine previous feature acquisition sources, such as language modelling # otherefr [SEP]"}
{"pre": "this scheme has proven to be effective for various tasks such as dependency parsing # otherefr, dependency parsing # refr, and information extraction # [SEP]", "cit": "we also used the cbc word clusters of pantel and lin # otherefr and # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this work, we use machine learning methods for subjectivity analysis # refr and sentiment analysis # otherefr. [SEP] features [SEP] this problem [SEP]", "cit": "automatic subjectivity analysis methods have been used in a wide variety of text processing applications, such as tracking sentiment timelines in online forums and [SEP]"}
{"pre": "this is in contrast to existing work in the text summarization task # otherefr ; # refr, which operate at the sentence level, e", "cit": "types and confidence scores are assigned to words using senserelate # refr, wsd software based on the 1in our prototype, we set [SEP]"}
{"pre": "one can imagine the same training procedure, in parameter estimation, as in # refr. [SEP] ( mert ) is to [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "# refr use the mert criterion to optimize the n - best lists using the downhill simplex algorithm # otherefr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "to obtain syntactic parses for the source language, we used the stanford parser # refr. [SEP] english ( 2 ) [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "first, to avoid unnecessary segments, e. g. provisions for or losses from executory, we parsed the financial ontology with the stanford [SEP]"}
{"pre": "in addition, a number of hand - crafted systems # otherefr ; # refr have shown that automatically derived bilexical dependencies,", "cit": "even robust parsers using linguistically sophisticated formalisms, such as tag # otherefr ; # refr, often use training data derived from [SEP]"}
{"pre": "similar to speech recognition? s recognizer output voting error reduction # otherefr ; # refra ; rosti et al 2007b ; [SEP]", "cit": "among other work, xiao et al # otherefr used bagging and boosting to get diverse system outputs for system combination and # refr used [SEP]"}
{"pre": "# refr. [SEP]. [SEP] it for an interpretation of the representation is based on the notion of structural disambiguation. [SEP] phenomena into [SEP] phenomena,", "cit": "sadler et al, 1989, sadler et al, 1990, # refr, and several difficulties have been pointed out. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "in this paper we present sucre # otherefr shared task : modeling unrestricted coreference in ontonote # refr. [SEP] ( 1 ) [SEP]", "cit": "while copa has been developed originally to perform coreference resolution on muc and ace data # otherefr, the move to the ontonote [SEP]"}
{"pre": "we use a linear model with the averaged perceptron # refr. [SEP] decoding # otherefr. [SEP] ( 1 ) [SEP] ( w, [SEP]", "cit": "this helps to avoid overfitting, cf. # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr introduced ulc metric in the mt evaluation metric for mt evaluation. [SEP] the output of dependency trees. [SEP] the constituency trees to [SEP]", "cit": "current efforts in syntax - based metrics, such as the headword chain based metric ( hwcm ) # refr, the lfg dependency tree [SEP]"}
{"pre": "in nlg, most systems are based on a constraint dependency grammar # otherefr, which specifies only # refr. [SEP] the [SEP] [SEP] [SEP]", "cit": "# refr perform surface realization of a flat semantics, which is np - hard, so they recast the problem as non - projective dependency parsing [SEP]"}
{"pre": "earlier works on this problem # otherefr ; # refr represented an example by the 4 - tuple < v, p, n [SEP], n", "cit": "the snow approach has been successfully applied to other problems of natural language processing # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this work, we apply monolingual settings # refr. [SEP] the original source language as the target language model, and the weights for each source", "cit": "researchers such as # refr and koehn and schroeder # otherefr have investigated mixture model approaches to adaptation. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "we used the data provided by the second language model used in # refr for machine translation. [SEP] the cross - entropy of ngram lms trained on", "cit": "log - linear interpolation is particularly popular in statistical machine translation ( e. g., # refr, because the interpolation weights can easily be discriminative [SEP]"}
{"pre": "in addition, we evaluate the joint inference framework based on joint parsing and semantic similarity between two tasks : word sense disambiguation # otherefr and", "cit": "the recent conll shared tasks # otherefr ; # refr have been focusing on semantic dependency parsing along with the traditional syntactic dependency parsing. [SEP]"}
{"pre": "we build a two transliteration mining systems # refr that use phrasal units as a source of target language transliteration [SEP] the [SEP] [SEP]", "cit": "we extract all word pairs which occur as 1 - to - 1 alignments # refr and later refer to them as a list of word pairs. [SEP]"}
{"pre": "in addition to the mt - based method, researchers have also investigated other methods for paraphrase generation, such as the pattern - based methods [SEP]", "cit": "bleu is a widely used metric in the automatic evaluation of mt # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use kytea # refr to segment japanese and chinese sentences. [SEP] the cwi corpus # otherefr ) to perform [SEP] [SEP] [SEP]", "cit": "this can be formulated as a two - step process of first segmenting words, then estimating poss # otherefr ; # refr. [SEP] [PAD]"}
{"pre": "for syntactic parsing, we use the output of charniak and johnson reranking parser # refr. [SEP] a selftraining [SEP] [SEP] [SEP] [SEP]", "cit": "coarse - to - fine parsing, also known as multiple pass parsing # otherefr ; # refr, first parses the input sentence with [SEP]"}
{"pre": "the proposition bank # otherefr is a tool that is trained on propbank # refr, nombank # otherefr. [SEP] annotations [SEP]", "cit": "we reproduce in table 3 the numbered arguments to karaka label mapping found in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this measure, which is defined in the log - linear model, is similar to the one used by # refr. [SEP] it compression [SEP] [SEP] [SEP]", "cit": "mturk has been used by many nlp researchers, has been shown to provide results similar to other human annotators and allows for a [SEP]"}
{"pre": "# refr report 54 % of negation tokens. [SEP] sentences in the bioscope corpus. [SEP] negation, containing negation, i. e. negation,", "cit": "morante and daelemans describe a method for im? proving resolution of the scope of negation by combining igtree, crf, and support [SEP]"}
{"pre": "we show how nivre? s # otherefr, and transition - based parsers # refr. [SEP] this technique [SEP] [SEP]y [SEP] [SEP]", "cit": "recently, # refr showed how to interpret shift - reduce actions as a generative model ; combining their idea and our transition system might enable the model [SEP]"}
{"pre": "in # refr, different alignment models were proposed based on a simple inversion transduction grammar # otherefr used the edit distance between alignments and the probability", "cit": "alignments from both? translation? directions are used to obtain symmetrized alignments by interpolating the hmm occupation statistics # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "in # refr, a technique which combines a phrase - based machine translation approach with a finite state transducer ( fst ) ( fsts. [SEP] [SEP]", "cit": "the following methods were investigated : ( monotone ) phrase - based mt on character level : a state - of - the - art phrase - based [SEP]"}
{"pre": "sentential alignment # refr is commonly used as a starting point for finding the translations of words or expressions from bilingual corpora. [SEP]. [SEP] ( [SEP]", "cit": "brown, lai and mercer # otherefr, # refr, and kay and rsscheisen # otherefr ), statistical machine [SEP]"}
{"pre": "morphological disambiguators that consider a token in context # otherefr, # refr, and achieved good results ( hebrew ) using [SEP]", "cit": "the input for the segmentation task is however highly ambiguous for semitic languages, and surface forms # otherefr ; # refr. [SEP] [PAD] [PAD]"}
{"pre": "finally, our work is also related to the work of # refr. [SEP] the structured perceptron, although it is more recent work in this paper", "cit": "we estimate the weights? using the averaged structured perceptron algorithm # otherefr, which is well known for its speed and good performance in [SEP]"}
{"pre": "most of the work in microblogging has focused on predicting age prediction # otherefr ; # refr. [SEP] the text [SEP] [SEP] [SEP] the", "cit": "predicting attributes of social media users is a growing area of interest, with recent work focusing on age # otherefr ; # refr, sex [SEP]"}
{"pre": "in the area of language analysis, the relative utility of syntactic structure is important for example when language modeling. # refr have a high utility of [SEP]", "cit": "for instance, phrase grammar parsing has been used to find the average number of sub - clauses, verb phrases, noun phrases and average tree depth [SEP]"}
{"pre": "in addition, the next step, we will show that our system is natural language processing, and information extraction, we developed for the text [SEP] [SEP]", "cit": "we are studying mechanisms under which the interpreter will override the parser and will get it out of trouble in processing very complex sentences # refr. [SEP]"}
{"pre": "for instance, # refr show improvements in french. [SEP] english # otherefr french. [SEP] this general, as well as [SEP] [SEP] [SEP] [SEP]", "cit": "from an empirical point of view, their incorporation has also been considered such as in # otherefr for dependency parsing and in # refr in [SEP]"}
{"pre": "# refr classify noun compounds from the web as a classification task, with the aim of resolving the ambiguous noun, [SEP] of the [SEP] of the [SEP]", "cit": "# refr use a? descent of hierarchy?, which characterizes the relation based on the semantic category of the two nouns. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we follow # refr and formalize semantic inference as an integer linear program ( ilp ). [SEP] ( ilp ). [SEP] the dependency structure", "cit": "another set of approaches has investigated the case where no logical forms are provided, but instead some form of feedback or response from the world is used [SEP]"}
{"pre": "besides, # refr proposed to improve the performance by selecting dense words in a particular sentence, but they did not attempt to capture the meaning they appear", "cit": "# refr learn task - specific embedding from an existing embedding and sentences with gold sentiment polarity. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "distributional thesauri have been used in a wide variety of areas including sentiment classification # otherefr, lexical acquisition # refr, co [SEP] [SEP]", "cit": "distributional thesauri have been used in a wide variety of areas including sentiment classification # otherefr, and parser lexicalisation # refr. [SEP]"}
{"pre": "in addition, we incorporate these features, and use features as previous work on hierarchical translation quality # otherefr ; # refr. [SEP] the [SEP]", "cit": "there is also substantial work in the use of target - side syntax # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the model is trained with the gradient descent algorithm described in # refr. [SEP] ( bfgs ) is a per - parameter estimation, and is [SEP]", "cit": "ep? ( e | f ) [ hk ]?? k? 2 ( 5 ) in order to train the model, we maximise [SEP]"}
{"pre": "sighan, the special interest group for chinese language processing of the association for computational linguistics, conducted four prior word segmentation bakeoffs, [SEP] [SEP]", "cit": "segmenting chinese sentences into words is a natural language processing task in its own right # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "one of the major approaches to disambiguate word senses is supervised learning # otherefr, # refr, # otherefr. [SEP] the discrimination", "cit": "splitting means to divide a polysemous verb into two hypothetical verbs and lumping means to combine two hypothetical verbs to make one verb out of [SEP]"}
{"pre": "we then parse the data using the collins parser # refr. [SEP] - las # otherefr. [SEP] the preprocessing step to new [SEP] [SEP] [SEP]", "cit": "for each of these 33 sentence types, 30 sentences were randomly extracted and the dependency parser malt - parser # refr, pre - trained on tal [SEP]"}
{"pre": "in # refr, pos tags were used to tagger the pos tagger of # otherefr. [SEP] this information. [SEP] a hidden [SEP]", "cit": "most work in the area of unknown words and tagging deals with predicting part - of - speech information based on word endings and affixation [SEP]"}
{"pre": "# refr show how to define the meaning of a word as a sentence to solve the meaning of the word in a sentence. [SEP] it allows for", "cit": "vecchi et al. have applied the additive and multiplicative models of # refr and adjective - specific linear maps of baroni and zamp [SEP]"}
{"pre": "dependency parsing has been intensively studied in recent years # otherefr ; # refr. [SEP] this work is in natural language processing [SEP] [SEP] [SEP] [SEP]", "cit": "these structures are equivalent to non - projective dependency parses # refrb ), and more generally could be relevant to any task that involves learning [SEP]"}
{"pre": "for chinese word segmentation, # refr used the pos tagging method in chinese word segmentation model. [SEP] tasks in chinese and in chinese word segmentation [SEP] tasks", "cit": "statistical chinese word segmentation gains high accuracies on newswire # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use an automatic generation of spatial locative markert # refr, which has been shown to be useful in a range of natural language generation [SEP]", "cit": "research on generation # otherefr ; # refr typically focuses on generating natural utterances for human consumption, where fluency is important. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "this idea has been successfully applied to a wide variety of tasks, including dependency parsing # otherefr, and machine translation # refr. [SEP] [SEP]", "cit": "this idea was first explored for weakly supervised learning # refr and recently by naseem et al # otherefr for multisource cross - [SEP]"}
{"pre": "we conducted our dependency parser and use the mate parser # refr, which were trained with the mate tools ( tools ). [SEP] 1 ) [SEP] [SEP]", "cit": "more precisely, we show that incorporating the induced pos into a state - of - the - art dependency parser # refr gives increases in labeled attachment [SEP]"}
{"pre": "the relations and modifier relations were found to be useful in information extraction # otherefr, # refr, named entities # other [SEP] [SEP]", "cit": "they propose a two - level hierarchy, with 5 classes at the first level and 30 classes at the second one ; other researchers # otheref [SEP]"}
{"pre": "one of the early ie systems on a number of ie systems ( ie ) systems ( e. g., # refr ) is that placed on", "cit": "as demonstrated by prior work # refr, grammar - based ie systems can be effective in many scenarios. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, we are interested in the segmentation of dialogue acts and only one way which we are aware of are aware of are aware of are aware", "cit": "dialogue acts have been used to benefit tasks such as machine translation # otherefr and the automatic detection of dialogue games # refr. [SEP] [PAD] [PAD]"}
{"pre": "the first systems capable of automatically learning a statistical language based on a logistic regression software trained on the ibm model 4 # otherefr ; # [SEP]", "cit": "similar techniques are used for correcting the output of english ocrs # refr and english speech recognizers # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for the arabic of the morphological analysis and disambiguation we use the arabic morphological analyzer # refr. [SEP] system. [SEP] ( msa ) [SEP] [SEP] [SEP]", "cit": "thus, msa tools cannot effectively model da ; for instance, over one - third of levantine verbs cannot be analyzed using an msa morphological [SEP]"}
{"pre": "in addition to negation cues, mainly focus on negation scope # otherefr # refr. [SEP] negations and crfs # otherefr shared", "cit": "2this task is popularized by various recently held shared tasks # refr. negation scopes, it is not clear how to feed this information [SEP]"}
{"pre": "in addition, we found that the automatic interpretation of the thematic labels contained in the corpus can be easily annotated for which this domain # [SEP] [SEP] [SEP]", "cit": "levin? s verb classes are easily accessible via verbnet # otherefr proposes a qualitative theory of motion based on spatio - temporal primitives, [SEP]"}
{"pre": "id participant cmu carnegie mellon university # otherefr cu - bojar charles university - bojar # refr cu - dep [SEP]", "cit": "id participant cmu carnegie mellon university # otherefr cu - bojar charles university - bojar # refr cu - dep [SEP]"}
{"pre": "to measure the relation between members of individual objects, we use the original relational representation of # refr. [SEP]? [SEP]? [SEP]? [SEP]? [SEP]", "cit": "in order to refer to an intended object # otherefr ; # refr utilized attributes of the target and binary relations between the target and distr [SEP]"}
{"pre": "we also show how perceptron learning with beam - search # refr can be used to train the shift - reduce parsing. [SEP] training time [SEP] [SEP]", "cit": "following # refr we also use the? early - update? strategy, where an update happens whenever the goldstandard action - sequence falls off the [SEP]"}
{"pre": "to measure the syntactic error detection, we use the lexical functional grammar proposed by magerman # otherefr and # refr. [SEP] ( 5 )", "cit": "some techniques, like # refr or sagot and villemonte de la clergerie # otherefr, bring a convenient [SEP]"}
{"pre": "there have been two general lines of research : the first one derives the nc semantics from the semantics of the nouns it is made of # other [SEP]", "cit": "there have been two general lines of research : the first one derives the nc semantics from the semantics of the nouns it is made of # other [SEP]"}
{"pre": "in particular, we show that the proposed graph entropy ( and # refr is based on latent and relation extraction, can be applied to a large [SEP]", "cit": "# refr combined web - scale corpora with a graph - based approach, assigning polarity scores to n - grams on the basis of the maximum weighed [SEP]"}
{"pre": "in the training phase, log - linear models are estimated with log - linear models # refr. [SEP] the likelihood of a stochastic disambiguation model,", "cit": "discriminative log - linear models are now becoming a de facto standard for probabilistic disambiguation models for deep parsing # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "pang and lee # otherefr, # refr and pang et al # otherefr ). [SEP] sentiment and subjectivity [SEP] (", "cit": "for example, pang et alused polarity # refr and subjectivity # otherefr english corpora to train machine learning algorithms to build sentiment [SEP]"}
{"pre": "in our experiments, we train a linear model based on the averaged perceptron algorithm # refr. [SEP]? s algorithm # otherefr introduced for", "cit": "thus, our work is applicable not only in cases where inference is done after a separate learning phase, as in # otherefr and others [SEP]"}
{"pre": "we show that it is advantageous to learn hierarchical dirichlet priors # otherefr and a model # refr for unsupervised word segmentation. [SEP] [SEP] [SEP] [SEP]", "cit": "f1 b r basic - unigram em? 76. 9 ( 0. 1 ) feature - unigram em 0. 2 84. [SEP]"}
{"pre": "the second type of collection that has been widely studied is the subject of much recent work in natural language processing # otherefr ; # refr.", "cit": "in # otherefr ; # refr authors propose extraction of noun phases and keywords. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper, we are currently working on the transtype2 # refr, an open source library for machine translation system combination. [SEP] [SEP] [SEP]", "cit": "an interesting approach was pioneered by the transtype project # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for example, the cubic grandparent edges in second - order dependency parsing slow down dynamic programs # otherefr and dependency parsing # refr can be", "cit": "such approaches, e. g. transition - based # otherefr ; torres # refr have attracted the most attention in recent years. [SEP]"}
{"pre": "we use features that capture dependency trees and use them as features, whereas they are limited in combination with semantic role labeling # otherefr ; #", "cit": "the alternative we propose is primarily motivated by the research on annotation projection # otherefr and direct transfer # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "se? # refr. [SEP] kernel for this task is a generalization of the verb classification. [SEP]. [SEP] kernel # otherefr for [SEP] [SEP]", "cit": "se? # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we report results on the bleu # refr, meteor # otherefr scores for the moses ( version 0. 8. [SEP] [SEP] [SEP]", "cit": "partly due to the large vocabulary size of czech, bleu score # refr correlates rather poorly with human judgments. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in recent years, a variety of approaches have been proposed for automatic classification, including regression models # otherefr, and [SEP] features [SEP] features [SEP]", "cit": "the swevoc metrics are also related to the language model features used in a number of studies # otherefr ; # refr. [SEP] [PAD]"}
{"pre": "# refr present a graph - based method that performs well in a word sense disambiguation task and showed a similarity score for a target word. [SEP]", "cit": "we use the extension of the simrank # otherefr node similarity algorithm proposed by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "improvements and extensions to this algorithm have been provided by karttunen # otherefr and # refr. [SEP] this algorithm [SEP] this algorithm [SEP]", "cit": "1c, ( 2 ) by compilation of weighted rewrite rules # refr, # otherefr, 5 ( 5 ) by conditionalization of [SEP]"}
{"pre": "in sentiment analysis, while people are able to achieve 87. 5 % accuracy on the movie reviews # refr, and 4. [SEP], and [SEP]", "cit": "many approaches to detect subjectivity and determine 1proceedings of the 7th international workshop on semantic evaluation # otherefr polarity of opinions [SEP]"}
{"pre": "in addition to the advantages mentioned above, factored translation models were proposed as a more efficient phrase - based system # refr which allow only one [SEP]", "cit": "many strategies have been proposed to integrate morphology information in smt, including factored translation models # refr, adding a translation dictionary containing inflected [SEP]"}
{"pre": "6similar results were obtained by an unsupervised tagger # refr. [SEP]? # otherefr, a trigram tagger, trained on the", "cit": "# refr, in contrast, reports accuracy of 75. 49 %, 80. 87 %, and 79. 12 % for unsupervised word - [SEP]"}
{"pre": "the tools of mate project # refr, which also rely on algorithms such as the alembic workbench on non - projectivity # otheref", "cit": "mate envisions three levels of user : coders, researchers for whom the coding task is performed and who need to view and manipulate the results [SEP]"}
{"pre": "for coreference resolution, we use stanford corenlp # otherefr ; # refr. [SEP] this problem [SEP]. [SEP] 481 [SEP] [SEP]", "cit": "this is an interesting observation because pronominal anaphora problem has been reported with much higher results on other domains # refr, and also on [SEP]"}
{"pre": "in # refr, different ways to use monolingual data as additional training data. [SEP] the same language model to generate the targetlanguage translation [SEP] for", "cit": "further approaches to domain adaptation for smt include adaptation using in - domain language models # refr, meta - parameter tuning on in - domain development [SEP]"}
{"pre": "we use the giza + + toolkit # refr to learn word alignments. [SEP] the reordering model to be estimated by a discriminative model, which", "cit": "the literature contains numerous descriptions of discriminative approaches to word alignment motivated by the desire to be able to incorporate multiple, overlapping knowledge sources # otheref [SEP]"}
{"pre": "some of them are frequency, point - wise mutual information # otherefr and the similarity of translation quality # refr. [SEP] the comparison of monol", "cit": "we employ ten system outputs ; nine are based on statistical machine translation ( smt ) systems ( gime? nez and ma ` # [SEP]"}
{"pre": "we evaluate our system on the benchmark test set, a recently presented in # refr and a language modeling framework. [SEP] natural language processing # other [SEP]", "cit": "past work has also focused on aligning text to a world # otherefr ; # refr, and many others. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition to the sts 2012 challenge, # refr introduced two subtasks : computing the similarity of sts? 2012, and the sts task of sts", "cit": "this approach is conceptually easy to implement and the sts shared task at semeval 2012 # refr # otherefr has shown that the best [SEP]"}
{"pre": "in addition to pbmt, researchers have also investigated the utilization of machine translation ( mt ) approaches # refr for qa and textual qa ( [SEP] [SEP]", "cit": "in the same context, # refr study methods for improving the translation quality removing noise from the parallel corpus. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the resulting model is a variant of the inside - outside algorithm described by # refr. [SEP] ( 1 ) = log2 [SEP] ( [SEP] ) [SEP]", "cit": "glc parsin ~ has been rediscovered a number of times # otherefr \\ ], \\ [ # refr \\ ], [SEP]"}
{"pre": "in smt, # refr used a publicly available software to obtain the translation quality for the ibm model 1. [SEP] in order to translate [SEP] the", "cit": "we know that better alignment models have been proposed and extensively compared # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the only difference between the accuracy of the two rrr is that was derived from a set of 1 ) paired f - score ( ~ ( ~", "cit": "on the other hand, the efficiency gains are not as big as those reported by # refr ( but note that we cannot measure ilarsing [SEP]"}
{"pre": "the most common approach is to use beam search # otherefr, but more principled dynamic programming solutions have been proposed # [SEP] [SEP] [SEP] [SEP]", "cit": "turboparser ), # refr, koo and collins # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "pivoting has also been used for paraphrasing and lexical adaptation # otherefr. # refr investigate pivot languages for resource - poor [SEP]", "cit": "we can also assume a more or less monotonic relation between the two languages which motivates the idea of translation models over character n - grams treating [SEP]"}
{"pre": "mounting methods that utilize co - occurrence information to be extracted for combining information extraction # otherefr ; # refr. [SEP] the user [SEP] [SEP] [SEP]", "cit": "commonly used ie techniques follow two main assumptions : ( 1 ) ie focuses on extracting information from syntactically and semantically? wellformed? pieces of [SEP]"}
{"pre": "in # refr, negation scopes are mostly dominated by only those in the negation of negation. [SEP]. [SEP]a et al. # otheref", "cit": "there have only been few research efforts in sentiment analysis examining the impact of scope modeling for negation in contrast to other research areas, such as the [SEP]"}
{"pre": "we parsed a minipar # refr of the english sentences using minipar # otherefr with minipar # otherefr. [SEP] (", "cit": "we use a broad - coverage parser # refr to extract dependency triples from the text corpus. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the noun - verb taxonomy and the catvar # refr. [SEP] distributional similarity software. [SEP] distributional similarity : w i [SEP] a sequence of", "cit": "for lexical freenet, # refr adds over 350 000 collocation pairs ( trigger pairs ) extracted from a 160 million word corpus of broadcast news [SEP]"}
{"pre": "classification involves detecting positive / negative reviews # refr. [SEP]. [SEP]. [SEP] the problem of sentiment is opinion. [SEP]. [SEP], which indicates the", "cit": "we used two datasets, customer reviews 1 # otherefr and movie reviews 2 # refr to evaluate sentiment classification of sentences. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "dwls were first introduced by # refr. [SEP] the notion of word linking was done by a discriminative word sequence model. [SEP] the probability p (", "cit": "# refr introduced the discriminative word lexicon ( dwl ) into phrase - based machine translation. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this approach, thesaurus construction is acquired from corpora \\ [ hindle, 1990 \\ ] \\ [ # refr \\ ]. [SEP] \\", "cit": "limitations of handcrafted thesauri can be summarized as follows \\ [ hatzivassiloglou and mckeown, 1993 [SEP]"}
{"pre": "this distinguishes it from unigrams from that its bigrams are bigrams, and therefore mis - classify documents according to [SEP] features of [SEP]", "cit": "this makes e - negotiation texts different from newsgroup messages, newspaper articles and other documents classified by # refr, where texts showe d [SEP]"}
{"pre": "this dataset consists of articles from different sources # otherefr, ( 2 ), and # refr, and # otherefr. [SEP] [SEP]", "cit": "while they have been compared with co - occurrence based models in simple similarity tasks at the word level # otherefr, we are aware of [SEP]"}
{"pre": "reg is related to content selection, which has been studied for generating text from databases # otherefr, and text # refr. [SEP] text [SEP]", "cit": "the nlp community has explored grounding text to physical attributes and relations # otherefr, generating text for referring to objects # refr and [SEP]"}
{"pre": "previous methods for query - focused on the problem can be divided into two main types # otherefr ; # refr. [SEP] the [SEP] patterns [SEP]", "cit": "following knowit - now # refr and espresso # otherefr, the? reliability? of a [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "iii and # refr ; daume. [SEP], 2004 ; daume. [SEP] & brill and daume. [SEP] this work learns as follows", "cit": "some researchers # refr have developed simple statistical models for aligning documents and headlines. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "coarse - to - fine ( lms ) decoder allow integrating lms with finite state machines # refr. [SEP] the fsts an approximate solution, [SEP] [SEP]", "cit": "more recently, # refr applied their beam filling algorithm to phrase - based decoding. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "syntactic information has been used in smt to provide a rich source of constraints for reordering # otherefr ; # refr. [SEP] the distance", "cit": "# refr model reordering as a sequence of classification steps based on a dependency parse of a sentence. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the two segmentation software of # refr and conduct experiments in the bake - off bake - based cws # otherefr to", "cit": "there are two primary classes of models : character - based, where the foundational units for processing are individual chinese characters # otherefr ; [SEP]"}
{"pre": "# refr use a probabilistic model over word sequences as sequences in a log - linear framework and train them. [SEP] a parameter on the same data.", "cit": "# refr learn phrases directly from sentence pairs using a joint probability model. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr use expectation maximization ( em ) to search for decipherment. [SEP] the zong of the zoning problem. [SEP]. [SEP] it", "cit": "# refr introduce the topic to the nlp community by demonstrating how to decode unfamiliar writing scripts using phonetic models of known languages. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "we build on a number of existing algorithmic ideas, including using the joint estimation technique of # refr, and [SEP] well - [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "besides semantic parsing for querying databases # otherefr, following navigational instructions # refr, and interacting in the real world via perception # other [SEP]"}
{"pre": "paraphrases allow for more flexible modeling, such as images # otherefr, or other representations # refr. [SEP] the entire sequence of expressions", "cit": "examples of groundings include pictures # otherefr, videos # refr, translations of a sentence from another language # otherefr. [SEP] [PAD]"}
{"pre": "the surface form construction is also a new approach by # refr. [SEP] the starting point for the sentence planning and an object that is [SEP] [SEP] [SEP]", "cit": "in the current implementation this is achieved by a version of polarity filtering where we associate not only the syntactic categories of root, substitution and foot nodes [SEP]"}
{"pre": "while a probabilistic model is a hidden markov model # otherefr, # refr and hmms # otherefr have been used successfully. [SEP]", "cit": "probabilistic content models were proposed by barzilay and lee # otherefr, and information ordering # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "aligning documents from different languages arises in a range of tasks such as parallel phrase extraction # otherefr, mining translations for out - of [SEP]", "cit": "this degrades performance of a variety of tasks, such as transliteration mining # otherefr ; # refr and multilingual web search # [SEP]"}
{"pre": "for evaluation of the system results, we use bleu # refr and ter # otherefr, which are the most widely used [SEP] the [SEP]", "cit": "one of the most widely used metrics for tuning is the bleu score # refr, tuned using the minimum error rate training # otherefr [SEP]"}
{"pre": "we use tinysvm2 along with yamcha3 # refr as the svm training and test software. [SEP] kernel # otherefr to shallow semantic", "cit": "first, our system uses start / end method to represent semantic chunks # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper we show how discourse information1 ( dt ) # refr and? recognizer. [SEP]. [SEP] [SEP] [SEP] [SEP] [SEP] representations [SEP] [SEP]", "cit": "while the task and annotations were framed from a semantic perspective, only one participating system actually employed explicit compositional semantics # refr, with results ranking [SEP]"}
{"pre": "current approaches employ various machine learning techniques for this task, such as inductive logic programming in earlier systems # otherefr ; # refr. [SEP] [SEP]", "cit": "current approaches for this task take a data driven approach # otherefr ; # refr, in which the learning algorithm is given a set of [SEP]"}
{"pre": "in order to find a solution using the marginal distribution, we adopt the maximum spanning tree ( mst ) framework proposed by # refra ). [SEP]", "cit": "use of global features for structured prediction problem has been explored by several nlp applications such as sequential labeling # otherefr and dependency parsing # [SEP]"}
{"pre": "in spoken language transliteration, # refr used a spoken language model. [SEP] system for speech recognition implemented in speech recognition results [SEP] [SEP] [SEP] [SEP]", "cit": "recent experiments performed by two groups of researchers at cmu have gathered ata on subjects using speech recognizers in office - like environments # refr. [SEP]"}
{"pre": "in the field of treebank, senseval - 3 # otherefr # refr and the redwoods treebank # other [SEP] [SEP] [SEP]", "cit": "other corpora, such as the english redwoods corpus # refr, combine both syntactic and structural semantics in a monostratal representation, but [SEP]"}
{"pre": "automata have been used to impose the pipeline of finite - state transducers # otherefr, and bayesian modelling # refr, and they do not consider", "cit": "in # refr, we showed how to model p ( pi ) as a renormalized product of many pairwise distributions prs ( xr, xs [SEP]"}
{"pre": "in genre classification, some research such as the influence of genres on the genre classification of text # otherefr ; # refr, while others", "cit": "the standard features for genre classification models include words, part - of - speech ( pos ) tags, and punctuation # refr, but constituent [SEP]"}
{"pre": "we report results on the bleu # refr scores # otherefr. [SEP] the bleu - 4 metric # refr, as the [SEP] [SEP]", "cit": "the release has implementations for bleu # refr, wer and per error criteria and it has decoding interfaces for phramer and pharaoh. [SEP]"}
{"pre": "in the case of ranking systems, the system is ability to detect and understand than 30 % for the words of the words, the system has [SEP]", "cit": "to deal with issues of output complexity we extend the approach of de # refr for testing a deep parser. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used minimum error rate training ( mert ) # refr to tune the feature weights for maximum log - linear model. [SEP] the [SEP] [SEP] [SEP]", "cit": "furthermore, wasp? 1 + + employs minimum error rate training # refr to directly optimize the evaluation metrics. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "previous work on chinese word segmentation has demonstrated that multinomials generated from a given document is only one or not, but also works that [SEP] [SEP]", "cit": "popular goodness measures include description length gain # otherefr, boundary entropy ( be ) # refr and normalized variation of branching entropy # otheref [SEP]"}
{"pre": "we use the stanford pos tagger # refr to tokenize and pos tag english. [SEP] retrieval. [SEP] retrieval. [SEP] retrieval improves the [SEP] retrieval", "cit": "we experimented with two freely available partof - speech taggers : the brill tagger # otherefr ; # refr. [SEP] [PAD]"}
{"pre": "although the type based approach is clearly bound to fail occasionally, it is commonly found to produce the strongest results, rivaling supervised systems # refr [SEP]", "cit": "# refr proposed a method to combine sense similarity with distributional similarity and configured predominant sense score. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in a vast body of related work, automated methods have been explored for the synonymy # otherefr ; # refr. [SEP] the [SEP]", "cit": "many nlp problems # otherefr ; # refr have benefited from having large amounts of data. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this idea has been developed and applied to a wide variety tasks, including morphological analysis # otherefr ; # refra ; de [SEP]a [SEP]", "cit": "a related thread of research is multi - source machine translation # otherefr ; # refr where the goal is to translate from multiple source languages [SEP]"}
{"pre": "in the transliteration field # refr, a statistical model was used. [SEP] the log - linear model described in detail by # [SEP] [SEP] [SEP]", "cit": "so, transliteration can also be termed as the process of obtaining the phonetic translation of names across various languages # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "in the conll - 2010 shared task, # refr introduced a cascaded crf model, which was then used to parse the training data [SEP] [SEP]", "cit": "the best result on hedge cue identification # refr obtained an f - score of 81. 3 using a supervised sequential learning algorithm to learn bio classes [SEP]"}
{"pre": "we use the same beam search algorithm as # refr. [SEP] the search space of beam search, beam search in local # otherefr. [SEP]", "cit": "for sequential search problems, such as tagging and incremental parsing, beam search coupled with perceptron algorithms that account for potential search errors have been shown [SEP]"}
{"pre": "in their approach, they partially correct posteriors # otherefr ; # refr. [SEP] this algorithm requires that [SEP] [SEP] [SEP] boundaries, [SEP] [SEP]", "cit": "learning natural language in an unsupervised way commonly involves the expectation - maximization ( em ) algorithm to optimize the parameters of a generative model, often a [SEP]"}
{"pre": "we used the minimum bayes risk ( mbr ) framework # refr to optimize the expected bleu score on the expected sentence f. [SEP] the minimum", "cit": "a very different use of loss functions was considered in the areas of signal processing and machine translation, where direct minimization of expected loss ( minimum bayes [SEP]"}
{"pre": "for example, the nlp community is in general, for pos tagging and word alignment # otherefr, and syntactic disambiguation # refr.", "cit": "# refr describes a version of it, and we know several other instructors who use it. 7 in most of these, the object is to [SEP]"}
{"pre": "for instance, # refr describe a generator for generator that is generated from an earley - type ~ - type ~ - ~ - ~ - ~", "cit": "busemann, 1987 ; van nonrd, to appear ;, dymetmann & isabelle, 1988 ; and # refr. [SEP] [PAD]"}
{"pre": "transition - based dependency parsing # otherefr ; # refr utilize a deterministic shift - reduce process for making structural predictions. [SEP] nonlocal features [SEP]", "cit": "with these methods, transition - based parsers have reached state - of - the - art accuracy for a number of languages # refr. [SEP] [PAD]"}
{"pre": "to measure the coherence of sentences, we use a statistical machine translation system trained on the japanese dependency trees # refr. [SEP] the source [SEP] [SEP] [SEP]", "cit": "syntactic score ( sc ) some erroneous sentences often contain words and concepts that are locally correct but cannot form coherent sentences # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "iii, 2011a ), finding frequent items # otherefr, and distributional similarity # refr. [SEP], finding frequent items # otherefr", "cit": "iii, 2011a ), finding frequent items # otherefr, and distributional similarity # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr used a similar method for disambiguating the attachments of a verb. [SEP] adjective, for disambiguating the list of [SEP] [SEP] [SEP]", "cit": "in our previous research on adjectives # refr we used pustejovsky is theory to classify adjectives in japanese. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "building upon the large body of research to improve tagging performance for various languages using various models ( e. g., # refr ) and the [SEP]", "cit": "a decoding method similar to the max - rule - product method in # refr is used to tag sentences using our model. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in machine translation, the phrase - based approach introduced by # refr employs a set of phrase pairs to force translations. [SEP] the [SEP] [SEP] [SEP] [SEP]", "cit": "the most prominent paradigms in statistical machine translation are phrase - based translation models # refr and tree - based approaches using some form of a synchronous context [SEP]"}
{"pre": "ibm models and hidden markov models # otherefr as well as the hidden - markov model ( hmm ) # refr, the hmm model # other", "cit": "word alignments traditionally are based on ibm models 1 - 5 # otherefr or on hmms # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the frequency counts are typically defined by or weighted finite set ad hocken # otherefr, # refr, and pereira # [SEP] [SEP]", "cit": "the last two points do not argue against he use of existing dictionaries, but show that the incomplete information that they provide needs to be supplemented [SEP]"}
{"pre": "in the last 4 - gram, we have taken a representation of a packed forest, as described by # refr. [SEP] the forest of the strings", "cit": "what is sometimes called a forest in natural language generation # refr is a finite wrtg without loops, i. e.,? n. [SEP]"}
{"pre": "in addition, we also use crfs as well as features in previous work # refr. [SEP] this problem was done in [SEP]a [SEP] [SEP] [SEP]", "cit": "crfs allow the computation of p # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we focus on the particular instantiation of sentence compression when the goal is to produce the compressed version solely by removing words or phrases from the original, [SEP]", "cit": "the simplification renders the task computationally feasible, allowing efficient decoding using a dynamic program # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "to make comparisons with previous work on sentiment summarization, we employ an integer linear programming ( ilp ) model to generate [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "some summarization systems that target reviews, opinion summarizers, extract particular information, opinion, from the input sentences and leverage them to select important [SEP]"}
{"pre": "we use the features from # refr and manning # otherefr to bootstrapping methods. [SEP] annotations in the target. [SEP] [SEP] [SEP] [SEP]", "cit": "our learning method is very closely related to the work of # otherefr ; # refr who concurrently developed the idea of using penalties based on [SEP]"}
{"pre": "in this paper we present our coreference resolution system that uses a combination of two coreference resolution systems : the conll 2012 shared task # [SEP]", "cit": "we have updated the publicly available conll coreference scorer with the proposed blanc, and used it to compute the proposed blanc scores [SEP]"}
{"pre": "in addition, there are several approaches that aim at generating a representation of an underspecified representation that are capable of determining the representation [SEP] a single", "cit": "in this companion paper we show that f - structures are just as easily interpretable asudrss # otherefr ; # refr : [SEP]"}
{"pre": "these data - driven parsing approaches obtain state - of - the - art results on the de facto standard wall street journal data set # other [SEP]", "cit": "two participating systems are based on maltparser : maltoptimizer # refr and ai : ku # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in machine translation, a number of systems have been proposed to translate a probabilistic framework for parse selection # otherefr ; # refr. [SEP] this", "cit": "these forest rescoring algorithms have potential applications to other computationally intensive tasks involving combinations of different models, for example, head - lexicalized parsing # [SEP]"}
{"pre": "in order to obtain the semantic information for each word, we compare to the semantic relation between a set of lexical and a test data using the sense", "cit": "among others we can mention extended wordnet # otherefr, large collections of semantic preferences acquired from semcor # refr or acquired from british [SEP]"}
{"pre": "our approach to unsupervised wsi has recently been applied to word sense disambiguation # otherefr, ( pedersen ) # refr, and [SEP]", "cit": "while there has been some previous work in sense discrimination # otherefr, # refr, # otherefr ), by comparison it is [SEP]"}
{"pre": "it has been shown that the semantics of conjuncts in coordinate structures cannot be derived from corpora, e. g., # refr. [SEP] phenomena", "cit": "this idea has already been explored before by various researchers from different methodological angles including distribution - based statistical approaches # otherefr ), similarity - [SEP]"}
{"pre": "semantic textual similarity # otherefr ; # refr. [SEP] textual entailment # otherefr incorporate semantic information into a biased system. [SEP] textual", "cit": "# refr use a modified logic prover that drops predicates when a proof cannot be found. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "reinforcement learning approaches # otherefr ; # refr can be used to learn the dialogue history, but they use a data that is, [SEP],", "cit": "in other work, rl has been used to choose among a subset of the actions in certain states # otherefr ; # refr. [SEP] [PAD]"}
{"pre": "pereira, # refr and lin # otherefr describe how to cluster words by using the grammatical relation. [SEP] the distributional similarity of the", "cit": "most systems extract co - occurrence and syntactic information from the words surrounding the target term, which is then converted into a vector - space representation of [SEP]"}
{"pre": "we focus on learning the likelihood of a small number of seed words with e. g. the same parameters that are in our framework [SEP] [SEP] [SEP]", "cit": "various functions such as the log - likelihood ratio # otherefr ; # refr, tf - idf # otherefr are typically used [SEP]"}
{"pre": "in the last several years, the cube growing amount of stack, a general consensus that change the state - of - the problem has received growing interest", "cit": "following the notation in # refr, a probabilistic scfg comprises a set of source - language terminal symbols ts, a set of target - language [SEP]"}
{"pre": "in contrast, recent work has focused on the analysis of distributional semantics # otherefr ; # refr. [SEP] the data set [SEP] ( i.", "cit": "for words that do not appear in wordnet, we use distributional similarity # refr as a proxy for word relatedness. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "there have been several proposed supervised approaches for sentiment analysis # refr. [SEP] this approach based on weakly supervised learning techniques to classify reviews or [SEP] [SEP] [SEP]", "cit": "there have also been increasing interests in exploiting bootstrappingstyle approaches for weakly - supervised sentiment classification in languages other than english # refr. [SEP] [PAD] [PAD]"}
{"pre": "statistical data about these various cooccurrence r lations is employed for a variety of applications, uch as speech recognition # otherefr and [SEP] the", "cit": "for example, # refr proposed the following model : t ( 9 ) where t denotes a topic id. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr measure the similarity between mt output of two english dialects. [SEP] different spelling correction. [SEP] the distance between two languages, [SEP]", "cit": "# refr present several modifications of the levenshtein distance that approximate linguistic intuitions better. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "a form of semi - supervised learning # otherefr ; # refr. [SEP] the training procedure for this work ; daume. [SEP] [SEP] [SEP]", "cit": "the notion of translation consensus, wherein similar sentences on the source side are encouraged to have similar target language translations, has also been explored via a [SEP]"}
{"pre": "in this approach, both alignment and scoring are performed utilizing a length - normalized weighted bitg # otherefr ; # refr. [SEP] [SEP] [SEP]", "cit": "there are some comparative studies of the reordering restrictions that can be imposed on the phrase - based or grammar - based models # refr, however [SEP]"}
{"pre": "these methods use neural network language models # otherefr ; # refr. [SEP] the individual words in two basic nlms approaches. [SEP] [SEP] [SEP]", "cit": "similarly, # refr use a hierarchical dirichlet model in combination with morph bigram probabilities. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we prune the resulting phrase table using the statistical significance test # refr. [SEP]. [SEP] the filtering, in order to compute the probability of a", "cit": "we filtered the obtained phrase table using the method described in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we follow # refr and formalize semantic representations within the framework of grounded language modeling. [SEP]. [SEP] it has been shown to be successful [SEP] in", "cit": "of course, other annotations ( ge and # refr carry more explicit forms of semantics. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the hpsg grammar has been extensively studied in the context of deep parsing # otherefr ; # refr and machine translation # otheref [SEP] [SEP]", "cit": "in related work, # refr describes an approach to packing in which alternative feature structures are represented as packed, distributed isjunctions of feature [SEP]"}
{"pre": "several approaches have been devised for building such parsers # otherefr ; # refr, though they did not perform well at the same sentence #", "cit": "for instance, we estimate the conditional paraphrase probability p ( e2 | e1 ) by marginalizing over all shared foreign - language [SEP]"}
{"pre": "it is important to disambiguate coordinate noun phrases # otherefr, # refr, and that are not sufficient to capture the meaning that is [SEP]", "cit": "in a similar vein, # refrb ) inspected wordnet similarity and relatedness measures and investigated their role in conjunct identification. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "we used minimum error rate training ( mert ) # refr to tune the feature weights for the log - linear model. [SEP]. [SEP] [SEP] [SEP]", "cit": "the statistical components of our system are modeled on the phrase - based system of koehn et al # otherefr, and component weights [SEP]"}
{"pre": "paraphrase generation can be used for many nlp applications, such as machine translation # otherefr, mt # refr, and document classification", "cit": "7exactly the same insight is behind the? source - side pseudoreferencebased feature? employed by # refr in their system for predicting [SEP]"}
{"pre": "the best statistical parsers have reached the conclusion that seem highly accurate constituency parsers # refr. [SEP] this technique to handle rich morphology # other", "cit": "parsing models have been developed for different languages and state - of - the - art results have been reported for, e. g., english [SEP]"}
{"pre": "# refr used mt ( clte ) to determine textual entailment ( clte ) detection, recently proposed by tei. [SEP] ( clte", "cit": "the promising performance indicates the potentialities of such a simple approach which integrates mt and monolingual te algorithms # otherefr ; jime # [SEP]"}
{"pre": "maruyama? s constraint dependency grammar ( cdg ) # refr is a formalism used in a postprocessing step, although the parsing of [SEP]", "cit": "the parsing method of constraint dependency grammar # refr axldressed exactly these issues. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "ftb - uc ( candito and # refr : an instantiation of the functionally annotated section that makes a distinction between mwes that are [SEP] [SEP]", "cit": "corrections historically, the ftb suffered from annotation errors such as missing pos and phrasal tags # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, we use an existing open ie system # refr. [SEP] a document collection, wikipedia link tuple, stanford, [SEP] 25 % [SEP] [SEP]", "cit": "related publication : # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the mcmc procedure here since this has been empirically that both the presence of inter alia. [SEP]a word # refr [SEP] into [SEP]", "cit": "previous work explored the usefulness of, for example, syllablestructure # refr or morphology # otherefra ) in word segmentation. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "english - chinese has been studied in a number of applications, including transliteration # otherefr, and machine translation # refr [SEP] [SEP] [SEP]", "cit": "the first task is transliteration in the strict sense, which creates new words in a target language # otherefr ; # refr. [SEP]"}
{"pre": "so far, research in automatic opinion recognition has primarily addressed learning subjective language # otherefr, and discriminating between positive and negative language # refr [SEP]", "cit": "we evaluated the subjectivity of each sentence using the automatic subjective sentence classifier from # refr, and find that 65. 6 % of palesti [SEP]"}
{"pre": "to evaluate the performance of these systems we follow # otherefr ; # refr and use the same wsd system. [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "finally, results are presented from the semeval - 2007 coarse grained all - words task # refr, and we explore the influence of [SEP]"}
{"pre": "for example, # refr proposed a method based on argumentative features for qa. [SEP] the path based on the work of named entity [SEP] [SEP] [SEP]", "cit": "ruch et. al. # refr studied the problem in the domain of biology literature and proposed an argumentative feedback approach, where expanded terms [SEP]"}
{"pre": "in order to acquire the taxonomical preference of a word w, we computed using the grammatical relation computed by # refr. [SEP] ( w ) [SEP]", "cit": "unsupervised methods use clustering of wordcontext vectors # refr, co - occurrence # otherefr to discover implicit relationships. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the model based order the hidden markov model ( hmm ) to estimate the probability p ( e | f ) of a [SEP] ( e [SEP]", "cit": "both extensions are inspired by and share similarities with models that have been successfully applied in work on text alignment for the task of machine translation # refr [SEP]"}
{"pre": "# refr proposed a method to learn narrative chains of events related to a protagonist in a single sentence. [SEP] with causal relations. [SEP] a", "cit": "several other nlp researchers have studied related topics e. g., identifying events, building of temporal chain of events sharing a common protagon [SEP]"}
{"pre": "the exicon is s ta t ionl l ) \\ [ t \\ ], in comparison \\ [ t \\ ] [SEP] \\ [ [SEP] [SEP]", "cit": "consequently, the integration of information from distinct mrd sources through simple word - sense matches is likely to fail in a significant number of instances # [SEP]"}
{"pre": "in the context of machine translation, itg has been explored for statistical word alignment in both unsupervised # otherefr ; # refr settings, [SEP]", "cit": "in the context of machine translation, itg has been explored for statistical word alignment in both unsupervised # otherefr ; # refr and supervised [SEP]"}
{"pre": "coreference resolution is a well - studied problem in computational linguistics # otherefr ; # refr. [SEP]. [SEP] this work has been done [SEP]", "cit": "specifically, in these approaches, one has to employ knowledge of the target language to design coreference rules # otherefr, # refr ) [SEP]"}
{"pre": "the second type of approach uses the simplified version of # refr, which is considerably reduced to a constituency treebank, partly inspired by the use", "cit": "the graphbased parser is similar to, except much faster, and performs slightly better than the mstparser # otherefr ; # refr [SEP]"}
{"pre": "the phrase - based approach corresponds to the method described in # refr. [SEP] the former subsection in # otherefr, but operates in [SEP] [SEP]", "cit": "possibly the most remarkable evolution of recent years in statistical machine translation is the step from word - based models to phrase - based models # refr. [SEP]"}
{"pre": "synchronization of tree adjoining grammars ( tags ) # refr are even more powerful than the previous formalisms, and have been applied in machine translation", "cit": "there are other variants of tags such as stags # refr, and mc - tags # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "transliteration methods typically fall into two categories : generative approaches # otherefrb ; # refr. [SEP] a word segmenter by [SEP] a window", "cit": "the percentage of correctly transliterated words are 37. 9 % for japanese and 25. 6 % 2note that one could also adopt other [SEP]"}
{"pre": "the approach is similar to n - gram language models based on the idea of word and co - occurrence backoff # refr. [SEP] the [SEP] [SEP]", "cit": "eva luat ion we evaluated our method by comparing its perplexity 1 and effect on speech - recognition accuracy with the baseline bigram [SEP]"}
{"pre": "the performance of wsd is reaching a common practice in the literature # otherefr ; # refrb ). [SEP] the [SEP] of [SEP] [SEP]", "cit": "we have tested different sf - s # otherefr ; # refr # otherefr named ti + cue. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "multi - instance learning # otherefr ; # refr. [SEP] a swd label distribution over a large set of facts extracted triples. [SEP] the", "cit": "prominent examples include question answering # otherefr, and information extraction systems # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the tempeval shared tasks # otherefr ; # refr have been one of the key venues for researchers to compare methods for temporal [SEP]", "cit": "the most relevant research topic is the temporal information extraction # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "to determine the head - word we used a set of hand - annotated sentences, thesaurus and the word senses of other words, [SEP] [SEP]", "cit": "similarly to our work, # refr # otherefr report coverage 86. 2 %, precision 71. 2 % and recall 61. 4 [SEP]"}
{"pre": "scfs can be useful for many nlp applications, such as parsing # otherefr, verb classification # refr or parsing scfs [SEP] [SEP]", "cit": "our system is based on a approach similar to that of the well - known cambridge subcategorization acquisition system for english # otherefr ; [SEP]"}
{"pre": "following # refr, we defined over context freeling ( henceforth t ) as defined in # otherefr ) to obtain the syntactic relation for", "cit": "to address this phenomenon context sensitive similarity and inference models have been proposed # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use a support vector machine # otherefr ; # refr. [SEP] kernel expansion # otherefr developed by active learning [SEP] effort [SEP] [SEP]", "cit": "in order to perform error - detection, we chose to adapt the approach of # refr which resembles uncertainty based sampling for active learning. [SEP] [PAD] [PAD]"}
{"pre": "identification, though an important problem, can be tackled with heuristics # refr or, potentially, by using a supervised classifier trained on a small [SEP]", "cit": "# refr were the first to introduce an unsupervised semantic role labeling system. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we trained the model using the structured perceptron # refr, with an online learning algorithm, with a structured perceptron # otherefr. [SEP]", "cit": "online structured learning algorithms such as the structured perceptron # refr and k - best mira # otherefr have become more and more popular [SEP]"}
{"pre": "wu # otherefr? binarization? for binarizing parse trees, and # refr present a formalism that is novel for our [SEP]", "cit": "# refr discuss methods for binarizing scfgs, ignoring the nonbinarizable grammars ; in section 2 we discuss the generalized problem [SEP]"}
{"pre": "in this paper, we evaluate the system with the semantic textual similarity ( sts ), which is an extension of the system introduced in the semev", "cit": "sts measures? the degree of semantic equivalence between two texts? # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "similar to the case of synonymy, the is - a relation defined in wordnet does not provide a native, real - valued degree [SEP]", "cit": "among various word similarity models # refr, the vector space models # otherefr are often used as the core component. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr and jeong et al. # otherefr, who use a morphological layer over the source language to segment the source sentence to segment", "cit": "research in translating into morphologically rich languages, has attracted interest for languages like arabic # otherefr, russian # refr, and turkish # other [SEP]"}
{"pre": "this has led to the development of a large amount of features # refr or the learning - based model, which can be generalized to a structured percept", "cit": "the perceptron has been used in previous work on dependency parsing by # refr, with a parser based on eisner? s algorithm # other [SEP]"}
{"pre": "the tagger used in this study is hun - pos ( pos ) tagging ), a hidden markov model ( hmm ), tnt # refr", "cit": "the tagger described in this paper is based on the standard hidden markov model architecture # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition to dialogue acts, researchers have focused on the topic modeling to study how to handle agents are non - collaborative or related, # otheref", "cit": "dosaka et aldeveloped a thoughtevoking dialogue system for multiparty conversations with a quiz game task # refr. [SEP] [PAD] [PAD]"}
{"pre": "in the experiments, the authors reported that the result of # refr achieved 72. 9 %, compared to 82. 8 % in the wsj", "cit": "to overcome this problem, unsupervised learning methods using huge unlabeled data to boost the performance of rules learned by small labeled data have been proposed recently # [SEP]"}
{"pre": "it uses the combination scheme originally developed by # refr. [SEP] the hypotheses consists of a tm based on a different mt system. [SEP] the idea.", "cit": "the increasing availability of mt engines and the need for better quality has motivated considerable efforts to combine multiple engines into one? super - engine? that [SEP]"}
{"pre": "in the case of dependency parsers, we used a log - linear model # refr. [SEP] the information about the [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "learning we model the problem of selecting the best derivation as a structured prediction problem # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "most of the reported work on paraphrase generation from arbitrary input sentences uses machine learning techniques trained on sentences that are known or can be inferred [SEP]", "cit": "most of the reported work on paraphrase generation from arbitrary input sentences uses machine learning techniques trained on sentences that are known or can be inferred [SEP]"}
{"pre": "13note that japanese is a head final language. f5b : pos of the word which the rightmost constituent word of idiom is [SEP]", "cit": "however, as in hashimoto et al # otherefra ) and # refr among others, the syntactic behavior of idioms is an important [SEP]"}
{"pre": "related work on interpreting temporal expressions has focused on constructing hand - crafted interpretation rules # otherefr ; # refr. [SEP] the [SEP] [SEP]", "cit": "our approach follows the work of # refr, both in the bootstrapping training methodology and the temporal grammar. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the features include : a maximum sentence segmentation lattice, minimum error rate training # refr, minimum bayes risk training # otherefr. [SEP] [SEP] [SEP]", "cit": "to tune the feature weights of our system, we used a variant of the minimum error training algorithm # otherefr that computes the error statistics [SEP]"}
{"pre": "we use the well - known pseudo - training corpus # refr which consists of 3 - gram lm trained on the target side of parallel data. [SEP]", "cit": "many techniques for smt domain adaption have focused on rather diverse domains such as using systems trained on europarl or news to translate medical [SEP]"}
{"pre": "there have been several recent ie approaches to ie acquisition \\ [ kupiec, 1992 \\ ] 2 \\ [ # refr \\ ], \\ [ yi", "cit": "the parser is used ibr reducing each clause or noun phrase to a tuple, consisting of the central arguments, ms described in detail in # refr [SEP]"}
{"pre": "in this paper, we use the dependency parser of # refr. [SEP] this model. [SEP] arbitrary svms the maxent [SEP] features of opinion [SEP]", "cit": "usually, sequence labeling models such as crf # otherefr ; # refr ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "transliteration methods typically fall into two categories : generative approaches # otherefr that try to produce the target transliteration given a source [SEP]", "cit": "other approaches exploit similarities in aligned bilingual corpora ; for example, # otherefr combine two unsupervised methods. # refr bootstrap with a classifier used [SEP]"}
{"pre": "the set of features consists of those pairs of the different error analysis systems # refr. [SEP] a source sentence, along the lines of which provides a", "cit": "these varying sources of mismatches made the automated scoring script used in the evaluation phase of the shared task # refr not so helpful during development, since [SEP]"}
{"pre": "fce : first certificate in english corpus # refr the fce dataset consists of 1238 scripts written by learners of english as part of the cambridge", "cit": "we first evaluate on the missing hyphen errors contained in the clc - fce # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, we plan to incorporate syntactic features, instead of using the gold standard data set as in # refr. [SEP] future work we consider [SEP]", "cit": "related work has recognized the large annotation burden the task demands, but aimed to keep the syntactic annotations and induce semantic roles # refr. [SEP] [PAD] [PAD]"}
{"pre": "in contrast, # refr proposed a model based on recursive neural networks that learns vectors using recursive neural networks, which models the recursive neural network rnn", "cit": "in principle, any model that produces vector - based representations of phrases or sentences could be used # otherefr ; # refr. [SEP] [PAD] [PAD]"}
{"pre": "# refr applied the distributional hypothesis on the target subtree. [SEP] kernel by taking a large corpus of nlp applications that are more diverse and [SEP] [SEP]", "cit": "similar approaches to graph modifications have been successfully used for several nlp tasks # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this relatively simple approach to translation can be remarkably effective, and, since its introduction, it has been the basis for further innovations, including developing [SEP]", "cit": "these have been applied to translation into morphologically rich languages, such as japanese, german, turkish, and finnish # otherefr ; # refr [SEP]"}
{"pre": "# refr describe a system for morphological morphological disambiguation that is trained on the korean penn treebank, and then applied it to hebrew,", "cit": "a similar point of view, that is attaching exception lists to general rules, may be found in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use a conditional markov model tagger # refr trained on the same dataset. [SEP] the sequence ( m3 ) of tags. [SEP] [SEP] [SEP]", "cit": "finally, the bioew scheme # refr was used to tag the tokenized corpora, under which the first token of a multitoken mention [SEP]"}
{"pre": "# refr use a log - linear model to identify noun - probability in abbreviations from a biomedical text. [SEP] 1 in biomedical text, the [SEP] article", "cit": "# refr note acronyms in biomedical literature tend to be used much more frequently than in news media or general english literature, and tend to be [SEP]"}
{"pre": "we train a trigram lm on the d with a modified kneser - ney smoothing # refr. [SEP] the smoothing algorithm. [SEP] the smoothing", "cit": "when training all the language models, modified kneser - ney smoothing # refr for n - grams is used. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use a hierarchical phrase - based translation grammar # refr for all - fragments. [SEP] the phrases of all words in the sentence and include as possible", "cit": "also, # otherefr ; # refr involve modular functions but where selection is over subsets of phrases ( rather than sentences as in our current [SEP]"}
{"pre": "we use the english pos - tagger # refr to train a crf model using the open source software package for l2, which uses the svm", "cit": "perhaps surprisingly, recent results have proved that methods handling the text at character level can also be very effective in text analysis tasks # otherefr [SEP]"}
{"pre": "to our knowledge, the only other work that has focused on the identification of named entities, i. e., information extraction [SEP] [SEP] [SEP] [SEP]", "cit": "in the question - answering context, # refr collected document co - occurrence statistics to uncover 1 ) art - whole and synonymy relationships to [SEP]"}
{"pre": "# refr goes on to experiment with assuming all of the allomorphic specification i to the lexicon, in addition to the [SEP] three class of verbs", "cit": "to overcome the first difficulty, a number of researchers have suggested augmenting fa with \" word grammars \", expressed in terms of feature formalisms [SEP]"}
{"pre": "in order to augment such parsers with empty category prediction, three rather different strategies have been proposed : ( i ) pre - processing of the [SEP]", "cit": "johnson # otherefr ; the best results we are aware of are due to # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "named entities using the stanford named entity recognizer # refr. [SEP] the recognizer person name entity recognizer for muc tagging named entities, [SEP],", "cit": "next, the spelling corrected dataset is run through the stanford named entity recognizer ( ner ). 4 stanford ner system first detects sentences [SEP]"}
{"pre": "svms and kernel methods have recently been applied to natural language tasks with promising results, e. g. # otherefr ; # refr [SEP]", "cit": "svms and kernel methods have recently been applied to natural language tasks with promising results, e. g. # otherefr ; # refr [SEP]"}
{"pre": "most of the recent work in this area has focused on supervised dependency parsing, such as # otherefr ; # refr, and unsupervised parsing #", "cit": "the past few years have seen considerable improvement in the performance of unsupervised parsers # otherefr ; # refra ; bod, 2006b [SEP]"}
{"pre": "the nlp community has recently seen a surge of interest in dependency parsing, with several conll shared tasks focusing on it # refr. [SEP] the", "cit": "dependency parsing has been applied to a fairly broad range of languages, especially in the conll shared tasks in 2006 and 2007 # refr. [SEP] [PAD]"}
{"pre": "surprisal # otherefr ; # refr. [SEP] the surprisal of the representational implicatures on the incrementally processing of the sentence", "cit": "in most formal theories of human sentence comprehension, input recognition and syntactic analysis are taken to be distinct processes, with the only feedback from syntax to [SEP]"}
{"pre": "the pyramid evaluation method # refr addresses the problem by using the pyramid metric evaluation metric in which summarization evaluation was first applied to select the summary content", "cit": "pyramid evaluation : the pyramid evaluation method # refr has been developed for reliable and diagnostic assessment of content selection quality in summarization and has been used [SEP]"}
{"pre": "we use the stanford named entity recognizer # refr to identify named entities. [SEP], person, organization, person, location, organization, [SEP],", "cit": "due to the large size of the corpora, we uniformly sampled a subset of documents for each corpus and ran the stanford ner tagger # refr [SEP]"}
{"pre": "following # refr, we use latent variable crf + # otherefr. [SEP] ( m1 ) =? l?? l? [SEP] [SEP]", "cit": "to guide the model to make a useful division into regions, we also require that identity characters such as ( b, b ) fall in even [SEP]"}
{"pre": "in our experiments, we use the conll 2009 data sets # refr. [SEP]. [SEP] the second - order model performs joint inference for different [SEP]", "cit": "dataset and evaluation measures we evaluate our model on conll dependency treebanks for 14 different languages # otherefr ; # refr, using [SEP]"}
{"pre": "in addition, an automatic named entity tagger # refr was run on the sentences to map the sentences to a set of 1. [SEP] words in", "cit": "corpus - based word sense disambignation algorjthm ~ such as # otherefr ; # refr relied on supervised learning fzom [SEP]"}
{"pre": "in this paper we show that the general tree - transducer - style # otherefr ; # refr can be found useful for machine translation [SEP] [SEP]", "cit": "regular tree grammars # otherefr and grammar formalisms # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "several supervised dependency parsing algorithms # otherefr ; # refr have been proposed and achieved high parsing accuracies on several treebanks, due in [SEP]", "cit": "several supervised dependency parsing algorithms # otherefr ; # refr have been proposed and achieved high parsing accuracies on several treebanks, due in [SEP]"}
{"pre": "for example, the paradise framework allows designers to predict user satisfaction from a system # refr. [SEP] system trained on the paradise dialogue [SEP] [SEP]", "cit": "once they had completed all tasks in sequence using one system, they filled out a questionnaire to assess user satisfaction by rating 8 - 9 statements, [SEP]"}
{"pre": "distributional similarity is measured by the ratio of the perplexity of the proposed by # refr. [SEP] the distance measure of word association between two words", "cit": "existing word association measures can be divided into three broad categories : ( i ) co - occurrence measures that rely on co - occurrence frequencies of both [SEP]"}
{"pre": "in addition to the bleu metric # otherefr ; # refr, we computed the n - gram string comparison. [SEP] (? [SEP] [SEP]", "cit": "the metric called mncd, which works similarly to mbleu # refr, showed improved correlation to human judgments in english, the only language where [SEP]"}
{"pre": "# refr describe a sentence alignment algorithm for paraphrase detection with a recent application of statistical machine translation. [SEP] the availability of simple string - to", "cit": "# refr also worked with english / simple english wikipedia data and moses. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we train the model, and use the wapiti toolkit # refr. [SEP] model for sentence segmentation, and sentence segmentation, and sentence boundary detection", "cit": "conditional maximum entropy models have been used for a variety of natural language tasks, including language modeling # otherefr, and finding sentence boundaries # [SEP]"}
{"pre": "everyday dictionaries are obviously not structured in a way that enables their immediate use in nlp systems, but several studies have shown that relatively simple [SEP]", "cit": "everyday dictionaries are obviously not structured in a way that enables their immediate use in nlp systems, but several studies have shown that relatively simple [SEP]"}
{"pre": "most previous work on relation extraction focuses on binary classification domain adaptation, for example # refr, incorporating syntactic features like abstractness, and np chunking", "cit": "first, most nf qa approaches tend to use multiple similarity models ( information retrieval or alignment ) as features in discriminative rerankers # refr. [SEP]"}
{"pre": "in related work, factored language models # otherefr are used to combine the factored language models with backoff # refr. [SEP] [SEP]", "cit": "in section 4, we explore and evaluate a variety 3for example, morphological features can be very helpful for modeling highly inflectional languages # [SEP]"}
{"pre": "several authors have suggested that efficiently store these problems in data equals over parallel data # otherefr ; # refr. [SEP] the training approach is [SEP]", "cit": "these publications were mostly dominated by rather heuristic methods and did not provide a theoretical analysis of the complexity of the decipherment problem : # other [SEP]"}
{"pre": "for example, # refr used a document collection in a multi - document summarization system that produces summaries that are similar to [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "# refr introduce a combination of extracted similar phrases and a reformulation through sentence generation. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "tree - adjoining grammar # otherefr \\ ] and its lexicalized variant \\ [ # refr \\ ] has been used in various ways", "cit": "2the tag derivation tree is the basis for semantic interpretation \\ [ # refrb \\ ], generation \\ [ shieber and schabes [SEP]"}
{"pre": "for this reason there is currently a great deal of interest in methods which incorporate syntactic information within statistical machine translation systems # otherefr ; # [SEP]", "cit": "preordering # otherefr ; # refr preprocess the input in such a way that the words on the source side appear closer to [SEP]"}
{"pre": "in our experiments, we use the model of # refr for computing coherence. [SEP] the latent topic model coherence. [SEP] the latent topic model by latent", "cit": "recently, researchers developed measures which evaluate the semantic coherence of topic models # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in recent years, research on cue phrases have been focused on the task of finding the scope of hedge detection # refr in biomedical texts specifically, [SEP]", "cit": "similarly to previous work in hedge cue detection # refr, we first convert the task into a sequential labeling task based on the bio scheme, where [SEP]"}
{"pre": "# refr use a sophisticated model of selectional preferences, which capture topic shift in social media. [SEP] tasks, might use the methodology of [SEP] [SEP]", "cit": "computational works in the nexus of language and the social arena deal with various topics such as language accommodation # otherefr, demographic language variation [SEP]"}
{"pre": "fixing a modest number of iterations a priori # otherefr,? 4. 1 ) or using a combination of the two # refr, [SEP]", "cit": "unsupervised objectives are, at best, loosely correlated with extrinsic performance # otherefr ; # refr, inter alia ). [SEP] [PAD] [PAD] [PAD]"}
{"pre": "methods for discourse relations have been proposed # otherefr, # refr. [SEP] this framework to include discourse relations, such as the lexicon, [SEP]", "cit": "on the other hand, this might be improved through further evidence in the form of entity chains, as explored earlier in # refr, but using [SEP]"}
{"pre": "in a different approach, # refr use a topic model to induce a translation model and use the document as its distributional collocations. [SEP] for each", "cit": "more recent work in smt uses latent representations of the document context to dynamically adapt the translation model with either monolingual topic models # refr or [SEP]"}
{"pre": "while weak supervision works well when the textual corpus is tightly aligned to the database contents ( e. g., negative ), we compare several [SEP]", "cit": "however, riedel et al? s model ( like that of previous systems # refr ) assumes that relations do not overlap? there cannot exist [SEP]"}
{"pre": "in addition, discriminative methods are increasingly used in machine translation # otherefr ; # refr. [SEP] the text t. [SEP] the [SEP] [SEP] [SEP]", "cit": "for each sentence in the training, three types of word alignments are created : maximum entropy alignment # refr, giza + + alignment # other [SEP]"}
{"pre": "# refr, lewis carroll, etc.......... [SEP] ame / met 1996 \\ [ \\ ] c", "cit": "for example, a direct translation of'he read mao ', which is acceptable in english an ( 1 japanese, is comt ) let [SEP]"}
{"pre": "in addition, while several knowledge sources exist for nlp tasks such as document retrieval # otherefr, # refr, and document retrieval # [SEP]", "cit": "the kb can be used, among others, for monolingual and cross - lingual information retrieval, which was demonstrated by # refr. [SEP] [PAD]"}
{"pre": "for example, # refr proposed a method for selecting high precision sentences by using a frequency cutoff of seed selected sentences extracted from the same topic. [SEP]", "cit": "future work will include : ( i ) comparing other approaches that uses link analysis to reduce redundancy, such as # refr, # otherefr [SEP]"}
{"pre": "# refr use a pos - markup to find compounds for compound words that are not in segmenting in - sequences. [SEP] languages in order [SEP]", "cit": "# refra ) investigated and compared merging methods inspired by popovic? et al # otherefr, where compound parts were annotated with symbols [SEP]"}
{"pre": "various machine learning strategies have been proposed to address this problem, including semi - supervised learning # otherefr ; # refr, multi - task [SEP]", "cit": "various machine learning strategies have been proposed to address this problem, including semi - supervised learning # otherefr ; # refr, multi - task [SEP]"}
{"pre": "transliteration methods typically fall into two categories : generative approaches # otherefr that try to produce transliteration from an n - gram [SEP]", "cit": "identification of terms to - be transliterated ( ttt ) must not be confused with recognition of named entities ( ne ) # refr. [SEP]"}
{"pre": "in addition to domain knowledge, several methods have been proposed to improve the performance of a word sense disambiguation task # otherefr ; # refr", "cit": "nonetheless, the knowledge acquisition bottleneck can be relieved by means of domain adaptation # refr or by effectively injecting a generalpurpose corpus into a smaller [SEP]"}
{"pre": "# refr use distributional similarity to determine the degree of semantic relatedness between words. [SEP] this work is a mixture of two vectors (? [SEP] [SEP] [SEP]", "cit": "jensen - shannon divergence # refr observed that in tasks in which related words have to be found, some measures prefer words with a frequency similar to [SEP]"}
{"pre": "# refr used morphological analysis on arabic morphological analysis and disambiguation for oovs by morphological analysis. [SEP] the oovs in a person of a person", "cit": "some previous approaches anticipate oov words that are potentially morphologically related to in - vocabulary ( inv ) words # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used mecab as a morphological analyzer and a kind of automatically acquired automatically acquired automatically acquired preference grammars for the presented in # refr. [SEP] [SEP]", "cit": "for example, we can use automatically extracted hyponymy relations # otherefr ; # refr, or automatically induced mn clusters # otheref [SEP]"}
{"pre": "several active learning # otherefr ; # refr ), and recently there has been little work on improving the quality of a language. [SEP] [SEP]", "cit": "more exact understanding of the mechanics of stopping is also useful for applications of co - training # otherefr, and agreement - based co - [SEP]"}
{"pre": "the parser is trained with the averaged perceptron algorithm # refr, with a variant of the greedy projective dependency parser # otherefr. [SEP] [SEP]", "cit": "# refr introduced a transition based nonprojective parsing algorithm that has a worst case quadratic complexity and an expected linear parsing time. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "# refr use a bayesian model of verb - noun combination instead of verbs and their arguments to model the role of verb arguments. [SEP] arguments and to", "cit": "following this work, # refr formulated role induction as the problem of detecting alternations and mapping non - standard linkings to cannonical ones, [SEP]"}
{"pre": "this is a variant of the problem of finding the semantic parses in a synchronous grammar # otherefr ; # refr, but its ability to", "cit": "finally, # refr report on a generation algorithm for unification categorial grammar that appears to be a special case of ours. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "we incorporate all our new features into a hierarchical phrase - based model # refr. [SEP] the word alignment matrix by augmenting the word alignment [SEP] [SEP]", "cit": "to further limit the space of extraction sets we are willing to consider, we restrict a to block inverse transduction grammar # otherefr ; # [SEP]"}
{"pre": "in addition, while the method can use in smt # otherefr, the translation model estimation, which can also be applied to machine translation", "cit": "however, this has been shown to be infeasible for real - world data ( denero and # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the past decade has witnessed the rapid development of linguistically syntax - based smt systems # otherefr ; de? # refr, which aim", "cit": "the method was also successfully applied to improve syntax - based smt translation # refr, using more sophisticated syntactical features. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "it is also possible for the word alignments leading to phrase - based smt models to be learned through transduction grammars # otherefr, # [SEP]", "cit": "the idea of iteratively segmenting the existing sentence pairs to find good phrasal translations has also been tried before ; # refr introduces the recursive alignment [SEP]"}
{"pre": "in the last decade, statistical parsing models have been shown to be successful in improving the performance of statistical parsers # refr. [SEP]. [SEP] [SEP]", "cit": "our notation fol - 1other elevant parsers imultaneously consider two or more words that are not necessarily n a dependency relationship # [SEP]"}
{"pre": "bod # otherefr ; # refra ). [SEP] this approach is to shallowly trained with a parse treebank of [SEP] sentences [SEP] [SEP]", "cit": "we first summarize the first fully instantiated dop model as presented in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "given the compression task, most models are trained to replicate human summaries either by removing branches # otherefr ; # refr, or maximum entropy #", "cit": "because it was developed in support of extractive summarization # otherefr, # refr, clarke and lapata # otherefr, [SEP]"}
{"pre": "for instance, the best performing word sense disambiguation task # otherefr ; # refr has examined the degree of cross - lingual machine translation", "cit": "we selected the top 3000 sentence pairs from the wmt 2012 development test sets, based on their distance to the clwsd trial and test [SEP]"}
{"pre": "we use the same features as # refr. [SEP] the linear model, trained on the conll - 2003 data set # otherefr sentences [SEP]", "cit": "we followed the settings in # refr and consider three main entities categories : per, loc and org. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "33549 and roth, 2003 ; cancedda et al, 2003 ; culotta and sorensen, 2004 ; toutanova [SEP]", "cit": "reranking appears extremely interesting if coupled with kernel methods # refr, as the latter allow for extracting from the ranking hypotheses a huge amount of [SEP]"}
{"pre": "in recent years, graph - based learning has been successfully used for question answering # otherefr ; # refr and relation extraction # other [SEP] [SEP]", "cit": "we used our qc system presented in # refr, which classifies each question into 6 - coarse categories ( i. e., abb [SEP]"}
{"pre": "this includes work on phrasestructure parsing # otherefr ; # refr, dependency parsing # otherefr. [SEP] this framework [SEP] [SEP] [SEP] [SEP]", "cit": "snow - based shallow parser # refr was used for shallow parsing. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, we are aware of are in fact that the quality of a model showing that it is necessary to assign state - of - the -", "cit": "indeed, the analysis produced by existing semantic role labelers has been shown to benefit a wide spectrum of applications ranging from information extraction # refr and [SEP]"}
{"pre": "in a statistical machine translation setting, it has been shown that a translation strategy crucially technique is particularly effective in the language generation process # otheref", "cit": "in that approach, the target language becomes the same as the source language # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the case of natural language generation, # refr used ontology axioms in nlg ( e. g., caraballo and [SEP] [SEP]", "cit": "while early nlg systems were mainly based on manually created rules # otherefr ; # refr, later approaches started applying statistical methods to the [SEP]"}
{"pre": "this approach is similar to work in \\ [ kuki et al # refr \\ ], and \\ [ wroblew \\ ], [SEP] filtering", "cit": "in order to reduce computational demands, state - of - the - art techniques such as subsumption - based packing # otherefr and the [SEP]"}
{"pre": "in # refr, we showed that for training, a model that is trained on the subset of features, which are automatically tagged with the training data", "cit": "we adopt the basic feature set used in # otherefr and # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use mxpost tagger # refr for pos tagging, and chunking # otherefr. [SEP] the word sequence labeling process, as well", "cit": "for the conll2000 dataset we adopted the same standard features used in # otherefrpos dataset we used the features presented in # refr [SEP]"}
{"pre": "# refr use a supervised classifier to identify the relations that occur more noun compounds. [SEP] features, which only consider verb relations. [SEP] such as gender", "cit": "# refr characterized the semantic relationship in a noun - noun compound using the verbs connecting the two nouns by comparing them to predefined seed verbs. [SEP] [PAD]"}
{"pre": "1988 ; neumann and finkler 1990 ). - 245 - currently developed approaches that consider parsing as well as generation # otherefr ; [SEP]", "cit": "1 according to # refr, a grammar is reversible if the parsing and generation problem is computable and the relation between strings and logical forms is symmetric [SEP]"}
{"pre": "for example, # refr and chambers and jurafsky # otherefr study the conditions for the use of supervised machine translation ( smt )", "cit": "the most relevant, and perhaps only, work in this area is that of # refr who linked predicates across document pairs, measuring the f1 [SEP]"}
{"pre": "this measure is tested in the pyramid measure # refr, which was used to measure the quality of the pyramid, weighted scores from the pyramid score (", "cit": "another method for summary evaluation is the pyramid method # refr, which takes into account the fact that human summaries with different content can be equally informative [SEP]"}
{"pre": "in this approach, i. e., semantic unification as well as the formalism of the utterance for dialogue system turning by # refr.", "cit": "# refr and kogure et al # otherefr introduced il locutionary force type planning from deep illocutionary force type [SEP]"}
{"pre": "in a corpus of nlg, # refr use statistical methods to adapt the dialogue state to the dialogue state to the dialogue management strategy. [SEP] [SEP]", "cit": "examples include adaptive or trainable nlg # refr, where the authors formulate their problem as a statistical planning problem and use rl to find a [SEP]"}
{"pre": "statistical machine translation has been cast as a way of reducing the process of reducing the process and has led to a lot of attention in many research #", "cit": "although the comparison against the zhu system, which uses syntax - driven machine translation, shows no clear benefit for syntax - based machine translation, it [SEP]"}
{"pre": "ulc ( gim? nez and m? # refr is an aggregated metric that incorporates several semantic information features and shows improved correlation with [SEP]", "cit": "feature - based qe models # otherefr ; # refr throw a wide range of linguistic and non - linguistic features into machine learn - [SEP] [PAD]"}
{"pre": "for example, in? john saw mary yesterday at the station?, only? john? and? mary? are required arguments while [SEP]", "cit": "this is often termed as the classification of verb diathesis roles or the lexical semantics of predicates in natural language # otherefr ; # [SEP]"}
{"pre": "in a first attempt to address the issue of determining how considerations of text can be defined by applying the centering algorithm to a single model to a", "cit": "the work of [ langkilde and knight, 1998 ; langkilde, 2002 ] describes a sentence realizer that uses [SEP]"}
{"pre": "in contrast, most of the previous work on lexicon induction, # refr use supervised methods to extract categories from a corpus of unlabelled texts. [SEP]", "cit": "previous research on lexicon induction proposed a widely applicable method based on coordination # otherefr ; # refr : first, a set of seed expressions [SEP]"}
{"pre": "empirically, i show that surprisal effects in human sentence processing remains much lower level as a task, when applied to other natural language processing # [SEP]", "cit": "hierarchical hidden markov model ( hhmm ) parsers have been proposed as psycholinguistic models due to their broad coverage within human - like working [SEP]"}
{"pre": "accordingly, existing graph - based dp models can be categorized into tree groups, namely, the first - order # otherefr ; # refr [SEP]", "cit": "in dependency parsing ( dp ), the number of dependencies in a part is called the order of a dp model # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "several broad - coverage dialogue systems have been developed for the domains of dialogue systems # otherefr ; # refr. [SEP] the cross - lingu [SEP]", "cit": "in current? troubleshooting? spoken dialogue systems ( sds ) # refr, the major part of the conversation is directed by the system, [SEP]"}
{"pre": "# refr use a pcfg to getar nodes that reduce the number of times over the 402m. [SEP] well - formed with [SEP] languages", "cit": "berg - kirkpatrick et al # otherefr ; # refr with a semi - markov dynamic program # otherefr. [SEP] [PAD]"}
{"pre": "we will show how to integrate syntax - semantics constraints on the complete - 2the ltags / machine translation task ( lr grammar ) \\ [ #", "cit": "semantichead - driven generation ( shieber et al, forthcoming ; # refr uses semantic heads and their complements as a locus of semantic locality [SEP]"}
{"pre": "in a typical planner for text summarization, paraphrasing # refr used a discourse tree structure to represent a sentence and then generate a sentence to", "cit": "sight # refr is a natural language system whose overall goal is providing blind users with interactive access to multimodal documents from electronically - available popular media sources [SEP]"}
{"pre": "iii, 2007 ; # refr. [SEP]. [SEP] this problem in domain, this work is trained with log - linear models, and without supervision.", "cit": "recently, several authors have found that learning new features based on distributional similarity can significantly improve domain adaptation # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition to semantic classes, we also use the f - measure # refr, which would link to annotate the proportion with precision quickly [SEP] [SEP]", "cit": "stage 1 : basic - level / instance concept collection : we use the doubly - anchored pattern dap developed in # refr : dap : [ seed [SEP]"}
{"pre": "in particular, we use the system of # refr, which requires a lexicon for building a generation system. [SEP]a ). [SEP] natural [SEP] natural", "cit": "other work focuses on surface realization? choosing among different lexical and syntactic options supplied by the lexical chooser and sentence planner? rather than on creating [SEP]"}
{"pre": "independently of this work, koo et al # otherefr and # refr showed that the matrix - tree theorem can be used to train edge", "cit": "koo et al # otherefr and # refr both describe how the matrix tree theorem can be applied to computing the sum of scores of [SEP]"}
{"pre": "there have been various efforts to integrate linguistic knowledge into smt systems, either from the target side # otherefr ; # refr or both [SEP]", "cit": "there have been various efforts to integrate linguistic knowledge into smt systems, either from the target side # otherefr ; # refr, just [SEP]"}
{"pre": "in addition, we plan to test the utility of the verb? noun, which is shown to be useful in natural language processing # otherefr", "cit": "information extraction ( ie ) # refr ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the model scaling factors? m1 are trained with respect to the final translation quality measured by an error criterion # refr. [SEP]. [SEP] [SEP] [SEP]", "cit": "current state of the art machine translation systems # refr use phrasal ( n - gram ) features extracted automatically from parallel corpora. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "several recent approaches to automatic acquisition of hypernym / or hyponym relationships # otherefr ; # refr. [SEP] this approach is [SEP]", "cit": "finkelstein - landau and # refr learn patterns for company merging relations with exceedingly good accuracies. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr use expectation maximization to em to estimate the joint likelihood of cognate words. [SEP]. [SEP] orthograph, [SEP]. [SEP]. [SEP] similarity", "cit": "there is a range of past work that has variously investigated cognate detection # otherefr ; # refr, character - level decipher [SEP]"}
{"pre": "the only difference between the1 and the1 - 3 reported f - score ( % ) are that the model for the conll [SEP] [SEP] [SEP]", "cit": "finally, we note that new approaches to corpus annotation of semantic dependencies also come with rich browser - based annotation interfaces # otherefr ; # [SEP]"}
{"pre": "in japanese, around 95 % word segmentation accuracy is reported by using a word - based language model and the viterbi - like dynamic programming [SEP]", "cit": "# refr recently proposed a generalized forward - backward algorithm that is a character synchronous method for unsegmented languages. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the algorithm has been applied to a wide variety of problems, including part - of - speech tagging # otherefr, lexical disambiguation # refr", "cit": "recent examples of this work include # refr, # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "most work in monolingual alignment employs dependency tree / graph matching algorithms, including tree edit distance # otherefr ; # refr, but [SEP] the", "cit": "most work in monolingual alignment employs dependency tree / graph matching algorithms, including tree edit distance # otherefr, linear regression / classification models [SEP]"}
{"pre": "the high level data can be used for pos tagging accuracy by machine learning techniques which are part - of - speech tagger # refr, [SEP] the", "cit": "on the other hand, according to the data - driven approach, a frequency - based language model is acquired from corpora and has the forms of [SEP]"}
{"pre": "the only requirement will be that a bottom - up arsing algorithm faces combinatorial problems in short phrases, such as clause headwords [SEP] [SEP] [SEP] [SEP]", "cit": "not ( : tlmt this generation process iunounts to a gem eralization of semantic - head - driven g eration ( [SEP]"}
{"pre": "dependency parsers have been tested on parsing sentences in english # otherefr ; # refr as well as many other languages # otherefra [SEP]", "cit": "mst represents global, exhaustive graphbased parsing # otherefr ; # refr that finds the highest scoring directed spanning tree in a graph. [SEP] [PAD]"}
{"pre": "it is unrealistic to compute the partition factor of the formula directly ; therefore, the factor has been computed by dynamic programing # otherefr [SEP]", "cit": "it is unrealistic to compute the partition factor of the formula directly ; therefore, the factor has been computed by dynamic programing # otherefr [SEP]"}
{"pre": "# refr use cross - lingual information retrieval to find the highest translation for the english transfer of a german sentence. [SEP] if they use [SEP] the", "cit": "there is also current work on learning more types and instances of transfer rules # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this model is trained on the training data and has been used in numerous nlp tasks # otherefr ; # refr. [SEP] [SEP] [SEP] [SEP]", "cit": "we used the mma system # refr trained on the training data to perform word segmentation and pos tagging and used the baseline parser to parse the [SEP]"}
{"pre": "these include sentence alignment # otherefr ; # refr. [SEP] the problem of y. [SEP] the source to a sentence to a sentence to a", "cit": "recently, new methods employ machine learning techniques to automatically build larger paraphrase collections from parallel corpora # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the parser moves in a more complete manner, and the part of speech tagger are tnt # refr, and the treetagger is used", "cit": "its applications range from sentence boundary disambiguation ( reynar and # refr to part - of - speech tagging # otherefr. [SEP] [PAD]"}
{"pre": "on the observation that treebanks allow for english are not limited to parser output, but for which we have been applied to the nli parse", "cit": "these include well studied grammars such as hierarchical phrase structure grammars and combinatory categorial grammars, and transforms that rearrange the tree such as the [SEP]"}
{"pre": "for example, # refr report that removing bilexical features derived from syntactic trees in the penn treebank, and in addition to the [SEP] analysis", "cit": "figure 3 : dependency graph for the example string. tributed to # refr, to percolate lexical heads up the tree. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "recent work has shown that bayesian methods can improve the performance of unsupervised pos tagging # refr. [SEP] the problem of unsupervised pos tagging ( m [SEP] [SEP]", "cit": "there has been a great deal of recent interest in the unsupervised discovery of syntactic structure from text, both parts - of - speech # refr and [SEP]"}
{"pre": "there have been many studies on the automatic acquisition of word similarity between words by comparing the similarity between their distributional similarity among senses # refr. [SEP] the", "cit": "nevertheless, informally, the relative entropy is used as the \" distance \" between two probability distribution in many previous works # refr. [SEP] [PAD] [PAD]"}
{"pre": "we note that the best result on the dmv model of # refr outperforms the state - of - the - art dependency parsers using the [SEP]", "cit": "many recent works have addressed the task ( e. g. # refr ) and its importance has increased due to the recent availability of huge corpora [SEP]"}
{"pre": "recent work by # refr has shown that these features may be useful for automatic analysis and generation of text planning tasks. [SEP] differences between discourse boundaries.", "cit": "the first type is discourse markers # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in experiments on this corpus, we show that the model significantly improves results on the experiments reported in # refr, and levy and manning # other", "cit": "relevant, in principle, to our discussion here, are also the results obtained with treebank grammars for german : # refr have trained a pc [SEP]"}
{"pre": "in addition, we show that the algorithm is closely related to the stochastic parsing algorithm for dependency parsing # otherefr ; # refr, in particular", "cit": "although discriminative phrase structure parsing has been shown to be challenging when it comes to efficiency issues # refr, we use here several approximations that make the [SEP]"}
{"pre": "a weighted hypergraph also defines a probability or other weight for each tree, and can be used to represent the hypothesis space considered # otheref [SEP]", "cit": "in their deterministic annealing formulation, # otherefr ; li and # refr, express the parameterization of the distribution? as??? [SEP]"}
{"pre": "in # refr, a maximum entropy model is used to predict the orientation of a word reordering model. [SEP] a source sequence of features. [SEP]", "cit": "to address this problem, # refr enhance the btg with a maximum entropy ( maxent ) based reordering model which uses boundary words of [SEP]"}
{"pre": "in this paper, we assume the socalled search - based approach to text orderings # refr, and does not consider the possibility of sentence ordering", "cit": "several papers in the recent literature # otherefr ; # refr have focused on defining local coherence, which evaluates the quality of sentence - to [SEP]"}
{"pre": "we also show that normal - form constraints can be applied to lexicalized grammars # otherefr ; # refr, and that some form is [SEP]", "cit": "composition introduces spurious ambiguities, which we eliminate by using # refr? s normal form. 1 coordinating conjunctions have a special category conj, [SEP]"}
{"pre": "we use giza + + # refr to learn word alignments, both directions, and apply the grow - diag - final heuristic to diag - and", "cit": "in this paper we present results on using a recent phrase - based smt system, pharaoh # refr, for nlg. 1 [SEP]"}
{"pre": "in the realm of openccg realization ranking models # otherefr ; # refr, we have incorporated alternative to optimize on a sentence - like ordering", "cit": "internally, such graphs are represented using hybrid logic dependency semantics ( hlds ), a dependency - based approach to representing linguistic meaning # refr. [SEP]"}
{"pre": "in this paper, we show that a deep parsing framework can be integrated into the parser of # refr. [SEP] this dependency parser is [SEP] [SEP] [SEP]", "cit": "curran and # refr is used, instead of hard assignment of single tags in a preprocessing step as done here. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "because directional alignments are preserved intact as components of our model, extensions or refinements to the underlying directional markov alignment model could be integrated cleanly [SEP]", "cit": "moreover, the bidirectional model enforces a one - to - one phrase alignment structure, similar to the output of phrase alignment models # otheref [SEP]"}
{"pre": "caught between the scylla of linguistically inadequate projective trees and the charybdis of computationally intractable non - projective trees, some researchers have [SEP]", "cit": "caught between the scylla of linguistically inadequate projective trees and the charybdis of computationally intractable non - projective trees, some researchers have [SEP]"}
{"pre": "parameter estimation for the disambiguation models include # otherefr ; # refr. [SEP]. [SEP] each partially ordered word or in a sentence [SEP] [SEP]", "cit": "we are generally interested in log - linear models for parsing # refr and other tasks. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "metaphor identification has been done using different approaches : violation of selectional preferences # otherefr, ( iii ), and lexical relations among [SEP] [SEP]", "cit": "the problem of metaphor modeling is gaining interest within nlp, with a growing number of approaches exploiting statistical techniques # otherefr ; # refr [SEP]"}
{"pre": "to overcome the false positive problem caused by the distant supervision assumption, researches in # otherefr # refr proposed multi - instance models to model [SEP]", "cit": "takamatsu et al. # refr claimed that the at - least - one assumption in multi - instance models would fail when there was [SEP]"}
{"pre": "we use a phrase - based decoder implemented with moses # refr. [SEP] bleu, nist2009, a 5 - gram language model [SEP]", "cit": "as noted in # refr, hiero can represent the same information with hierarchical rules of the form ux, xu, and xux. [SEP] [PAD]"}
{"pre": "in this paper, we show how to solve the reordering problem, by adopting a probabilistic finite state transducer - based translation model ( wfst )", "cit": "one might try to address this issue by limiting a priori the amount of re - ordering, in the spirit of # refr, which would allow [SEP]"}
{"pre": "for assessment of content, the focus is traditionally on topical appropriateness of the vocabulary # otherefr ; # refr, although recently other aspects, [SEP]", "cit": "for assessment of content, the focus is traditionally on topical appropriateness of the vocabulary # otherefr ; # refr, although recently other aspects, [SEP]"}
{"pre": "bilingual lexicon extraction from comparable corpora has received considerable attention since the 1990s # otherefr ; # refr ; peters and picchi [SEP] [SEP] [SEP]", "cit": "the underlying assumption is that translations of words that are related in one language are also related in the other language # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this measure has been applied to tasks such as word sense disambiguation # otherefr, and sentence compression # refr. [SEP] this [SEP] [SEP] [SEP]", "cit": "pecina # otherefr, however, found pmi to be the best collocation extraction measure ; and # refr found it to be [SEP]"}
{"pre": "we use the features of # refr, except that the parsers trained on a manually annotated treebank, and we use features that are designed for", "cit": "a look at the performance sheet in the contest shows that two systems with quite different approaches # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "the cohesion constraint is used in our experiments are the experiments used by # refr. [SEP] the cohesion of the dependency length of the word and the two", "cit": "the details of this algorithm are described in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "brown clustering has been used extensively in supervised nlp tasks such as parsing # otherefr, semantic role labeling # refr, question answering # other", "cit": "brown clustering has been used extensively in supervised nlp tasks such as parsing # otherefr ; # refr, named - entity recognition # other [SEP]"}
{"pre": "we also plan to explore other approaches for bilingual lexicons which are not able to produce backoff # refr. [SEP] the crosslingual exicon", "cit": "for languages with limited electronic resources, i. e. low - density languages, however, we cannot use automated techniques based on parallel corpora # [SEP]"}
{"pre": "while entity - mention models have previously been shown to be worse or at best marginally better than their mention - pair counterparts # otherefr ; [SEP]", "cit": "while other work has used this framework as a starting point for entity - level systems # otherefr ; # refr, we will show that [SEP]"}
{"pre": "over the last decade, # refr, and others 2 have contributed to this issue the term areferential description'is due to a [SEP] [SEP] [SEP]", "cit": "recently, we have introduced several improvements o these methods # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr use machine learning techniques to automatically identify whether they train a patient or not a named entity or not. [SEP] features ( ad hoc or [SEP]", "cit": "# refr use quoted speech attribution to reconstruct the social networks of the characters in a novel. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "preposition sense disambiguation the psd system is a newer version of the system described 10lack of space prohibits a sufficiently thorough discussion of [SEP]", "cit": "the constraints of prepositional constructions have been explored by rudzicz and mokhov # otherefr and o? hara and [SEP]"}
{"pre": "in recent years, reranking techniques have been successfully applied to the so - called history - based models # otherefr ; # refr [SEP]", "cit": "we use the support vector machine # otherefr based algorithm proposed in # refr as the reranker in this paper. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "while reranking has benefited many tagging and parsing tasks # otherefr including semantic role labeling # refr, it has not yet been [SEP]", "cit": "the syntactic features introduced by collins # otherefr for reranking syntactic parse trees have been proven successfully in both english and spanish # refr [SEP]"}
{"pre": "dirt # otherefr # refr define a measure of entailment rules for dirt as defined by snow et al. # other [SEP] a", "cit": "along this vein, such inference rules constitute a crucial component in generic modeling of textual inference, under the textual entailment paradigm # otherefr [SEP]"}
{"pre": "thus, the discourse relations are processed with an incremental understanding strategy of actions semantics # otherefr ; # refr. [SEP]'[SEP]'[SEP] [SEP]", "cit": "most previous formal and computational models of conversational implicature \\ [ gazdar, 1979, # refr, hirschberg, 1985, las [SEP]"}
{"pre": "therefore, researchers have proposed alternative approaches to learning synchronous grammars directly from sentence pairs without word alignments, via generative models # otherefr ; # [SEP]", "cit": "the first line is to modify word alignment by exploring information of syntactic structures # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "brown clustering has been used extensively in supervised nlp tasks such as parsing # otherefr, named entity recognition # refr, question answering # [SEP]", "cit": "however, only immediately adjacent words are taken into account as recognized e. g. by koo et al. # otherefr, and [SEP]"}
{"pre": "table 1 : sentence similarity the set of sentences extracted by simple string similarity to a set of paraphrases # otherefr ; # refr.", "cit": "then, we evaluated the translation quality using bleu # otherefr and me - teor # refr, and performed significance testing using bootstrap [SEP]"}
{"pre": "however, due to the spontaneous nature of the posts, microblogs are notoriously noisy, containing many non - native texts, containing the", "cit": "to the best of our knowledge, we are the first to target the task of ill - formed word detection in the context of short text messages [SEP]"}
{"pre": "in # otherefr, ( 2 ) and # refr used a corpus of decision trees, 6, 6, 6, 6, 6,", "cit": "in # refr the problems of data sparseness is approached with a supervised back - off model, with interesting results. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this is a variant of the algorithm described in # refr. [SEP] this paper extends the concept of \\ [ # otherefr [SEP] [SEP]y [SEP]", "cit": "we evaluated the rdt generation model by comparing its performances with another system also competing in the give challenge but based on a classical approach on # [SEP]"}
{"pre": "# refrb ) compared several web counts for noun - verb clustering, and verb - object pairs. [SEP] the web by using web as a corpus", "cit": "# refr use the web to obtain frequencies for unseen bigrams in a given corpus. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we show that for instance, recently by ddtm et al # otherefr, using the parser of # refr and trained on the conll", "cit": "another line of work that integrates corpus - level declarative information into sentence - level models includes the posterior regularization # otherefr ; # refr, [SEP]"}
{"pre": "as more and more conversation data becomes available, researchers have investigated automated processing of conversation data to acquire useful information, for example, related to opinions [SEP]", "cit": "recent studies have also developed approaches to summarize conversations # otherefr and to model conversation structures ( dialogue acts ) from online twitter conversations # refr [SEP]"}
{"pre": "pcfg - las to test our hypothesis, we use the grammatical formalism of probabilistic context - free grammars # otherefr ; # refr, [SEP]", "cit": "# refr have recently shown that better handling of named entities ( nes ) in broad coverage surface realization with lfg can lead to substantial improvements in [SEP]"}
{"pre": "we evaluated the bleu scores # refr of translations on test set with four references for tuning. [SEP] the comparison of different [SEP] batch lattice - based", "cit": "our tuning baseline is an implementation of hypergraph mert # otherefr, directly optimizing ibm bleu4 # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "in this paper we use an unsupervised learning approach to solve the problem of missing et al # otherefr, # refr, and suggest that contextual", "cit": "measuring the contextual fitness of a term in its context is a key component in different nlp applications like speech recognition # otherefr, co [SEP]"}
{"pre": "for instance, in the dependency - based smt model, # refr find that the best derivation of a bilingual sentence. [SEP] a source [SEP] it", "cit": "in recent years, syntax - based smt has made promising progress by employing either dependency parsing # otherefr ; mi and # refr or [SEP]"}
{"pre": "the mechanisms summarised here were designed solely to produce puns, but the notions of? schema? and? are not radically # refr. [SEP]", "cit": "the generation literature provides multiple examples of content selection components developed for various domains # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "transformation - based learning has been applied to a wide variety of natural language processing tasks, including part of speech tagging # otherefr, preposition", "cit": "it has been applied to a wide variety of tasks, including part of speech tagging # otherefr, prepositional phrase attachment # refr [SEP]"}
{"pre": "we used the stanford parser to get dependency trees for each document, parses were preprocessing by the stanford parser # refr. [SEP] sentences. [SEP] [SEP]", "cit": "this includes a pos tagger and dependency parser, comparable in accuracy to the current stanford dependency parser # refr ; an np extractor that uses [SEP]"}
{"pre": "for instance, measures that compute the association strength between the elements of an expression have been employed to determine its degree of compositionality # otheref [SEP]", "cit": "this consideration relates our work to that of baldwin et al. # otherefr, # refr, weller and fritzinger # [SEP]"}
{"pre": "this observation has led to a vast amount of research on unsupervised grammar induction # otherefr ; # refr. [SEP] non - projective dependency trees [SEP]", "cit": "for treebanks with non - projective trees we use the pseudo - projective parsing technique to transform the treebank into projective structures # refr. [SEP]"}
{"pre": "in this paper, we show that the cube pruning strategy # otherefr ; # refr can be used effectively in extracting the non [SEP] [SEP] [SEP]", "cit": "p # otherefr ; # refr, or can be integrated at a shallow level in a reranking manner # otherefr. [SEP]"}
{"pre": "ilp has been used extensively for summarization in nlp lately # otherefr ; # refr, and it has been shown that it", "cit": "for each dependency from word w to head 5as pointed out by daume iii and # refr and krahmer et al # otheref [SEP]"}
{"pre": "the only difference between the system and the accuracy of the distributional similarity when was on the target words in two languages # refr. [SEP] [SEP] [SEP] the", "cit": "# refr use a corpus and word similarities to induce a ranking of word senses from an untagged corpus to be used in wsd. [SEP] [PAD]"}
{"pre": "# refr propose a method that performs contextual information, and showed that this result is consistent with the methods for the modeling of meaning that they are not", "cit": "in particular, the question of operationalizing semantic compositionality in vector spaces # refr received much attention. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we parsed the training data using the charniak parser # refr. [SEP] - internal annotations provided by the penn treebank # otherefr", "cit": "much noun phrase? internal structure is not made explicit in the ptb, and the enju treebank from which our pas representation derives pred [SEP]"}
{"pre": "nivre? s parser has been tested for swedish # otherefr, english # refr, czech # otherefr. [SEP]. [SEP] [SEP]", "cit": "the two best - performing systems in the conll - x shared task # refr can be classified along two lines depending on the method they used [SEP]"}
{"pre": "the task of sentence compression in particular has benefited from the availability of a simple english wikipedia and english wikipedia # otherefr, [SEP] the [SEP]", "cit": "other work focuses on lexical simplifications and substitutes difficult words by more common wordnet synonyms or paraphrases found in a predefined dictionary # [SEP]"}
{"pre": "statistical parsing models have recently been proposed that employ a probabilistic context - free grammar # otherefr ; # refr. [SEP] this appears to be a", "cit": "recently, specific probabilistic tree - based models have been proposed not only for machine translation # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper we describe a new approach to stochastic statistical surface generation ( glr ), an input to a packed forest, a, a,", "cit": "langkilde [ # refr ] provides an evaluation of coverage of halogen and shows runtimes around 28 seconds for sentences with average lengths [SEP]"}
{"pre": "previous work in nlp has focused on using the implicit syntactic information available in part - of - speech # otherefr ; # refr, [SEP]", "cit": "previous work in nlp has focused on using the implicit syntactic information available in part - of - speech # otherefr, punctuation # [SEP]"}
{"pre": "dinu and baroni, 2013 ; # refr. [SEP] the british national corpus # otherefr. [SEP] the [SEP] the [SEP] [SEP] [SEP] [SEP]", "cit": "they are also used for modeling the meaning of a phrase or a sentence # refr ; wartena, 2013 ; mitchell, 2011 ; g [SEP]"}
{"pre": "leveraging information from one language for the task of disambiguating another language has received considerable attention # otherefr ; # refr. [SEP] [SEP] [SEP]", "cit": "leveraging information from one language for the task of disambiguating another language has received considerable attention # otherefr ; # refr. [SEP] [PAD] [PAD]"}
{"pre": "text structuring the insertion task is closely related to the extensively studied problem of sentence ordering. 3 most of the existing algorithms represent text structure as a [SEP]", "cit": "in accordance with recent work in the emerging field of text - to - text generation # otherefr ; # refr, we assume that the [SEP]"}
{"pre": "in this paper, we use an n - gram language model, with a modified version of the ibm model # refr. [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "table look - up using an explicit translation lexicon is sufficient and preferable for many multilingual nlp applications, including \" crummy \" mt [SEP]"}
{"pre": "this can be achieved either by using more features extracted from the parse tree # refr. [SEP] features of the same sentence, [SEP] [SEP] the [SEP] [SEP]", "cit": "it has been the subject of much recent research since the release of the penn discourse treebank 2. 0 # otherefr ; # refr [SEP]"}
{"pre": "we use an al framework called l1, which is the l1, l2, and l2, is stochastic., which is a", "cit": "for example, both haghighi and klein # otherefr and # refr have demonstrated results better than 66. 1 % on the apart [SEP]"}
{"pre": "among others, existing rte datasets are the de - 1http : / / www. nist. gov / 2http : / [SEP] [SEP]", "cit": "the dataset was created following the crowdsourcing methodology proposed in # refr, which consists of the following steps : [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, punctuation marks are ignored : while wsj { 1 }, not punctuation marks, are not informative [SEP]. [SEP]. [SEP]", "cit": "as standard practice shifts away from relying on gold part - of - speech # otherefrb ; # refrc, inter alia ), [SEP]"}
{"pre": "in recent years, a variety of approaches have been proposed for automatically learning selectional preferences # otherefr ; # refr. [SEP] this [SEP] [SEP]", "cit": "o s? eaghdha, 2010 ) and distributional similarity metrics # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "statistical parsing models have recently been developed for grammatical relations # otherefr ; # refr. [SEP] & # otherefr in the context of machine", "cit": "model 3 using parseval, while clark and curran # otherefr and # refr report 84 % and 86. 7 % f1 [SEP]"}
{"pre": "id participant cmu - uka carnegie mellon university, usa # otherefr limsi limsi limsi limsi limsi", "cit": "for instance, statistical systems are heavily optimized to their training data, and do not perform as well on out - of - domain data ( ko [SEP]"}
{"pre": "at this point, we have many different parsing models that reach and even surpass 90 % dependency or constituency accuracy on this test set # [SEP]", "cit": "the approach in this paper is reminiscent of co - training # otherefrb ) and up - training # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the nlp community has recently devoted much attention to developing the nlp community, and the focus has been devoted to developing the semantics and knowledge [SEP]", "cit": "there had already been tremendous progress in syntactic parsing # otherefr ; # refr this work is licensed under a creative commons attribution 4. 0 [SEP]"}
{"pre": "in contrast, most of the unsupervised approaches to this problem, # refr do not rely on hand - annotated corpora, and do not perform well on", "cit": "# refr describe a supervised approach that trains separate classifiers for topic and sub - topic segmentation ; more relevant for the current work is the unsupervised method [SEP]"}
{"pre": "as regards i ), recently there are several works that take an integrated approach incorporating semantic role labeling systems # refr. [SEP] the problem of predicate -", "cit": "these works include # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in comparison, most previous work on discourse parsing # otherefr ; # refr, all not only exact inference. [SEP] the [SEP] [SEP] [SEP] [SEP]", "cit": "recently, discriminative reranking has been used successfully in some nlp tasks such as pos tagging, chunking, and statistical parsing # other [SEP]"}
{"pre": "in this paper, we evaluate the system of # refr. [SEP] non - projective dependency parsing. [SEP] a two - projective dependency parser : a set", "cit": "first, we investigate the impact of using different flavours of covington? s algorithm # otherefr for nonprojective dependency parsing on [SEP]"}
{"pre": "we use a forest - to - string ( m2m ) system # refr to extract word alignments. [SEP] the [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "next, we compared the unsupervised aligner giza + +, with the supervised aligner nile, which uses syntactic information to improve alignment [SEP]"}
{"pre": "to measure the quality of segmentation, we use the ir - based mt evaluation metric # otherefr, which is the general web [SEP] [SEP] [SEP]", "cit": "early translation retrieval methods were widely used in example - based and memory - based translation systems # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "in our experiments, we used the stanford parser # refr and the stanford lexicalized model # otherefr. [SEP]. [SEP] the representations of syntactic", "cit": "extending a technique presented in # refr and adopted in # otherefr for function labels, we split some part - of - speech tags into [SEP]"}
{"pre": "in dependency parsing, the task of inferring a dependency structure over the last sentence, has gained a lot of research in a wide [SEP] natural language [SEP]", "cit": "this type of model has been used by, among others, eisner # otherefr, # refra ), and nakagawa # [SEP]"}
{"pre": "we use an automatic clustering algorithm # refr to disambiguate the senses of the words according to their underlying distribution. [SEP] ( [SEP] ) [SEP] [SEP] [SEP]", "cit": "once the corpus has been processed, clusters are repeatedly merged using hac with the average link criteria, following # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we conducted our dependency parser and use the mate parser # refr, which were trained on the conll 2009 data set, and then converted to [SEP]", "cit": "# refr considers information of more surrounding words for the graph - based models, while zhang and nivre # otherefr define a set of [SEP]"}
{"pre": "it was also used for the bleu metric # refr, which measures the n - gram overlap between the reference and machine translation output. [SEP] [SEP]", "cit": "we chose these sets because bleu # refr, our baseline metric, performed particularly poorly on them ; this left room for improvement in addition to [SEP]"}
{"pre": "the basic concept of the approach has been described by # refr. [SEP] ( m ) each system to produce a probability distribution over a set of [SEP]", "cit": "some rights reserved. word - based combination techniques using confusion networks # refr ; sim et al, 2007 ; rosti et al, 2007b [SEP]"}
{"pre": "in the nlp community, maximum entropy models have been used for sequential conditional random fields # otherefr, and structured prediction # refr. [SEP]", "cit": "l1 - regularization # refr :? l1? # otherefr in the context of sparse regression. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, timeline summarization techniques # otherefr ; # refr designed specifically for the identification of the timeml. [SEP] [SEP] [SEP] [SEP]", "cit": "existing research carried out on the interpretation of temporal expressions, e. g. by # otherefr ; # refr, suggests that many temporal [SEP]"}
{"pre": "in contrast, adding new features to some supervised systems # refr is easy, but the need of annotated data is a problem. [SEP] if they do", "cit": "# refr and taskar et al # otherefr represent alignments with several feature functions that are then combined in a weighted sum to model word [SEP]"}
{"pre": "we used the verbnet # refr to find the generalization properties of the lexeed. [SEP] frames. [SEP] text, which are annotated with [SEP] assumptions", "cit": "the number of decisions for each sentence is proportional to log2 in the length of the sentence # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we tune model weights using batch mira # refr for tuning and feature weights were tuned on the development set. [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "we use the moses smt framework # otherefr, and the batch version of mira for tuning # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "the first is the conditional maximum entropy of transcripts of # refr. [SEP] words, sentence, e. g. [SEP], sentence, sentence, sentence", "cit": "it has been successfully applied to single documents # otherefr ; # refr, and integer linear programming # otherefr, have been proposed [SEP]"}
{"pre": "# refr, for example, treat evaluation of machine translation systems by using single - word frequency instead of the original word ( the time ) to measure", "cit": "in a simpler approach, # refr use higher order rouge scores to approximate both content and linguistic quality. pyramid responsiveness features max min no. [SEP]"}
{"pre": "the model of # refrb ) can be seen as a generalization of the part of the head transducer of machine translation ( mt ) derivation # other", "cit": "the model is intended to combine the lexical sensitivity of n - gram models # otherefr without he computational overhead of statistical lexicalized treeadj [SEP]"}
{"pre": "english pos - tagging is a chinese chunking and word segmentation # refr. [SEP] this preprocessing step, in learning phrase structures. [SEP] [SEP] [SEP] [SEP]", "cit": "the chinese side of these two corpora were parsed using a constituency parser # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the algorithm has been applied to automatic acquisition of noun - noun co - occurrence pairs # refr, and the number of words in the same sentence,", "cit": "fortunately, using distributional characteristics of term contexts, it is feasible to induce part - of - speech categories directly from a corpus of sufficient size, [SEP]"}
{"pre": "there has been a lot of research in determining the sentiment of words and constructing polarity dictionaries # otherefr ; # refr. [SEP] this problem", "cit": "so far, however, this has only been applied to specific syntactic contexts # otherefr, or tasks # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the corpus has been part of speech tagged and lemmatized with stanford part - of - speech tagger # refr, and parsed with malt [SEP]", "cit": "from the annotated document, the plain tokenized text is extracted and analyzed by one or more of the following nlp tools : # otheref [SEP]"}
{"pre": "recent work by # refr, contrast, estimation methods still fall outside the set of estimation. [SEP] a latent variable model. [SEP] by em [SEP] a", "cit": "# refr train an unsupervised pos tagger using contrastive estimation, which seeks to move probability mass to a positive example e from its neighbors ( [SEP]"}
{"pre": "phrase - based models # refr are good at learning local translations that are pairs of ( consecutive ) units are words, as in the context - dependent", "cit": "it implements the phrase - based smt approach # refr and is based on local search, where a state consists of a full translation of a [SEP]"}
{"pre": "for instance, the information may be extracted by an information propagation method # refr, or automatically ( e. g., or carpenter [SEP] [SEP]", "cit": "cussens and pulman # otherefr describe a symbolic approach which employs inductive logic programming and # refr and fouvry # other [SEP]"}
{"pre": "# refr showed that constituency trees is important to get dependency trees with syntactic cohesion information. [SEP] the source language and the target language sentence. [SEP]", "cit": "for description convenience, we make use of the notion of spans # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "dependency parsing has been actively studied in recent years # otherefr ; # refr. [SEP] this work allows the use of a dependency parser. [SEP]", "cit": "# refr show how the dependency model from clark and curran # otherefr extends naturally to the partialtraining case, and also how to [SEP]"}
{"pre": "the first systems capable of automatically learning a small number of verbal subcategorization frames ( scfs ) from unannotated english corpora emerged [SEP]", "cit": "previous work while work has been done on various sorts of collocation information that can be obtained from text corpora, the only research that i am [SEP]"}
{"pre": "we extracted a general scfg # otherefr from the parallel corpus with a combination of several statistical machine translation systems # refr. [SEP] the [SEP]", "cit": "we exclude any unary rules # refr, and only keep rules that have scope up to 3 # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in fact, many approaches have been proposed that utilize unlabeled data ( e. g., # refr ), by incorporating the local context into the", "cit": "recent topic models consider word sequence information in documents # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr showed that a web corpus can be used to estimate the frequencies of vocabulary size and text. [SEP]. [SEP] documents per [SEP]. [SEP] the", "cit": "charikar # otherefr proposed an approximation of the cosine measure using random hyperplanes # refr used this cosine variant and showed it to [SEP]"}
{"pre": "the taggers are based on a maximum entropy markov model ( memm, see # refr for an overview ). [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "using an maximum entropy approach to pos tagging, # refr reports a tagging accuracy of 96. 6 % on the wall street journal. [SEP] [PAD] [PAD]"}
{"pre": "scfs can be used to represent the comlex syntax # otherefr, anlt # refr, and comlex # otheref [SEP] [SEP]", "cit": "scf frames the scfs recognized by the classifier were obtained by manually merging the frames exemplified in the comlex syntax # refr, anlt # [SEP]"}
{"pre": "in addition to domain mainstays such as support vector machines and maximum entropy models, we find increased application of joint models # otherefr [SEP]", "cit": "the features for this stage are primarily drawn from bjo? # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "bootstrapping techniques # otherefr, semi - supervised learning # refr, and unsupervised techniques # otherefr. [SEP] the training process of [SEP]", "cit": "in the wsd work involving the use of context, we can find two approaches : one that uses few strong contextual evidences for disambiguation purposes [SEP]"}
{"pre": "we use the illinois named entity tagger # refr to provide the part of speech tags for the english pos tagging. [SEP] features. [SEP] the current", "cit": "our baseline is slightly lower than that of turian et al. # otherefr, because they use the bilou encoding of ne types [SEP]"}
{"pre": "in the domain of syntactic parsing, the idea that a natural language processing technique has been applied to a wide variety of problems, including parsing, lexical", "cit": "for instance, # refr use explanation - based learning to specialize a given general grammar to a specific domain. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this has led to the development of various data - driven dependency parsers, such as those by yamada and matsumoto # otheref [SEP]", "cit": "in particular, many transition - based parsers # otherefr ; # refr are stack - based # otherefr, meaning that they [SEP]"}
{"pre": "in this paper, we show that the proposed parser is closely related to the task of word reordering # refr, which can be applied to our", "cit": "to improve such word reordering, one promising way is to separate it from the translation process as preordering # otherefr ; # refr [SEP]"}
{"pre": "sentence alignment was performed using the stanford word segmenter # refr in? ukb? en. [SEP]? [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "using the predictions of the english - spanish systems as pseudoreferences and likewise the original source as reference for the back - translation system we computed [SEP]"}
{"pre": "paraphrase extraction using a discriminative model trained on the entire bitext space can be extracted using features based on quasi - synchronous grammars # refr.", "cit": "both these systems reported results outperforming previous systems such as # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for example, # refr used a syntax - based system that allows a sentence to translate in english source. [SEP]. [SEP] it to capture long /", "cit": "in this work, we investigate the use of rule markov models in the context of treeto - string translation # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "to remove grammatical sentence, we employ the dependency parse tree generated by # refr. [SEP] the subtree of # otherefr. [SEP] the [SEP] [SEP]", "cit": "sentence compression produces a summary of a single sentence that retains the most important information while remaining grammatical # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "because such mert # refr tuning may be unstable for higher n, several methods were proposed where the n + 1 phrase tables are merged into [SEP]", "cit": "these methods are based e. g. on confusion networks # refr and joint optimization of word alignment, word order and lexical choice # otheref [SEP]"}
{"pre": "currently, the best - performing english np interpretation methods in computational linguistics focus mostly on two consecutive noun instances # otherefr, # refr, [SEP]", "cit": "this paper presents observations on our experience with an annotation scheme that was used in the training of a state - of - the - art noun phrase [SEP]"}
{"pre": "brent,! 991, 1993 ; # refr vary largely according to the methods used and the number of scfs being extracted. [SEP].", "cit": "brent,! 991, 1993 ; ushioda et al, 1993 ; briscoe and carroll, 1997 ; manning [SEP]"}
{"pre": "# refr describes a semi - supervised approach for generating word order languages by using a dependency representation of linear order. [SEP] a dependency structure for each word", "cit": "again, while the former is catered for in most tactical generation systems, only selected aspects of the latter have been dealt with and only [SEP]"}
{"pre": "in particular, we find that the set of n - best list can be found in the teli ~ e. g., by # refr", "cit": "assuming a first - order, partial - decomposition model of lexical semantics, as given in / # refr /, the translations for this class would [SEP]"}
{"pre": "this paper describes our coreference resolution system participating in the close track of conll 2011 shared task # refr. [SEP] this paper [SEP] [SEP] [SEP] [SEP]", "cit": "various different knowledge sources from shallow semantics to encyclopedic knowledge are being exploited # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the senselearner # otherefr, which has been used in the senselearner # refr project. [SEP] [SEP] [SEP] features [SEP]", "cit": "a different version of our own senselearner system # refr, using three of the semantic models described in this paper, combined with semantic generalizations [SEP]"}
{"pre": "we use crfs as well as a novel statistical machine learning problem # otherefr ; # refr. [SEP] this approach is [SEP] [SEP] [SEP] [SEP]", "cit": "a detailed description of crfs can be found in # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr use a sophisticated algorithm that improves the rte ( rte ) of short sentences. [SEP] contradictions ). [SEP] contradictions [SEP] well", "cit": "others have only earned very scarce and recent attention, like preconditions # otherefr and functionality # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr describe a system that combines visualnesss and lexical properties, and syntactic patterns in a text. [SEP] system. [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "the tuna challenges # refr are an exception ; participants were required to provide surface realizations, which were evaluated via nist, bleu and string [SEP]"}
{"pre": "we use a sentence alignment # refr since it is based on a direct comparison of two different paraphrases. [SEP] the algorithm of # otheref", "cit": "only those pairs identified as occurring in either training data or the corpus to be classified were included in the final classifier. operation | procedure operation | [SEP]"}
{"pre": "in addition, we show how this system can be trained on the same data ( in addition to the same manner, see # refr for a [SEP]", "cit": "it is worth noting that tetreault # otherefr discourse theory and veins theory # refr to identify and remove candidate antecedents that are [SEP]"}
{"pre": "# refr applied a supervised learning algorithm to classify noun phrases. [SEP] unarys and also developed a statistical system that learns semantic relation [SEP] system within", "cit": "kim and baldwin # otherefr and # refr focused on nominal relations in compound nouns. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in recent years, there has been a growing interest in the speculative aspect of biomedical language # otherefr ; # refr. [SEP] this approach [SEP]", "cit": "# refr started to do annotations on biomedicine article abstracts, and conducted the preliminary work of automatic classification for uncertainty. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this fact has given rise to a large body of research on unsupervised # otherefr, semi - supervised # refr, and transfer # otheref", "cit": "previous work has also described supervised and semi - supervised approaches to predicting inflectional morphology # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "for example, # refr proposed a method to extract keywords from a set of sentences and use it to compute sentence similarity to find the summary given sentences", "cit": "graph - based methods # otherefr ; # refrb ) have also been proposed to rank sentences or passages based on the pagerank algorithm [SEP]"}
{"pre": "we use a simple english predicate ( prop ) framework to evaluate our srl system, and ( ii ) # refr. [SEP] predicate / argument structures", "cit": "regarding the learning component of the systems, we find pure probabilistic models # otherefr, decision trees # refr, and support vector machines # [SEP]"}
{"pre": "in the graph - based setup, the projectivity and initializing the output of the conll 2009 # otherefr, a set [SEP] rich", "cit": "contrasting our models with the scores from mcdonald et al. # otherefr, we can see that they are comparable with some differences that are [SEP]"}
{"pre": "in the past, several years have witnessed the rapid development of robust statistical dependency parsing models # otherefr ; # refr, and [SEP] [SEP] [SEP]", "cit": "# refr were the first proposing to use deep networks for dependency parsing. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this model was later generalized by # refr, but it provides a complete solution. [SEP]. [SEP] features for this problem. [SEP] itg - based", "cit": "in each iteration, it considers all possible alignments for each pair of sentences, and 1these abstract notions ( lexical association, proximity, tendencies towards [SEP]"}
{"pre": "cross - lingual annotation projection # otherefr, dependency parsing # refr, semantic role labeling # otherefr. [SEP] the srl [SEP]", "cit": "the model performs argument identification and classification # refr separately in a pipeline? first each candidate is classified as being or not being a head of an [SEP]"}
{"pre": "the only statistical significance of the results was not by # refr. [SEP]. [SEP] the frequencies of verbs was encoded as follows : [SEP] the derivation [SEP]", "cit": "i followed # otherefr / # refr who defined selectional preference as the amount of information a verb provides about its semantic argument classes. [SEP]"}
{"pre": "in # refr, a mixture model was used to optimize the weights for the different feature functions. [SEP] the weights. [SEP] the weights in a log", "cit": "we differ from their work by using both the in - domain sourcelanguage corpus and its corresponding automatic translation for adaptation, which is shown in our [SEP]"}
{"pre": "for instance, moore and charniak # otherefr and # refr used the dependency structure for parse selection and error propagation. [SEP] ( 1", "cit": "we apply transform and join paradigms to grammar induction, an important problem of computational linguistics that involves notoriously difficult objectives # refr ; de marc [SEP]"}
{"pre": "in addition, while there has been much recent work on improving mert? s performance # otherefr ; # refr, their method may be", "cit": "there has been much work on improving mert? s performance # otherefr ; # refr, or on replacing mert wholesale # [SEP]"}
{"pre": "the conll - x shared task # refr. [SEP] a las of 87. 5 the sentences in the conll shared tasks on dependency parsing [SEP]", "cit": "this dependency parser has been shown to have state - of - the - art accuracy in the conll shared tasks on dependency parsing # refr3 [SEP]"}
{"pre": "this can be seen as an extension of the textual definition of collins? kernel # refr, or on the entire document set. [SEP] [SEP] [SEP] [SEP]", "cit": "for their extraction, we follow the feature design in # refr, using crf + + 5 with unigram / features and freebase as learning [SEP]"}
{"pre": "we chose support vector machines ( svms ) for our task, since they have shown good performance on a variety of natural language processing ( nlp", "cit": "for relations ( or pairs of words ), we employ and extend features in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in our experiments, we use the lemmatizer framework # refr and the czech - english - czech tagger # otherefr. [SEP] the", "cit": "section 3 introduces and evaluates some new variations of sempos ( kos and # refr, a metric based on the deep syntactic representation of the sentence [SEP]"}
{"pre": "most of the work in subjectivity detection has been based on word sequence labeling in multi - party dialogues # otherefr ; yu and #", "cit": "yu and # refr addressed three challenges in the news article domain : discriminating between objective documents and subjective documents such as editorials, detecting subjectivity [SEP]"}
{"pre": "for instance, # refr used the syntactic behavior of the charniak parser # otherefr. [SEP] ( gen ) [SEP] ( [SEP] [SEP] [SEP]", "cit": "their approach is closer to the unsupervised bilingual parsing model developed by # refr, which aims to improve monolingual performance. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper, we assume the socalled graph - based approach # otherefr ; # refr, and adopt the basic idea of [SEP] text", "cit": "in particular, # refr attempted to use a reinforcement approach to do keyword extraction and summarization simultaneously, on the assumption that important sentences usually contain [SEP]"}
{"pre": "supervised learning methods applied to verb classification and part - of - speech tagging # otherefr ; # refr. [SEP] a tagger [SEP] [SEP] [SEP]", "cit": "although these properties are redundant with the intransitive / transitive distinction, recent work in machine learning # otherefr ; # refr has shown that [SEP]"}
{"pre": "paraphrase generation can be used for parameter optimization using log - linear models, such as the log - linear model # otherefr, and", "cit": "paraphrases allow for more flexible matching of system output against human references for tasks like machine translation and automatic summarization # otherefr ; [SEP]"}
{"pre": "in 2008, the conll 2009 shared task on joint parsing and semantic role labeling, two tasks have been established to three such as sequential labeling #", "cit": "lately, predicate - argument structure analysis has been regarded as a task of assigning semantic roles of arguments as well as word senses of a predicate [SEP]"}
{"pre": "the only statistical pmcfg parsing algorithms # refr all use bottom - up parsing algorithms as a data - driven bottom - up parsing strategy. [SEP] the", "cit": "this is an extension of the algorithm by # refr to which we added statistical ranking. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "mira has been used in smt by # refr. [SEP] this method to efficiently optimize the feature weights for the first [SEP] features, except that", "cit": "recently, researchers have proposed a large number of additional features ( taro # refr and parameter tuning methods # otherefr which are better able [SEP]"}
{"pre": "evidence from the surrounding context has been used previously to determine if the current sentence should be subjective / objective # otherefr and adjacency pair information has", "cit": "observing the relations marked by annotators, we found that same covers not only identity, but also part - whole, synonymy, generalization [SEP]"}
{"pre": "this measure has been the ability to address the noisy channel issue by # refr. [SEP] the classification problem is the key to the general definition of log", "cit": "this type of evaluation is of some use when one is using mt to aid human translation ( although the relationship between number of edits and actual [SEP]"}
{"pre": "in # refr, a joint probability model is used, which is trained on the entire training set. [SEP] probability of phrases [SEP] the [SEP] probability of", "cit": "for example, # refr for a joint phrase based model, # otherefr for a complex model of insertion, deletion and head - word [SEP]"}
{"pre": "opinion mining spans a variety of subtasks including : creating opinion word lexicons # otherefr, identifying opinion expressions # refr, identifying opinion expressions", "cit": "the second dataset consists of 234 reviews for two different web - services collected from epinions. com, as described in # refr. [SEP] [PAD]"}
{"pre": "we compare our approach with that presented in # refr, a comparison of supervised probabilistic synchronous grammars, which have shown that learning a semantic parser [SEP] [SEP]", "cit": "semantic parsers map sentences to logical representations of their underlying meaning, e. g., zelle and mooney # otherefr, [SEP]"}
{"pre": "the approach of # refr falls outside the scope of this paper is based on the direct translation model 2the notion of transformation - based i. e", "cit": "system combinations by coupling mt systems serially or in parallel have been attempted before e. g. via hypothesis selection # otherefr or by statistical [SEP]"}
{"pre": "the data - oriented parsing ( dop ) # refr can be used to obtain the structural correspondence between any translation pairs of a node. [SEP] ( [SEP]", "cit": "in previous approaches to data - oriented translation ( dot : # refr ), such fragments were produced manually. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, we plan to use existing multilingual tools # refr, a natural language generation system that can generate natural language text from [SEP] text [SEP]", "cit": "the method was invented to meet the needs of applications using'wysiwym editing'# refr, which allow an author to control [SEP]"}
{"pre": "thus, the ability to distinguish different semantic relations is crucial if two relations should not explicitly signal the assumption that hold between two types are mutually salient [SEP]", "cit": "following the successful employment of linguistic features for various tasks # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the baseline tagger is a variant of the model that learns domain and parameters from the model trained on the same data, and the model [SEP] [SEP]", "cit": "in such cases, we must take steps to adapt a model trained on the source domain for use in the target domain # otherefr ; [SEP]"}
{"pre": "in particular, we are aware of several approaches for annotation projection # otherefr ; # refr. [SEP] the procedure proposed a feature set [SEP] [SEP]", "cit": "since a common ground for comparison is thus lacking we added a new, consistent tokenization based on the julie lab tokenizer # refrb [SEP]"}
{"pre": "the joint probability phrase - based model proposed by # refr provides a strong probabilistic framework consisting of phrase - based statistical machine translation ( smt ) systems", "cit": "most phrase - based translation models # otherefr ; # refr rely on a pre - existing set of word - based alignments from which they [SEP]"}
{"pre": "we used bleu # refr, ter # otherefr, which are the most widely used in smt systems. [SEP] the [SEP] [SEP] [SEP]", "cit": "the reordered sentence is then re - tokenized to be consistent with the baseline system, which uses a different tokenization scheme that is more [SEP]"}
{"pre": "we show that our models are very effective in producing question answering ( qa ) # refr. [SEP] this simple question classifier. [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "ted alignments given two predicates or arguments in two sentences, we attempt to align the two sentences they appear in using a tree edit distance ( ted [SEP]"}
{"pre": "therefore, phrase reordering modeling has attracted intensive attention in the past decade # otherefr ; # refr. [SEP] the relative frequencies [SEP] the [SEP]", "cit": "therefore, phrase reordering modeling has attracted intensive attention in the past decade # otherefr ; al - onaizan and # refr [SEP]"}
{"pre": "we tuned the feature weights on the wmt - 10 devset using mert # refr and evaluate on the test set. [SEP] [SEP] [SEP] [SEP]", "cit": "the latter are learned using a log - linear model with minimum error rate training # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the computational morphology of the computational linguistics literature has received considerable attention in computational linguistics, e. g., # otherefr ; gi # refr", "cit": "we also present empirical observations on the distribution of the syntax and meaning of noun phrases on two different corpora based on two state - of - the [SEP]"}
{"pre": "supervised semantic parsers # otherefr ; # refr rely on manual supervision for the target domain # otherefr. [SEP] natural [SEP] natural [SEP]", "cit": "many supervised learning frameworks have been applied, including inductive logic programming # otherefr ; # refr, machine translation - style synchronous grammars # other [SEP]"}
{"pre": "for instance, the em algorithm described in # refr is used to train the ibm model 1, and it on the hmm? ibm model? [SEP]", "cit": "implementing various alternative approaches from the literature, including ibm model 2 # otherefr, and smoothing # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "multilingual learning has been applied to a number of unsupervised and supervised learning problems, including word sense disambiguation # otherefr, and learning [SEP]", "cit": "multilingual learning has been applied to a number of unsupervised and supervised learning problems, including word sense disambiguation # otherefr, and morphological [SEP]"}
{"pre": "dependency trees are provided by the mst parser # refr. [SEP] if they use a graph - based parser fails to predict the entire [SEP] features of [SEP]", "cit": "in the conditional models of? 3 and? 6, these features are those of an edge - factored dependency parser # refr. [SEP] [PAD] [PAD]"}
{"pre": "we can find some other approaches that use finite state transducers # otherefr ; # refr. [SEP] the problem as a decision process problem. [SEP]", "cit": "knight and al - onaizan # otherefr studied wfst models in call - routing tasks, and # refr modeled phrase [SEP]"}
{"pre": "we also show how they had been used in the nlp community to automatically construct paraphrases and lexical resources for ir systems # otherefr", "cit": "in the context of ir, efforts have been made to use syntactic information to enhance retrieval # otherefr ; # refr, but not by [SEP]"}
{"pre": "# refr use a joint probability model for machine translation, but the use of a word as a phrase ( spe ) model. [SEP] a probability distribution", "cit": "a phrase - based smt system # refr was trained on the bitext. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "there have been a few previous attempts to solve the problem of unsupervised wsd # otherefr, # refr, and lin # other [SEP] [SEP]", "cit": "this can be done by smoothing the observed frequencies # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr present a method for finding proper noun phrases. [SEP] co - occurrence frequencies that is required to determine if a noun phrase is a noun phrase", "cit": "we have recently automated the process of verb? object pair acquisition from corpora for two types of cue phrases # refr and are planning on expanding this [SEP]"}
{"pre": "crowdsourcing can allow inexpensive and rapid data collection for various nlp tasks # otherefr ; # refr. [SEP] the data [SEP] training [SEP]", "cit": "crowdsourcing can allow inexpensive and rapid data collection for various nlp tasks # otherefr, including human evaluations of nlp systems # [SEP]"}
{"pre": "for chinese, we parse the chinese treebank # otherefr parser, and use the berkeley parser # refr. [SEP] [SEP] [SEP] annotations # [SEP]", "cit": "recently, # refr introduces an automatic hierarchical state - split approach to refine the grammars, which can alternately split and merge the basic nonterminal [SEP]"}
{"pre": "these publications were mostly dominated by rather heuristic methods and did not provide a theoretical analysis of the complexity of the decipherment problem : # other [SEP]", "cit": "these publications were mostly dominated by rather heuristic methods and did not provide a theoretical analysis of the complexity of the decipherment problem : # other [SEP]"}
{"pre": "we have already discussed in section 3 how to annotate human agreement with that looks for building dialogue output, for use of the general annotation scheme #", "cit": "we are fortunate to have access to a valuable corpus of 37 dialogues between nurses and patients, each comprising 200 - 1200 utterances # refr [SEP]"}
{"pre": "the constraints that we adopt the tree - based approach of # refr that is widely used in the sentence compression task. [SEP] text compression. [SEP] a", "cit": "english sentences are usually analyzed by a full parser to make parse trees, and the trees are then trimmed # otherefr ; # refr [SEP]"}
{"pre": "we use the same lexical substitution ( tsg ) task # refr, which is a lexical substitution task for disambiguating english lexical substitution. [SEP] [SEP]", "cit": "similar to the evaluation framework defined by? zbal et al. # otherefr english lexical substitution task # refr, where category si he [SEP]"}
{"pre": "entity coreference resolution is a well studied problem with many successful techniques for identifying mention clusters # otherefr ; # refr ; haghighi [SEP]", "cit": "as ( 1c ) shows, nps can also refer to events, and so corefer with phrases other than nps # refr. [SEP] [PAD] [PAD]"}
{"pre": "table 2 compares our results to the two feature sets, we used the malt - parser # otherefr, and the mst parser # refr.", "cit": "these approaches include techniques such as text pre - processing and normalization # otherefr, selectional preferences modelled from word co - occurrences obtained from [SEP]"}
{"pre": "# refr use document context profiles or concepts to determine the word of a sentence. [SEP] sentence. [SEP] text passages based on the [SEP] content they [SEP]", "cit": "prior research has demonstrated the usefulness of sentence extraction for generating summary text taking advantage of surface level features such as word repetition, position in text, [SEP]"}
{"pre": "the arabic text was preprocessed to produce two different transliteration systems, those of # refr. [SEP] the [SEP] characteristics of [SEP] [SEP]", "cit": "this generated a substring to substring translation model such as in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "several recent works # otherefr ; # refr explore using an external world context as a supervision signal for semantic interpretation. [SEP] sentences [SEP] [SEP] [SEP]", "cit": "although the numbers are not directly comparable due to different splits in the data7, we can see that with a similar number of logical forms for [SEP]"}
{"pre": "for instance, # refr found that the performance of parsers of the domain of parsers, and also show comparable performance on grammatical relations, but", "cit": "moreover, a given corpus might not always be as homogeneous as originally thought # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in # refr, we proposed an approach based on markov logic networks ( referred to as? event triggers to annotate? event annotations ), and", "cit": "such? how?? questions are common on faq websites # refr, which further supports the importance of process extraction. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "most previous work on normalization of social media text focused on word substitution # otherefr ; # refr. [SEP] the noisy non - standard [SEP] [SEP]", "cit": "# refr used an unsupervised noisy channel model considering different word formation processes. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper, we focus on the annotation of a particular treebank - style annotation (? ) which is defined in # refr. [SEP] the", "cit": "rebholz - schuhmann and # refrc ) did an intrinsic evaluation of the ssc where they created an 4http : / [SEP]"}
{"pre": "there has been a growing interest in corpus - based approaches which retrieve possible tags, related words are not available ( such as dictionaries ), and", "cit": "# refr learn a pos - for * in * rp jj nn cd # otherefr 1 ( 3 ) min 24, 730 gold [SEP]"}
{"pre": "the experiments reported in this paper use the english lfg grammar constructed as part of the xle system # refr. [SEP] ( a stochastic disambiguation", "cit": "this was done to some extent in # refr to automatically generate training data for the log - linear disambiguation component of xle. [SEP] [PAD] [PAD]"}
{"pre": "# refr. [SEP] integrating multimodal parsing on a finite state representation of the multimodal integration. [SEP] characteristics, e. g. [SEP] characteristics of multimodal expressions", "cit": "# refra proposes a modular approach to multimodal language processing in which spoken language parsing is completed before lnultimodal parsing. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "there have been many attempts to combine several aspects of scientific - intensive process, such as # otherefr ; # refr. [SEP] ( 1 )", "cit": "more recently contractor et al # otherefr have used automatically annotated argumentative zones # refr to guide the creation of extractive summaries of [SEP]"}
{"pre": "this work extends the basic probabilistic framework of synchronous grammars # otherefr ; # refr. [SEP] the noisy - channel framework [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "following previous works on semantic parsing # refr ; jones et al., 2012b ), we split the dataset into two portions. [SEP] [PAD] [PAD]"}
{"pre": "# refr used a thesaurus - based method for wsd in which the senses are four word - sense categories, but they [SEP] the [SEP]", "cit": "for example, # refr used a thesaurus to generate 1042 statistical models of the most general categories. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used the mxpost tagger # refr trained on english and the pos tagger for arabic, and we used a maximum entropy tagger for", "cit": "we then proceed to split the data into smaller sentences and tag them using ratnaparkhi? s maximum entropy tagger # refr. [SEP] [PAD]"}
{"pre": "morphological analysis or segmentation is crucial to the performance of several applications : machine translation # otherefr ; # refr ; habash and sadat [SEP]", "cit": "many researchers have tried to employ morphology in improving word alignment techniques # otherefr, among others, for various languages ; # refr, bo [SEP]"}
{"pre": "this algorithm exhibits a fundamental dvantage over supervised learning algorithms # otherefr, # refr, and lehman # otherefr ) [SEP]", "cit": "it assumes that nearby words provide strong and consistent clues to the sense of a target word, see # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "previous work has shown that multinomials are useful for text simplification and inference tasks # otherefr ; # refr. [SEP] text [SEP] text [SEP]", "cit": "similarly, but with a different focus, open ie, # refr, deals with a large number of relations which are not pre - specified. [SEP]"}
{"pre": "we parse the english documents using the stanford parser # refr. [SEP] english ( section 2 ). [SEP] the patterns to extract dependency relations [SEP] the [SEP]", "cit": "for the generation of the parse trees we used the stanford parser # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we evaluate our wsi system on the semeval - 2007 word sense induction task # refr. [SEP] the second [SEP] system of [SEP] 1 [SEP]", "cit": "the recent semeval wsi tasks # refr have provided a standard framework for evaluating wsi systems, with a controlled training corpus designed to [SEP]"}
{"pre": "in multi - document summarization, particularly along with multiple document summaries, such as biograph # otherefr, and [SEP] ( boy [SEP] [SEP]", "cit": "iii and marcu, 2006 ; # refr, inter alia ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for example, the cubic grandparent edges in second - order dependency parsing slow down dynamic programs # refr, belief propagation # otherefr, also", "cit": "we could also introduce new variables, e. g., nonterminal refinements # refr, or secondary linksmij # otherefr [SEP]"}
{"pre": "in the second wsd setting, the accuracy of a word w is found by # refr. [SEP] ( w ) = argmax ~ w (", "cit": "to further reduce the number of induced clusters, we applied a post - processing stage, which exploits the one sense per collocation property # refr [SEP]"}
{"pre": "in information extraction, for instance, dependency patterns have been used to extract relevant information from text resources # otherefr ; # refr. [SEP] [SEP]", "cit": "the summarizer uses the following features, as reported in previous work # otherefr ; # refra ) :? querysimilarity : [SEP]"}
{"pre": "# refr formulated an ilp model for jointly extract and showed that jointly extractions often use conditional random fields ( crf ) of opinion holders [SEP]", "cit": "sentiment - oriented relation extraction # refr is concerned with recognizing sentiment polarities and comparative relations between entities from natural language text. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr. [SEP] his constraint - based ( or semi - ) semantic disambiguation system includes a set of heuristic rules. [SEP] three types of relations", "cit": "arbiter pursues limited coordination identification i the spirit of # refr and rindflesch # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the only surface forms that are semantically morphological and disambiguation are mostly based on a ~ approximating distribution is are stated based on a set of error types", "cit": "3 3this is the reverse of # refr algorithm, where roots are matched before affixes. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used the berkeley aligner # refr to train the word alignment models. [SEP] the em algorithm of the berkeley aligner # otherefr [SEP]", "cit": "unsupervised methods have seen substantial reductions in alignment error # refr as measured by the now much - maligned aer metric. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in particular, intrinsic evaluations have been designed to evaluate the systems that run on the data set and the realization of referring expression generation ( reg ) [SEP]", "cit": "while these results differ from previous findings # refr, in which no significant correlations were found between extrinsic measures and automatic intrinsic metrics, it is worth [SEP]"}
{"pre": "ulc ( gim? nez and m? # refr is an aggregated metric that incorporates several semantic similarity features and shows improved correlation with [SEP]", "cit": "there was also work on explicitly evaluating mt adequacy with aggregated linguistic features ( gime? nez and ma ` # refr and textual entailment [SEP]"}
{"pre": "figure 1 : example of an example of structural n - gram language model for structural mt ( ebmt ), ( ebmt ), ( eb", "cit": "when one of the following conditions holds true for a linguistic phenomenon, rbmt is less suitable than ebmt. # otherefr ; # [SEP]"}
{"pre": "in this paper, we describe the system with which we participated in the? event extraction task, and the turku event extraction system [SEP] [SEP] [SEP]", "cit": "an overall notable trend was the use of full dependency parsing # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr applied a similarity measure to pp - attachments that can be defined by computing the distance between the sense of a lexical semantic similarity ( [SEP]", "cit": "it is worth mentioning that the idea of generating pseudo - synonyms could be seen as the opposite of the? pseudo - word? task used [SEP]"}
{"pre": "in this work, we compare the performance of bilingual dictionaries for domain adaptation # otherefr and the use of monolingual lexical features in a", "cit": "the work that is most closely related to ours is # refr, where a multilingual domain kernel is learned from comparable corpora, and subsequently used [SEP]"}
{"pre": "for instance, the syntactic relation between entities # otherefr ; # refr or the head of the head noun phrases # otherefr are [SEP]", "cit": "work has been done on detecting relations between noun phrases # otherefr, named entities # refr, and clauses # otherefr. [SEP] [PAD]"}
{"pre": "since the initial release of the penn treebank # otherefr ; # refr ). [SEP] a source sequence for non - projective japanese [SEP] [SEP]", "cit": "different ways have been proposed to deal with non - projectivity # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "lattice - based methods differ in the types of nodes ( words ) and edges represent many ) are distributed in the training corpus # refr. [SEP] [SEP]", "cit": "lattices are adopted also in chinese word segmentation # otherefr, decompounding in german # refr, and to represent classes of translation [SEP]"}
{"pre": "paraphrasing has been used in the past and several authors, e. g., # otherefr ; # refr. [SEP] this [SEP]", "cit": "currently not many resources are available for paraphrasing ; one example is the microsoft paraphrase corpus # otherefr ; # refr, [SEP]"}
{"pre": "this representation has been successfully applied to a number of tasks in nlp # otherefr and ir # refr. [SEP] this [SEP] [SEP] [SEP] [SEP]", "cit": "earlier work, # refr, proposed a method for inducing bilingual lexica using monolingual feature representations and a small initial lexicon to bootstrap with. [SEP]"}
{"pre": "in this work, we evaluate on the performance of the task of automatic gender identification, as well as a precision and recall of the rise [SEP] research", "cit": "cumulatively up to 20 % error reduction is achieved relative to the standard # refr algorithm for classifying individual conversations on switchboard, and accuracy for [SEP]"}
{"pre": "we used a simplified version of the conll 2007 shared task # refr. [SEP] a single model to a single dependency parser, a single [SEP] [SEP]", "cit": "recent work has successfully developed dependency parsing models for many languages using supervised learning algorithms # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used minimum error rate training ( mert ) # refr to tune the decoder for optimizing log - linear model parameters. [SEP]. [SEP]. [SEP]", "cit": "we carried out all our experiments using a state - ofthe - art phrase - based statistical english - to - japanese machine translation system # refr. [SEP]"}
{"pre": "in fact, several popular weakly supervised learning algorithms such as self - training # otherefr, co - training # refr, and integer [SEP] [SEP]", "cit": "anaphoricity ng and cardie # otherefra ) and # refr show that when used effectively, explicitly predicting anaphoricity can be [SEP]"}
{"pre": "in this paper, we selected because the summary of a discourse - reference resolution component, the senseval - 3 of the # refr and the results", "cit": "as a result, centering theory is best viewed as a cluster of theories, each of which specifies the parameters in a different ways : e [SEP]"}
{"pre": "the work by # refr is also in semantic role labeling # otherefr. [SEP] a flat classification scheme. [SEP] this [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "a lot of attention has been recently devoted to the design of systems for the automatic labeling of semantic roles ( srl ) as defined in two [SEP]"}
{"pre": "in # refr, noun phrase find thesaurus categories in the context of a syntactically noun phrases, while they use the backoff n -", "cit": "for example, in # refr clustering pp heads according to wordnet synsets produced only a 1 % improvement in a pp disambiguation task, [SEP]"}
{"pre": "metaphor identification has been studied under the framework of metaphor modeling # otherefr and metaphor detection # refr. [SEP] this intuition that a local [SEP] [SEP]", "cit": "since these compositions most frequently occur 2 # refr distinguishes between metaphor identification ( which she calls recognition ) and interpretation. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the xerox implementation of the machine translation system # refr can be described as finite - state transducer, as well as sets of - the formalism [SEP]", "cit": "algorithms which compile regular grammars into automata # otherefr ; grimley - evans, kiraz, and # refr do not make use [SEP]"}
{"pre": "in tempeval 2007, 2010 # otherefr ; # refr used maximum entropy models to predict the discourse relations. [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "for event - event tlinks, we also use tense / class / aspect match, tense / class / aspect bigrams as [SEP]"}
{"pre": "for chinese, we use the chinese parser of # refr for parsing sentences, a rule and a mechanism that is trained and a subset of [SEP] [SEP]", "cit": "in addition, we also included a feature template from # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this model outperforms a baseline model, which we use the model of # refr. [SEP] features, which only model of domains the? s letters,", "cit": "since words that occur once are likely to occur again # refr, the polya model is better suited to model the occurrences of words and users [SEP]"}
{"pre": "moving beyond directly related work, major themes in smt adaptation include the ir # otherefr ; # refr. [SEP] text # otheref [SEP]", "cit": "bss is related with instance weighting # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper, we evaluate the maxent aligner # refr and evaluate it on two tasks. [SEP] the [SEP] [SEP] [SEP] the [SEP] [SEP] [SEP]", "cit": "in our approach, the input sentences are first aligned using a modified version of a recent phrase - based alignment approach # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "consequently, accurate corpus annotation has been intensely investigated # otherefr ; # refr. [SEP] and hypertagging # otherefr [SEP] [SEP]", "cit": "thanks to automatic information extraction and semantic web efforts, keyword search over unstructured web text is rapidly evolving toward entityand type - oriented queries # other [SEP]"}
{"pre": "mcclosky et al. # otherefr report an f - score of 92. 1 % using selftraining applied to the rerank [SEP]", "cit": "the techniques examined are structural correspondence learning # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "these data - driven parsing approaches obtain state - of - the - art results on the de facto standard wall street journal data set # other [SEP]", "cit": "conducting a complete and faithful evaluation across languages would require a harmonized universal annotation scheme ( possibly along the lines of ( de marneffe [SEP]"}
{"pre": "we parsed the english portion of the corpus with the stanford parser ( de marneffe and # refr. [SEP] ( the [SEP] ) [SEP] [SEP]", "cit": "to obtain dependency trees, we passed the stanford constituency trees through the stanford constituency - to - dependency converter ( de marneffe and [SEP]"}
{"pre": "most of the research on automatically predicting sentence level either on the target language ( either for ), by using syntactic information, or both # refr [SEP]", "cit": "similar models have been successfully applied in the past to other tasks including parsing # otherefr, and machine translation # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "in this paper, we describe a method of centering theory which includes both of grammatical and lexical coherence, and resolution, using the subject of \"", "cit": "there are two advantages to this approach : first of all, agreement on the? building blocks? is much easier to reach than agreement on the [SEP]"}
{"pre": "we incorporate all our new features into a linear model # refr and train them using the linear model. [SEP] features of # otherefr. [SEP]", "cit": "here we take first steps toward such a? universal? decoder, making the following contributions : arbitrary feature model # otherefr ; # refr [SEP]"}
{"pre": "early systems used hand - crafted syntactic rules ; for example, # refr, to reorder the syntactic relations of the sentence [SEP] [SEP] [SEP]", "cit": "sentence simplification systems # refr are capable of compressing long sentences by deleting unimportant words and phrases. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr developed a system that uses morphological analyzers, and a set of heuristic rules for strings. [SEP] languages1. [SEP] languages1. [SEP]", "cit": "only very few approaches have addressed word internal variations # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used a multi - threaded version of the giza + + tool # refr. 1 this speeds up the process and corrects an [SEP]", "cit": "to automatically align the parallel corpora we used mgiza # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper, we follow the approach of # refr and apply a discriminative reranker to the training process. [SEP] a role in a [SEP]", "cit": "the release of semantically annotated corpora such as framenet # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the only difference between the accuracy of the parser on a sentence boundary is that signal or punctuation # otherefr ; # refr. [SEP] [SEP]", "cit": "the use of a rich set of contextual features is also the basic idea of the approach taken by # refr, who employ predicates capturing syntactic and [SEP]"}
{"pre": "a typical example of such knowledge has been shown to be well in information extraction systems # refr. [SEP] this approach is well suited to use [SEP] [SEP]", "cit": "while multiple machine learning approaches have been proposed for information extraction in recent years # otherefr, manually created regexes remain a widely adopted [SEP]"}
{"pre": "we use a linear model that is trained with the averaged perceptron algorithm # refr. [SEP] parameter averaging # otherefr. [SEP] ( 1 )", "cit": "the training is performed by a single generalized perceptron # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the latent variable approach of # refr is capable of learning high quality parses in the state of the art statistical parsing models that are conditional independence #", "cit": "system f1 # otherefr ( s. t. + combo ) 92. 62 # refr # otherefr ( combo [SEP]"}
{"pre": "in the case of dependency parsers, we explore the domain adaptation of the parser of charniak and johnson # otherefr [SEP] ( [SEP]", "cit": "semisupervised learning from partial annotations may be sufficient to learn complete parsers # refr.. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in fact, pos tagging has been demonstrated for increasing the amount of research on unsupervised pos tagging # otherefr ; # refr. [SEP] [SEP] [SEP]", "cit": "supervised learning of taggers from pos - annotated training text is a well - studied task, with several methods achieving near - human tagging accuracy # [SEP]"}
{"pre": "the verb classification task can be addressed by identifying verbs that are semantically typed in english \\ [ # refr \\ ]. [SEP] ( 5 ) [SEP] [SEP]", "cit": "the sampling error can be dealt with # refr but predetermined cutoff percentages stir require eye - bailing the data. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "tuning was performed using the mert implementation # refr with the default settings. [SEP] at. [SEP]. [SEP]. [SEP] versions of the document level #", "cit": "nevertheless, there are a number of techniques including mert # otherefr ; # refr, pro # otherefr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "in a theoretical framework, the nlg problem of non - deterministic decision making has been addressed from many different angles, including penman - style and", "cit": "u t te rances we have already mentioned that speech repairs constitute a good benchmark for studying the generation and cancellation of pragmatic inferences along sequences [SEP]"}
{"pre": "initially, ne classication centered on supervised methods, statistically learning from tagged corpora, using bootstrapping, # refr. [SEP] the method [SEP] [SEP] [SEP]", "cit": "multicategory bootstrappers, such as nomen # refr and wmeb # otherefr, reduce semantic drift by extracting multiple categories simultaneously in [SEP]"}
{"pre": "figure 1 : bootstrapping algorithm for responsebased life event identification. modeling # refr. [SEP] the relation extraction of regular expressions in a weakly [SEP] [SEP]", "cit": "also related approaches are distant or weakly supervision # refr that rely on available structured data sources as a weak source of supervision for pattern extraction from related [SEP]"}
{"pre": "in addition, the inclusion of contextual role knowledge in the resolution process requires relative pronouns in the documents, the resolution of candidate antecedents [SEP] by", "cit": "another source of inspiration is the work by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "paraphrase recognition is mostly understood as a feature representation, although the user? s answers are known to be inferred meaning of words that? words", "cit": "3note the incorrect presupposition in the cue provided by the instructor. machine translation evaluation # otherefr, paraphrase recognition ( e [SEP]"}
{"pre": "unsupervised phrasal itgs recently, phrase alignment with gibbs sampling # otherefr ; # refr, and parameter estimation with gibbs sampling # otheref", "cit": "unsupervised phrasal itgs recently, phrase alignment with itgs # otherefr ; # refr are popular. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "unification operations are based on the algorithms described in # refr and lefever and # otherefr. [SEP] unification. [SEP] [SEP] [SEP]", "cit": "this resulted in formalisms as, for example, # refr, # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the natural language toolkit # otherefr # refr. [SEP] the text t ( h i. e., a simple english [SEP] [SEP] [SEP] [SEP]", "cit": "each document was split into sentences using the punkt sentence tokenizer # otherefr in nltk # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the only difference is that we are aware of little or no nlp quality exploiting the output of a ccg parser # refr. [SEP] [SEP] [SEP]", "cit": "# refr and bodenstab et al # otherefr both extend this approach by classifying chart cells with a finer granularity. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "# refr addressed the problem of revising the scientific paper. [SEP] the citation context in citation context ; it has been studied in # otherefr", "cit": "previous work has shown the importance of citations in scientific domains and indicated that citations include survey - worthy information # otherefr ; # refr. [SEP]"}
{"pre": "in this paper we show that a ccg parser gives state - of - the - art results than # refr accuracy of disambiguation accuracy # other", "cit": "this leaves the parser the task of managing the very large parse space resulting from the high degree of lexical category ambiguity # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "the only sense of the collocations are abstracted by the application of multilingual lexical acquisition # refr. [SEP] the cluster based features [SEP] the cluster", "cit": "klapaftis & manandhar # otherefr 86. 4 hac 86. 0 cwu 85. 1 cww 84 [SEP]"}
{"pre": "# refr use ilp to incorporate local dependencies and global constraints. [SEP] the local context of sentences as features. [SEP] the same data they use [SEP]", "cit": "different features and classifiers have been explored for this task, such as bayesian method # otherefr, crf # refr, and recently reinforcement learning [SEP]"}
{"pre": "for instance, the field of natural language processing was developed, the first level that can be described in # refra ), [SEP], [SEP],", "cit": "the eu funded research project gemini ( generic environment for multilingual interactive natural interfaces ) aimed at the development of an application generation platform ( ag [SEP]"}
{"pre": "in this paper, we show that the model of # refr is intended to automatically construct a process imdb from a large lexical database. [SEP]ly", "cit": "these heuristics first consider concatenation operations, forming categories such as? np + v?, and then resort to ccg # refr style? sla [SEP]"}
{"pre": "in fact, one of the advantages of the noisy - channel approach is to rely on parallel corpora with a noisy channel model, and a model [SEP]", "cit": "li and # refr present methods that take advantage of monolingual distributional similarities to identify the full form of abbreviated chinese words. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "statistical techniques include estimated from the domain and the probability distribution of the estimated probability distribution p # otherefr, and the n - gram model #", "cit": "pereira & schabes 1992, # refr to infer a grammar over bracketed texts or to obtain maximum - likelihood estimates for a highly [SEP]"}
{"pre": "in this paper, we focus on the scenario of dependency treebank by annotating new syntactic parsing, as well as a resource for dependency analysis in", "cit": "this paper describes the critical challenges that a parser faces in q & a applications and reports on a number of extensions of a deterministic machine - learning [SEP]"}
{"pre": "in contrast, bilingual parallel data is in abundance and has been used in extracting paraphrases # otherefr ; # refr. [SEP] [SEP] [SEP]", "cit": "high - quality parallel data is essential for tuning and evaluating statistical mt systems, and it plays a role in a wide range of multilingual nl [SEP]"}
{"pre": "in this paper we show how the combinatory categorial grammar # otherefr and the tagger for german and english and the par [SEP] [SEP]", "cit": "the closest approach to tulipa corresponds to the semtag system13, which extends tag parsers compiled with dyalog with a semantic calculus module [SEP]"}
{"pre": "we used minimum error rate training # otherefr to optimize the feature weights for the log - linear model. [SEP] the bleu score # refr", "cit": "case - insensitive bleu4 # refr was used as the evaluation metric. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "to avoid the drawback, several linguistic clues, such as fine - grained classification of named entities and coordinated sentences, have been utilized # refr [SEP]", "cit": "examples in # otherefr ( 2 ) a. burst into tears? cried b. comfort? console # refr a number of [SEP]"}
{"pre": "the texts have been processed with the genia tagger # refr, a maximum entropy tagger trained on the entire training data. [SEP] [SEP] [SEP]", "cit": "although, to our knowledge, there currently does not exist an off - the - shelf named entity recogniser for german, we were able to [SEP]"}
{"pre": "lexical probabilities are computed in a sentence - by - length n - gram language model, and then rescoring n - gram word n ( c )", "cit": "we use a state - of - the - art phrase - based translation system as described in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "previous work has shown that citations in scientific domains and indicated that citations include survey - worthy information # otherefr ; # refr. [SEP] models #", "cit": "while past work has often focused on citation structure # otherefr ; # refr, our emphasis is on the text content, following ramage [SEP]"}
{"pre": "the system? s two main components draw on improved versions of a state - of - the - art srl system # refr [SEP] the [SEP] the", "cit": "in this work, we re - train an existing srl system ( bjo? # refr on product review data labeled with comparative predicates and [SEP]"}
{"pre": "we can use similarity measure introduced by # refr, though we can be compactly plugged in the same corpus. [SEP] the [SEP] [SEP] the [SEP]", "cit": "skew divergence the skew divergence, a variant of kl divergence, was proposed in # refr based on an insight : the substitutability of one [SEP]"}
{"pre": "in order to classify unknown words, # refr obtained an f - score on the 90 % of noun compounds from 86 % on the wall street journal", "cit": "4. 1. 4 distributional similarity since many recent methods for related tasks, such as noun classification, are based on so - called distributional similarity [SEP]"}
{"pre": "in # refr, we showed that humans can increase in personal email messages, an instance - specific emotion lexicon ( curr ) are not to measure [SEP]", "cit": "ing suicide notes # otherefr ; # refr. 1 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "examples are andersen # otherefr and # refr. [SEP] this approach performed against a set of classification ( foster and b ) [SEP] [SEP] [SEP] [SEP]", "cit": "for esl applications, this includes the detection of errors involving articles # otherefr ; # refr, verb forms # otherefr. [SEP]"}
{"pre": "in our work, we use the senseclusters corpus - based word ( wsi ) # refr and focus on the problem of learning [SEP] [SEP]", "cit": "most of the work in wsi is based on the vector space model, where the context of each instance of a target word is represented as [SEP]"}
{"pre": "another approach, which we may consider in the future, would be to annotate a small subset of the training examples with full ccg derivations [SEP]", "cit": "# refr present an algorithm that learns ccg lexicons with semantics but requires fully? specified ccg derivations in the training data. [SEP] [PAD] [PAD]"}
{"pre": "cross - lingual dependency parsing is the task of inferring dependency trees for observed sentences in a target language where there are few or no labeled training [SEP]", "cit": "cross - lingual dependency parsing is the task of inferring dependency trees for observed sentences in a target language where there are few or no labeled training [SEP]"}
{"pre": "in fact, the conll shared tasks on syntactic dependency parsing in 2006 and 2007 # refr, had been evaluated on both languages. [SEP] [SEP] [SEP]", "cit": "in particular, the conll shared tasks on dependency parsing have provided over twenty data sets in a standardized format # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "additionally, we used gold standard annotations for propbank - bank, and frame elements # refr. [SEP] the joint model of [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "other researchers have also looked at this subproblem # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in contrast, lexas uses supervised learning from tagged sentences, which is also the approach taken by most recent work on wsd, including # [SEP]", "cit": "other potential association measures are mutual information # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "there have been many studies on the automatic extraction of discourse relations ( e. g., # refr ), if any other anaphoric ( e", "cit": "on the other hand, this might be improved through further evidence in the form of entity chains, as explored earlier in # otherefr ; [SEP]"}
{"pre": "for example, pleonastic 2http : / / www. sf. icsi. com / m. com / m. edu / [SEP]", "cit": "a second line of work explores the use of distinct local models for different types of mentions, specifically for different types of anaphoric mentions [SEP]"}
{"pre": "syntax - based approaches such as # otherefr ; # refr heavily rely on the parse - tree to constrain the search space by assuming a [SEP]", "cit": "in # refr, hiero variables were disambiguated with additional binary feature functions, with their weights optimized in standard mer training. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "we use a hidden markov model ( hmm ) # refr. [SEP] the nes ) for recognition and training and is used to extract named entities [SEP] [SEP]", "cit": "frequently used techniques include hidden markov models # refr, maximum entropy models # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "liu and gildea # otherefr and # refr use input side srl to train a tree - to - string smt system [SEP]", "cit": "ulc ( gim? nez and m? # refr is an aggregated metric that incorporates several semantic similarity features and shows improved correlation with [SEP]"}
{"pre": "for example, the parser of charniak # otherefr had been applied to parsing time, and we use a fast as well as maximum", "cit": "while the modification given in section 2. 2 is specific to cyk parsing, we believe that placing restrictions based on the output of a chunk [SEP]"}
{"pre": "the texts were processed using the treex platform # otherefr1, e2, and the czech tagger # refr. [SEP] [SEP]a", "cit": "english sentences were analyzed using ( among other tools ) morce tagger # refr and maximum spanning tree parser. 2 the resulting deep syntactic # [SEP]"}
{"pre": "we build a neural network # otherefr ; # refr. [SEP] features sequence labeling # otherefr by using a neural network [SEP] features [SEP]", "cit": "wsabie # otherefr is a supervised embedding approach that has shown promise in nlp tasks # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr, bogutaev et al # otherefr. [SEP] the notion of valency is based on [SEP] the information of the verbs of", "cit": "recent work which aims to bring these three threads together in relation to the lexical representation of nouns includes \\ [ briscoe et ai., [SEP]"}
{"pre": "in nlp, kernel methods have been applied to tasks such as pos tagging # otherefr, syntactic parsing # refr, semantic role labeling [SEP]", "cit": "an alternative approach is to implicitly generate the whole feature space using tree kernels # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "most prior work on event extraction, e. g., # refr, uses ( 1 ) a combination of rule - based and a rule -", "cit": "specifically, # refr use eventbased features to represent sentences and shows that this approach improves the quality of the final summaries when compared with a baseline [SEP]"}
{"pre": "to evaluate the quality of spoken language understanding, we use the composite assessment tool # refr. [SEP] the sentence planning [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "while the approach has had considerable success in natural language generation # otherefr ; # refr, it often requires human labels on system output for [SEP]"}
{"pre": "we use mxpost tagger # refr and parsed with the log - linear model # otherefr. [SEP] the conditional generalized [SEP] [SEP] [SEP]", "cit": "both charniak # otherefr were trained using the goldstandard tags, as this produced higher accuracy on the development set than using # [SEP]"}
{"pre": "the use of graph modeling techniques has been extensively used in prior work on dialogue segmentation # otherefr ; # refr. [SEP] this [SEP] [SEP] [SEP]", "cit": "# refr specify a list of cue phrases by hand ; the cue phrases are used as a feature in a maximum - entropy classifier for conversation dise [SEP]"}
{"pre": "in isozaki? s work # refr, they adopted a root finder in their system to find the root word of the root node in", "cit": "a bottom - up algorithm proposed by # refr is use for a deterministic dependency structure analysis. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "many systems that deal with syntactic analysis have been developed # otherefr ; # refr. [SEP] this work only focused on the [SEP] effort [SEP] [SEP]", "cit": "many methods exist for clustering, e. g., # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "particularly, the latter made team? 09 task people reference faust? 12 - 3c # otherefr stanford 1 - - - - -", "cit": "particularly, the latter made team? 09 task people reference faust? 12 - 3c # otherefr concordu? 1 - [SEP]"}
{"pre": "with the emergence of the important role of word - to - word segmentation have been proposed # otherefr ; # refr, they are [SEP] [SEP]", "cit": "this allows the word segmentation problem to be modeled as a sequence labeling problem, and lends itself to discriminative sequence modeling techniques # otherefr [SEP]"}
{"pre": "we can use features derived from syntactic trees in order to support vector machines, e. g. # otherefr ; # refr. [SEP] the", "cit": "for example, all possible sub - trees can be used as features # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in dependency parsing, good solutions for semantic role labeling is crucial to many natural language processing tasks, such as syntactic parsing # otherefr [SEP] [SEP]", "cit": "we consider the dependency - based version of semantic role labeling as described in # refr and transfer an srl model from one language to another. [SEP]"}
{"pre": "we rescore the first 1000 - best hypotheses with mbr, taking the negative sentence level bleu score as the loss function # refr. [SEP]", "cit": "another example is minimum - bayes - risk decoding # refr, where, assuming f? defines a probability distribution over all candidates, one seeks the [SEP]"}
{"pre": "language understanding has been well studied in the context of question / answering # otherefr ; # refr, machine translation # otherefr. [SEP]", "cit": "a few unsupervised approaches exist # otherefr ; # refr, but these are specific to translating language into queries in highly structured database and cannot [SEP]"}
{"pre": "in the second experiment, the output is aligned ( the berkeleylmanno ) # refr, and the? b n [SEP] [SEP] [SEP] ( [SEP]", "cit": "we first evaluate bagel using the bleu automated metric # refr, which measures the word n - gram overlap between the generated utterances and the [SEP]"}
{"pre": "we use the suffix array grammar extraction # otherefr and suffix array extraction # refr. [SEP] this toolkit. [SEP] via parallel training [SEP] [SEP] [SEP]", "cit": "the joshua 1. 0 release also included re - implementations of suffix array grammar extraction # refr and minimum error rate training # otherefr [SEP]"}
{"pre": "as an alternative to automatic alignment, # refr find that a system trained on data, is not a. [SEP] ( source text ). [SEP] [SEP]", "cit": "such a parallel data - text resource could then be used to train an existing data - to - text generation system, or even to build a [SEP]"}
{"pre": "4see, for example, andry et al # otherefr on compilation, # refr on coding dags, duda & ge [SEP]", "cit": "following ltag conventions # otherefr, # refr, cahill & : evans # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use a conditional markov model tagger # otherefr and a conditional markov model ( cmm ) # refr with the character - level conditional", "cit": "while it is not directly obvious that there is much information in these truncated substrings, character n - grams have successfully been used for finegrained [SEP]"}
{"pre": "two approaches have emerged to alleviate the problem of da - english parallel data scarcity : using msa as a bridge language # otherefr ; # [SEP]", "cit": "there has been a number of efforts on dialect identification # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the nonparametric bayesian model of # refr, pitman - yor process # otherefr. [SEP] this problem [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "one of the first bayesian pos taggers is described in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "dependency relations have been widely adopted in nlp relation extraction systems such as shallow parsing # otherefr ; # refr. [SEP] this [SEP] [SEP] [SEP]", "cit": "finally, semantic annotators, such as lund # refr and swirl # otherefr, add roles to each node in a parse [SEP]"}
{"pre": "the beam search algorithm improves parsing flexibility in deterministic parsing # otherefr ; # refr, and dynamic programming # otherefr showed that, [SEP]", "cit": "this procedure is known as? arc - standard? # otherefr ; # refr, which is more complicated and less similar to the classical [SEP]"}
{"pre": "# refr describe a method for extracting translation pairs from german to english. [SEP], but is a form of the basic [SEP]. [SEP] the [SEP] the", "cit": "there is a growing body of work on the use of syntax for improving statistical machine translation, from approaches such as # otherefr on the [SEP]"}
{"pre": "statistical parsing models have recently been developed for combinatory categorial grammar # otherefr ; # refr ; hockenmaier and steedman", "cit": "like the models of goodman # otherefr, the additional features in our model are generated probabilistically, whereas in the parser of # [SEP]"}
{"pre": "in particular, we assume that the system is trained on the basis of production systems # otherefr ; # refr ; the [SEP] - [SEP] [SEP]", "cit": "indeed, implementing the translation might require as much effort as would be required to build a simple custom generator ; cf. # otherefr ; [SEP]"}
{"pre": "model parameters that maximize the loglikelihood of the training data are computed using the log - linear model # refr. [SEP] ( 1 ) gradient descent [SEP]", "cit": "the model parameters,? u, are estimated using numerical optimization methods # refr to maximize the log - likelihood of the training data. [SEP] [PAD] [PAD]"}
{"pre": "we use a variant of the synchronous tagger of # refr. [SEP] a tag derivation tree adjoining grammar derived from a training synchronous tag.", "cit": "indeed, some work generated paraphrases using ( non - probabilistic ) synchronous grammars # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the case of english, # refr found that a morphological learner might be useful for the acquisition of phonemes in the lexicon. [SEP] [SEP] [SEP]", "cit": "here, we follow # refrb ) in using a linguistically and statistically controlled method, starting from audio recordings and using a standard hidden markov [SEP]"}
{"pre": "in this experiment, we used the n - gram word form of the english lexical substitution system # refr. [SEP]. [SEP] it [SEP] [SEP] [SEP] [SEP]", "cit": "under the provided scoring metrics, two consistently high - performing systems in the semeval 2007 evaluations are the ku # otherefr and unt [SEP]"}
{"pre": "to classify words, we assigned a word w and cluster on the words appearing in the target expression, using the backoff and the backoff [SEP]", "cit": "limitations of handcrafted thesauri can be summarized as follows \\ [ # refr ; uramoto, 1996 ; hindle, 1990 \\ [SEP]"}
{"pre": "the xtag system # refr provides a phrase structure parser for english, and a number of hand - written rules, to convert traces into [SEP] [SEP]", "cit": "even the xtag grammar # refr, which deals with the major constructions of english in enviable detail, does not offer a full analysis of [SEP]"}
{"pre": "previous work on verb classification has discussed the use of features for various nlp tasks # otherefr ; # refr. [SEP] the [SEP] the [SEP]", "cit": "other work in automatic lexical semantic lassification has taken an approach in which clustering over statistical features is used in the automatic formation of classes # other [SEP]"}
{"pre": "# refr presented an answer extraction algorithm for answer summarization that change from the dbnsom. [SEP] ( social media is likely to [SEP] [SEP] [SEP]", "cit": "in email summarization field, the qa pairs are also extracted from email contents as the main elements of email summarization # refr. [SEP] [PAD] [PAD]"}
{"pre": "we trained the model using the averaged perceptron # refr. [SEP] ( 5 ) =??? k ( k ) log [SEP] ( the )", "cit": "in this work, we focus on an alternative training approach using the averaged perceptron algorithm of # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr. [SEP]. [SEP] a l ( g ) d ) d. [SEP] a l i l i l i l j [SEP] it d.", "cit": "as is true for many other grammar formalisms in which there is a derivation / parse distinction, an alternative to finding the most probable parse is [SEP]"}
{"pre": "we present a novel approach for sentiment classification based on ideas from distributional similarity # otherefr ; # refr. [SEP] kernel # otherefr further", "cit": "we have not seen recursive neural networks ( rnn ) applied to qa yet, but socher has developed applications to paraphrase # refr [SEP]"}
{"pre": "mcccj the bllip parser # refr, also variously known as the charniak parser, the charniak - johnson parser, [SEP]", "cit": "although all systems perform syntactic analysis of input texts, there is a fair amount of variety in the applied parsers, which include the parser of [SEP]"}
{"pre": "to avoid this problem, many smoothing techniques have been proposed for enriching # otherefr, and semantic parsing # refr. [SEP] the [SEP] [SEP]", "cit": "we calculate this likelihood by cs / ( cs + cn ) where cs 5all string matching steps have been implemented using the simstring string retrieval [SEP]"}
{"pre": "on the other hand, it is hardly possible to ignore non - projective structures completely, given that 25 % or more of the sentences in some [SEP]", "cit": "as shown by # refr, the second phase of pseudo - projective dependency parsing can be interleaved with the first, by replacing the usual one [SEP]"}
{"pre": "this has led to considerable interest in learning contextual information, in particular # refr ; we show that this topic can learn [SEP] [SEP] linguistic knowledge [SEP] [SEP]", "cit": "# refr use a technique based on cca and alignments to project monolingual word representations to a common vector space. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, we use a simple distance reordering model # otherefr, which is a monotonic language model to predict the output of a large", "cit": "alternatively, one can define models that assign a cost to the relative position of each pair of words in the sentence, and search for the sequence [SEP]"}
{"pre": "parsing technologies have improved considerably in the past few years, and high - performance syntactic parsers are no longer limited to pcfg - based frameworks [SEP]", "cit": "# refr investigated the impact of parsing accuracy on statistical mt. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr presented a new framework that combines the scores of a pair of sentences with their shallow syntactic and lexical features to incorporate various semantic information. [SEP]", "cit": "the method shows considerable improvement over the baseline as measured by bleu scores and stanford? s entailmentbased mt evaluation metric # refr ). [SEP]"}
{"pre": "thus, we assume that the environment chooses a set of unnatural is not an important step in many cases, a separate class [SEP] research [SEP] [SEP]", "cit": "the only work described in a recent review # otherefr as completely unsupervised? the grasp model # refr? does attempt to induce syntax from [SEP]"}
{"pre": "statistical approaches to sentence planning and lexical substitution have been explored # otherefr ; # refr. [SEP] this problem by learning a re - implemented [SEP]", "cit": "# refr use a cost matrix and decision theoretic principles to optimise turn - taking in a dialogue system under the constraint that users prefer no gaps [SEP]"}
{"pre": "opinionfinder # refr for opinionfinder. [SEP] english ( unigram ) is a lot of research in which two [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "there has been a large and diverse body of research in opinion mining, with most research at the text # otherefr, sentence # refr [SEP]"}
{"pre": "in contrast, classifiers for text classification, support vector machines # otherefr ; # refr. [SEP] features sequence labeling # otherefr [SEP] [SEP]", "cit": "they later applied a series of text normalisations and n - gram feature selection algorithms to improve performance # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr presented a method that uses corpus of news articles annotated with their literal and figurative language. [SEP] features. [SEP] features [SEP] the properties", "cit": "in recent years, the computational linguistics community has seen substantial activity in the detection of figurative language # refr one aspect of which is the [SEP]"}
{"pre": "the resulting english corpus is parsed using a state - of - the - art statistical parser # refr. [SEP] the information of the penn [SEP] [SEP]", "cit": "textcap first uses the domain - independent charniak parser # refr to convert sentences in the source document into a sequence of syntactic parses [SEP]"}
{"pre": "these include multiple translations of the same text # otherefr ; # refr. [SEP] distributional similarity scores factor relative to each other h is used for", "cit": "these include large monolingual texts # otherefr ; # refr, comparable corpora # otherefrb ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "edits # otherefr ; # refr have recently been applied to esl learners such as article edits, and turn - taking [SEP] [SEP]", "cit": "based on an automatic classification using the model presented in our previous work # refr, we excluded edits classified as vandalism, revert [SEP]"}
{"pre": "# refr used a kernel to estimate the dependency relations between named entities. [SEP] sentences. [SEP] kernel trees, which they exploit the dependency trees [SEP] [SEP]", "cit": "while many supervised machine learning approaches have been successfully applied to the rdc task # otherefr ; # refr, few have focused on weakly [SEP]"}
{"pre": "in particular, we use the subjectivity clues defined in # refr as the syntactic dependency structure of the sentences. [SEP] the documents we add a [SEP]", "cit": "wilson et al # otherefr subjectivity clues, gathered from three sources ( # refr ; # otherefr and the general inquire [SEP]"}
{"pre": "in addition, infobox could be applied to identify mentions, as shown in figure 1. 3 specifically, we are disambiguating [SEP] [SEP] [SEP]", "cit": "previous work has used various ml approaches for ranking, such as svms # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the work of # refr is the main reason that it is that it is much easier to learn, but which is the one of the three stages", "cit": "bos # otherefr, # refr, pinkal # otherefr ) and as such hold a promise for incremental semantic interpretation. [SEP] [PAD]"}
{"pre": "we evaluated translation quality using uncased bleu # refr and ter # otherefr. [SEP] the former subsection by the word error rate ( wer", "cit": "we adopted the case - insensitive bleu - 4 # refr as the evaluation metric, which uses the shortest reference sentence length for the brevity [SEP]"}
{"pre": "the first, f, e, f, f, f, f, f, f, f2, f2s, and score of", "cit": "for example, # otherefr ; # refr for chinese and english, the shortage of manually wa corpora has recently been relieved by the [SEP]"}
{"pre": "multi - document summarization has been successfully used in information extraction # otherefr, and sentiment summarization # refr. [SEP] [SEP] [SEP] [SEP] text", "cit": "finally, # refr describe non - lexical word - frequency features, similar to our ratio features ( f. 4? f. 7 ), [SEP]"}
{"pre": "with linear run - time complexity, they were commonly regarded as a faster but less accurate alternative to graph - based chart parsers # otheref [SEP]", "cit": "by comparing the results in table 5 and the results in table 6 we can see that the semi - supervised features achieve an overall improvement of 1 [SEP]"}
{"pre": "we used the stanford dependency parser # refr for the experiments. [SEP] analysis of which is based on the stanford dependency representation # otherefr. [SEP]", "cit": "three dependency parsers were used for these experiments : minipar3 # otherefr and the stanford5 parser # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "crowdsourcing services such as amazon mechanical turk has been used for various nlp tasks in natural language processing # otherefr ; # refr.", "cit": "# refr found in their own mechanical turk system that the workers who contributed more tended to show lower quality, 2 3 4 0. 2 0 [SEP]"}
{"pre": "the classification steps of most approaches vary in the choice of the classifier # otherefr, maximum entropy classification # refr, svm classifiers # other [SEP]", "cit": "rahman and ng # otherefr, # refr ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, seeds are used for extracting instances of semantic relations # otherefr, ( gi # refr, and relation extraction # otheref [SEP]", "cit": "manually selected seeds can also be used # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, we use a pos tagger # otherefr and the stanford pos tagger # refr. [SEP] his tagger [SEP] [SEP] [SEP]", "cit": "in contrast, some temporal taggers were recently made available, e. g., dante # otherefr, tipsem # refr [SEP]"}
{"pre": "subjective expressions are words and phrases being used in a sentence semantics # otherefr ; # refr. [SEP] subjectivity analysis [SEP] ( e. g", "cit": "# refr constructed a highprecision classifier for contiguous sentences using the number of strong and weak subjective words in current and nearby sentences. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "we use the joshua decoder # refr to get an english translation. [SEP] - japanese translation. [SEP] translation. [SEP]. [SEP] the link grammar.", "cit": "synchronous tree adjoining grammars ( tag ) ( shieber and # refr are a good candidate. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the recent work of # refr supervised learning of coreference resolution, using features of the mentions to the mention of the mention of the mention [SEP]", "cit": "it is well known that muc by itself is insufficient because it gives misleadingly high scores to the? single - chain? system that puts all [SEP]"}
{"pre": "we used yamcha # refr as a text chunker, which is based on svm and uses polynomial kernel functions. [SEP] features. [SEP] features [SEP]", "cit": "we use tinysvm2 along with yam - cha3 # otherefr # refr as the svm training and classification software. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "to measure the degree of semantic equivalence, we use the cosine similarity, and the kullback - leibler measure # refr. [SEP] [SEP] [SEP] [SEP]", "cit": "we compare the algorithm with state - of - the - art algorithms, including locality sensitive hashing # refr and divideskip # otherefr [SEP]"}
{"pre": "we used the first 125 retrieval conferences ( see section 4 ) 1 ) 1 for the evaluation of our previous work # refr. [SEP] [SEP] [SEP] [SEP]", "cit": "we use an xml schema called scixml ( first introduced in # refr ) that we extend to include images. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for this reason, we use an online learning algorithm and its efficient implementation # refr. [SEP] kernel # otherefr. [SEP] the structured perceptron", "cit": "mira is a very popular method in the nlp community and has been applied to nlp tasks like word segmentation and part - of - [SEP]"}
{"pre": "in contrast, other approaches # refr, employ a rhetorical structure theory # otherefr to decide which segments are passed to the rhetorical goals", "cit": "as for any generated text, a good summary also requires a text plan # refr # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, before the conll - 2012 shared task, there has been a lot of work on the performance of coreference resolution using the stanford", "cit": "for example, # refr compare four state - of - the - art systems on three different corpora and report b3 scores between 63 and 77 [SEP]"}
{"pre": "in general, the substitutions reported on the precision for quantifier scoping # refr makes the link to the effect of an underspecified model on", "cit": "section 6 discusses the relationship between monotonic interpretation, pereira is categorial semantics # refr, and context change approaches to semantics. [SEP] [PAD] [PAD]"}
{"pre": "there are two main approaches to dependency parsing : maximum spanning tree # otherefr ; # refr. [SEP] 1 [SEP]? [SEP]? [SEP]? [SEP]", "cit": "according to bohnet? s report # refr, a fast featuregenerationtemplate : p. word + p. pos0 0 feature : [SEP]"}
{"pre": "paraphrase acquisition is mostly done at the sentence - level, e. g., # otherefr ; # refr, which is [SEP]", "cit": "finally, the developed paraphrase collection will be attested through applications, such as sentence compression # refr and machine translation # otherefr [SEP]"}
{"pre": "# refr use svms to tag these noun phrases. [SEP] a statistical model that learns reordering probabilities in a stochastic chunk. [SEP] back [SEP] decision", "cit": "in particular, boosting # otherefr ; # refr offers the possibility of achieving high accuracy from a collection of classifiers which individually perform quite poorly [SEP]"}
{"pre": "in addition, several researchers have shown that the automatically acquired paraphrase generation task # otherefr ; # refr can be used to perform sentence", "cit": "zhao et al # otherefra ) enrich this approach by adding multiple resources ( e. g., thesaurus ) and further extend [SEP]"}
{"pre": "in the past, only reranking on k - best lists was proposed by # refr. [SEP] non - projective dependency parsing # otherefr", "cit": "# refr used a re - ranking scheme to provide global features while we simply augment the features of an existing parser. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the classification approach has been used to deal with the most common grammatical mistakes made by esl learners, such as article and preposition errors # other", "cit": "the choice of learning algorithm for each classifier is motivated by earlier findings showing that discriminative classifiers outperform other machine - learning methods on error correction tasks # [SEP]"}
{"pre": "in this paper, we use svms # otherefr and a probabilistic model which is a widely used method for training and evaluation. # refr", "cit": "among a number of existing categorization methods, we experimentally used one proposed by # refr, which formulates p ( c | d ) as in [SEP]"}
{"pre": "we evaluate our proposed model with the coreference resolution evaluation metrics that were used in the conll shared tasks on coreference resolution # otherefr", "cit": "both parameters were empirically adjusted on the development set for the evaluation measure used in this shared task : the unweighted average of muc # other [SEP]"}
{"pre": "in the japanese, several groups have been proposed on the source side # otherefr ; # refr. [SEP] this approach by translating the source [SEP]", "cit": "to resolve this problem, we have proposed a paraphrasing approach in which the utterances are automatically paraphrased prior to transfer # otheref [SEP]"}
{"pre": "we parse the chinese sentences with the berkeley parser # refr and use the split - merge parser4. [SEP] the berkeley parser # otherefr [SEP]", "cit": "although these approaches can improve the performance of basic probabilistic context free grammar # otherefr ; # refr that perform significantly better than the baseline pc [SEP]"}
{"pre": "in addition to srl, there has also been some work on using the propbank and nombank annotations # otherefr ; # refr.", "cit": "to alleviate this dependence, previous work has explored k - best parsers # refr, combination systems # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for example, the parser of # refr was used to obtain the information on the linguistically relevant words. [SEP] the collins parser # otherefr", "cit": "an architecture which fulfills this requirement is weighted constraint dependency grammar, which was based on a model originally proposed by # refr and later extended with [SEP]"}
{"pre": "finally, we use pos features to parameterize a distortion model in a limited distortion decoder # refr. [SEP] bleu on a 2 - parameter [SEP]", "cit": "# refr use it for their bold updating strategy to update discriminative feature weights. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "id participant cmu carnegie mellon university # otherefr cu - bojar charles university - bojar # refr cu - dep [SEP]", "cit": "some of these features made use of additional data and / or resources, such as a secondary id participating team prhlt - upv universit [SEP]"}
{"pre": "we use the rst discourse treebank ( rst - dt ) # refr, which is a sublanguage space of 2 - 3 analysis. [SEP] discourse", "cit": "the data that we use to develop and evaluate our discourse parser is the rst discourse treebank ( rst - dt ) # refr, which is [SEP]"}
{"pre": "functions for simple phrases directly map distributional vectors of words to distributional vectors for the phrases # otherefr ; # refr. [SEP] the phrases # other", "cit": "functions for simple phrases directly map distributional vectors of words to distributional vectors for the phrases # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "morphological features : automatically extracted tokenized tokens # otherefr ; # refr. [SEP] the word identities # otherefr are [SEP] [SEP] [SEP] [SEP]", "cit": "another approach we will also focus is dividing words into characters and applying character - level models # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the regular tree tagger described in # refr. [SEP]. [SEP] a l, in order to determine the class of weighted finite - state", "cit": "it corresponds to a set of weighted rewrite rules # otherefr ; # refr learned from the alignment. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the ibm models, the ibm models # otherefr and the ibm models # refr for models ( 6 ) are unsupervised [SEP] [SEP] [SEP] [SEP]", "cit": "since the original ibm paper, there has been a large amount of research exploring the original ibm models and modern variants # otherefr ; # [SEP]"}
{"pre": "monolingual distributional similarity is widely known to conflate words with opposite meaning and has motivated a large body of prior work on antonym detection # [SEP]", "cit": "# refr attempts to improve the ranking by limiting paraphrases to be the same syntactic type. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "then the labeled data is used to train the classification model, which is finally used to classify unseen test data # refr. [SEP] [SEP] [SEP] [SEP]", "cit": "# refr propose another way of incorporating unlabeled data. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, before the unsupervised pos induction task, the system of # refr has been an active research topic for combining and a number of unsupervised [SEP]", "cit": "in one strand of this work, annotations are assumed only in a resource - rich language and are projected onto a resource - poor language using the [SEP]"}
{"pre": "previous idiom detection systems fall in one of two paradigms : phrase classification, where a phrase p is always idiomatic or literal, e. [SEP]", "cit": "for instance, shutova et al # otherefr, and # refr detect verb / noun idioms ( blow smoke ). [SEP] [PAD] [PAD]"}
{"pre": "in addition, we show that the discriminative model ( e. g., # refr ) can be used to improve the performance of a discriminative model", "cit": "in addition, feature - based integration has been used by # refr, who trained a discriminative word alignment model using features derived from the ibm models [SEP]"}
{"pre": "much research effort has been made to address the transliteration issue in the research community # otherefr ; # refr ; hermjakob [SEP]", "cit": "much research effort has been made to address the transliteration issue in the research community # otherefr ; # refr ; hermjakob [SEP]"}
{"pre": "in contrast, the work of # refr, we presented a statistical and machine learning approach for this task. [SEP] a maximum entropy framework. [SEP] [SEP]", "cit": "extraction of entities and their relationships is usually done in a pipelined system that first identifies entity mentions, next resolves mentions into unique [SEP]"}
{"pre": "in addition to the textual similarity task ( sts ), we used an approach similar to the one introduced by # refr. [SEP] [SEP] [SEP] the [SEP]", "cit": "motivated by the recent work on semantic textual similarity # refr, we use as model features a series of similarity measures based on word overlap and semantic [SEP]"}
{"pre": "in this work, we use the sentiment polarity ( annotated ) tool ( e. g., # refr, and ( 2 ) of [SEP] [SEP]", "cit": "so far, we focused on adjectives as sentiment indicators, however, there have been studies showing that other parts of speech can be very helpful [SEP]"}
{"pre": "among others, multilingual content synchronization has been recently proposed as an ideal framework for the exploitation of clte components and the integration of semantics and [SEP]", "cit": "in line with a number of systems that model the rte task as a similarity problem ( i. e. handling similarity scores between t and [SEP]"}
{"pre": "assessing the quality of a learning algorithm? s output and selecting high quality instances has been addressed for supervised algorithms # otherefr and and and and", "cit": "many nlp systems use the output of supervised parsers # otherefr for qa, # refr for ie, # otherefr for [SEP]"}
{"pre": "we follow the framework of # refr, who propose three different feature types to use the knowledge of the predicate coreference model. [SEP] [SEP] the [SEP]", "cit": "that way we try to overcome the plateauing in performance in coreference resolution observed by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used the holmes system # refr. [SEP] textual entailment # otherefr. [SEP] textual entailment # otherefr used [SEP] inference [SEP]", "cit": "while many approaches have addressed this problem, our work is most closely related to that of # otherefr ; # refr, which convert the [SEP]"}
{"pre": "in our experiments, we use the corpus created by # refr. [SEP] documents ( 1 ), a. [SEP] ) of documents, we [SEP] [SEP]", "cit": "there has been a thriving cottage industry adding more and more information to topic models to correct these shortcomings ; either by modeling perspective # other [SEP]"}
{"pre": "on both efficiency and statistical grounds, much recent tsg work has focused on fragment selection # otherefr ; # refr. [SEP] [SEP] [SEP] [SEP]", "cit": "in the domain of syntactic parsing, the idea that all training fragments1 might be relevant to parsing has a long history, including tree - substitution [SEP]"}
{"pre": "# refr have used a similar approach to translate unknown words that occur in the training corpus. [SEP] it as shown in such [SEP] ( [SEP] [SEP] [SEP]", "cit": "first, it is known that the domain and genre can influence mt performance # refr, so we wanted to control the set of genres. [SEP]"}
{"pre": "# refr used a graph - based model for unsupervised part - of - speech tagging, and performed pos tagging using cross - lingual [SEP] the tag", "cit": "# refr instead of the feature - hmm for pos induction on the foreign side. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "kernel functions are very effective at modeling diverse linguistic phenomena by implicitly representing data in high dimensional spaces, e. g. # otherefr ; [SEP]", "cit": "more recently, kernel functions, which implicitly represent data in some high dimensional space, have been employed to study and further improve many natural language systems [SEP]"}
{"pre": "to obtain entailment relationships for predicates, previous work has focused on the problem of learning entailment rules # otherefr ; # refr. [SEP]", "cit": "thus, acquisition of such knowledge received considerable attention in the last decade # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this binarization is done in a similar way to johnson # otherefr and # refr. [SEP] the problem of pcfg [SEP] [SEP] [SEP]", "cit": "ing a dependency parser2 # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "however, it is more difficult to prove our approach # refr. [SEP] this system that uses a log - linear model, in which the decision space", "cit": "# refr used inside - outside unsupervised learning algorithm to augment the rules for finding heads, and achieved an improved lr / lp of 78. 8 [SEP]"}
{"pre": "we follow a standard log - linear approach to disfluency detection, as described in # refr. [SEP] # otherefr. [SEP] [SEP] [SEP]", "cit": "# refr found that the occurrence of disfluencies that had been removed could be predicted to a satisfactory degree. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, entity linking # otherefr and determine the relationships between bioene named entities # refr. [SEP] features [SEP] the link between name [SEP]", "cit": "while recent research has used nil features to determine whether they are being asked to link an entity not in wikipedia # otherefr ; # refr [SEP]"}
{"pre": "we use semcor # refr, a balanced, semantically annotated dataset, with all content words manually tagged by trained lexicographers [SEP] [SEP] [SEP] all", "cit": "one of the first large scale hand tagging efforts is reported in # refr, where a subset of the brown corpus was tagged with wordnet july [SEP]"}
{"pre": "web - based semantic class lexicons have been successfully used to extract common nouns in a variety of natural language processing # otherefr, [SEP] [SEP]", "cit": "there has also been work on fully unsupervised 1meta - bootstrapping # otherefr ; # refr ), however clustering methods may or [SEP]"}
{"pre": "we evaluated the translation quality using case - insensitive bleu metric # refr. [SEP] bleu # otherefr on the iwslt05 [SEP]", "cit": "the quality of the translation output is evaluated using bleu # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "metaphor identification has been done using different approaches : violation of selectional preferences # otherefr, and lexical relations in wordnet # refr. [SEP]", "cit": "a second general approach to the binary classification problem has been to use mismatches in properties like abstractness # otherefr, semantic similarity ( li [SEP]"}
{"pre": "while there has been substantial progress in improving the performance of subcategorization frames ( e. g., # refr, charniak [SEP] [SEP]", "cit": "while there has been substantial previous work on the task of sf acquisition from corpora # refr ; manning # otherefr, amongst others ) [SEP]"}
{"pre": "while such data contains noise, it has been shown to be useful in practice # refr. [SEP] documents ( ace ), [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "following traditional approaches, we employ a linearchain crf # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, feature - based approaches have been proposed that mainly differ in feature engineering ( in feature structure ), feature - based approaches have also been", "cit": "the kinds of non - linear effects common in semitic languages, where vowel and consonant patterns are interpolated in words # otherefr ; # [SEP]"}
{"pre": "transliteration methods typically fall into two categories : generative approaches # otherefr that try to produce the target transliteration given a source [SEP]", "cit": "transliteration methods typically fall into two categories : generative approaches # otherefr ; # refr that try to produce the target transliteration [SEP]"}
{"pre": "f1 measure of # refr and f - score is commonly used in compress systems. [SEP] the compression rate training. [SEP] [SEP] [SEP] [SEP] [SEP] to", "cit": "a notable exception is sentence compression for which end - to - end rewriting systems are commonly developed # otherefr ; # refr. [SEP] [PAD] [PAD]"}
{"pre": "in particular, the maxent model is defined by the probability of a candidate antecedent for each mention # otherefr ; # refr [SEP] [SEP] [SEP]", "cit": "model parameters were estimated with the limited memory variable metric algorithm and gaussian smoothing # otherefr, using tadm # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "# refr extended this approach to the other hand - crafted hpsg grammar for english and to the more fine - grained grammar. [SEP]", "cit": "several partial parsing strategies have been proposed # refr as the robust fallbacks for the parser when no available analysis can be derived. [SEP] [PAD] [PAD]"}
{"pre": "the classification of sentences is well - studied in the tradition of error detection # otherefr, detecting decisions over a noun phrase [SEP] [SEP] [SEP] [SEP]", "cit": "prior work indicates that three aspects of article quality can be successfully predicted : a ) whether a text meets the acceptable standards for spelling # [SEP]"}
{"pre": "the model of # refr makes use of probabilistic content. [SEP] with a related model for identifying descriptions of objects. [SEP]y [SEP]y [SEP], [SEP]", "cit": "# refr proposes to introduce probabilities to overcome uncertainties due to discrepancies in knowledge and cognition between subjects. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper, we show that the proposed algorithm is inspired by the easy - first parsing algorithm # otherefr ; # refr. [SEP] [SEP]", "cit": "in this paper, we implement our approach based on graph - based parsing models # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in particular, we focus on the syntactic of a particular syntactic tree kernel # refr. [SEP] a subtree, which is a property of the structural [SEP]", "cit": "in this paper, we carry out tree kernel engineering # refr to increase both accuracy and speed of the boundary detection and argument classification phases. [SEP] [PAD]"}
{"pre": "it has been shown that an additional layer of the ranking perceptron algorithm # refr is an extension of moses # otherefr. [SEP] (", "cit": "moreover, our ranking model is related to reranking # refr in smt as well. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "morphological analyzers for english, noun - verb lexicons, are represented as finite state morphology # refr. [SEP] the morphological analyzers [SEP]. [SEP]", "cit": "to distinguish nouns from other words, the university of pennsylvania morphological nalyser ( described in # refr was used to generate the set of words [SEP]"}
{"pre": "we used the automatically constructed case frames from 4 billion web # refr. [SEP] the british national corpus, which contains japanese, as a case frames for", "cit": "we proposed a method to construct a japanese case frame dictionary automatically by arranging large volumes of parse results by coupling a verb and its closest case [SEP]"}
{"pre": "8the n - best feature extraction already uses relative counts # otherefr 90. 1 s # refr 90. 1 s # otherefr", "cit": "in contrast to that line of work, we also do not restrict ourselves to working with kbest output, but work directly with a packed forest [SEP]"}
{"pre": "sentence alignment # otherefr ; # refr is a scenario of natural language generation from multiple news summarization. [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "msa is commonly used in bioinformatics to identify equivalent fragments of dnas # otherefr and has also been employed for learning paraphrases # [SEP]"}
{"pre": "we follow the standard approach of # refr, using a hidden markov model ( hmm ), ( hmm ), ( hmm - ), which we", "cit": "this task goes beyond named entity recognition ( e. g., # refr ) because it requires the recognition of role relationships. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "in this paper, we first take a different approach, in which the context of semantic textual similarity ( sts ), we obtained the top 3 [SEP]", "cit": "the best performing systems were ukp # otherefr, takelab (? # refr mean = 0. 6753 and soft cardinality # [SEP]"}
{"pre": "the corpus - based method we used was first described in # refr. [SEP] the former # otherefr. [SEP] the expressions of the [SEP] [SEP]", "cit": "most studies focus on extracting parallel sentences from noisy parallel corpora or comparable corpora, such as bilingual news articles # otherefr ; # refr, [SEP]"}
{"pre": "the bayesian framework put in this paper extends this idea to our inference while most work in itg grammar induction # otherefr ; # refr,", "cit": "another strand of related research is in estimating a broader class of synchronous grammars than itgs, such as scfgs # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "we used the wordnet : similarity package # refr to calculate the similarity score between a sentence. [SEP]. [SEP] the wordnet similarity [SEP] [SEP] [SEP]", "cit": "we measure semantic similarity using the shortest path length in wordnet # otherefr as implemented in the wordnet similarity package # refr. [SEP] [PAD]"}
{"pre": "unsupervised induction of semantics has also been studied in # refr and titov and klementiev # otherefr but the induced representations are related", "cit": "the relations represent clusters over strings of words # otherefr, or logical expressions # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used minimum error rate training ( mert ) # refr to tune the feature weights for the log - linear model. [SEP] ( 1 ).", "cit": "giza + + was used for word alignment # refr and phrase translations of up to 10 words are extracted in the moses phrase table. [SEP]"}
{"pre": "iii and marcu # otherefr, # refr ). [SEP] this framework. [SEP] a large number of coreference / machine learning [SEP] features", "cit": "motivated in part by # refr, we create cluster - level features from the relational features in our feature set using four predicates : none, most [SEP]"}
{"pre": "in addition, according to their frequency, the probability of a noun phrase that occur with certain linguistic properties ( cf. \\ [ # refr \\ ]", "cit": "a more statistically oriented approach is undertaken in # refr where a methodology for syntactic recognition of complex nominals is described. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper, we focus on the role of the proposition bank # otherefr ; # refr. [SEP] features [SEP] this technique [SEP] [SEP] [SEP]", "cit": "many researchers have investigated applying machine learning to corpus specifically annotated with this task in mind, prop - bank, since 2000 # otherefr ; [SEP]"}
{"pre": "several researchers have proposed normalization # otherefr ; # refr. [SEP] this problem by learning simple heuristics. [SEP] the posterior probability of each [SEP] [SEP]", "cit": "most current approaches emphasize within - sentence dependencies such as the distortion in # otherefr, and syntax mappings in # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "we use the bidirectional model of # refr. [SEP] a distortion limit of two adjacent phrases, we incorporate some form of reordering [SEP] a distortion limit", "cit": "we train model weights discriminatively using minimum error rate training ( mert ) # refr, optimizing f - measure. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this system translates each new token by the fact that the system can be evaluated by the following the fact that they are particularly stable [SEP] the [SEP] [SEP]", "cit": "the bleu scores # refr measured on sytem100, system200, system300 are respectively 65. 45, 65. 82 and 65 [SEP]"}
{"pre": "among the various models for tagging, there are maximum entropy models # otherefr ; # refr. [SEP] ( 97. 15 % ) [SEP] [SEP]", "cit": "among the various models for tagging, there are maximum entropy models # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we show how nivre? s # otherefr, mstparser # refr, mstparser # otherefr. [SEP]. [SEP]", "cit": "following # refr, we present an application of a maximum spanning tree algorithm for a directed graph to non - projective labeled dependency parsing. [SEP] [PAD] [PAD]"}
{"pre": "several projects # otherefr ; # refr have explored learning of spoken dialogue tutoring spoken dialogue tutoring systems # otherefr. [SEP] this", "cit": "for the last decades, intelligent tutoring systems # otherefr ; # refr, computer sciences # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "finally, our work is related to question answering ( qa ), where presented a question generation task is presented in # refr. [SEP] ( [SEP] [SEP]", "cit": "one approach for generating comparable questions would be to employ traditional question generation, which syntactically transform assertions in a given text into questions # otheref [SEP]"}
{"pre": "in the unsupervised evaluation setting, the system outputs are compared by using metrics v - measure # refr and v - measure # otherefr. [SEP]", "cit": "these include variation of information # otherefr, v - measure # refr, and their respective variants nvi # otherefr. [SEP] [PAD]"}
{"pre": "we use the stanford pos tagger # refr to obtain the perspectives p and l. [SEP]. [SEP]. [SEP] a 97. [SEP] a word sequence", "cit": "in the semantic structure extraction system, we used the stanford part - of - speech tagger # refr to tag the training and test sentences and [SEP]"}
{"pre": "in order to make the search tractable, the feature set needs to be restricted to features over single edges ( i. e., nonprojective", "cit": "we used the pseudo - projective transformation introduced in # refr to cast non - projective parsing tasks as projective. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "there have been many studies on fine - grained opinion mining, e. g., # otherefr ; # refr. [SEP] text spans", "cit": "they simply choose the nps in a product review as the product attribute candidates # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "interestingly, recent works # refr have shown that such systems can be efficiently trained under indirect and imperfect supervision and hence scale nlp tasks # other [SEP]", "cit": "while it has been shown that paraphrasing methods are useful for question answering # refr and relation extraction # otherefr, this is, [SEP]"}
{"pre": "such pos tagging work has been plentiful and includes efforts to induce pos tags without labels # otherefr, incomplete dictionaries # [SEP]", "cit": "early work showed much promise for this strategy # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we start from 2 training instances ; results were the same or slightly better with 10 or 100 instances. work has also focused on projecting syntactic annotations [SEP]", "cit": "the information needed to resolve coordinate np ambiguity cannot be derived from hand - annotated data, and we follow previous work in looking for new information sources [SEP]"}
{"pre": "in works such as # otherefr ; # refr, reordering decisions are done? deterministically?, thus placing these decisions outside the [SEP]", "cit": "by contrast, other studies # otherefr ; # refr are more in the spirit of psmt, in that multiple reorderings are [SEP]"}
{"pre": "distributional thesauri have been used in a wide variety of areas including sentiment classification # otherefr, predicting semantic relations # refr, and syntactic", "cit": "thus, the ability to distinguish different semantic relations is crucial if approaches to the composition of distributional representations of meaning that are currently receiving considerable interest # [SEP]"}
{"pre": "# refr use a log - linear model to define a probability distribution over word alignments. [SEP] a log - linear model. [SEP] the probability of phrases", "cit": "recently, several successful attempts have been made at using supervised machine learning for word alignment # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the only broad coverage statistical parsers # otherefr ; # refr is a probabilistic lfg grammar, but also the representation of the sentences being", "cit": "this paper builds on a growing body of work which goes beyond # otherefr, # refr, rimell et al # otherefr [SEP]"}
{"pre": "we used bleu # refr, ter # otherefr to evaluate the translation quality. [SEP] the current automatic evaluation metric, bleu # [SEP]", "cit": "we evaluated our augmented model by comparison with dependency - to - string model and hierarchical phrase - based model on chinese - to - english translation in [SEP]"}
{"pre": "the senses of subjectivity in word sense disambiguation was proposed by # refr. [SEP] a cross - lingual model in both word sense disambig [SEP]", "cit": "subjectivity at the word sense level has been discussed by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this approach is inspired by the semi - supervised approach of yarowsky # refr, which learns a fixed set of words that are part - of", "cit": "the bootstrapping methods for language independent ner of # refr have a similar effect. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "al has already been applied to several nlp tasks, such as document classification # otherefr, named entity recognition ( ner ) # refr,", "cit": "examples of al used in language engineering include named entity recognition # otherefr ; # refr, text categorization # otherefr. [SEP] [PAD] [PAD]"}
{"pre": "in order to make different natural language processing tasks be able to help each other, jointly modeling methods become popular recently, such as summarization techniques #", "cit": "many approaches use a variety of graph clustering algorithms for wsi : others # refr use hierarchical agglomerative clustering on hierarchical random graphs created from [SEP]"}
{"pre": "in this paper we show that the use of stag - style synchronous tree - adjoining grammars # otherefr for stags and the", "cit": "martin and vere # otherefr established the first connections between the two traditions ; also # refr and maletti # otherefr [SEP]"}
{"pre": "leaves of fragments can be terminals, synchronous grammars, and tree substitution grammars # otherefr ; # refr. [SEP] the derivation forest in a log", "cit": "in addition to being motivated by rule - based systems, we also see advantages to english syntax within the statistical framework, such as marrying [SEP]"}
{"pre": "the second method is inspired by work in parser combination, an idea that has been applied successfully several times and relies on the fact that different parsing [SEP]", "cit": "in this work, f1, f2, and fs are identical : all of them correspond to the feature set described by # refr. [SEP]"}
{"pre": "iii and marcu, 2004 ; giuglea and moschitti, 2004 ; toutanova et al, 2004 ; kaz [SEP]", "cit": "iii and marcu, 2004 ; giuglea and moschitti, 2004 ; toutanova et al, 2004 ; kaz [SEP]"}
{"pre": "in the rst bank, the rst discourse treebank ( pdtb ) were developed by # refr. [SEP] the annotation scheme of [SEP] [SEP] [SEP] [SEP]", "cit": "another research line is to use humanannotated corpora as training data, e. g., the rst bank # refr used by # [SEP]"}
{"pre": "in addition to the standard ( sections 3 ) senseval - 3 ) dataset, we compare our system with the stanford tagger # refr. [SEP]", "cit": "relations and pos tags are obtained using a dependency parser tratz and hovy # otherefr, supersense tags using sstlight # refr [SEP]"}
{"pre": "for experiments on the test set, we show that the models trained on the wsj corpus ( section 22 7 ) wsj [SEP] 9 [SEP] 9", "cit": "supervised training methods already applied to pp attachment range from stochastic maximum likelihood # refr or maximum entropy models # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "there have been several proposed measures for the automatic acquisition of semantic relations between nouns # otherefr ; # refr. [SEP] the patterns [SEP] [SEP] [SEP]", "cit": "following # refr, the fh and fc thresholds were set to 1000 words per million ( upper bound for fc ) and 100 words per million ( [SEP]"}
{"pre": "in addition, we also investigate the use of the system of # refr, which was the first step and we evaluated on two new lexical sample tasks", "cit": "the state - of - the - art supervised wsd methodology, reporting the best results in most of the senseval - 3 lexical sample tasks [SEP]"}
{"pre": "in the area of the monolingual parallel corpora, monolingual comparable corpora have been used to provide paraphrase extraction # otherefr, sentence", "cit": "the current research emphasis is on automatically learning paraphrases from comparable or aligned corpora # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, before the annotation of text, the tarsqi model # refr goes semi - automatic annotation of 22 of causality. [SEP] [SEP] [SEP]", "cit": "table 2 : inter - annotator agreement by task. linked causally in wordnet ( gi # refr were used to collect examples for annotation [SEP]"}
{"pre": "we show that the mstparser # refr is a non - projective solution, again, again show that any task of a sentence pair of both", "cit": "we use an online learning framework called mira # refr for training a discriminative model for the word alignment task # otherefr. [SEP] [PAD] [PAD]"}
{"pre": "bruce and wiebe also performed a separate test by using a subset of the \" interest \" data set with only 4 senses # otherefr [SEP]", "cit": "yogi = sw ( w, ) ( 5 ) wiedef the salient word vector ( swv ) for a word contains a saliency weight [SEP]"}
{"pre": "this is the case for minimum error rate training # refr, except that the ibm model 4, except that it supports traditional discriminative training, and achieves", "cit": "due to scalability issues, most of these recent methods can only train on a small dev set of about a thousand sentences rather than on the full [SEP]"}
{"pre": "the model scaling factors? 1,..,? m? m? 1, n? 1, n? 1, n? 1,", "cit": "recently so - called reranking techniques, such as maximum entropy models # otherefr and gradient methods # refr, have been applied to [SEP]"}
{"pre": "the simplest of these # refr make no use of a syntactic hierarchy to increase the precision of the precision grammars, whereas jaist # otheref [SEP]", "cit": "hierarchical phrases # refr are encoded in a tree structure just as linguistic trees. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "much of the work done well at the automatic acquisition of social media is that of conversational behavior, e. g., # refr, [SEP]", "cit": "lexical formality is obviously related to lexicon - based readability # otherefr, and is also relevant to the recent interest in identifying social [SEP]"}
{"pre": "li and # refr, and brill # otherefr present a probabilistic model for learning the dependencies between prepositions. [SEP] bilexical", "cit": "thus, our proposed method can in effect wouldiscover'implicit word senses fi'om corpus data. and methods of resolving ambiguity are also [SEP]"}
{"pre": "we also compare with # refr and moschitti # otherefr, as well as features for information extraction tasks [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "we carried out 5 - fold cross - validation with the tree kernel toolkit4 # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in smt, the lm probability p # otherefr and daum # refr defined over the document to separate process. [SEP] the cross -", "cit": "to exploit topic information for statistical machine translation # otherefr ; # refr to improve translation quality. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper, we compare two document summarization tasks, and compare two approaches : sentence compression approaches to sentence compression and sentence compression # otheref", "cit": "a few researchers have focused on other aspects of summarization, including single sentence ( knight and # refr, paragraph or short document ( da [SEP]"}
{"pre": "the n - gram based mt system combination software was bleu # refr, ter # otherefr. [SEP] the bleu score [SEP] [SEP] [SEP]", "cit": "the minimum operation used to compute the clipped counts ( matches ) in the bleu score # refr was replaced by a differentiable function, so [SEP]"}
{"pre": "the morphological analysis itself has been part - of - speech tagging and lemmatized with stanford tagger # otherefr ; # refr. [SEP] [SEP]", "cit": "0. 4 # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the chinese penn treebank # otherefr has seen a lot of research efforts # refr, and recently # otherefr. [SEP] the latter", "cit": "to see which tagging confusions contribute to which error reductions, we adapt the pos ablation approach of # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper, we use a topic signatures # refr. [SEP] a topic signatures built from the repository of topic signatures of tsf. [SEP] [SEP]", "cit": "topic signatures ( ts ) are word vectors related to a particular topic # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this is similar to the concept of decision lists as described in # refr. [SEP] the text is represented by a maximum entropy classifier. [SEP] [SEP] [SEP]", "cit": "concepts do not have to be directly observable as text snippets? they can represent abstract properties that particular text units may or may not satisfy [SEP]"}
{"pre": "in this paper, we focus on the task of identifying political speech, as well as non - native english speakers of the task # refr. [SEP]", "cit": "another recent stylometric experiment in automatic identification of deception was performed by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, we show translation features based on a phrase - based system # otherefr to deal with reordering as implemented by [SEP] [SEP] [SEP]", "cit": "there are additional variants, such as the maximum jump d strategy ( mjd ), a polynomial - time strategy described by # refr, and [SEP]"}
{"pre": "in order to make the sentence ordering task of sentence ordering a document from the document to its ( or ) - based content - bearing sentences that can", "cit": "modeling ordering constraints sentence ordering has been extensively studied in the context of probabilistic text modeling for summarization and generation # otherefr ; # refr [SEP]"}
{"pre": "we used the model defined by # refr and sun et al # otherefr to learn the clustering of the mentions. [SEP] entities [SEP] for", "cit": "similar models have been used to learn subcategorization information # refr or properties of verb argument slots # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "our scfs can be used as a source of features regarding the subcategorization frames # otherefr ; # refr. [SEP] the scfg", "cit": "most existing systems rely on handwritten rules # refr or simple cooccurrence statistics # otherefr applied to the grammatical dependency output of supervised statistical [SEP]"}
{"pre": "to address this problem, we extend the general subjectivity of the document ( su and # refr to be independent emotion categories ), by [SEP] it", "cit": "voll and taboada # otherefr show that adjective - based sentiment classification is improved by examining topicality ( whether each sentence is [SEP]"}
{"pre": "for french, german, italian and german analyses of a constituency treebank # otherefr, which allows a lexicalized parser to be split", "cit": "for spanish and french, it was shown by cowan and collins # otherefr and in # refr, that restructuring the treebanks [SEP]"}
{"pre": "minimum error rate training # refr is a common method for optimizing a model parameters of translation quality. [SEP] it produces a comparison of translation quality, [SEP]", "cit": "many state - of - the - art machine translation # otherefr ; # refr rely on several models to evaluate the? goodness? of [SEP]"}
{"pre": "in addition, we computed the following bleu score # otherefr, a set of translation edit rate ( 2 ), [SEP] the [SEP] [SEP]", "cit": "this approach was recently re - implemented and extended by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "nivre? s parser has been tested for swedish # otherefr, english # refr, czech # otherefr. [SEP]. [SEP] [SEP]", "cit": "multilingual parsers of participants in the conll 2006 shared task # refr can handle japanese sentences. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "other metrics are based on computing the precision, e. g., bleu # otherefr, nist # refr, ter # otheref", "cit": "initial motivation for this work comes from developing the king alfred translation environment # refr supporting students of anglo - saxon english translating sentences into [SEP]"}
{"pre": "in contrast, most previous work on semi - supervised learning approaches for relation extraction include # otherefr, # refr, # otherefr.", "cit": "talukdar et al # otherefr and # refr present graph - based approaches to the similar problem of class - instance learning. [SEP] [PAD]"}
{"pre": "numerous studies are concerned with feature extraction, typically trying to enrich the classifier with more linguistic knowledge and / or more world knowledge # otherefr [SEP]", "cit": "this second step is typically achieved using greedy heuristics # otherefr ; ng and # refr, although more sophisticated clustering approaches have been used, [SEP]"}
{"pre": "we used a paired bootstrap test # refr to calculate the expected bleu score of the translated german metric. [SEP] the hypothesis exactly once the [SEP] [SEP]", "cit": "on this task we only tested our submodular function that worked best on the statistical significance was measured using the paired bootstrap resampling test of [SEP]"}
{"pre": "in addition, we also show that the parser of # refr can be applied to english, as well as a french - english parser. [SEP] it", "cit": "ptb parser we use for comparison is the publicly available berkeley parser # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this study, we show that the reported character - level ( f ) can be obtained by automatically acquired from corpora ( e. g.,", "cit": "later people came to realize that indexes are often multi - word terms and their generation might involve more elaborated syntactic analysis on phrasal or sentential [SEP]"}
{"pre": "this procedure is repeated the average f - score of the entire text. 8 of the vocabulary ( normalized ) # refr. [SEP] text [SEP] the [SEP]", "cit": "this optimization problem can be solved using one of many unsupervised segmentation approaches # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the google web 1t 5 # otherefr 5 - gram lm # refr to store the zero - cutoff stupidbackoff #", "cit": "research groups # refr have shown that using an immense distributed computing paradigm, up to 6 - grams can be trained on up to billions [SEP]"}
{"pre": "these transducers are compiled from regular expressions that use finite - state calculus operators, mainly the replace operators # refr. [SEP] itgs, [SEP] [SEP] [SEP]", "cit": "transducers compiled from simple replace expressions upper - > lower # otherefr, # refr are generally nondeterministic in the sense that they may [SEP]"}
{"pre": "in the last years, several papers have successfully applied to a wide variety of nlp tasks, including word sense disambiguation # otherefr ;", "cit": "van durme and gildea # otherefr proposed applying lda to general knowledge templates extracted using the knext system # refr. [SEP] [PAD]"}
{"pre": "in the context of spoken language generation, referring expressions has been used for text generation # otherefr ; # refr. [SEP] this information [SEP] [SEP]", "cit": "epicure # otherefr ; # refr, and systems developed by dalianis and hovy # otherefr all use various forms [SEP]"}
{"pre": "# refr proposed a method that uses co - occurrence statistics to measure the accuracy of a large corpus of disambiguated in word window. [SEP] the uml", "cit": "clustering nouns by argument structure can uncover naturally related objects # otherefr and spectral methods can relate distinct classes of nouns with certain kinds of verbs [SEP]"}
{"pre": "the tempeval community focused on the classification of the temporal links between events, or an event or a temporal expression ; using shallow [SEP] [SEP] [SEP]", "cit": "features for the classifier include many of those in # otherefr ; # refr : namely, event keyword and its dominant verb, verb and [SEP]"}
{"pre": "in this paper we use an interactive approach to dialogue generation that is based on the assumption that its dialogue acts in the dialogue system turn are [SEP] [SEP]", "cit": "naturalness in spoken interaction can be characterised by features such as incrementality and immediacy # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "early event extraction systems used handcrafted patterns # otherefr ; # refr ), or unsupervised learning # otherefr ). [SEP] features", "cit": "this approach was also used to train glacier? s sentential event recognizer # refr, and they demonstrated that this approach worked reasonably [SEP]"}
{"pre": "the second parser is that, as described in # refr, can be used to parser accuracy and achieved by a variety of parsers and [SEP] phenomena", "cit": "the rasp parser is based on a manually constructed pos tag - sequence grammar, with a statistical parse selection component and a robust one obvious omission [SEP]"}
{"pre": "in the latter case, the correctness of the final results reported by using the average score computed by a summary sentence generated by a reference translation [SEP] the", "cit": "the work of # refr on local coherence might be a possible candidate for estimating focus ( q4 ), while an automatic parser could be run [SEP]"}
{"pre": "for example, the main focus of the meaning of the meaning of the structures # otherefr ; # refr. [SEP] this paper is about [SEP]", "cit": "5we used the statistical japanese dependency parser cabocha # refr for parsing. http : / / chasen. naist. jp / [SEP]"}
{"pre": "in addition, we used frequency statistics as well as selectional preference # otherefr ; # refr to assign verbs to the prepositions.", "cit": "we adapted the method of # refr which uses log - likelihood for finding words that characterise differences between corpora. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "transliteration methods typically fall into two categories : generative approaches # otherefr that try to produce the target transliteration given a source [SEP]", "cit": "previous works usually take a generative approach, # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use stanford ner tagger # refr to pos tagging named entity mentions. [SEP] the preprocessing step of tag dictionary. [SEP] in [SEP] the onto", "cit": "the stanford crf - based ner tagger was used as the monolingual component in our models # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "a hypergraph, as demonstrated by huang and chiang # otherefr, is a compact data - structure that can encode an exponential number [SEP]", "cit": "other solutions to the reachability problem include targeting reachable oracles instead of the reference translation ( li and # refr or making use of alternative training criteria [SEP]"}
{"pre": "variations of this method were proposed by # otherefr ; # refr. [SEP] ( w ) in step 1 a cross - lingu [SEP] [SEP] [SEP]", "cit": "several techniques have been proposed to deal with these ambiguity cases # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "plsa -, lda -, and cca - based cross - lingual models have also been trained and tested on bilingual dictionaries # otheref", "cit": "comparable documents can also be used for learning word - level translation lexicons # otherefr ; # refr.. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr describe a * this work, and only consider a very simple and elegant interpretation for efficient inference. [SEP] it is np - hard # other", "cit": "previous work on this topic in nlp or machine learning includes work on inference in markov random fields # otherefr ; work that encodes constraints [SEP]"}
{"pre": "recently, # refr have proposed a structured vector space model ( svs ) that a word recurring and its meaning change in context [SEP] [SEP] [SEP]", "cit": "a recent result that the svs model builds on is that selectional preferences can be represented as prototype vectors constructed from seen arguments # otheref [SEP]"}
{"pre": "while many of the current state - of - the - art approaches have been proposed for anaphora resolution # otherefr ), machine learning methods", "cit": "specifically, we extend # refr machine learning approach to information - status determination with lexical and structured features, and exploit learned knowledge of the information status [SEP]"}
{"pre": "statistical approaches to incremental processing that address some of these problems have been addressed # otherefr ; # refr. [SEP] this work was done [SEP] [SEP]", "cit": "a general abstract model of incremental processing based on buffers and a processor was developed by # refr and is illustrated in figure 2. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "this idea of translating to english to stems and then inflecting the stems in a separate step has been studied by # refr, who use a maximum", "cit": "recently, several studies # otherefr ; # refr proposed modeling targetside morphology in a phrase - based factored models framework # otheref [SEP]"}
{"pre": "5http : / / www. nactem. ac. uk / download. php? target = grec / event annotation guidelines. [SEP]", "cit": "simstring1 is a software library utilising the cp - merge algorithm ( okazaki and # refr to enable fast approximate string matching. [SEP] [PAD]"}
{"pre": "# refr use a parser and a pos tagger to tag the tokens surrounding in the sentences. [SEP] unsupervised pos tag. [SEP] chunk. [SEP] features", "cit": "second, to obtain good results, manually created pos tags are used as input in all the unsupervised parsers mentioned above except of seginer? [SEP]"}
{"pre": "we use the senseval - 3 english lexical sample system # refr to train and evaluate our system. [SEP] system. [SEP] different senseval - [SEP]", "cit": "this was mainly because of their attested strength at earlier senseval evaluations # otherefr, # refr and mutual complementarity discovered by us # [SEP]"}
{"pre": "graph - based methods view the problem as finding an optimal tree from a fully - connected directed graph # otherefr ; # refr, while [SEP]", "cit": "# refr show that sgd achieves optimal test performance with far fewer iterations than other optimization routines such as l - bfgs. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "there has been a lot of work done in the nlp community on sentence boundary detection in text # otherefr ; # refr, [SEP] [SEP]", "cit": "7http : / / aye. comp. nus. edu. sg / parscit / could be successfully identified using parscit. [SEP]"}
{"pre": "we use a support vector machines - based representation proposed by # refr for the purpose of kernels. [SEP] kernel trees and rule - based kernels have [SEP]", "cit": "recently, # refr proposed an algorithm to linearize convolution kernels. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr applied it to the task of translating unknown words in several european languages, an idea investigated as well by denoual # otherefr [SEP]", "cit": "various solutions to data sparsity have been studied, among them the use of part - of - speech tags, suffixes and word stems to normalize [SEP]"}
{"pre": "functions for simple phrases directly map distributional vectors of words to distributional vectors for the phrases # otherefr ; # refr. [SEP] ( 5 ) [SEP]", "cit": "functions for simple phrases directly map distributional vectors of words to distributional vectors for the phrases # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr reports negative results for two reordering tables : one for the phrase table obtained from the dso corpus. [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "similar arguments were presented in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the method of # refr to obtain the semantic parser. [SEP] natural language understanding. [SEP] a representation of the environment. [SEP] it [SEP] it", "cit": "many supervised learning frameworks have been applied, including inductive logic programming # otherefr ; ge and # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this is mainly motivated by the rapid growth of deception in written sources, and in particular in web content, including product reviews, online dating [SEP]", "cit": "recently, # refr have introduced an opinion spam dataset containing gold standard deceptive positive hotel reviews. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "a good trade - off between fully supervised and fully unsupervised approaches is distant supervision, a semi - supervised procedure consisting of finding sentences that contain two [SEP]", "cit": "much of the previous work uses heuristics, e. g. extracting sentences only from encyclopedic entries # refr, or syntactic restrictions on [SEP]"}
{"pre": "decision lists # otherefr have been used for a variety of natural language tasks, including accent restoration # refr, word sense disambiguation # [SEP]", "cit": "the final system was a decision list classifier that found the log - likelihoods of the correspondence be - association for computational linguistics for the semantic analysis [SEP]"}
{"pre": "we then parsed all sentences using the nivre parser # refr. [SEP] the information of the corpus. [SEP] the patterns across [SEP] [SEP] the [SEP]", "cit": "we parsed the text using the maltparser 1. 7, a linear time dependency parser # refr. 5 we then extracted the representative [SEP]"}
{"pre": "morfessor # refr algorithm : morfessor baseline + brown et al. # otherefr. [SEP] the generative process of [SEP] [SEP] [SEP]", "cit": "one answer was provided by # refr, who showed that already one hundred manually segmented words provide significant improvements to the quality of the output when comparing [SEP]"}
{"pre": "we use the stanford parser # refr, which uses a lexicalized pcfg model trained on syntactic trees, and applied to obtain the semantic [SEP] [SEP]", "cit": "1 current statistical parsers do not use or output this richer information because performance of the parser usually decreases considerably, since a more complex task is [SEP]"}
{"pre": "mwes occur frequently in language and interpreting them correctly would directly improve results in a number of tasks, such as translation and chunking # other [SEP]", "cit": "# refr uses syntactic fixedness to identify english vnics. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "learning then reduces to finding a set of parameters that are estimated by identifying a local maximum of an objective function such as the likelihood # otheref [SEP]", "cit": "other methods are based on maximum likelihood estimation, searching for the grammar that has the largest posterior given the training corpus # otherefr ; # [SEP]"}
{"pre": "in this paper we discus the performance of word sense induction and semeval - 2010 competition # refr task. [SEP] this problem wasp [SEP] [SEP]", "cit": "the task is aimed at overcoming the wellknown limitations of in vitro evaluations, such as those of previous semeval tasks on the topic # [SEP]"}
{"pre": "leveraging information from one language for the task of disambiguating another language has received considerable attention # otherefr ; # refr. [SEP] the [SEP]", "cit": "leveraging information from one language for the task of disambiguating another language has received considerable attention # otherefr ; burkett and # refr [SEP]"}
{"pre": "caught between the scylla of linguistically inadequate projective trees and the charybdis of computationally intractable non - projective trees, some researchers have [SEP]", "cit": "caught between the scylla of linguistically inadequate projective trees and the charybdis of computationally intractable non - projective trees, some researchers have [SEP]"}
{"pre": "even though some works try to address the problem of summarizing multiparty written conversions # otherefr ; # refr ), they do so [SEP]", "cit": "as a by - product of our approach, we also propose an extractive summarization model based on phrasal queries to select the summary - [SEP]"}
{"pre": "the use of semantic role labeling has been successfully applied to a wide variety of nlp tasks # otherefr ; # refr. [SEP] [SEP] [SEP]", "cit": "for example, # refr extract explicit srl rules by analyzing framenet cases. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for instance, the idea of using large - scale parallel corpora, # refr proposed a siamese neural network based on the bag - of words [SEP]", "cit": "word - level translation lexicons can also be learned from comparable documents # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for english, we additionally used the 50 - best parser by # refr. [SEP] the self - trained biomedical parsing. [SEP] the crf - based [SEP]", "cit": "to identify potential lvcs within sentences, we first extract all sentences where one or more of the six verbs occur from bnc ( xml edition [SEP]"}
{"pre": "in a pattern discovery, # refr proposed a method for unsupervised discovery of concepts, where the links are defined by the links between them are selected for", "cit": "in several studies # otherefr ; # refr it has been shown that relatively unsupervised and language - independent methods could be used to generate many [SEP]"}
{"pre": "in a later work # refr, the idea is extended to word sense disambiguation # otherefr by using a local maximum entropy model to include", "cit": "it is well known that the different contexts that distributional semantics catches do not always directly refer to what linguists would consider distinct senses # refr [SEP]"}
{"pre": "hypergraph search is a compact data structure that is useful in many nlp applications, including part of speech tagging # otherefr ; # [SEP]", "cit": "a hypergraph, as demonstrated by # refr, is a compact data - structure that can encode an exponential number of hypotheses generated by a regular [SEP]"}
{"pre": "another line of research approaches grounded language acquisition by # refr is based on the assumption that the word co - occurrences can be [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "lexical formality is obviously related to lexicon - based readability # refr and lexical simplification # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the conll 2009 data sets # refr with the ones provided by the organizers for the conll - 2008 shared task. [SEP] [SEP]", "cit": "a somewhat more advanced tool is malteval ( nilsson and # refr, which offers a number of predefined search patterns ranging from part - [SEP]"}
{"pre": "numerous previous studies have considered distant or weak supervision from a single relational database as an alternative to manual supervision for information extraction # otherefr ; [SEP]", "cit": "numerous previous studies have considered distant or weak supervision from a single relational database as an alternative to manual supervision for information extraction # otherefr ; [SEP]"}
{"pre": "there have been a number of studies on both natural language processing # otherefr ; # refr. [SEP] this approach performed well [SEP] [SEP] [SEP] [SEP]", "cit": "see # refr for the details. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "markov logic networks can be represented as log - linear models, when grounded, and are therefore straightforward to extend with latent variables # otherefr [SEP]", "cit": "completely unsupervised monolingual anaphora resolution has been approached using, e. g., markov logic # refr and the expectation - maximisation algorithm [SEP]"}
{"pre": "the task setup and data since have served as the basis for numerous studies # otherefr ; # refr. [SEP] this [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "al., 2012a ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "it is an online training algorithm and has been successfully used in many nlp tasks, such as pos tagging # otherefr and word sense disambig", "cit": "# refr present a procedure to directly optimize the global scoring function used by a phrasebased decoder on the accuracy of the translations. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "the former approach # otherefr ; gi # refr outperform a similar approach in which the interpretation of noun compounds were evaluated using the ( gi [SEP]", "cit": "# refr classify noun compounds from the domain of medicine, using 13 classes that describe the semantic relation between the head noun and the modifier [SEP]"}
{"pre": "most often, such pairs are extracted from small bilingual lexicons # otherefr ; # refr. [SEP] the crosslingual glosses [SEP] [SEP]", "cit": "due to their low cost of acquisition, several researchers have tried to exploit such comparable corpora for bilingual lexicon extraction # otherefr ; # refr [SEP]"}
{"pre": "# refr use an information - theoretic measure of cooccurrences to partition the distribution of words in the context of text. [SEP] the [SEP] it [SEP]", "cit": "for example, # refr begin with a cooccurrence matrix and transform this matrix into a clustering. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this result confirms previous work in the context of lemmatization and part - of - speech ( pos ) tagger # refr, and syntactic chunking", "cit": "this also holds for other lemmatisation and morphological research, such as # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this has been expounded in the past 2. 1 of the bionlp? 11 recognition software for coreference resolution task # refr [SEP]", "cit": "the activity in this subfield of nlp can be gauged by : # otherefr ; # refr in the general domain, as [SEP]"}
{"pre": "this problem has been extensively studied in the past and several years # otherefr ; # refr, e. g., # otherefr", "cit": "the hiero model # otherefr ; # refr formulates phrase - based translation in terms of a synchronous context - free grammar # other [SEP]"}
{"pre": "in a study of predicting the definition of a formal definition of a formal text, some interesting variation of a formal definition of a particular interest was supported", "cit": "major proponents of rhetorical parsing have been # otherefr, # refr, and # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "crfs have been successfully applied to many sequence labeling tasks # otherefr ; # refr. [SEP] this approach is done when training [SEP] [SEP] [SEP]", "cit": "crfs have been successfully applied to a number of real - world tasks, including np chunking # refr, chinese word segmentation # otheref [SEP]"}
{"pre": "anna rounded the corner at elm ), and other phenomena interact to produce a broad range of choices for most language generation tasks # otheref [SEP]", "cit": "the efficacy of this approach has been well - established in many areas, including automated evaluation of machine translation systems # otherefr, question answering [SEP]"}
{"pre": "we use the same features as those in # refr. [SEP] ( 1 ) : select the word, we first use the sense tagger [SEP] [SEP]", "cit": "bayes # otherefr ) senseval - 3 2nd best system ( senselearner 64. 6 # refr ) [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for parsing french, we use the berkeley parser # refr. [SEP]. [SEP] it achieves 90 % accuracy on the penn treebank, and [SEP] [SEP]", "cit": "here, we report the results of experiments coupling lattice parsing together with the currently best grammar learning method : the berkeley pcfg - la parser # [SEP]"}
{"pre": "we report results on two metrics : bleu # refr and nist # otherefr. [SEP] the relative error rates ( we [SEP] [SEP] [SEP] [SEP]", "cit": "in a first set of experiments, we use the wmt 2010 shared task data # otherefr and show significant improvements of up to 1 [SEP]"}
{"pre": "in # otherefr ; # refr, people presented models that use lexical features from the phrases to predict their orientations. [SEP] distortion tables [SEP] [SEP]", "cit": "syntax information has been used for reordering, such as in # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr showed that surprisal calculated from a probabilistic earley parser correctly predicts wellknown processing phenomena that were believed to emerge from parse trees ; thus", "cit": "under surprisal theory # refr, processing difficulty at word wi is proportional to reading time at wi, which in turn is proportional to the surpr [SEP]"}
{"pre": "in contrast, conditional random fields # otherefr and the crf model by # refr. [SEP] arbitrary crfs model by [SEP] the wapiti", "cit": "we use the tool wapiti # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "virpioja et al # otherefr, # refr, and others are primarily concerned with using morpheme segmentation in smt, [SEP]", "cit": "segmented translation performs morphological analysis on the morphologically complex text for use in the translation model # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we report translation results in terms of lower - case bleu scores # refr. [SEP] the measurement of the translation quality of the [SEP] ble [SEP] [SEP]", "cit": "the evaluation metrics used in our experiments are wer ( word error rate ), per ( positionindependent word error rate ) and bleu ( bilingual [SEP]"}
{"pre": "in addition, by analyzing the morphological features, it is well known that ner can be categorized as in three categories : persons ( 1 ) rule -", "cit": "in # refr, a factor graph based approach is proposed that jointly performs ner and named entity normalization on tweets. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the first of our segmentation aims to develop a baseline, but only a subset of 21 % reduction in the training data. # refr presented a baseline", "cit": "this analysis is aided by the fact that there are three types of japanese characters, kanji, hiragana, and katakana : [SEP]"}
{"pre": "aspect aggregation : some systems group aspect terms that are synonyms or near - synonyms # otherefr ; # refr. [SEP] the [SEP] [SEP]", "cit": "so far, ate methods have been evaluated mainly on customer reviews, often from the consumer electronics domain # otherefr ; # refr. [SEP] [PAD]"}
{"pre": "balahur et al # otherefr? a different keyphrases ( 5 ) as a highly established by # refr. [SEP] this", "cit": "many more methods were proposed and evaluated within the semeval shared task # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the patterns we use were inspired by # refr. [SEP] patterns. [SEP] the patterns we proposed by # otherefr. [SEP] the patterns [SEP] [SEP]", "cit": "substantial research exists on the learning of hyperonymy relations # refr, meronymy relations # otherefr ; o. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "the only statistical pmcfg parsing algorithms # refr for the development and test data. [SEP] the laj is the starting point for the model, although", "cit": "models that can handle non - independent lexical features have given very good results both for part - of - speech and structural disambiguation # otheref [SEP]"}
{"pre": "the inside probabilities of complete - links (? 2 ) can be defined over strings in the inside - outside algorithm, and we propose a method for", "cit": "one might instead look into versions of the current algorithm for more lexically - oriented formalisms uch as stochastic lexicalized tree - adjoining [SEP]"}
{"pre": "different from the bilingual parsing # otherefr ; # refr that improves parsing performance with bilingual constraints, and the bilingual grammar induction # otheref [SEP]", "cit": "different from the bilingual parsing # otherefr ; # refr that induces grammar from parallel text, the syntax projection aims to project the syntactic knowledge [SEP]"}
{"pre": "the cross - lingual textual entailment task # otherefr and # refr, is an extension of the textual entailment task # otheref", "cit": "translations have been generated by the crowdflower3 channel to amazon mechanical turk4 ( mturk ), adopting the methodology proposed by # [SEP]"}
{"pre": "for this task, we use the same features as # refr, svm - light # otherefr. [SEP] the two current state - of -", "cit": "they use two kinds of features : syntactic ones and wordbased ones, for example, the path of the given pair of nes in the parse [SEP]"}
{"pre": "the algorithm moves all dimensions \\ [ # refr \\ ] are used to extract definite descriptions \\ [ brie, 1991 \\ ] has [SEP] \\ [", "cit": "in this paper, we review # refr \\ ] algorithm for determining the content of a referring expression. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "most prior work on natural - language generation uses sentence ordering, e. g., by das et al. # otherefr, [SEP] [SEP]", "cit": "this approach is similar in spirit to the work of # refr on unsupervised biography production. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we evaluated translation quality using case - insensitive bleu metric # refr on the nist 2004 / 2005 / 2006 test set. [SEP] the results. [SEP]", "cit": "as translation metrics, we use bleu # refr, as well as ribes # otherefra ), which is similar to kendall [SEP]"}
{"pre": "the maximum entropy model used here is similar to that of # refr, which uses decision trees to select the highest scoring words in the corpus. [SEP]", "cit": "these belong to two main categories based on machine learning # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr proposed a method for identifying the text that uses discourse relations in a dependency tree based on the penn discourse treebank. [SEP] discourse treebank", "cit": "we exploited the corpus of # refra ), who annotated 100 randomly chosen spontaneous face - to - face dialogues from the verbmobil [SEP]"}
{"pre": "in the domain of sentiment analysis, the main focus has been on the computational linguistic analysis and the creation of a document # otherefr ; #", "cit": "in # refr, a method to extract a domain terminology from available documents such as the web pages is proposed. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "brill and resnik # otherefr used a loglikelihood neural network, p, and # refr used a transformation of the forward by [SEP]", "cit": "because language - processing tasks typically can only be described as a complex interaction of regularities, subregularities and ( families of ) exceptions, [SEP]"}
{"pre": "there have been many studies on coreference resolution in the literature, e. g., # otherefr ; ng and # refr. [SEP]", "cit": "other works have used a different strategy to reduce the imbalance between positive and negative samples # otherefr ; ng and # refr, where only [SEP]"}
{"pre": "we use a multi - threaded version of the giza + + tool # refr. 1 this speeds up the process and corrects an [SEP]", "cit": "we word - aligned each paraphrase pair using the mgiza + + implementation of ibm model 4 # otherefr ; # refr. [SEP]"}
{"pre": "in recent years, supervised learning techniques have been successfully applied to many sentiment analysis problems # otherefr ; # refr ranging from twitter data # other", "cit": "# refr propagate information from seed labels along a linked structure that includes twitter? s follower graph, and saif et al # otheref [SEP]"}
{"pre": "in addition to the original ibm translation model 1, we also ran the eisner? s alignment error model # refr. [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "synchronous grammar formalisms that are capable of modeling such complex relationships while maintaining the context - free property in each language have been proposed for many years [SEP]"}
{"pre": "the meaning of the utterance is similar, as well as the theory of discourse segment boundaries has been extensively used in the context of other work [SEP] l", "cit": "the only realization of the focus feature that we accommodate is intonational accent ; however, our theory can easily be extended to allow for other overt [SEP]"}
{"pre": "previous approaches to debate stance classification have focused on three debate settings, namely congressional floor debates # otherefr ; # refr, companyinternal [SEP]", "cit": "unigram systems are proved reliable in sentiment analysis # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr used svm classifiers to train svm classifiers for tweets with a large majority novel statistical model derived from google n - gram model generated automatically generated data", "cit": "although some recent work has started exploring the use of natural language processing, most work to date is based on shallow lexico - syntactic patterns ( [SEP]"}
{"pre": "in a similar approach, # refr proposed an incremental understanding strategy to model based on incrementality. [SEP] events. [SEP] frames, which are treated as", "cit": "however, the general approach ere has more in common with whittemore and # refr or zarri # otherefr, where event [SEP]"}
{"pre": "we used mecab 4 # refr and the stanford dependency parser ( cabocha ) as a dependency parser to assign pos [SEP] a chunk [SEP] the", "cit": "for j - e translation, we used the cabocha parser # refr to analyze the context document. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "they can be roughly divided into three categories : string - to - tree models # otherefr ; # refr ), and tree - to -", "cit": "they can be roughly divided into three categories : string - to - tree models # otherefr ; # refr ). [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for a proposal on the interpretation of an ambiguous expression, see # refr. [SEP] argue \\ [ 1 \\ ]. [SEP] \\ [ 1 \\ ]", "cit": "complex relations uch as the one in \" luhe - oil alarm \" can sometimes be glossed as \" for \". ( v =, [SEP]"}
{"pre": "# refr used a parser to parse accuracy of the training data to boost switchboard. [SEP] repairs. [SEP] repairs. [SEP] the presence of", "cit": "given that state - of - the - art edit detection performs at about 80 % f - measure # refr, much of the benefit derived here [SEP]"}
{"pre": "the confusion networks were built using the incremental hypothesis alignment algorithm with flexible matching introduced in # refr. [SEP] [SEP] [SEP] [SEP] into blocks of [SEP] [SEP] [SEP]", "cit": "the pairwise alignment methods proposed by # refr, he et al # otherefr are able to match also synonyms and words with identical stems [SEP]"}
{"pre": "in the literature, different approaches have been applied to natural language processing tasks like named entity recognition # otherefr, part of speech tagging # refr", "cit": "algorithms for sequence learning obviously work on sequence data, so respective al approaches need to select complete sequences instead of single text tokens # refr. [SEP] [PAD]"}
{"pre": "the relation between the two predicates is defined to be one between the terms of the predicate? s relations # refr. [SEP] - 1 [SEP] [SEP] [SEP]", "cit": "there has been work on detecting relations within noun phrases # otherefr and syntax - based comma resolution # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use approximate randomization test # refr with 1000 repetitions to determine score difference significance : results in bold are significant with p? 0. 01 and [SEP]", "cit": "10for assessing significance, we apply the approximate randomization method described in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "table 1 compares our results to the two stanford parser variants # otherefr, stanford parser # refr, and the charniak parser # other", "cit": "parse sentence match : these are binary features that indicate whether the examined boundaries correspond to a sub - tree whose root is labeled? s? ( [SEP]"}
{"pre": "# refr and baldwin et al # otherefr ). [SEP] the hypothesis identification of the non - compositionality of mwes using contiguous phrases", "cit": "# refr applied information - theoretic measures to automatically - extracted dependency relations to find mwes. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this paper describes the systems submitted by the national research council canada # otherefr ( lefever and # refr. [SEP] the [SEP] english lexical", "cit": "we present our system wsd2 which participated in the cross - lingual word - sense disambiguation task for semeval 2013 ( le [SEP]"}
{"pre": "dorr and gaasterland # otherefr and # refr focus on the tense of events, we propose an embedding representation that is most", "cit": "early systems investigated rule - based approaches to parsing the durations and orderings of events from the tenses and aspects of their verbs # otheref [SEP]"}
{"pre": "for instance, # refr uses ( the v - n ) n - gram counts, which are word - by frequency of word occurrences. [SEP] the", "cit": "5we are aware of the fact that other measures of lexical association have been proposed # refr, and mi values were computed using adam berger? [SEP]"}
{"pre": "for this purpose, # refr proposed a method based on similarity to find the best of a set of questions annotated for training data. [SEP] the [SEP]", "cit": "many studies # refr # otherefr have been done on retrieving similar q & a pairs from social qa websites as answers to test questions. [SEP]"}
{"pre": "the second enhancement tries to minimize the translation quality of the translation by rearranging the words in the source sentence to better match the correct word order in", "cit": "this years improvements were added to the liu baseline system # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr describe a method for combining ibm model 1. [SEP]. [SEP]. [SEP]. [SEP]. [SEP], a technique for alignment, and it has", "cit": "# refr also suggested adding multiple empty words to the target sentence for ibm model 1. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "as a promising approach to solve the problem of vocabulary gap, smt has been widely exploited in many applications such as information retrieval # otheref [SEP]", "cit": "inspired by extraction - based document summarization # refr, we can extract one or more important sentences from the given document to construct translation pairs. [SEP]"}
{"pre": "we use a sentence segmentation tool # otherefr to convert the empty nodes in the penn treebank # refr. [SEP] the word boundaries. [SEP]", "cit": "the brief introductions of the cctb and the pctb are given as below # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the giza + + toolkit # refr to learn word alignments, again in both directions. [SEP] characteristics of the [SEP] [SEP] characteristics of conventional", "cit": "we employ the phrase - based smt framework # refr, and use the moses toolkit # otherefr, using a single reference translation [SEP]"}
{"pre": "in bionlp? 09 shared task on event extraction # refr, the first large scale evaluation of biomedical event extraction systems, drew the bionl", "cit": "like the previous lll and biocreative2 - ppi relation extraction tasks # otherefr, the bionlp? 09 shared task [SEP]"}
{"pre": "for example, in the english multi - parallel chinese dependency trees # otherefr, # refr, and the tree - to - string translation model", "cit": "in recent years, syntax - based smt has made promising progress by employing either dependency parsing # otherefr or constituency parsing # refr [SEP]"}
{"pre": "in the multilingual track of the conll 2007 shared task on dependency parsing, a single parser must be trained to handle data from ten different [SEP]", "cit": "interestingly, though the two systems have similar accuracies overall, there is a clear distinction between the kinds of errors each system makes, which we argue [SEP]"}
{"pre": "several nl ie systems have been based on a statistical and linguistic analysis program that can be used to reduce the search space # otherefr, [SEP]", "cit": "in experiments reported elsewhere, we have applied srv to collections of electronic seminar announcements and world wide web pages # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "the disambiguation of hpsg grammars for natural language generation # otherefr ; # refr. [SEP] the statistics [SEP] the [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "the same problems also arise with hpsg parsing, and recent studies # otherefr ; # refr proposed a number of solutions including the methods [SEP]"}
{"pre": "transformation - based learning has been applied to a wide variety of natural language processing ( nlp ) tasks, such as part - of - speech tagging", "cit": "most hybrid approaches combine statistical information with automatically extracted rule - based information # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the top - 10 parser of # refr to obtain ccg semantic representations. [SEP] the training of # otherefr. [SEP] it [SEP]", "cit": "traditional semantic parsers # otherefr ; # refr have two limitations : ( i ) they require annotated logical forms as supervision, and ( [SEP]"}
{"pre": "there has been much recent work on incorporating long historyand domain - independent features # otherefr ; # refr. [SEP] features [SEP] the nlms", "cit": "there is a long tradition of research on representations for nlp, mostly falling into one of three categories : 1 ) vector space models and dimensionality [SEP]"}
{"pre": "for instance, using linear combinations # otherefr ; # refra ; albrecht and hwa, 2007b ) or a variety of [SEP]", "cit": "other metrics are based on computing lexical precision, e. g., bleu # otherefr, maxsim # refr, and ol [SEP]"}
{"pre": "in particular, we compare our system to the recently proposed by # refr for each 10 - fold cross - validation. [SEP] features derived from the [SEP]", "cit": "the problems are answer scoring # refr, on data from stackoverflow. com, and multi - attribute sentiment analysis # otherefr. [SEP]"}
{"pre": "a phrasal exicon \\ [ # refr, dyer and zernik, 1986 \\ ] are to be added to the noun phrases [SEP] [SEP]", "cit": "in a series of papers # refr, paul jacobs has developed a relationship he calls a view. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr used a thesaurus to generate 1042 statistical models of thesaurus categories, both words and classes of their senses. [SEP] the", "cit": "others such as lesk # otherefr, and # refr have turned to machine readable dictionaries ( mrd is ) in an [SEP]"}
{"pre": "in addition, most of the projective dependency parsing framework has been recently applied to the parser of # refr, but it is the only to make non", "cit": "as a light - weight formalism offering syntactic information to downstream applications such as smt, the dependency grammar has received increasing interest in the syntax parsing [SEP]"}
{"pre": "in this work, we concentrate on the the cross - lingual setting which has been done in the nlp community # refr [SEP] [SEP] [SEP] [SEP]", "cit": "measures of cross - language relatedness are useful for a large number of applications, including cross - language information retrieval # otherefr, cross - [SEP]"}
{"pre": "this has led to the development of efficient data - driven dependency parsers, which are accurate than maltparser # refr, nivre et al", "cit": "data - driven dependency parsing has been shown to give accurate and efficient parsing for a wide range of languages, such as japanese # otherefr [SEP]"}
{"pre": "model f - score # otherefr 84. 4 model f - score # refr 62. 4 model f - score # otherefr 86", "cit": "meanwhile, one strong point of the hdp based models is that they can model the diversity and commonality in multiple correlated corpora # otheref [SEP]"}
{"pre": "the annotation of corpora is based on the annotations of the sentences corpus are parsed by a sentence containing the sentence and [SEP] the annotations of the [SEP]", "cit": "investigations into the interpretation of narrative discourse # refr have, however, shown that very specific lexical information plays an important role in determining temporal interpretation. [SEP]"}
{"pre": "# refr presented a graph - based framework for unsupervised part - ofspeech tagging, extending the direct translation model with label propagation. [SEP] features [SEP] [SEP]", "cit": "in more recent work, # refr propose a graph - based framework for projecting syntactic information across languages. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "metrics bleu # otherefr, meteor # refr and ter # otherefr were computed using the moses scorer which is used in", "cit": "in addition to that we have computed the following two groups of standard metrics as baselines : metrics participant meteor carnegie mellon university # [SEP]"}
{"pre": "phrase - based smt approaches # otherefr ; # refr are a probabilistic model that describes a probability model for statistical machine translation ( smt", "cit": "possibly the most remarkable evolution of recent years in statistical machine translation is the step from word - based models to phrase - based models # otheref [SEP]"}
{"pre": "we use nombank # refr to train a probabilistic model from propbank # otherefr. [SEP] arguments of wordnet and framenet [SEP] [SEP]", "cit": "second, we present results on propbank - style semantic role labeling # otherefr ; # refr, that approach strong baselines, and [SEP]"}
{"pre": "transliteration methods typically fall into two categories : generative approaches # otherefr that try to produce the target transliteration given a source [SEP]", "cit": "machine learning techniques # otherefr and named entity recognizers # refr have been used for this purpose. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the resolution of np coordination has been extensively studied in the past # otherefr ; # refr. [SEP] - la & [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "inspired by previous literature demonstrating the power of metrics based on pointwise mutual information # otherefr ; # refr, we test an approach exploiting [SEP]"}
{"pre": "we use the srilm toolkit # otherefr to train the lm and rank scores # refr on the tokens provided by the word [SEP] [SEP] [SEP]", "cit": "approach for the statistical analysis of n - grams in texts # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this scenario is applicable to a large set of languages and has been considered by a number of authors in the past # otherefr ; # [SEP]", "cit": "this research trend was initiated by yarowsky et al. # otherefr ; # refr for syntactic dependencies, in # otherefr [SEP]"}
{"pre": "the xml markup was removed, and the corpora were lemmatized using the negra annotation tool # refr. [SEP]text5 the negra annotation", "cit": "several features of the tool have been introduced to suite the requirements imposed by the architecture of the annotation scheme ( cf. # refr ), which [SEP]"}
{"pre": "in addition to the regular distance distortion model, we incorporate a four - based lexicalized reordering model of # refr with three orientation and [SEP] the", "cit": "in addition, in order to improve the translation quality, we adopted some popular techniques, including three lexicalized reordering models # otherefr [SEP]"}
{"pre": "in the context of the parsing model, the strategy of # refr is used to deal with an underspecification which was among the original governor", "cit": "to address this problem, grammar - based checkers typically employ robustness techniques # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for comparison, we use the conll - x format # refr, leaving the standard dependency parsing algorithm for projective dependency trees and hence include [SEP] non", "cit": "following pitler et al # otherefr, we report in table 1 figures for the training sets of six languages used in the conll [SEP]"}
{"pre": "# refr used a bilingual corpus to disambiguate the sense of a word, and a set of classes derived from a contextual disambiguated version of the", "cit": "this property of words was first described and quantified by # refr, and has become known generally as the? one sense per collocation? property [SEP]"}
{"pre": "in 2006, the 2007 shared task was multilingual dependency parsing, where participants were evaluated from the conll 2006 and 2007 shared tasks # refr.", "cit": "an important part of this research effort are the conll 2006 and 2007 shared tasks # otherefr ; # refr, which allowed for a [SEP]"}
{"pre": "in order to produce the usefulness of wsd for computational linguistics, a number of approaches have been proposed that go beyond the scope of this [SEP] [SEP]", "cit": "mohammad and # refr show that their method can be used to compute semantic distance in a resource poor language l by combining its text with a [SEP]"}
{"pre": "# refrb ) and chan et al. # otherefr smt system, respectively. [SEP] the assumption underlying meaning [SEP] the probability distribution of", "cit": "there are also some work that employed the context information to make a better choice of translation rules # refr. all the work employed rich context information [SEP]"}
{"pre": "in particular, we adopt the approach of # refr and train and evaluate it on two domain corpora. [SEP] english verb clustering ( noun + [SEP] [SEP]", "cit": "verbnet # otherefr ) these are not comprehensive and are inadequate for specific domains # refrb ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this is also true in question answering # otherefr ; # refr. [SEP] : it is possible to apply statistical techniques to [SEP] the [SEP] [SEP]", "cit": "for instance, we may find metrics based on full constituent parsing # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use a statistical model # refr since it is based on a hidden markov model. [SEP] features approach # otherefr recently developed for hindi", "cit": "several ml techniques have been successfully used for the ner task of which hidden markov model # refr, maximum entropy # otherefr are most common [SEP]"}
{"pre": "in the domain of the ideas, the task of dialogue acts in dialogue acts are known to utterances in the literature # otherefr ; # refr", "cit": "the utterances may propose domain actions # otherefr that directly contribute to achieving the agents'goal, such as \" let is send engine e [SEP]"}
{"pre": "in addition, several unsupervised methods have been proposed to identify main subjectivity, including a variety of lexical items, such as polarity shift ( yu and", "cit": "for example, yu and # refr separated facts from opinions and assigned polarities only to opinions. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the task of coreference resolution is to tokenise each coreference using the output of the ace program # otherefr, which was [SEP].", "cit": "among these tools, there is only one team used an external coreference resolution framework, reconcile, which achieved the state - of - the [SEP]"}
{"pre": "we show that the model for normal - form # otherefr ; # refr is based on the assumption that is even higher than [SEP] [SEP] [SEP]", "cit": "given an input sentence, and a current lexicon which assigns categories to at least some of the tokens in the sentence, we apply the following two [SEP]"}
{"pre": "for example, # refr used a dependency parser to derive a word duration of a pos tagger and show that in a dependency parser can be trained", "cit": "for dependency scores, we present directed attachment accuracy, undirected attachment accuracy, and the? neutral edge detection? ( ned ) score introduced by # [SEP]"}
{"pre": "for example, the average f1 of the stanford parser # refr reaches a 6 80 %. 6 % relative frequency scores trained on the wall street", "cit": "other path - length based measures include the wu & palmer similarity ( wu and # refr. s ( a, b ) pwupal = [SEP]"}
{"pre": "this problem has been extensively studied in the context of monolingual lexicons # otherefr and bilingual lexicon induction # refr. [SEP] [SEP] [SEP] [SEP]", "cit": "this problem has been extensively addressed in the bilingual lexicon acquisition literature # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in contrast, in this paper, we present a framework of gradient descent for estimation # otherefr that is similar to the? contrastive estimation", "cit": "as an object - oriented c + + library, it also facilitates rapid implementation of new estimation techniques # otherefr ; # refr. [SEP] [PAD]"}
{"pre": "for english, we use the lexical substitution task described by # refr. [SEP] a collection of english lexical substitution. [SEP] a target word within a window", "cit": "consider the occurrence of verb shed in the following semeval 2007 lexical substitution task # refr example : cats in the latent phase only have the [SEP]"}
{"pre": "we are currently developing a grammar encoding of german text and a combination of tools and tools for the various language processing platform since it provides a diverse array", "cit": "there exists only very little other work that considers integration of shallow and deep nlp using an xml? based architecture, most notably # refr. [SEP]"}
{"pre": "previous research in wsd use the task of word sense disambiguation # otherefr ; # refr ) and supervised learning algorithms have shown that [SEP]", "cit": "in recent coarse - grained evaluations, such systems have achieved accuracies of close to 90 % # otherefr ; # refr. [SEP] [PAD] [PAD]"}
{"pre": "# refr use a hierarchical translation model, which allows a hypothesis alignment problem that allows for the incorporation of non - terminals to allow for non - local", "cit": "extensions to hiero # refr discuss procedures to combine discriminative latent models with hierarchical smt. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "tinguish the verb classes ~ in exploring these quesuons, we focus on verb classlficauon for several reasons verbs are [SEP]", "cit": "palmer # otherefr and # refr argue that the use of syntactic frames and verb classes can simplify the definition of different verb senses. [SEP] [PAD]"}
{"pre": "in fact, the twitter messages are very few words and this can be extracted from a single topic # refr. [SEP] features [SEP] the model to score", "cit": "event detection on twitter has been a hot research topic in recent years # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the mapping can be based on synchronous context - free grammars # otherefr, and synchronous grammars # refr. [SEP] current n - gram models [SEP]", "cit": "instead of using annotated training data consisting of sentences and their corresponding logical forms # otherefr ; # refr, most of these approaches leverage non [SEP]"}
{"pre": "in addition to wktwiki, we take advantage of probabilistic context - free models # otherefr ; # refr, as well as spearman [SEP]", "cit": "s? # refr and van de cruys et al # otherefr, who propose to use latent variable models. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "rtms rank 1st in all of the tasks and subtasks of qet14 # otherefr ; pasca ; [SEP] [SEP] [SEP] [SEP]", "cit": "id participating team dcu dublin city university team 1, ireland # otherefr multilizer multilizer, finland rtm - dcu dublin [SEP]"}
{"pre": "transliteration methods are becoming an important component of many natural language processing # otherefr ; # refr. [SEP] the source [SEP] [SEP] [SEP] [SEP]", "cit": "machine transliteration methods are divided into grapheme - based # otherefr ; # refr and combined techniques # otherefr. [SEP] [PAD]"}
{"pre": "we note that the two approaches proposed by minimum bayes risk decoding # otherefr and mt systems # refr are used to scale the best [SEP] [SEP]", "cit": "arabic and urdu are segmented using mada # otherefr, a distortion limit of 6, 100 - best translation options, mbr [SEP]"}
{"pre": "in addition to contextual similarity, researches have been shown to be useful in other areas of natural language processing # otherefr ; # refr. [SEP]", "cit": "the patterns in a pattern synset can be taken as paraphrases # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used the mxpost tagger # refr trained on training data to provide part - of - speech tags for the text. [SEP] the tagger", "cit": "following # otherefr, we used the pos tagger by # refr trained on the full training data to provide pos tags for development and [SEP]"}
{"pre": "we used the dataset from # refr. [SEP] the penn treebank # otherefr to train a classifier, we automatically construct a [SEP] [SEP] [SEP]", "cit": "m, assign it a wikipedia page pi in a context - sensitive way ( pi may be null ). - if pi 6 = null : [SEP]"}
{"pre": "in fact, the twitter data has been used for twitter # refr, but it has not been difficult to measure increases in performance. [SEP] this [SEP]", "cit": "however, we have no general strategy in place to systematically recognize unconventionally spelled words # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition to domain mainstays such as support vector machines and maximum entropy models, we find increased application of joint models # otherefr [SEP]", "cit": "while the parserbased systems of uet - nii and isi perform below others here, it should be noted that related approaches have achieved competitive [SEP]"}
{"pre": "meteor # refr? meteor measures precision and recall for unigrams and applies a fragmentation penalty. [SEP] bleu # otherefr on the [SEP] ble", "cit": "results are reported on three metrics, bleu # otherefr and meteor ranking scores # refr based on truecased output. [SEP] [PAD] [PAD]"}
{"pre": "the second set of experiments has been that combining the wsj - parsed models # refr. [SEP] unannotated data # other [SEP] [SEP]", "cit": "this type of discriminative training has been applied to log - linear variants of hidden markov models # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "statistical machine translation # otherefr ; # refr. [SEP] this approach by allowing making it one of the following three stages : a ) [SEP] [SEP]", "cit": "contrastive evaluation scores : for the ranking task, each translation is scored with an automatic metric # otherefr, using the other translations as [SEP]"}
{"pre": "in addition, different ways have been proposed to deal with real data # otherefr ; # refr. [SEP] this problem [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "automatic techniques for finding semantic classes include unsupervised clustering # otherefr, classification # refr and many others. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in 2010, we applied the turku event extraction system to detecting events in all 18 million pubmed abstracts, showing its scalability and generalizability into [SEP]", "cit": "we developed for the bionlp? 09 shared task the turku event extraction system, achieving the best performance at 51. 95 % f [SEP]"}
{"pre": "# refr showed that for generating backing, the frequencies of each word with a sense is effective in the context of its language processing tasks. [SEP]", "cit": "by using amazon mechanical turk, a burgeoning forum for psycholinguistic research # refr, we were able to recruit a large number of [SEP]"}
{"pre": "similar to speech recognition? s recognizer output voting error reduction # otherefr ; # refra ; rosti et al 2007b ; [SEP]", "cit": "this means that little or no gains will typically be seen when combining a good system with poor performing systems even if the systems col - 1the [SEP]"}
{"pre": "german for italian ( cf. ), # refr describe how to integrate structures of a set of types of structures that are used to account for the", "cit": "this assumption underlies a growing number of recent syntactic theories which give up the context - free constituent ba. ckbone, cf. # other [SEP]"}
{"pre": "twitter also provides a wealth of user dialog, and a variety of dialog acts have been observed # otherefr and predicted # refr. [SEP] this", "cit": "we take english tweets from the corpus constructed by burger et al # otherefr which contains 2. 9m tweets ( excluding retwe [SEP]"}
{"pre": "forest reranking methods have been proposed, including hypergraph reranking # otherefr ; # refr, and hypergraphs # otheref", "cit": "hypergraph - reranking in mt is similar to the forest - reranking for monolingual parsing # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this includes work on coarse - to - fine parsing # otherefr, and latent annotations # refr, and latent variable grammars # otheref [SEP]", "cit": "our model leverages multiple automatically learned latent variable grammars, which differ only in the seed of the random number generator used to initialize the em learning [SEP]"}
{"pre": "previous work on predicting multi - word similarity # otherefr ; # refr has shown that using mt output to obtain the reference translation ( [SEP] [SEP]", "cit": "however, all these methods suffer from several limitations : first, they provide no interpretable information about the quality of the system ( only a relative [SEP]"}
{"pre": "it has been shown that the use of a semantic relatedness tagger, which has a number of applications, including the lexical sample of open [SEP] lexical", "cit": "previous efforts aimed at automatically linking wikipedia to wordnet include full use of the first wordnet sense heuristic # otherefr and a supervised approach [SEP]"}
{"pre": "in recent years, several dependency parsing algorithms # otherefr ; # refr have been proposed and achieved high parsing accuracies on several treebanks [SEP]", "cit": "in recent years, syntax - based smt has made promising progress by employing either dependency parsing # otherefr ; # refr on the source [SEP]"}
{"pre": "# refr present an unsupervised method for classifying nounmodifier roles in verb. [SEP]. [SEP]. [SEP]. [SEP] frames with a latent variable model in", "cit": "in other work, # refr has explored unsupervised methods to discover role - slot mappings for verbs, but not to apply this knowledge to label text [SEP]"}
{"pre": "phrase - based systems, including the original ibm translation models # otherefr, and the phrasal # refr, are [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "experiments are performed using a single phrase - based chinese - to - english translation system, built with the stanford phrasal machine translation toolkit # refr [SEP]"}
{"pre": "statistical parsers make use of both a and b3 # otherefr ; # refr. [SEP] the techniques of the [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "in order to extract the linguistic features necessary for the models, all sentences containing the target word were automatically part - of - speech - tagged using [SEP]"}
{"pre": "in contrast, # refr propose an approach to extractive captions, which indicates images, but not require full sentences ( or phrases ) [SEP] [SEP]", "cit": "gaining a better understanding of natural language, and especially natural language associated with images helps drive research in both computer vision and natural language processing # other [SEP]"}
{"pre": "# refr argue that social media is not a coherent domain at all, and that it is difficult to assign pos taggers. [SEP] ( e.", "cit": "these are the result of unintentional errors, dialectal variation, conversational ellipsis, topic diversity, and creative use of language [SEP]"}
{"pre": "two approaches have emerged to alleviate the problem of da - english parallel data scarcity : using msa as a bridge language # otherefr ; # [SEP]", "cit": "there has been a number of efforts on dialect identification # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper, we follow the technique of # refr and apply a similar method to the algorithm for unsupervised learning to a large number of different [SEP]", "cit": "to the best of our knowledge, there is no existing research for hebrew that does what we did for arabic, namely to use simultaneous [SEP]"}
{"pre": "we used minimum error rate training ( mert ) # refr to tune the feature weights for the decoder. [SEP] - domain model. [SEP] [SEP] [SEP]", "cit": "we then built separate english - to - spanish and spanish - to - english directed word alignments using ibm model 4 # otherefr, combined [SEP]"}
{"pre": "the most common practice in the literature is to report the monolingual maximum likelihood of a translation model is a large hidden markov model ( hmm ) #", "cit": "using a log - linear model # refr, we obtain : pr ( ei1 | fj1 ) = exp ( m? m = 1 [SEP]"}
{"pre": "the algorithm is implemented in terms that are similar to the multi - tabular parsing algorithm of # refr. [SEP]. [SEP] = argmax ~ w", "cit": "the technique has been adapted to other formalisms than context - free grammars in \\ [ # refr \\ ]. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the first analysis task, which we have addressed the problem of query 1http : / / www. question answering. definition. definitional qa systems", "cit": "the so - called? definition? or? other? questions at recent trec evaluations # refr serve as good examples :? good answers? [SEP]"}
{"pre": "2other lexicalized pcfg models, # refr showed that over the size of the non - terminal symbol x is unfea ~, can be", "cit": "2it has recently been questioned whether these? bilexical? features actually contribute much to parsing performance # otherefr ; # refr, [SEP]"}
{"pre": "id participant cmu carnegie mellon university # otherefr cu - bojar charles university - bojar # refr cu - dep [SEP]", "cit": "some of these features made use of additional data and / or resources, such as a secondary id participating team prhlt - upv universit [SEP]"}
{"pre": "# refr describe a phrase - based translation system for german - english, where a phrase - based decoder is designed for morphological analysis, and [SEP] [SEP]", "cit": "to avoid this pitfall, talbot and osborne # otherefr use a datadriven approach to cluster source - language morphological variants that [SEP]"}
{"pre": "the systems that beat the baseline used either the grammatical annotations provided by the organizers # otherefr ; # refr, or a robust and [SEP]", "cit": "the approaches building on this work # refr ; nicolae et al2007, among others ) are supervised, mostly using shallow surface features [SEP]"}
{"pre": "# refr proposed to use the shift - reduce parsing algorithm as a traveling salesman problem # otherefr. [SEP] the dp - best decoding algorithm", "cit": "while some authors try to integrate syntax into phrase - based decoding # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in a vast body of related work, automated methods have been explored for the semantics of descriptions of descriptions of images # otherefr ; # refr", "cit": "it has recently been the subject of extensive theoretical discussion # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the last step, an efficient realization module # refr builds on a constraint satisfaction way that enables an efficient shiftreduce parser [SEP] 6, that is", "cit": "strategies that have been introduced to reduce the search space in integrated systems include greedy / incremental search algorithms # otherefr, constructing a dependency graph [SEP]"}
{"pre": "in the early days of natural anguage systems, # refr describe a probabilistic framework for the task of building aggregation of an nlg for the application", "cit": "we refer the reader to # otherefr for the content determination module, to # refr for the document structuring module and to danlos # [SEP]"}
{"pre": "for example, # refr use machine learning techniques for this task, such as classification and machine translation ( mt ) for the assessment task [SEP] [SEP] [SEP]", "cit": "the work we present here is strongly based on approaches towards sas by meurers and colleagues # otherefrb ; # refr. [SEP] [PAD] [PAD]"}
{"pre": "our parser is based on the averaged perceptron algorithm # refr, except that it is competitive with a higher order of features. [SEP] a higher order", "cit": "by comparing the results in table 5 and the results in table 6 we can see that the semi - supervised features achieve an overall improvement of 1 [SEP]"}
{"pre": "in contrast, recent work has focused on the opinion mining context for online social networks, rather than deriving arbitrary online discussions # otherefr [SEP] discussions", "cit": "our work is closely related to recent studies on detecting subgroups from online discussions # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, the bionlp 2009 shared task was one of the community - wide efforts to address the problem of the bionlp [SEP] event", "cit": "since the bionlp 2009 shared task # refr, this field has evolved from the extraction of a unique binary interaction relation between proteins and / [SEP]"}
{"pre": "in # refr, we showed that emotion detection, emotion detection, can be used to improve the performance of social media models in sentiment analysis [SEP] tweets", "cit": "with the rapid proliferation of microblogging, there is growing amount of emotion analysis research on newly available datasets of twitter posts # otherefr [SEP]"}
{"pre": "recent work on treebank parsing with discontinuous constituents # refr has shown that it is feasible to directly parse discontinuous constituency annotations, as well as [SEP]", "cit": "more concretely, a context - free grammar can be read off from discontinuous trees that have been transformed to context - free trees by the procedure [SEP]"}
{"pre": "the most common knowledge about the new term modeling improves the performance with predicted word alignment models # otherefr ; # refr. [SEP] the problem of", "cit": "for instance, functional words in one language tend to correspond to functional words in another language # refr, and the syntactic dependency of words in each [SEP]"}
{"pre": "# refr use a probabilistic model with a split - merge latent variable parser for english. [SEP] languages, trained on the penn2 [SEP] [SEP] [SEP] [SEP]", "cit": "morphological disambiguation there has been a lot of work on arabic pos tagging and morphological disambiguation # otherefr ; # refr. [SEP] [PAD] [PAD]"}
{"pre": "it is also possible for the word alignments leading to phrase - based smt models to be learned through transduction grammars # otherefr, # [SEP]", "cit": "in particular, phrase - based smt models such as koehn et al # otherefr, # refr ), whose output is [SEP]"}
{"pre": "linguistically syntactic approaches # otherefr ; # refr employ linguistically syntactic information to enhance their reordering capability and use non - contiguous phrases [SEP]", "cit": "the formally syntax - based models use synchronous context - free grammar ( scfg ) but induce a grammar from a parallel text without relying on any [SEP]"}
{"pre": "mbr hypotheses selection is then performed using sentence - level bleu score # refr. [SEP] the best hypothesis as the loss function over the [SEP] [SEP]", "cit": "finally, we used minimum bayes risk decoding # refr based on the bleu score # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr proposed a tag - based chunker that is based on a theory of dialogue acts from a corpus of speech recognizers. [SEP] [SEP] [SEP]", "cit": "# refr and worm # otherefr proposed understanding utterances by combining partial parses. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used five lexical features, namely : i ) the target c1 ( dt ) = log2 ( ii ) log2 ( ii ) log", "cit": "the inexact matching is based on the use of ontologies such as verbnet # otherefr and distributional semantics similarity metrics, such as de [SEP]"}
{"pre": "recently, many successful joint models have been proposed, such as joint tokenization and pos tagging # otherefr, joint word segmentation and pos [SEP]", "cit": "recent research on dependency parsing usually overlooks this issue by simply adopting gold pos tags for chinese data # otherefr ; # refr. [SEP] [PAD]"}
{"pre": "we used the mma system # refr trained on the training data to perform word segmentation and pos tagging. [SEP] the training material. [SEP] [SEP] [SEP]", "cit": "we used treetagger and mstparser # otherefrb ) for japanese, mma # refr and cnp # otherefr [SEP]"}
{"pre": "recursive neural network ( rnn ) models are promising deep learning models which have been applied to natural language processing # refr and have been well studied in", "cit": "wang and # refr achieve excellent ( sometimes state - of - the - art ) results on many benchmarks using binary naive bayes ( nb ) log [SEP]"}
{"pre": "the bionlp shared task ( st ) series has been instrumental in encouraging the development of methods ( bjo? # refra ) and [SEP]", "cit": "the event annotation extended the guidelines and manual 1http : / / nersuite. nlplab. org team institution members tees - [SEP]"}
{"pre": "for example, in the corpus of # refr, we are using an annotated learner corpus, and then used a subset of the meeting spurts (", "cit": "previous ythis work was performed while the author was at icsi. work on detecting ( dis ) agreements has been focused on meeting data. [SEP]"}
{"pre": "in addition to the well - known hierarchical phrase - based model # refr, our approach differs from the many previous works of hiero smt [SEP]", "cit": "# refr distinguishes statistical mt approaches that are? syntactic? in a formal sense, going beyond the finite - state underpinnings of phrasebased models [SEP]"}
{"pre": "in phrase - based smt, the phrase probability estimates a phrase based translation probability # refr. [SEP] the phrase probability p ( s | t |", "cit": "this can happen, if we define features that penalize longer phrase pairs, such as lexical weighting, or if we apply smoothing # refr. [SEP]"}
{"pre": "the most common approach to temporal expression extractions is to use tarsqi # refr, which treats entity temporal expressions and [SEP] this relation [SEP] the", "cit": "building on timeml # otherefr several works # refr identify temporal relationships in free text, but don? t focus on fact extraction. [SEP]"}
{"pre": "these include syntactic and semantic regularities # otherefr ; # refr. [SEP] distributional representations # otherefr. [SEP] the latent variable model by", "cit": "the f features encode directional aspects of distributional inclusion : that the hyponym contexts should be included in after recent work using subtraction to represent analogy [SEP]"}
{"pre": "in fact, the task of rewriting which is more in the process of the question remained text # otherefr ; # refr. [SEP] the [SEP]", "cit": "another interesting research is inui et al? s lexical and syntactical paraphrasing system for deaf students # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "sp have been proven to help many natural language processing tasks that involve attachment de -? partial of this work was done when the first author visiting [SEP]", "cit": "beyond induction on argument classes only, # refr propose a class - toclass model that simultaneously learns sp on both the predicate and argument classes. [SEP]"}
{"pre": "tree kernels have been successfully used in many nlp applications, e. g., parse reranking and adaptation, # refr. [SEP] substr", "cit": "for this purpose, kernel methods, and in particular tree kernels allow for representing trees in terms of all possible subtrees # refr. [SEP] [PAD] [PAD]"}
{"pre": "for example, # refr demonstrated that sentiment analysis helps to detect sentiment analysis on the document set, and the overall sentiment of such a sentence is [SEP]", "cit": "following # refr and the release of the polarity 2. 0 dataset, it is common for sentiment analysis tasks to attempt to classify text segments as [SEP]"}
{"pre": "the approach has been shown to give improvements over the map classifier in many areas of natural language processing including automatic speech recognition # otherefr, [SEP]", "cit": "finally, we use linearised lattice minimum bayesrisk decoding # refr to combine translation lattices # otherefr as produced by rules extracted under each [SEP]"}
{"pre": "we use the hierarchical dirichlet process ( dp ) of learning - based grammars, which have been used for unsupervised part of speech tagging # refr. [SEP]", "cit": "the model of haghighi and # refr incorporated a latent variable for named entity class. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in language independent tasks, # refr disambiguation are mostly focusing on? e. g.,? english, and arabic? [SEP] [SEP] [SEP] [SEP]", "cit": "arabic text is then segmented with amira # refr according to the atb scheme7. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the distribution p ( e | f ) can be defined using the log - linear model # refr. [SEP]. [SEP]. [SEP]. [SEP]. [SEP]", "cit": "another application of hard clustering methods # otherefr or the atr decision - tree part - of - speech tagger # refr. [SEP] [PAD] [PAD]"}
{"pre": "the chinese sentences were word segmented using the 2008 version of the stanford chinese word segmenter # refr. [SEP] segmented the chinese segmentation [SEP] [SEP] [SEP] [SEP]", "cit": "in our experiments we used two state - of - the - art chinese word segmenters : one developed at harbin institute of technology # other [SEP]"}
{"pre": "the third major approach involves extrinsic evaluation, where the parser? s output is used in a downstream task, such as machine translation # otheref [SEP]", "cit": "ssn # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the training data released by the task organizers comes from the nucle corpus # refr, which contains essays written by learners of english as a [SEP]", "cit": "the training data provided for the task is a subset of the nucle v2. 3 corpus # refr, which comprises essays written in english [SEP]"}
{"pre": "the comlex syntax dictionary # refr. [SEP] subject verb consists of verb ( verb, a predicate - argument, a predicate senses ). [SEP] dictionary", "cit": "syntactic lexicons have been derived from other resources? the lingo erg lexicon # otherefr contains entries extracted from comlex # refr, [SEP]"}
{"pre": "simultaneously, mounting efforts have been directed towards smt models employing linguistic syntax on the source side # otherefr ; # refr or both # [SEP]", "cit": "recent research tries to address these issues, by re - structuring training data parse trees to better suit syntax - based smt training # otheref [SEP]"}
{"pre": "in statistical parsing literature, it is common to see parsers trained and tested on the same textual domain # otherefr ; # refra [SEP]", "cit": "this issue can be seen across different parsing models # refr ; gildea, 2001 ; bacchiani et al, 2006 ; mcclos [SEP]"}
{"pre": "the c & c ccg parser # refrb ) is used to evaluate the c & c ccg parser. [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "we perform the same diversity experiment using the depbank - style grammatical relations # otherefr ; # refr output of the parser. [SEP] [PAD] [PAD]"}
{"pre": "the senses in word similarity # otherefr ; # refr. [SEP] the latent variable model by simply taking the representation of the words into a target", "cit": "others have adopted the same underlying idea, using alternative methods and techniques # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we build on a number of existing algorithmic ideas, including using ccgs to build meaning representations # otherefr, building derivations to transform the output", "cit": "many supervised learning frameworks have been applied to the task of learning a semantic parser, including inductive logic programming # otherefr ; # refr and [SEP]"}
{"pre": "in the spirit of recent work in dependency parsing, # refr demonstrated that dependency parsing on the single arc in dependency parsing, followed by arc in malt", "cit": "the performance of joint - p2 + mst - 2 is comparable to the system of huang and sagae # otherefr, who report [SEP]"}
{"pre": "for chinese, we use the stanford corenlp suite # otherefr ; # refr. [SEP] this model is a pairwise coreference [SEP] [SEP]", "cit": "compared 1http : / / nlp. stanford. edu / software / dcoref. shtml with machine learning methods, # [SEP]"}
{"pre": "most ner systems # otherefr ; # refr produce a set of classifiers that employ machine learning techniques to extract information from unlabeled data. [SEP] data", "cit": "in addition, for each o token and ne segment, a confidence score is computed using the constrained forward - backward algorithm # refr, which calculates [SEP]"}
{"pre": "figure 1 shows excerpts from three training examples in the atis corpus # refr. [SEP] ( car ) a sentence from [SEP] text. [SEP]", "cit": "we perform experiments in two benchmark semantic parsing datasets : geoquery # otherefr and atis # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in contrast, in # refr, the authors invoke an hmm ( i. e., a ) solver to be used 1 ) a single label", "cit": "another class of effort reduction techniques is pre - annotation, which uses supervised machinelearning systems to automatically assign labels to the whole data and subsequently let [SEP]"}
{"pre": "# refr has shown that adding part - of - speech ( pos ) tags to improve the accuracy of spoken language systems. [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "reranking has been used in many tasks to find better global solutions, such as machine translation # otherefr, and disfluency [SEP]"}
{"pre": "in previous work, # refr use statistical learning to rank the output of a predicate to label ambiguous coordinate noun phrase. [SEP] ( s ) [SEP] [SEP]", "cit": "finally, we evaluate dsp on a common application of selectional preferences : choosing the correct antecedent for pronouns in text # refr. [SEP] [PAD] [PAD]"}
{"pre": "the surprisal # otherefr ; # refr. [SEP] the current n - gram models ( w ) is a much basic idea [SEP] in the", "cit": "the ranking - based approach has been generalized by surprisal models # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in a multilingual perspective, this has been proposed as a means of linguistic preprocessing by a number of researchers, e. g., well [SEP]", "cit": "unsupervised methods use n - gram statistics # otherefr ; # refr or semantic information # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this work, we use the sentiment polarity classifier, created by # refr. [SEP] the method of # otherefr. [SEP] sa [SEP] the", "cit": "although the task of identifying the overall sentiment polarity of a document has been well studied, most of the work is highly domain dependent and favoured [SEP]"}
{"pre": "in recent years, a number of approaches have been proposed for dealing computationally with selectional preference acquisition # otherefr ; # refr ; mcc [SEP]", "cit": "overwhelmingly, word - net is chosen as the default resource for dealing with the sparse data problem # otherefr ; # refr ; clark [SEP]"}
{"pre": "in english, nombank # refr provides more than 10, 000 sentence 10, and indicate that the proposition bank # otherefr [SEP] [SEP] [SEP]", "cit": "as a complement to propbank, nombank # refr annotates nominal predicates and their corresponding semantic roles using similar semantic framework as propbank. [SEP]"}
{"pre": "in addition to the mt - based method, researchers have also investigated other methods for paraphrase generation, such as the pattern - based methods [SEP]", "cit": "in question answering # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in japanese, the task of using decision lists has been considered to be useful in japanese # refr. [SEP]p problems, [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "a decision list # refr is a sorted list of decision rules, each of which decides the value of class given some features f of an event [SEP]"}
{"pre": "semantic role labeling # otherefr ; # refr. [SEP] the text associated with a syntactic relation between a two annotators and a predicate - argument", "cit": "in this paper, we combine the data from framenet with the lth semantic parser # otherefr, until very recently # refr the semantic [SEP]"}
{"pre": "in answering this question, several pieces of work # otherefr ; # refr have already been proposed. # otherefr described a statistical [SEP]", "cit": "unlike phrase structure labels, function labels are contextdependent and encode a shallow level of phrasal and lexical semantics, as observed first in # refr [SEP]"}
{"pre": "dependency trees are representations of the syntactic structure of a sentence # otherefr ; # refr. [SEP] this paper ) [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "the nlp - community has in recent years witnessed a surge of interest in dependency - based approaches to syntactic parsing, spurred by the con [SEP]"}
{"pre": "dependency unif ication grammar ( dug, # refr ) defines a dependency structure for the representation f syntactic analyses. [SEP] ( 1 ) for", "cit": "a dependency theory of syntactic structure indicates yntactic relations directly between the words of a sentence # otherefr, # refr. [SEP] [PAD] [PAD]"}
{"pre": "1http : / / www. nist. gov / speech / tests / ace / the ace / the ace / the ace / the ace", "cit": "in addition, most of these approaches # otherefr ; # refr is semi - supervised but again relies on the local grammatical context. imposed [SEP]"}
{"pre": "we used a phrase - based smt system # refr to translate the chinese - english source sentence using a chinese - english translation model. [SEP] [SEP]", "cit": "our decoder provides two extensions to moses # refr : # otherefr to efficiently find all discontinuous phrases in the training data that also appear [SEP]"}
{"pre": "concrete consequences of this general abstract setting and applications to empirical data are by limited resources such as wordnet # otherefr, and [SEP] [SEP] [SEP]", "cit": "in the last 4 - 5 years, researchers have begun to introduce compositional operations on distributional semantic representations, for instance to combine verbs with their arguments [SEP]"}
{"pre": "for instance, zollmann et al # otherefr train a lm trained on the target side - side parse trees of the training data using", "cit": "recent innovations have greatly improved the efficiency of language model integration through multipass techniques, such as forest reranking # otherefr ; # [SEP]"}
{"pre": "in addition, we show that the performance of the single word alignment task can be improved by looking for one - countability (? 5 ) [SEP]", "cit": "we applied this matching algorithm to wordlevel alignment using the english - french hansards data from the 2003 naacl shared task # refr. [SEP] [PAD]"}
{"pre": "# refr propose an algorithm that identifies word meanings for terms and their sense disambiguation problem. [SEP] a graph of co - occurrence graphs. [SEP] the", "cit": "in word sense disambiguation ( wsd ), an even narrower context is taken into consideration, for instance in graph based wsd models # [SEP]"}
{"pre": "while a similar direction has been previously explored in # refr, the recent work of # otherefr takes it one step further by not only considering", "cit": "as in some of the recent work on learning semantic representations # refr, we assume that dependency structures are provided for every sentence. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "# refr use morphological information to improve the smt system. [SEP] this approach. [SEP] the morphological information. [SEP] a morphological analyzer and show [SEP] improvements", "cit": "recent research has demonstrated that adding information about word structure increases the quality of translation systems and alleviates sparsity in language modeling # otherefrb ; [SEP]"}
{"pre": "this approach is similar to the conversions in phrase structure parsing # otherefr ; # refr. [SEP] this approach is to our [SEP] [SEP] [SEP]", "cit": "our plan is to take our analogy to tag more seriously # otherefr ) and use a label akin to adjunction to encode leftward [SEP]"}
{"pre": "in the graph - based dependency parsers, hereafter referred to as edge labels, encode the non - projective trees of each dependent words as a [SEP]", "cit": "2nd - order searches, which consider two siblings at a time, are available with no increase in asymptotic complexity # otherefr ; # [SEP]"}
{"pre": "the penn treebank # refr has more than a hundred phrase structure and a syntactic structure, but it has been found to be usefully annotate", "cit": "propbank # otherefr is an annotation of the wall street journal portion of the penn treebank ii # refr with? predicate - argument [SEP]"}
{"pre": "# refrb ) report that self - training can improve the accuracy of parser output by adding punctuation features extracted from the training data. [SEP] [SEP]", "cit": "in contrast, # refra ) report improved accuracy through self - training for a twostage parser and re - ranker. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "in # refr, a mixture model is trained on a subset of target tokens is used to select the most probable list. [SEP] the weights indicating the", "cit": "typical methods used in this direction include dynamic data selection # otherefr and data weighting # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in contrast, the approach used by # otherefr to find the most appropriate pos tags for all words in the text. 2 [SEP] [SEP] [SEP]", "cit": "typically, the local context around the word to be sense - tagged is used to disambiguate the sense # otherefr ; # refr, [SEP]"}
{"pre": "we use mxpost tagger # refr and implemented the word sequence tagger of # otherefr to provide the part - of - speech tags", "cit": "motivated by our goal of representing syntax, we used part - of - speech ( pos ) tags as labeled by a maximum entropy tagger # [SEP]"}
{"pre": "this representation has been used in previous work, e. g., # otherefr ; # refra ). [SEP] phenomena into [SEP] [SEP]", "cit": "since we wish to evaluate the strength of our method alone without any additional nlp effort, we bypass the issue of approximating the true distribution of [SEP]"}
{"pre": "we use the splitmerge method of # refr, and the authors indeed try to infer meaningful temporal expressions in english and chinese # other [SEP] [SEP]", "cit": "of these, heideltime ( stro? tgen and # refr and sutime # otherefr provide particularly strong competition. [SEP] [PAD] [PAD]"}
{"pre": "it has been shown that sentiment information can be used to achieve even for document classification # otherefr ; # refr. [SEP] sentiment [SEP] sentences [SEP]", "cit": "similar to # refr, we therefore argue that global sentiment emanates from the composition of local sentiment. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr explored multiple random fields ( blum ) for an n - best list of k - best lists are introduced by # refr. [SEP] the", "cit": "5 we tune parameters using mert # otherefr with random restarts # refr on the development set. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the second best set was first proposed by # refr. [SEP] non - projective dependency parsers trained on the wall street journal section of the penn tree", "cit": "can we combine the advantages of both approaches, that is, construct an incremental parser 1 # refrb ) is a notable exception : the mst [SEP]"}
{"pre": "on the other hand, the supervised machine learning approach by using latent variables to improve the relation extraction algorithm, recently introduced by # refr. [SEP] [SEP]", "cit": "# refr performed distant supervision using facts obtained from wikipedia infoboxes. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr analyzed the issue of identifying affectiveness as a classification task, which can be used to predict the polarity of a text. [SEP] the [SEP]", "cit": "stylometric analyses, which relies mainly on machine learning algorithms, turned out to be effective in several forensic tasks : not only the classical field of [SEP]"}
{"pre": "depending on the type of output, these models can be divided into two categories : the constituentoutput systems # otherefr ; # refr and [SEP]", "cit": "compared with the constituent - output systems, the dependency - output systems provide a simpler platform to capture the target - side syntactic information, while also [SEP]"}
{"pre": "for instance, the hierarchical translation system of chiang # otherefr, # refr, and discontinuous segmented versions of the europarl corpus #", "cit": "# refr ) for unification - based gra. mmars. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr and zhang et al # otherefr propose the use of morphological analysis for smt. [SEP] the source language as a source [SEP] [SEP]", "cit": "instead, by intelligently expanding the target space using linguistic information such as morphology # refr, or relying on the baseline system to generate candidates similar [SEP]"}
{"pre": "we use a new implementation of the visualisers : the output of image captions, which is based on the image description [SEP] [SEP] [SEP] [SEP]", "cit": "to perform the entire visual pipeline we use vsem, an open library for visual semantics # refr. 5 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "other approaches include the use of wikipedia features in the topic models in the structured classification process # otherefr, # refr, where the text [SEP]", "cit": "in our experiments, we focus on neutrality and style flaws, since they are of particular high importance within the wikipedia community # otheref [SEP]"}
{"pre": "we use the term? representation proposed by # refr for computing the feature weights? for the two feature functions. [SEP] features, using the weighted directed", "cit": "this suggests a new method for generalizing step 2 of the algorithm described in the previous section as follows ( see illustration in figure 3 ) : [SEP]"}
{"pre": "in addition, before the conll - 2011 shared task # refr. [SEP] this problem is treated as a single reference resolution model that is [SEP] [SEP]", "cit": "however, as # refr notes, research on co - reference resolution has mostly been applied to written text ; this task is more difficult in dialogue [SEP]"}
{"pre": "in addition to gold ccg, there has been a wide - coverage tagger that can achieve state - of - the - art accuracy for english", "cit": "treebank there have been some efforts at automatically extracting treebanks of ccg derivations from phrase structure treebanks # otherefr ; [SEP]"}
{"pre": "much work that followed improved upon this strategy, by improving the features ( ng and # refrb ), the type of classifier # otheref [SEP]", "cit": "as another example, denis and baldridge # otherefr and # refr perform joint inference for anaphoricity determination and coreference resolution [SEP]"}
{"pre": "in addition, we also show that the performance of the system is % of the multilingual lexical sample task # refr, as well as in the", "cit": "semeval - 2010 tasks on cross - lingual word sense disambiguation ( lefever and # refr and cross - lingual lexical [SEP]"}
{"pre": "a more powerful backoff model was recently introduced in # refr. [SEP] a factored language model that estimates the probability p ( w [SEP] [SEP] [SEP]", "cit": "in # refr this method was generalized to a backoff model with multiple paths, allowing the combination of different backed - off probability estimates. [SEP]"}
{"pre": "we use a twitter - based architecture which has been shown to be effective in various tasks ranging from sentiment analysis # otherefr [SEP] features [SEP] features", "cit": "the work in # refr partially accounts for this problem and argues that using word bigram features allows improving over bow based methods, where words are [SEP]"}
{"pre": "# refr use a semi - supervised learning algorithm to map unlabeled data from unlabeled data. [SEP] the target in order to improve its accuracy. [SEP] [SEP]", "cit": "we use the standard splits and construct our data set in the following way, following s? # refr : each word in the data wi is [SEP]"}
{"pre": "nivre? s parser has been tested for swedish # otherefr, while mcdonald? s parser has been applied to english # refra [SEP]", "cit": "we report experiments on twelve languages from the conll - x shared task # refr. 5 all experiments are evaluated using the labeled attachment score ( [SEP]"}
{"pre": "it has been shown that a similar approach can be used to rank the output of # refr and is the good summarization # otherefr.", "cit": "# refr explored enhancing single - document summariation using news query logs, which may also be applicable to wikitopics. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "we parse the texts using the berkeley parser # refr. [SEP] ( svm ) and two other classifiers. [SEP] features that are used for machine [SEP] [SEP]", "cit": "as shown by lin et al # otherefr, # refr or wellner et al # otherefr, the context of a connective [SEP]"}
{"pre": "graph - based methods have been used for sentence compression # otherefr ; # refr. [SEP] sentences in word alignment # otherefr [SEP] [SEP]", "cit": "a similar approximation method is also used in # refr for acyclic dependency graphs. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "several supervised learning algorithms have been applied to wsd # otherefr ; # refr. [SEP] the algorithms for nlp problems are done in comparison", "cit": "we think that the study of the domain dependence of wsd - - in the style of other studies devoted to parsing # refr - - is [SEP]"}
{"pre": "recent work by och et al. # otherefr, # refr, and veenstra et al # otherefr, among others.", "cit": "later metrics that move beyond n - grams achieve higher accuracy and improved robustness from resources like wordnet synonyms # otherefr ; # refr [SEP]"}
{"pre": "for instance, the noun number and subject of verb, the subject of a passive - aggressive algorithm has been applied to the wsd problem of [SEP]", "cit": "there has already been evidence of models trained on wsj doing poorly on non - wsj data on parses # otherefr, word [SEP]"}
{"pre": "for example, pleonastic it has been identified using heuristic approaches # otherefr, # refra ) ) ) ) ) ) ) )", "cit": "while researchers who evaluate their resolvers on gold nps point out that the results can more accurately reflect the performance of their coreference algorithm, sto [SEP]"}
{"pre": "most of the previous msc approaches rely on syntactic parsers for producing grammatical compressions, e. g. # otherefr ; # refr.", "cit": "in text domain, # otherefr proposes to use a synchronous context - free grammars ( scfg ) based method to compress the sentence. [SEP]"}
{"pre": "it has been widely used in compressive summarization # otherefr ; # refr. [SEP] ( 1 ) sum ) [SEP] ( s ) [SEP] [SEP]", "cit": "trevor et al proposed synchronous tree substitution grammar # otherefr, which allows local distortion of the tree topology and can thus naturally capture structural [SEP]"}
{"pre": "we show how nivre? s # otherefr parser, and the berkeley parser # refr. [SEP]. [SEP] mcdonald # otheref [SEP] [SEP]", "cit": "the most similar work is that of the conll shared task work # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "sentiment analysis research has been performed to predict the sentiment of words on sentiment analysis # refr. [SEP] sentiment classification of movie reviews # otherefr.", "cit": "for example, sentiment analysis / opinion mining from unstructured user generated content such as online reviews and blogs often relies on learning sentiments from word [SEP]"}
{"pre": "previous approaches to debate stance classification have focused on three debate settings, namely congressional floor debates # otherefr ; # refr, companyinternal [SEP]", "cit": "previous approaches to debate stance classification have focused on three debate settings, namely congressional floor debates # otherefr ; # refr, companyinternal [SEP]"}
{"pre": "instead researchers condition parsing decisions on many other features, such as parent phrase - marker, and, famously, the lexical - head of the [SEP]", "cit": "instead researchers condition parsing decisions on many other features, such as parent phrase - marker, and, famously, the lexical - head of the [SEP]"}
{"pre": "for example, # refr proposed a method based on edit distance measure, that incorporates a combination of probabilistic topic models, and information fusion of [SEP] sentences", "cit": "perhaps the most well - known method is maximum marginal relevance # otherefr, as well as cross - sentence informational subsumption # refr, [SEP]"}
{"pre": "in particular, we use a sentence structure defined by # refr which is a sentence - level label for each node corresponds to a lexical [SEP] a sentence", "cit": "in particular, the development of bleu # otherefr ; # refr and pro # otherefr, to optimize bleu, or [SEP]"}
{"pre": "we also tried the following measures : bleu # refr, ter # otherefr. [SEP] bleu # otherefr, a loose [SEP]", "cit": "we also measured bleu # refr and other automatic evaluation scores to show that head finalization can actually improve the translation quality. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "the availability of robust statistical parsers # otherefr ; # refr based on framenet - based srl systems are also included in the [SEP]", "cit": "srl based on framenet is thus not a novel task, although very few systems are known capable of completing a general frame - based annotation [SEP]"}
{"pre": "we used the stanford dependency parser ( sst and # refr for english ). [SEP] sentiment classification. [SEP] sentiment classification. [SEP] sentiment classification, we presented", "cit": "in this paper we explore the utility of sentiment analysis # otherefr ; # refr and semantic word classes for improving why - question answering ( [SEP]"}
{"pre": "the only difference between the two ( 1 ) and the bestperforming method is that is notoried by a method for resolving _ ( ~", "cit": "as such, these ambig0ities wilt he treated by the general method deserihud in \\ [ # refr \\ ], which [SEP]"}
{"pre": "in addition, since non - projective dependencies are available in the cfg backbone to recover non - local dependencies # refr. [SEP]. [SEP]. [SEP]", "cit": "in addition to cfg - oriented approaches, a number of richer treebank - based grammar acquisition and parsing methods based on hpsg # other [SEP]"}
{"pre": "we show that for three languages, a non - projective dependency parser gives state - of - the - art results for english # refr. [SEP] the", "cit": "data we use data prepared for the conll 2006 / 07 shared tasks # refr. 4 we follow standard practice in removing punctuation and using [SEP]"}
{"pre": "the tarsqi project ( temporal awareness and reasoning systems for question interpretation ) 3 # refr has been developed and a number of other tasks, [SEP]", "cit": "csr has also been added to a state of the art system for detecting textual entailment # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for example, # refr and chambers and jurafsky # otherefr study the conditions for the conditions of this argument. [SEP] frames. [SEP]", "cit": "the knowledge about the likelihood of external causation might be helpful in the task of detecting implicit arguments of verbs and, especially deverbal nouns # [SEP]"}
{"pre": "to measure relatedness, relatedness is an important nlp task that may be more effective in automatically disambiguation systems # otherefr ; # refr.", "cit": "these results are consistent with previous findings # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr report the first automatic decipherment of the zodiac - 408 cipher. [SEP], and then infer [SEP] accurate sampling full [SEP]", "cit": "# refr formulate decipherment as an integer programming problem and provide an exact method to solve simple substitution ciphers by using letter n - gram [SEP]"}
{"pre": "in recent years, statistical machine translation ( smt ) has been rapidly towards the incorporation of domain adaptation # refr. [SEP] this information [SEP] [SEP] [SEP]", "cit": "for example, triggerbased lexicon model # otherefr ; # refr and context - dependent translation selection # otherefr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "we use a statistical tagger # refr to pos - tag the pos - tag set. [SEP] tags [SEP] morphological information. [SEP] the morphological information [SEP]", "cit": "statistic - based algorithms based on belief network # otherefr, lexicalized hmm # refr and maximal - entropy model # otherefr use [SEP]"}
{"pre": "we use the ibm model 1 # otherefr and the hmm model # refr. [SEP] itg channel model # otherefr [SEP] [SEP] [SEP]", "cit": "we define the score of an alignment a and segmentation s in using a model that makes semi - markov independence assumptions, similar to the work in [SEP]"}
{"pre": "in the linguistics community, the nlp community has been done while the nlp community # otherefr ; # refr, it has been shown", "cit": "simply put : the spreadsheet designed by jason # refr for teaching hidden markov models is fantastic. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the features are the same as those in # refr. [SEP] the text e? i. the features, we compute the weights in the maximum score", "cit": "figure 1 : an example of an alignment between an english and a hindi sentence to learn the weights associated with the parameters used in our model [SEP]"}
{"pre": "# refr use morphological analysis on the target side of the parallel data, and thus the morphology of the morphology of a parallel corpus. [SEP] research [SEP]", "cit": "recently, several studies # otherefr ; # refr proposed modeling targetside morphology in a phrase - based factored models framework # otheref [SEP]"}
{"pre": "paraphrase generation can be used for inference while many nlp applications, such as machine translation # otherefr, sentence compression # refr,", "cit": "these include sentence alignment # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the syntactic constraints the english grammar was automatically by the spelling correction # refr. [SEP] and the spelling correction tool preposition errors,", "cit": "the'90s have in fact seen a renewed interest in grammar checking, and proposals have been made for systems covering english # refr and [SEP]"}
{"pre": "the state - of - theart joint models include reranking approaches # otherefr ; # refr, and single - model approaches # [SEP]", "cit": "the state - of - theart joint models include reranking approaches # otherefr ; # refr, and single - model approaches # [SEP]"}
{"pre": "# refr developed an answer validation method which uses information retrieval scores. [SEP] the path between a predicate identification process. [SEP] the dependency structure of [SEP] it", "cit": "# refr apply semantic c? 2008. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in # refr, we showed how to develop a general exicon that can be used to obtain a general exicon from exicon on the t", "cit": "we have parsed w7 ad ject ive def in i t ions # refrb ) us ing sager is l inguist ic [SEP]"}
{"pre": "quantitatively, subjective sentences in the product reviews amount to 78 % # refr, while subjective sentences in the mpqa, we observe that annotators contain", "cit": "the first approach employs opinionfinder # refra ), an off - the - shelf opinion analysis utility. 1 in particular, opinionfind [SEP]"}
{"pre": "this model was trained on each of the english target side, and the sampling of the test set using the minimum error rate training corpus # refr,", "cit": "su et al # otherefr, # refr and bangalore et al # otherefr employ string edit distance between reference and output [SEP]"}
{"pre": "in addition, most smt systems are built with the moses toolkit # otherefr ; # refr. [SEP] this decision trees [SEP] [SEP] [SEP]", "cit": "the log - linear model is also based on standard features : conditional probabilities and lexical smoothing of phrases in both directions, and phrase penalty # refr [SEP]"}
{"pre": "historically, there have been two main approaches to model non - locality : # otherefr ; # refr ), and # otherefr.", "cit": "historically, there have been two main approaches to model non - locality : # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, unlike phonetic transcription schemes, which are often specific to a particular translation lexicon, are well - known to be effective # refr. [SEP]", "cit": "transliterations can be generated for tokens in a source phrase # refr, with o ( f, e ) calculating phonetic similarity rather than orthog [SEP]"}
{"pre": "the pyramid f - score # refr has been used for evaluating content evaluation. [SEP] summarization ( mds ). [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "different methods have been used in the above summarization research to compare system generated summaries with human annotation, such as f - measure, rouge [SEP]"}
{"pre": "the second hypothesis, we used a method described in # refr. [SEP] ( j ) to align the parallel sentences of several sentences [SEP] the [SEP] [SEP]", "cit": "an ir - based method for document alignment is given in # refr, and a feature - based method can be found in # otherefr [SEP]"}
{"pre": "in a similar vein, # refr use a statistical translation model to train a word translation model. [SEP] features from the training data. [SEP] the source", "cit": "# refr focus on the task of noun - phrase translation. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "clarke et al # otherefr describe approaches for learning semantic parsers from questions paired with database answers, while # refr presents work on unsupervised [SEP]", "cit": "semantic parsing is the task of translating natural language utterances to a formal meaning representation language # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the work of # refr, we showed that a lexicalized pcfg augmented on the training data that is available. [SEP] to the training corpus", "cit": "for the specific task addressed in this paper? assigning heads in treebanks? we only know of one earlier paper : # refr. [SEP] [PAD]"}
{"pre": "paraphrases are alternative ways to convey the same information # refr, including automatic paraphrasing, multi - word translation, and lexical substitution #", "cit": "without these resources, researchers have resorted to developing their own small, ad hoc datasets # refr, and have often relied on human judgments to [SEP]"}
{"pre": "as a promising approach to solve the problem of identifying keyphrases such as wikipedia has been studied in # otherefr ; # refr,", "cit": "moreover, citation contexts were used for scientific paper summarization # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "citation context has been explored in several studies # otherefr ; # refr. [SEP] this approach ; mezad et al. [SEP] [SEP] [SEP]", "cit": "we have recently presented a test collection of scientific research papers ( ritchie, teufel & # refr, which we intend to use [SEP]"}
{"pre": "in # refr, the authors modify the minimal rules by incorporating syntactic structure into a phrase - based system. [SEP] a phrase - based system while [SEP]", "cit": "several approaches have been proposed to address these issues : from filtering the extracted synchronous grammar # refr to alternative bayesian approaches for learning minimal grammars # other [SEP]"}
{"pre": "# refr, for example, use syntactic tree adjoining grammars, a range of current lexical resource for english ( e. g. [SEP] lexical", "cit": "this paper explores fine - grained lexical semantic representations? approaches that view a verb as more than a simple predicate of its arguments ( e. [SEP]"}
{"pre": "we use a statistical model to find word occurrences # refr. [SEP] the similarity between two languages. [SEP] the text is [SEP]. [SEP] [SEP] [SEP] [SEP]", "cit": "most of those that achieve text segmentation only rely on the intrinsic characteristics of texts : word distribution, as in # otherefr and # refr [SEP]"}
{"pre": "in order to facilitate the annotation process, we used an annotated corpus of predicate - argument relations ( i. e. explicit german ) and [SEP] the", "cit": "the tred extension for discourse annotation in pdt was first described in m? # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the stanford pos tagger # refr to obtain the perspectives p and l. [SEP]. [SEP]. [SEP] the conditional probability of [SEP] [SEP] [SEP]", "cit": "all data is tokenized, pos tagged # refr and lemmatized, resulting in 341, 557 sense definitions and 3, 563 [SEP]"}
{"pre": "in addition to treating the ambiguous supervision problem as an alignment problem, there are several works # otherefr ; # refr. [SEP] [SEP] [SEP] [SEP]", "cit": "clarke et al # otherefr and # refr trained systems on question and answer pairs by automatically finding semantic interpretations of the questions that would generate [SEP]"}
{"pre": "ilp - based models have been developed for several subtasks ranging from sentence compression # otherefr ; # refr, and headline generation [SEP]", "cit": "ilp - based models have been developed for several subtasks ranging from sentence compression # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the selectional preference has been shown to be useful for tasks such as selectional preference # otherefr and semantic role labeling # refr. [SEP]", "cit": "similarly, erk et al. propose an argument - oriented similarity model based on semantic or syntactic vector spaces # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the features include : a maximum sentence length of 80, grow - diag - final - and symmetrization of giza + + alignments, [SEP]", "cit": "finally, they are binarized into a probing data structure # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for example, smith and smith # otherefr show that joint parsing ( and # refr improve monolingual ). [SEP] the source language sentence to", "cit": "on both english and chinese, the addition of bilingual features improves dependency arc accuracies by + 0. 6 %, which is mildly significant using the [SEP]"}
{"pre": "we use the 50 classes automatically generated by # refr. [SEP] the source and target word order between source and target languages. [SEP] the source [SEP] a", "cit": "word alignment was estimated with giza + + tool2 # otherefr, coupled with mkcls3 # refr, which allows for statistical [SEP]"}
{"pre": "# refr used this method for semi - supervised dependency parsing as a fully supervised learning technique. [SEP] features. [SEP] the current work of brown et al", "cit": "using such techniques # refr report significative improvement on the penn treebank # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used the multeval toolkit # refr for optimizer instability. [SEP]. [SEP]. [SEP] the optimizer process of 4. [SEP] it to", "cit": "we report average scores over optimizer runs and conduct statistical significance tests using the methods described by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the phrase - based statistical machine translation approach # refr has become widely used in the last few years. [SEP] this approach to statistical machine translation. [SEP]", "cit": "multiple phrase - probability feature functions in the log - linear models, including a joint prob - 1a version of portage is made available by [SEP]"}
{"pre": "dependency trees are converted to dependency trees, and use mst parser # refr. [SEP] if they are connected to how well they are non - projective dependency", "cit": "for english, we compare the performance of two dependency parsers, maltparser # otherefr and mstparser # refr, and [SEP]"}
{"pre": "embodiments of this idea include semantic similarity # otherefr, entity repetition # refr, entity repetition # otherefr. [SEP] the text [SEP]", "cit": "indeed, there is a risk that the automatically derived list of cue phrases could be too specific to the word usage in 9as in # refr [SEP]"}
{"pre": "in addition, we plan to incorporate the highly inflection properties, such as the joint probability, and [SEP] ( [SEP] ), a [SEP] [SEP] [SEP]", "cit": "computational corpus studies related to adjectives were performed by \\ [ justeson and katz 1991 ; hatzivassiloglou and mck [SEP]"}
{"pre": "# refr show that for pcfg parsing, unlexicalized parsers are almost equivalent to a simple pcfg model based on statistical model,", "cit": "this was followed by a collection of linguistically motivated propositions for manual or semi - automatic modifications of categories in treebanks # refr. [SEP] [PAD]"}
{"pre": "the translation models were trained using the open - source toolkit jane 2 descent ( och, a gradient descent ) for the machine translation task of learning [SEP]", "cit": "next, we explore a class of models where the stan - 5following # refr, it is customary to combine both these probabilities as feature [SEP]"}
{"pre": "we used bleu # refr, which is the lexical similarity between two output sentences. [SEP] : a reference ( e ) =? [SEP] [SEP] [SEP]", "cit": "the most commonly used metrics, bleu # refr and alike, perform simple exact matching of n - grams between hypothesis and reference translations. [SEP] [PAD]"}
{"pre": "the algorithm has been applied to a large number of text processing applications, including machine translation # otherefr, and lexical acquisition # refr [SEP] [SEP]", "cit": "these problems have recently been the topic of intense research # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we employ a dual decomposition # otherefr ; # refr for performing approximate inference. [SEP] ( 1 ) [SEP]. [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "dependencies 1http : / / w3. msi. vxu. se /? nivre / research / penn2malt. [SEP]"}
{"pre": "the minimum error rate training ( mert ) # refr was used for parameter tuning. [SEP] ( mert ). [SEP] ). [SEP] [SEP] [SEP]", "cit": "we will show that some achieve significantly better results than the standard minimum error rate training of # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the results show that, indeed, using the same methodology can be achieved by means of integrating nlp techniques # refr. [SEP] the [SEP] [SEP] [SEP]", "cit": "the white - board project # refr uses monotonic xml annotation to integrate deep and shallow processing ( figure 2, middle ). [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the beam search algorithm improves parsing flexibility in deterministic parsing # otherefr ; # refr, and dynamic programming # otherefr showed that the efficient", "cit": "# refr suggested a transitionbased projective parsing algorithm that keeps b different sequences of parsing states and chooses the one with the best score. [SEP] [PAD] [PAD]"}
{"pre": "with notable exceptions # otherefr ; # refr supervised approaches to coreference resolution are often realized by pairwise classification of anaphor - antecedent candidates [SEP]", "cit": "with notable exceptions # otherefr ; # refr supervised approaches to coreference resolution are often realized by pairwise classification of anaphor - antecedent candidates [SEP]"}
{"pre": "we used the following resources : wordnet : similarity package # refr to calculate the similarity score between pairs of candidate items. [SEP] the english [SEP] [SEP]", "cit": "the typical approach to semantic relatedness is to either measure the distance between the constituent words by using a knowledge base such as word - net or ro [SEP]"}
{"pre": "we use minimum error rate training # refr to tune the feature weights for the log - linear model. [SEP] bleu score. [SEP]. [SEP] the", "cit": "we use minimum error rate training ( mert ) # refr to tune the decoder. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, we use topic signature words # refr. [SEP] this algorithm. [SEP] the topic of the words plays a role in the same [SEP] in", "cit": "log - likelihood ratio for words in the input number of topic signature words # refr and percentage of signature words in the vocabulary. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "iii, 2010 ; # refr to identify potential translation candidates based on cross - lingual information retrieval # otherefr. [SEP] the [SEP] [SEP] [SEP]", "cit": "additionally, vulic? et al # otherefr constructed several models that utilize a shared cross - lingual topical space obtained by a multil [SEP]"}
{"pre": "in addition, we plan to incorporate event relations on the temporal relation between event entities, and only two systems that were trained to annotate text [SEP]", "cit": "# refr and in - house annotations. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr presented an unsupervised part - ofspeech tagging where the framework is based on a fullylexicalized pcfg model for unsupervised parsing. [SEP]", "cit": "these include ccm # refr, the dmv and dmv + ccm models # otherefr which we use here. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, when there exist a lot of researches for estimating appropriate word order in japanese and chinese. # refr proposed a lot of [SEP] languages [SEP]", "cit": "furthermore, as the related works, there are various researches on word reordering for improving the performance of statistical machine translation # otherefr ; [SEP]"}
{"pre": "# refr used a rule - based language model as features in simple english wikipedia. [SEP] text simplification operations, a classification approach that leverage non - simple", "cit": "# refr, for example, use a tree - based simplification model which uses techniques from statistical machine translation ( smt ) with this data set [SEP]"}
{"pre": "state - of - theart joint models include reranking approaches # otherefr ; # refr, and single - model approaches # other [SEP]", "cit": "jiao et al # otherefr, extended by # refr, reported a semi - supervised crfs model which aims to guide the learning [SEP]"}
{"pre": "the most common algorithm for part - of - speech tagging is the - probability that ( pos ) taggers are based on a set of features [SEP]", "cit": "much research as been done to improve tagging accuracy using several different models and methods, including : hidden markov models # otherefr ; linear separ [SEP]"}
{"pre": "we show that the model for surrounding context can be improved by using the simple additive and multiplicative models of # refr, a vector multiplication [SEP] ( [SEP]", "cit": "a parallel strand of research seeks to represent the meaning of larger compositional structures using matrix and tensor algebra # otherefr ; # refr. [SEP] [PAD]"}
{"pre": "while many other nlp systems that address complex task have focused on identifying contiguous topic boundaries # otherefr, ferna? # refr, fern", "cit": "recent work # refr showed that directed graphical models ( dgms ) outperform other machine learning techniques such as support vector machines ( svms ) for [SEP]"}
{"pre": "in addition, the bionlp 2009 and its proper usage # otherefr ; # refr. [SEP] the recognition of the scientific literature [SEP] the", "cit": "biomedical nlp literature our analysis of temporal trends builds on the idea proposed by # refr in their analysis of the changing trends in the field of [SEP]"}
{"pre": "in # refr, the authors present a corpus of transcribed speeches, we used a subset of the wall street journal corpus ( newspaper ) [SEP]", "cit": "there has been a considerable amount of research on incorporating affect # otherefr # refr # otherefr in computer interfaces, so that, [SEP]"}
{"pre": "# refr and zanzotto et al # otherefr propose the full additive model ( fulladd ), where the two vectors to [SEP]", "cit": "subsequently, other high - dimensional extensions by rudolph and giesbrecht # otherefr, regression models by # refr, and [SEP]"}
{"pre": "in addition, an automatic lexicon of the parses from the english grammars of the hpsg grammars of the hpsg grammars of the hpsg grammars", "cit": "the lingo grammar matrix # refr is a similar tool developed for hpsg that uses a type hierarchy to represent cross - linguistic generalizations. [SEP] [PAD]"}
{"pre": "we annotated our relations like penn discourse treebank ( pdtb ) and the penn discourse treebank ( pdtb ) # refr. [SEP] ( discourse", "cit": "relations between larger segments step 1 is inspired by work done for english in the penn discourse treebank2 # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the feature weights for the log - linear model are optimized using minimum error rate training ( mert ) # refr. [SEP]. [SEP] [SEP] [SEP] [SEP]", "cit": "translation models were trained over the bilingual data that was automatically word - aligned using giza + + # refr in both directions, and the diag [SEP]"}
{"pre": "the impact of different chinese word segmentation methods on ir has received extensive attention in the literature # otherefr ; # refr. [SEP] the [SEP] the", "cit": "despite the superior performance of bigram segmenters # otherefr ; # refra ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the second change occurred with the word alignment model by # refr, was computed among the target words, but the maximum entropy, then aligner #", "cit": "intersection links ( i. e., common to both direct and inverse alignments ) play an important role in creating the final alignment ( och and [SEP]"}
{"pre": "in addition to the regular distance distortion model, we incorporate a forest as a translation process into a translation process as a translation process and a translation process", "cit": "syntax - based preprocessing approaches that have relied on hand - written rules to restructure source trees for particular translation tasks have been quite widely used [SEP]"}
{"pre": "we use the following baseline set of features :? 1. the current similarity score described in # refr. [SEP] ( 1 ). [SEP] [SEP] [SEP]", "cit": "semantic textual similarity ( sts ) estimates can be used for information extraction # refr, question answering # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr use em to learn hidden variables in an hmm. [SEP] incomplete queries. [SEP]ly trained on the same data, using the em [SEP] [SEP]", "cit": "# refr trained a tagger for hebrew using a manually - created lexicon which was not derived from an annotated corpus. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "we used the first - order model of carreras # otherefr and second - order features ( e. g., # refr [SEP]", "cit": "following the work of # refr, we used the mx - post # otherefr tagger trained on training data to provide part - of [SEP]"}
{"pre": "in contrast, the approach described in # refr, a compilation of unification - based grammar is constructed. [SEP]. [SEP]. [SEP] the [SEP] [SEP]", "cit": "this testgrammar is based on the implementation f an analysis of partial vp topicalization i german # otherefr in the troll system [SEP]"}
{"pre": "# refr annotated a chinese treebank, such as the syntactic tree ( chunk ), the dependency structure of a predicate1. [SEP]. [SEP] [SEP]", "cit": "meanwhile, the semantic annotation of pctb mainly deals with the predicateargument structure of chinese verbs in penn chinese proposition bank # refr. [SEP] [PAD]"}
{"pre": "temporal inference or reasoning to solve conflicting temporal expressions and induce temporal order of events has been used in tempeval # otherefr ; # refr", "cit": "the tempeval # refr challenge has led to a number of works on temporal relation extraction # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "unknown words, or out - of - vocabulary # refr, have been the focus of previous words. [SEP] the translation. [SEP] the word [SEP] [SEP]", "cit": "bilingual lexicon induction is the task of learning translations from monolingual texts, and typical approaches compare projected distributional signatures of words in the source language with [SEP]"}
{"pre": "previous srl systems have explored the effects of using different lexical features, and experimented on different machine learning algorithms. # otherefr ; [SEP]", "cit": "the growing interest in learning deeper information is to a large extent supported and due to the recent development of semantically annotated databases such as framenet # [SEP]"}
{"pre": "this setting has been considered before, most notably in # refr, where any translation lexicon is constructed with only a small amount of bilingual lexicon. [SEP]", "cit": "the marked difference in the availability of monolingual vs parallel corpora has led several researchers to develop methods for automatically learning bilingual lexicons, either by [SEP]"}
{"pre": "we evaluate using bleu - 4 # refr and ter # otherefr. [SEP] the optimization of our algorithm. [SEP] the [SEP] the [SEP] [SEP]", "cit": "we report bleu scores # refr on untokenized, recapitalized output. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use mxpost tagger # refr and parsed with the loglinear model. [SEP] the conditional probability of # otherefr to segment the", "cit": "therefore, the base forms have been introduced manually and the pos tags have been provided partly manually and partly automatically using a statistical maximum - entropy based [SEP]"}
{"pre": "in this paper, we focus on shallow parsing, previous work # refr and we assume that x - y can be defined by [SEP] [SEP] [SEP] [SEP]", "cit": "molina and pla # otherefr # refr ), we formulate chunking as a tagging task. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the mda system developed at xrce # otherefr ; # refr uses a combination of word - based translation models based on lexicalized text order", "cit": "the paradigm of translation for monolinguals introduced by kay in 1973 # otherefr ; # refr ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the second - order hmm tagger of # refr, which is a pos - tagging model that is freely available for pos - tagging [SEP]", "cit": "for example, recent research has found that the quality of the tag - dictionary is crucial to the success of such methods # otherefr ; [SEP]"}
{"pre": "our bootstrapping model can be viewed as a form of self - training # otherefr ; # refr ), and statistical machine translation # other", "cit": "our bootstrapping model can be viewed as a form of self - training # otherefr ; # refr ), and cross - category training [SEP]"}
{"pre": "in addition, entity - based models are promising # otherefr ; # refr. [SEP] this model allows a compact representation of the relational between entity", "cit": "recent work has shown that these entity - level properties allow systems to correct coreference errors made from myopic pairwise decisions # otherefr ; [SEP]"}
{"pre": "in addition, we use the inclusion of features ( 1 ) our system is the coreference resolution system # refr. [SEP] this table 1 ) [SEP]", "cit": "specifically, when searching for an antecedent formk, its candidate antecedents are visited in an order determined by their positions in the associated parse tree [SEP]"}
{"pre": "in addition, we show that the system outperforms the state - of - the - art srl systems # refr by combining it with the [SEP] system", "cit": "the resulting f - score of 75. 2 lies even higher than the top score for this particular data set reported in the conll shared task [SEP]"}
{"pre": "the evaluation was done using the m2 method # refr. [SEP]. [SEP] a sequence model built using maximum entropy ( m [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "we use the m2 scorer # refrb ) provided by the organizer of conll - 2013 for the evaluation of our system. [SEP]"}
{"pre": "in recent years, there has been an increasing interest in the task of hedge classification, which has been introduced a trend of work on the task of", "cit": "early work on speculative language detection tried to classify a sentence either as speculative or non - speculative ( see, for example, # refr ). [SEP]"}
{"pre": "several approaches have been proposed to alleviate the annotation burden # otherefr ; # refr. [SEP] this problem to [SEP] the noisy - channel of [SEP]", "cit": "synchronous parsing has seen a surge of interest recently in the machine translation community as a way of formalizing syntax - based translation models # refr. [SEP]"}
{"pre": "# refr use svms to obtain backoff translation quality. [SEP] the error rate training dataset. [SEP] the mt setup used in each round [SEP] [SEP]", "cit": "mturk has been used extensively for annotating and evaluating nlp tasks and has been shown to provide data that is as reliable as other [SEP]"}
{"pre": "to address this problem, # refr proposed to deal with learning subjective language. [SEP] sentences in a product of news text, [SEP] subjectivity [SEP] [SEP]", "cit": "in addition to researches focusing on explicit sentiments # otherefr, or working on inferring implicit opinions # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "zpar # refr performs transition - based dependency parsing with a stack of partial analysis and a queue of remaining inputs. [SEP] sentences of the [SEP] all", "cit": "zpar # otherefr ; # refr performs transition - based dependency parsing with a stack of partial analysis and a queue of remaining inputs. [SEP]"}
{"pre": "we use the dataset introduced by # refr for classification. [SEP] the text classification task of forum conversation discussions, and the dialogue act tagging [SEP] the [SEP]", "cit": "discourse disentanglement is the process of automatically identifying coherent sub - discourses in a single thread ( in the context of user forums [SEP]"}
{"pre": "the cross - lingual textual entailment task # otherefr and # refr, is an extension of the textual entailment task # otheref", "cit": "cross - lingual textual entailment # otherefr ; # refr as an extension of textual entailment # otherefr. [SEP] [PAD] [PAD]"}
{"pre": "the most well - known models that rely on the wordnet similarity between the two words in the text # otherefr ; # refr. [SEP]", "cit": "knowledge - based measures use knowledgesources like thesauri, semantic networks, or taxonomies # otherefr ; # refr. [SEP]"}
{"pre": "# refr use the incremental parser of # otherefr. [SEP] a simplified pcfg which they use the incremental parser of # otherefr [SEP]", "cit": "to avoid some of the early prediction of structure, the version of the roark parser that we used performs an additional grammar transformation beyond the simple [SEP]"}
{"pre": "for example, the parse tree that is produced by a parser will be problematic, # refr. [SEP] if the rules are allowed, [SEP], [SEP]", "cit": "practically, a timeout mechanism and a process for recovery from unsuccessful translation ( e. g., applying the idea of fitted parse # refr [SEP]"}
{"pre": "itg has been extensively explored in unsupervised statistical word alignment # otherefr ; # refr. [SEP] itg aligner # otheref [SEP] [SEP]", "cit": "itg has been extensively explored in unsupervised statistical word alignment # refr and machine translation decoding # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in order to find the optimal solution using the marginal distribution, we adopt the maximum spanning tree ( mst ) framework proposed by # refra ).", "cit": "for dependency parsing, # refr proposed a method which can incorporate some types of global features, and riedel and clarke # otherefr studied [SEP]"}
{"pre": "in recent years, there has been a growing interest in sentiment analysis over the past years, with the advent of microblogs # otherefr", "cit": "# refr make use of three different sentiment detection websites to label twitter data, while davidov et al # otherefr use twitter hashtag [SEP]"}
{"pre": "for example, # refr demonstrated that transfer information from dependency trees derived from dependency trees, and that constituency trees designed for english. [SEP] the english", "cit": "dependency grammars are arguably more robust to transfer since syntactic relations between aligned words of parallel sentences are better conserved in translation than phrase structure # refr. [SEP]"}
{"pre": "as regards the basic tree ( rt ) kernel ( sptk ), an svm - light ) ( tk ) # refr is a tree kernel that", "cit": "reranking appears extremely interesting if coupled with kernel methods # otherefr ; # refr, as the latter allow for extracting from the ranking [SEP]"}
{"pre": "we use a phrase - based smt system # refr to translate phrases as word - alignment. [SEP] a mixture of two alignment [SEP] a [SEP] [SEP]", "cit": "one approach is to leverage underlying word alignment quality such as in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "to determine the polarity of a sentence, we first determine the polarity of the polarity shift - reduce sentence polarity shift ( polarity ) and the polarity of", "cit": "other methods have been proposed which utilize composition of sentences # otherefr ; # refr, but these methods use rules to handle polarity reversal, [SEP]"}
{"pre": "we use the stanford corenlp suite to lemmatize and partof - speech tag each word # otherefr, and dependency [SEP] [SEP]", "cit": "joint parsing of both the source and the target text along with searching for the best alignment between the trees has been approached in a more # other [SEP]"}
{"pre": "iii and # refr. [SEP] this approach is to use coreference features, and the idea of entity - mention detection, as this [SEP] [SEP] [SEP]", "cit": "with notable exceptions # otherefr ; daume iii and # refr supervised approaches to coreference resolution are often realized by pairwise classification of anaph [SEP]"}
{"pre": "we used approximate randomization test # refr for the purpose. [SEP] the sampling of the mt model, we used a simple technique of collins and paired bootstrap", "cit": "work on discriminative reranking has been reported before by och and ney # otherefr, and # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "most commonly, one entity systems # refr find that only entity types are not just a single orthograph, and instead of [SEP], the relationships between", "cit": "14these last two points suggest that the mutation model should operate not on simple ( entity, string ) pairs, but on richer representations in which [SEP]"}
{"pre": "$ $ % & because of the importance of the importance of the tasks of the argument structure of the predicates, i. e., semantic role", "cit": "verbnet has been used in a variety of nlp applications, such as semantic role labeling # refr, inferencing # otherefr. [SEP]"}
{"pre": "expressions determined by wsms several recent works, including lin # otherefr, # refr, # otherefr, and many others. [SEP]", "cit": "in the above model, if a = 0 and b = 1, the resulting model is similar to that of # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "for example, in the context of intelligent essay grading, # refr developed a system that combines automated essays - to - one language with a short", "cit": "research and development in automated essay scoring has begun to flourish in the past five years or so, bringing about a whole new field of interest [SEP]"}
{"pre": "we report results on the bleu # refr, nist # otherefr. [SEP] the bleu - 4 metric # otherefr. [SEP]", "cit": "finally, we used minimum bayes risk decoding # otherefr based on the bleu score # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "so far, scl has been applied successfully in nlp for part - of - speech tagging and parsing # otherefr ; # [SEP] and", "cit": "therefore, whenever we have access to a large amount of labeled data from some? source? ( out - of - domain ), but we [SEP]"}
{"pre": "these features have been used in previous nli tasks # otherefr ; # refr. [SEP] this problem is linear in many respects [SEP] [SEP] [SEP]", "cit": "# refr for the berkeley parser # otherefr ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr proposed a related task of selectional preference modeling that has proven useful for question answering # otherefr. [SEP] features [SEP] natural [SEP] [SEP]", "cit": "# refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in contrast with recent work in statistical parsing, # refr, and hockenmaier and steedman # otherefr. [SEP] this information", "cit": "# refr uses tree adjoining grammar as an alternative to context - free grammar, and here we use another? mildly context - sensitive? [SEP]"}
{"pre": "in addition to the translation model ( tm ), fourteen feature functions are combined : a targetlanguage model that captures the bleu score # refr [SEP]", "cit": "the weight vector? is learned using the minimum error rate training framework # otherefr and bleu # refr measured on nt09 # other [SEP]"}
{"pre": "simple english wikipedia has been previously used for many text simplification approaches # otherefr ; # refr and has been shown to be simpler than normal [SEP]", "cit": "finally, many recent text simplification systems have utilized language models trained only on simplified data # otherefr ; # refr ; improvements in simple language [SEP]"}
{"pre": "in this work, we compare two performance measures : the familiar task of named entity recognizer # otherefr and the chinese word segmentation [SEP] [SEP]", "cit": "lots of efforts have been devoted to semisupervised methods in sequence labeling and word segmentation # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the same idea of using sentence splitting paraphrases extracted from the original text corpus is used by # refr. [SEP] the text t ) [SEP] [SEP]", "cit": "for example, one may want a text to be shorter # otherefr, or more adapted for subsequent machine processing tasks # refr. [SEP] [PAD]"}
{"pre": "to address this problem, some pioneering work in unsupervised learning and distributional similarity measures # otherefr ; # refr, rely on the [SEP] [SEP]", "cit": "some systems, in fact, are dedicated to related problems, such as identifying whether the senses of two synonyms are the same in a particular [SEP]"}
{"pre": "in addition, we have incorporated these systems to content determination by focusing on the user to a database and then attempt to perform some specific interactive [SEP] text", "cit": "for more information on ilex, see knott et al # otherefr and # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the stanford pos tagger # refr was used to tag the english and the stanford pos tagger # otherefr. [SEP]. [SEP] [SEP] [SEP]", "cit": "for lemmatization, the stanford corenlp lemma annotator # otherefr ; # refr is used. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "different formalizations of indirect negative evidence have been incorporated in several computational learning models for learning e. g. grammars # otherefr ; # [SEP]", "cit": "in recent years, with advances in probability and estimation theory, there has been much interest in bayesian models # otherefr ; parisien, [SEP]"}
{"pre": "it has been shown that for many parameter estimation systems # otherefr ; # refr, including expectation # otherefr, [SEP]. [SEP] [SEP]", "cit": "for example, # refr have penalized the approximate posterior over dependency structures in a natural language grammar induction task to avoid long range dependencies between words [SEP]"}
{"pre": "significance testing was performed using approximate randomization # refr, with p < 0. 05. [SEP]. [SEP]. [SEP]. [SEP]. [SEP]. [SEP] [SEP]", "cit": "in each part, statistical significance is computed against the baseline [ b ] by approximate randomization as in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "figure 1 : tree structure with the task of identifying the preposition and determine whether the phrase or not a sentence are known to be [SEP] [SEP] [SEP]", "cit": "in the longer term, we hope to compare different types of parsers in both the preposition selection and error detection tasks, i. e [SEP]"}
{"pre": "text planning : an explicit ordering of propositions ( including the argument positions of an article, a generation component is implemented in the text planner \\ [ #", "cit": "rst was made operational s a technique for planning the structure of paragraphs in # otherefra ) and # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, a number of researchers have built systems to take joint segmentation and part - of - speech tags as well as word clusters # otheref", "cit": "alternative approaches are that of # refr on joint parsing and named entity recognition and the work of # otherefr which uses collocation information to [SEP]"}
{"pre": "we use the ctb dataset from # refr, a ctb - 5 - 6. 0 international chinese word segmentation lattices corpus. [SEP] [SEP] [SEP]", "cit": "# refr found that the first character in a chinese word is a useful indicator of the word? s pos. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this procedure is known as? head - corner parsers # refr, which can be trained on a treebank ; in which they detect [SEP] [SEP]", "cit": "the computational model is based on # refr dependency parsing algorithm. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "continuous representation of words and phrases are proven effective in many nlp tasks # otherefr ; # refr. [SEP] the text [SEP] the [SEP] [SEP]", "cit": "embedding learning algorithms have been extensively studied in recent years # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "three strategies have been proposed : # otherefr ; ( iii ) pre - processing the input sentence with a finite - state trace tagger [SEP]", "cit": "however, with few exceptions # otherefr ; # refr, output trees produced by state - of - the - art broad coverage statistical parser [SEP]"}
{"pre": "in the domain of computer dialog systems, several works # otherefr ; # refr have been proposed. [SEP] this ontology of the [SEP] [SEP] [SEP]", "cit": "frequently, production systems # otherefr or simple word - to - concept lexica # refr are employed for this task. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "following evaluations in machine translation as well as previous work in sentence compression # otherefr ; # refr, we evaluate system performance using f metrics [SEP]", "cit": "most approaches to sentence compression are supervised # otherefr ; # refr following the release of datasets such as the ziff - davis corpus # [SEP]"}
{"pre": "minimum error rate training # otherefr ; # refr, dependency parsing # otherefr. [SEP]. [SEP] this objective due to the model,", "cit": "minimum error rate training # otherefr ; # refr, dependency parsing # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use tinysvm2 along with yamcha3 # refr as the svm training and test software. [SEP] ( 1 ) 2 [SEP] [SEP] [SEP] [SEP]", "cit": "indeed, sequential classification approaches with kernel support vector machines offer competitive performance in pos tagging and chunking # otherefr ; # refr. [SEP] [PAD]"}
{"pre": "in addition, a number of different transition systems have been proposed, in particular for dealing with non - projective dependencies, which were beyond the scope [SEP]", "cit": "a transition - based framework with global learning and beam search decoding # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the resulting system is based on the output of the comic syntax, the systems # refr or a finite verbmobil system # otherefr", "cit": "the underspecified semantic representation technique we have used in this paper reflects the core semantic part of the verbmobil interface term, vit # [SEP]"}
{"pre": "in contrast, the work of # refr, which takes the incremental parsers trained on the penn discourse treebank. [SEP] [SEP] phenomena related [SEP] [SEP]", "cit": "many current parsers fall into the class of historybased grammars # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in our experiments, we use a natural language understanding ( nlu ) # refr, a knowledge - based approach that extends [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "traditionally such semantic knowledge is handcrafted, though some software aids exist to enable greater productivity # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr showed that the similarities between literal and nonliteral use were extracted from the japanese idiomatic expression. [SEP] subjectivity. [SEP] a verb", "cit": "the few token - based approaches include a study by # refr, who devise a supervised method in which they compute the meaning vectors for the [SEP]"}
{"pre": "one way to approach this is by extending the translation model, as described by # refr. [SEP] ( s ) [SEP] ( w ;. [SEP] [SEP]", "cit": "in statistical machine translation # otherefr ; gime? nez and ma ` # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "at this point, we have many different parsing models that reach and even surpass 90 % dependency or constituency accuracy on this test set # [SEP]", "cit": "even for nlp tasks in which structured classification is effective # otherefr ( or? uptraining? # refr ) gives state - of [SEP]"}
{"pre": "a small number of efforts has been dedicated to the simultaneous learning of the probabilities of phrase translation pairs as well as hierarchical reordering, e. g", "cit": "this learning problem is fraught with the risks of overfitting and can easily result in inadequate reordering preferences ( see e. g. # [SEP]"}
{"pre": "unsurprisingly, independent selection of tokens for an output sentence does not lead to fluent or meaningful compressions ; thus, compression [SEP]", "cit": "the extraction by knight and marcu # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "natural language understanding has been well studied in the context of question / answering # otherefr, entailment # refr, sentiment analysis # other [SEP]", "cit": "several studies deal with numerical expressions in the context of information extraction # otherefr, and question answering # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "statistical methods to detect topic segmentation have used the web [ # refr, they are unable to identify main verb errors # otherefr [SEP] [SEP] [SEP]", "cit": "one means of injecting long - range awareness into a language model is by retaining a cache of the most recently seen n - grams which is smoothed [SEP]"}
{"pre": "# refr found that the proposed polarity ( or the concept ) can be used to improve the performance of state - the - art sentiment classification task.", "cit": "we removed 22 legislators with a mixed record, that is, those who gave 20 - 60 % support to one of the positions. 2 [SEP]"}
{"pre": "# refr examine the use of statistical machine translation for text simplification, and the automatic simplification definition of simple english wikipedia. [SEP] a text containing [SEP] a", "cit": "this is similar to the definition of ( cf. # refr ), except that we avoid defining a specific, limited, set of simplification operations [SEP]"}
{"pre": "while many approaches have adapted nlp systems to specific domains # otherefr ; # refr ; daume. [SEP] the cross [SEP] [SEP] [SEP] [SEP]", "cit": "following the set - up of # refr, we experiment on the 263k adjective pairs malouf extracted from the british national corpus ( [SEP]"}
{"pre": "in this paper, we use the? nearest? model of # refr, which constructs a vertex. [SEP] subjectivity and a word onto its context", "cit": "much work on sentiment analysis have been directed to determine the polarity of opinion using anotated lexicons with prior polarity # refr. [SEP] [PAD] [PAD]"}
{"pre": "statistical language models based on large corpora has been examined in # refr for generation. [SEP] text # otherefr they use a statistical [SEP] [SEP] [SEP]", "cit": "the first one, pioneered by # refr, introduces statistics in the generation process by training a model which reranks candidate outputs of a [SEP]"}
{"pre": "the advent of statistical machine translation, and most recently phrase - based approaches ( pbmt, see # refr, koehn et al # [SEP]", "cit": "feature function weights in the loglinear model are set using och? s minium error rate algorithm # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "algorithmic connections in addition to handcurated connections across languages, one could also consider automatic means of mapping across languages, such as using edit distance #", "cit": "first, it throws away information important to sentiment analysis like syntactic constructions # otherefr and document structure # refr that may impact the sentiment [SEP]"}
{"pre": "this is a mixed - initiative dialog as defined by \\ [ # refr \\ ]. [SEP] the problem of dialogue processing [SEP] the task [SEP] it [SEP]", "cit": "# refr described amethod of determining when to include optional warrants to justify a claim based on factors uch as communication cost, inference cost [SEP]"}
{"pre": "in particular, we use recursive neural networks # otherefr ; # refr. [SEP] a recursive neural network ( rnn ) a [SEP] [SEP] [SEP]", "cit": "recursive neural networks # otherefr and extensions # refr, on the other hand, do work with trees of arbitrary shape, but process them [SEP]"}
{"pre": "# refr proposed a method to detect sub - sentential links in parallel sentences. [SEP] the projection of dependency structures. [SEP] the dependency structures. [SEP]", "cit": "previous methods mostly use rule - based parsers for preprocessing # refr, # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr use a very simple decision to identify the selectional preferences to achieve the relative frequencies of the concept given in the same manner. [SEP] [SEP]", "cit": "in # otherefr ) and in discovery of selectional preferences ( e. g., # refr ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "margin infused relaxed algorithm # otherefr ; # refr. [SEP] the optimization of mert with a related mt system. [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "# refr also tuned the parameters with small batches of sentences and optimized a hinge loss not explicitly related to bleu using stochastic gradient descent. [SEP] [PAD]"}
{"pre": "the part - of - speech tagging uses the brill tagger # refr trained on the wall street journal corpus2, was [SEP] [SEP] [SEP] [SEP]", "cit": "the part - of - speech tagging task is performed with high accuracy using an improved version of brill is tagger # refr. [SEP] [PAD] [PAD]"}
{"pre": "in addition to the verbnet project at the university of pennsylvania # otherefr and the framenet project at the framenet project # refr.", "cit": "the knowledge - based approach employed herein # otherefra ) operates on an ontology partially derived from framenet data # refr and is described by [SEP]"}
{"pre": "in addition, we use a bilingual training corpus to obtain the word alignments, which are then used to obtain the word alignment by # refr. [SEP]", "cit": "meanwhile, it is also observed that the phrase pairs that appear frequently in the bilingual corpus are more reliable than less frequent ones because they are more [SEP]"}
{"pre": "in this paper, we describe the upper model for the basic network ( default, upper model \\ [ # refr \\ ] ), and ( 2", "cit": "to enhance the semantic processing in mt systems, many system include conceptual networks called ontologies or semantic taxonomies \\ [ # refr ; carlson [SEP]"}
{"pre": "we use the standard n - gram language model from the english penn treebank to train # otherefr, and the recently proposed by # refr", "cit": "when examples are labeled automatically, through user feedback # otherefr ; # refr, faster learning can reduce the lag before a new system is [SEP]"}
{"pre": "in addition, the averaged perceptron algorithm # refr can achieve substantial improvements in performance. [SEP] the state - of - the - art ner system [SEP]", "cit": "while ner from formal texts has been well studied, relatively little work on ner for twitter was reported. # otherefr described an approach to [SEP]"}
{"pre": "paraphrases allow for more flexible matching of system output against human references for tasks like machine translation and automatic summarization # refr. [SEP] [SEP] [SEP]", "cit": "unfortunately, we have yet to incorporate into the evaluation framework previous findings in paraphrase identification and extraction # otherefr ; # refr. [SEP]"}
{"pre": "artificial ungrammaticalities have been used in various nlp tasks # otherefr the idea of treebanks ( e. g.,", "cit": "this is true of precision grammars, where analyses can be more or less preferred ( see, e. g., # refr, and in [SEP]"}
{"pre": "in contrast, in the ibm models, it is a hidden markov model # otherefr ; # refr, as it has been shown that models", "cit": "some of these models are partially supervised, combining unlabeled parallel text with manually - aligned parallel text # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr used a semi - supervised classifier to detect five documents for text classification. [SEP] features, both the readability of being extracted. [SEP] [SEP]", "cit": "we also explored the discriminative power of other features such as readability features # refr, html tags and named entity tags in genre classification ( table [SEP]"}
{"pre": "cross - lingual dependency parsing is the task of inferring dependency trees for observed sentences in a target language where there are few or no labeled training [SEP]", "cit": "from the perspective of applying deep networks in natural language processing systems, there are a number of works in the literature # otherefr ; # [SEP]"}
{"pre": "this result suggests that the model can be used to model derivations, which is similar to the class of # refr. [SEP] languages like the one introduced", "cit": "similarly, with context free languages, # refr showed that converting between two parametrisations of models for stochastic context free languages are equivalent but that [SEP]"}
{"pre": "we compare lda - sp to several state - ofthe - art methods achieving an 85 % increase in recall precision over mutual information [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "lda - sp? s auc is significantly higher than both similarity - based methods according to a paired ttest with a significance level below 0. [SEP]"}
{"pre": "the model is similar to the one described by # refr. [SEP]. [SEP] ( 1 ) =? i log p ( e | e [SEP] [SEP]", "cit": "in the unsupervised setting, a variety of successful systems have leveraged lexical cohesion # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this type of reasoning has been recognized by the same textual entailment acquisition task # refr. [SEP] the current lexical [SEP] textual entailment methods [SEP] [SEP]", "cit": "automatically learning entailment rules from the web many algorithms for automatically learning paraphrases and entailment rules have been explored in recent years # other [SEP]"}
{"pre": "thus, the ability to distinguish different semantic relations is crucial if approaches to the composition of distributional representations of meaning that are currently receiving considerable interest # [SEP]", "cit": "also of note, # refr propose a vector offset method to capture syntactic and semantic regularities between word representations learnt by a recurrent neural network [SEP]"}
{"pre": "we show that for supervised learning, using the online learning algorithm of l1 - regularized pcfgs, 11. 8 % in our monol", "cit": "one sees this clear trend in the supervised nlp literature? examples include the perceptron algorithm for tagging # otherefr, stochastic gradient for [SEP]"}
{"pre": "the first tagging consists of the text using the lt - xml2 tagger # refr, which has been shown to be useful in [SEP] text [SEP]", "cit": "information on lemmatisation, as well as abbreviations and their long forms, is added using the morpha lemmatiser # refr and the [SEP]"}
{"pre": "in this work, we use the spectral graphbased approach of # refr, where they train a classifier on the entire data set [SEP] features, [SEP]", "cit": "an example of a problem that shows this behaviour is emotion analysis, where the goal is to automatically detect emotions in a text # otherefr [SEP]"}
{"pre": "we use a version of the space - based approach # refr. [SEP] uniqe # otherefr. [SEP] the word w [SEP] uniq", "cit": "given a large corpus of text data, we built the assymetric trigger relation by finding the pairs in the cross - product of the vocabulary [SEP]"}
{"pre": "for example, # refr show that bag - of - words beat for unigrams outperformed bigrams, and unigrams outperform bigrams", "cit": "the way they were added is similar to incorporating the negation effect described by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we find that the most likely compressed feature are models for srl systems # refr, which operate over the full ccg parser. [SEP] if they", "cit": "these were first annotated with semantic roles using a stateof - the - art semantic role labeling system # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the tempeval 2007 shared tasks # otherefr ; # refr, in which the authors present a clear distinction between events and their temporal", "cit": "temporal reasoning has been the focus of several international natural language processing ( nlp ) challenges in the general domain such as ace, tempeval [SEP]"}
{"pre": "thus, some research has been focused on deriving different word - sense groupings to overcome the fine? grained distinctions of wn # otheref [SEP]", "cit": "for many applications ( e. g., information retrieval ) coarsely defined senses are more useful ( see # refr for discussion ). [SEP] [PAD]"}
{"pre": "in a study of feature - based systems on lexical information, # refr report that unifier grammars ( i. e., j [SEP] )", "cit": "the interaction of morphological nalysis with spelling correction # otherefr ; # refr is another possibly fruitful area of work. [SEP] [PAD] [PAD]"}
{"pre": "smadja # otherefr ; zaiu # refr, and the list can be continued. rigid noun phrases # otherefr. [SEP] [SEP]", "cit": "since choosing a classification threshold depends primarily on the intended application and there is no principled way of finding it # refr, we can measure performance [SEP]"}
{"pre": "in addition to the textual information available in open ie, named entity recognition # otherefr and relation extraction # refr. [SEP] the problem [SEP] kernel", "cit": "to address the shortcoming of ds, riedel et al. # otherefr and # refr cast the relaxed ds assumption as multi - [SEP]"}
{"pre": "wysiwym ( what you see is what you meant ) is a user - interface technology through which a domain expert can be used to a", "cit": "# refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "several computational models have been developed to represent and measure sentence readability # otherefr ; # refr. [SEP] features based on [SEP] features [SEP] [SEP]", "cit": "more advanced machine learning techniques such as classification and regression have been applied to the task of reading level prediction # otherefr ; # refr ; [SEP]"}
{"pre": "we used bleu # refr, ter # otherefr to test the translation accuracy. [SEP]. [SEP] the technique of koehn, [SEP]", "cit": "for lattice rescoring, we selected a linear combination of bleu # refr and ter # otherefr as optimization criterion,?? : [SEP]"}
{"pre": "to measure the similarity between sentences, we use the cosine similarity # otherefr and the similarity of the word vectors with n - gram [SEP] [SEP]", "cit": "measures from machine translation evaluation are often used to evaluate lexical level approaches # otherefr, including bleu # refr, a metric based on [SEP]"}
{"pre": "in addition to convote, we incorporate features extracted automatically extracted and labeled entities from twitter ner systems # refr. [SEP] the same dictionary. [SEP] [SEP]", "cit": "in addition finin et. al. # otherefr investigate person name recognizers in email, and # refr apply a minimally supervised approach [SEP]"}
{"pre": "in 2007 the issue of the fine sense granularity of wordnet was addressed in two different semeval disambiguation tasks, leading to the beneficial [SEP]", "cit": "wsd was then performed using the isr - wn network in combination with the algorithm of gutie? rrez # otherefr, [SEP]"}
{"pre": "several supervised dependency parsing algorithms # otherefr ; # refr have been proposed and achieved high parsing accuracies on several treebanks, due in [SEP]", "cit": "for non - projective parsing, the analogy to the inside algorithm is the o # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper, we focus on the hypergraph representation of a particular forest reranking by # refr. [SEP] the algorithm of # otheref", "cit": "an appealing alternative is to rerank the hypergraph directly # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in fact, the goal of tutoring systems is to predict the goal of computer tutoring systems, and the systems will be evaluated as such systems", "cit": "our application is an interactive essay - based personalized learning environment # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr use svms as well as n - gram features in a discriminative tagger. [SEP] the text chunker. [SEP] the results [SEP] [SEP]", "cit": "# refr showed that syntactic patterns, derived by a parser, are more effective than other stylistic features. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used the precomputed alignments that are semantically related to our method, but we can be applied to any kind of bilingual lexicons from an", "cit": "there is a long tradition of research into bilingual terminology extraction # otherefr, # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in # refr, cache - based language models were proposed to combine the probability of a translation model. [SEP] of the probability of a word sequence [SEP]", "cit": "in # refr, adaptation techniques were applied to imt, following the ideas by # otherefr and adding cache language models ( lm ) [SEP]"}
{"pre": "there have been several studies on extractive methods for sentence compression # otherefr ; # refr. [SEP] text compression # otherefr proposed to", "cit": "there have been some studies that have used discourse structures locally to optimize the order of selected sentences # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "linear - chain crfs have been applied to a variety of tasks including named entity recognition # otherefr, relation extraction # refr, sentence [SEP]", "cit": "although oie often has lower precision than traditional information extraction, it is able to extract a wider variety of relations at precision levels that are often [SEP]"}
{"pre": "this model is similar to the one described by # refr. [SEP]. [SEP] - probability p ( w ; w ; w ; w j ) =", "cit": "# refr use contrastive estimation instead of em, while smith and eisner # otherefr use structural annealing which penalizes long - distance [SEP]"}
{"pre": "nivre? s parser has been tested for swedish # otherefr, english # refr, czech # otherefr. [SEP]. [SEP] [SEP]", "cit": "nivre? s parser has been tested for swedish # otherefr, czech # refr, bulgarian # otherefr. [SEP] [PAD]"}
{"pre": "preposition errors are common among japanese learners of english # refr. [SEP], japanese learners of english # otherefr and preposition [SEP] [SEP] [SEP]", "cit": "we treat the task of particle error detection as one of particle selection, and we use machine learning because it has proven effective in similar tasks for [SEP]"}
{"pre": "to evaluate the quality of the generated texts, we use bleu # refr and nist # otherefr. [SEP] ( 1 ) [SEP] [SEP] [SEP]", "cit": "the underlying idea of formula 14 was proposed by # refr as the bleu metric for the semi - automatic evaluation of machine - translation systems. [SEP]"}
{"pre": "# refr use a more general form of a bag - of - words representation, which allows the problem of common representation. [SEP] features. [SEP] this", "cit": "# refr use edit distance as a feature for determining if two words are coreferent. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the context of machine translation, itg has been explored for statistical word alignment in both unsupervised # otherefr ; # refr and supervised [SEP]", "cit": "the common practice of plugging some aspect of a learned itg into either ( a ) a long pipeline of training heuristics and / or ( [SEP]"}
{"pre": "there are several works which treat coreference resolution as an unsupervised problem # otherefr ; # refr. [SEP] the em algorithm [SEP]. [SEP] the", "cit": "em has been previously used for coreference resolution # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the part - of - speech tags from # refr. [SEP] this simple parser and the tagger of # otherefr. [SEP] [SEP]", "cit": "we investigated four individual approaches for the syntax - features? a regular - expression - based quasi - parser, a system based on dekang [SEP]"}
{"pre": "in contrast, bootstrapping approaches # otherefr ; # refr to lexical semantic relations have been used. [SEP] ( snipp [SEP] [SEP] [SEP] [SEP]", "cit": "the main results to date in the field of automatic lexical acquisition are concerned with extracting lists of words reckoned to belong together in a particular [SEP]"}
{"pre": "in this paper, we use svmtool # otherefr to select the top 1000 - best results for all our experiments. [SEP] the method", "cit": "in this manner, previous studies, e. g. # otherefr ; # refr, obtained a level of inter - annotator agreement [SEP]"}
{"pre": "a proposed classifier for noun phrase parsing is designed, which is trained with the cyk parser # refr, and the accuracy measure achieved by a memory", "cit": "an adaptive pruning method for fast hpsg parsing was proposed by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr use statistical measures over the verb - particles, and show that the mwes are usefully in an identification process of mwes as features", "cit": "in a previous study # refr, the authors came up with a dozen possible syntactic forms for verb - object pairs ( based on passiv [SEP]"}
{"pre": "reinforcement learning can be used to learn to read instructions and perform actions in an external world # refr. [SEP] natural language instructions # otherefr.", "cit": "learning to interpret language from a situated context has become a topic of much interest in recent years # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in particular lopez # otherefr use a minimum count threshold for all rules, while # refr describe variational em for rule extraction, and show significant", "cit": "in particular lopez # otherefr use a minimum count threshold for all rules, and # refr propose a finer - grained filtering strategy based [SEP]"}
{"pre": "several approaches have been developed specifically for learning from english, including : the examples of an english resource, and the other languages for the ws [SEP] coverage", "cit": "currently, the best - performing english np interpretation methods in computational linguistics focus mostly on two consecutive noun instances # otherefr, # refr, [SEP]"}
{"pre": "in addition to the regular distance distortion model, we incorporate a maximum entropy model # refr that is used to construct a large amount of automatically [SEP] the", "cit": "the machine alignments were generated using a supervised maximum entropy model # refr and then corrected using an improved correction model # otherefr. [SEP] [PAD] [PAD]"}
{"pre": "in this paper, we show how nivre? s # otherefr normal - form constraints built from the parallel tree - adjoining [SEP]", "cit": "rambow, wier and vijay - shanker themselves introduce d - tree grammar # refr and candito and kahane introduce [SEP]"}
{"pre": "clarke et al # otherefr describe using distant supervision, # refr use weak supervision from conversational logs and goldwasser et al # [SEP]", "cit": "in this respect, our work relates to models for grounding language, where semantic parsing techniques are used to automatically map linguistic instructions to domain - [SEP]"}
{"pre": "in senseval - 2, the best performing system # refr achieved an f - score on the senseval - 3 english lexical sample task, [SEP]", "cit": "the percentage of official training data used as tagged data ssubset = { s1 }, 42. 8 % ssubset = { [SEP]"}
{"pre": "# refr and villavicencio et al # otherefr use supervised learning to rank english verb constructions. [SEP] subjectivity and object (", "cit": "earlier studies on the detection of light verb constructions generally take syntactic information as a starting point # otherefr ; # refr, that is, [SEP]"}
{"pre": "for evaluation, we use bleu scores # refr, which are the most widely used in moses - oracle. [SEP] the [SEP] [SEP] [SEP] [SEP]", "cit": "for mce learning, we selected the reference compression that maximize the bleu score # refr ( = argmaxr? rbleu ( r [SEP]"}
{"pre": "in the part - of - speech hterature, whether taggers are based on a rule - based approach # otherefr, # [SEP]", "cit": "the same kind of idea is developed in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for example, # refr reported that a classifier trained on lexical aspect features. [SEP] features derived from the verbs onto an event ( only ). [SEP]", "cit": "table 2 : privative featural identification of aspectual classes # refr ; dorr, to appear ) and assigned lcs templates from [SEP]"}
{"pre": "since the initial release of the penn treebank # otherefr ; # refr ). [SEP] the context of a word must be broken [SEP] into", "cit": "morphological analysis or segmentation is crucial to the performance of several applications : machine translation # otherefr, and syntactic parsing # refr. [SEP] [PAD] [PAD]"}
{"pre": "in recent years, chinese semantic role labeling has received much research effort # otherefr ; # refr. [SEP] this paper [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "we first extend the study on chinese shallow parsing presented in # refr by raising a set of additional features. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "dependency parsers have been tested on parsing sentences in english # otherefr ; # refr. [SEP] the parsers trained on the same [SEP] [SEP]", "cit": "dependency parsing has been intensively studied in recent years # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr used a bag of words on pos - tags to create new information and show that the information of the information contained in the sentences cannot be", "cit": "other works have used a different strategy to reduce the imbalance between positive and negative samples # otherefr ; # refr, where only samples composed [SEP]"}
{"pre": "this is because the set of features consists of longer phrases ( 1. 6 ) in terms of monolingual features ), the relative frequency of the", "cit": "more recent work # refr has shown that properties of reordering, source and target language complexity and relatedness can be used to predict translation quality. [SEP]"}
{"pre": "# refr extend this approach to this general application areas. [SEP] this problem in computational linguistics that it has been shown to be effective in various [SEP] tasks", "cit": "these works adhere to a fully latent representation of meaning, whereas # refr assign symbolic attribute meanings to adjectives, nouns and composed phrases by incorporating [SEP]"}
{"pre": "we use the exicons described by # refr. [SEP] the patterns of a lexical database \\ [.........", "cit": "another application for which a sprouted synonym tree is useful is third - generation - line dictionary systems # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "previous work on automatic text simplification has shown that a rich feature space such as # otherefr ; # refr and simplification # other [SEP] [SEP] [SEP]", "cit": "text simplification has also been shown to improve the performance of other natural language processing applications including semantic role labeling # refr and relation extraction # otheref [SEP]"}
{"pre": "the lexicalized pcfgs use the lexicalized pcfg probabilities for each pcfg which was transformed by the lexicalized pcfg probabilities in tree", "cit": "# refr, model 2 ) uses a more sophisticated model in which all arguments in this sequence are generated jointly, as in a treebank grammar [SEP]"}
{"pre": "permutation parsers have been used to implement hierarchical re - ordering models # refr and to enforce inversion transduction grammar # otherefr. [SEP] the it", "cit": "in particular, we show that an existing itg constraint # refr does not prevent all non - itg permutations, and we demonstrate that the [SEP]"}
{"pre": "in contrast, dynamic programming techniques that allow the efficient dynamic programming of a projective parser have been proposed # refr. [SEP] to solve the problem [SEP] [SEP]", "cit": "dynamic programming for the simulation of arc - standard parsers have been proposed by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for instance, # refr show that the constraints yield better alignment coverage than the ibm models for statistical machine translation ( smt ). [SEP] a [SEP]", "cit": "this problem has received a lot of attention in the literature # otherefr, # refr, al - onaizan and papinen [SEP]"}
{"pre": "as usual, we calculate the score of a candidate by the dot product between a high dimensional feature and a weight w : score ( y ) [SEP]", "cit": "this data setting is the same as in # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr ). [SEP] the recognition of the utterances ( e. g. [SEP] the entropy of candidates for dependency or between two sentences ). [SEP]", "cit": "erbach # otherefr, # refr and fouvry # otherefr followed a unification - based symbolic approach to unknown word [SEP]"}
{"pre": "this similarity is computed by a combination of features proposed by # otherefr ; # refr for the representation of lexical items rather than [SEP] the word", "cit": "we adopted the smoothed partial tree kernel ( sptk ), defined in # refr : it is convolution kernel that allows to measure the similarity between [SEP]"}
{"pre": "# refr use machine translation for multilingual sentiment analysis. [SEP] the cross - lingual sentiment analysis framework. [SEP] the subjectivity analysis [SEP] translation of", "cit": "# refr use machine translation for multilingual sentiment analysis. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "commandtalk # otherefr and tl : tains - 96 # refr are spoken language systems but they interface to simulation or help facilities rather [SEP]", "cit": "commandtalk # otherefr and trains - 96 # refr are spoken language systems but they interface to simulation or help facilities rather than semi - [SEP]"}
{"pre": "to evaluate the wordnet wsd algorithm we use # refr and thesaurus based wordnet # otherefr. [SEP] random walks [SEP] random", "cit": "we applied pagerank and personalized pagerank on the wikipedia graph using freely available software # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr use ilp to find the global optimization and show significant gains. [SEP] improvements in multi - document summarization. [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "for example, # refr used it to model the hidden abstract concepts across documents as well as the correlation between these concepts to generate topically coherent [SEP]"}
{"pre": "subsequently, other high - dimensional extensions by rudolph and giesbrecht # otherefr, # refr and grefenstette [SEP]", "cit": "subsequently, other high - dimensional extensions by rudolph and giesbrecht # otherefr, and recursive neural network based solutions by [SEP]"}
{"pre": "dependency parsers have been tested on parsing sentences in english # otherefr ; # refr as well as many other languages # otherefr.", "cit": "for instance this could mean separating parentheticals or separating appositions # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr use the same set of pos categories and use them to induce syntactic clusters. [SEP] tokens. [SEP] the same dictionary of tokens. [SEP] a", "cit": "there is also work on alternative unsupervised models that are not hmms # otherefr ; # refr ; reichart et al, 2010b [SEP]"}
{"pre": "in 2012 we applied our baseline features based on the full textual similarity ( sts ) task # refr. [SEP] the sts model by [SEP] the [SEP] [SEP]", "cit": "similarly, s # refr used a support vector regression model which incorporates features computed from sentence pairs. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr reports negative results for self - training in the training scenario collins parser # otherefr. [SEP] the same training approach. [SEP] [SEP] [SEP]", "cit": "table 1 shows that parser accuracy increases with the size of the in - domain selftraining material. 3 the figures confirm the claim of mcclos [SEP]"}
{"pre": "continuous semantic space representations have proven successful in a wide variety of nlp and ir applications, such as document clustering # otherefr, and [SEP]", "cit": "continuous semantic space representations have proven successful in a wide variety of nlp and ir applications, such as document clustering # otherefr ; # [SEP]"}
{"pre": "there have been some recent attempts at the unconstrained problem of generating a sentence from a multi - set of input words # otherefr ; # refr", "cit": "in fluency improvement # refr, parts of translation hypotheses identified as having high local confidence are held fixed, so that word ordering elsewhere is strictly local [SEP]"}
{"pre": "in english, most of the remaining words are not 2. 2. 4 %, and we follow the same approach used in # other [SEP] [SEP]", "cit": "much work has been done on automatic arabic diacritization # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we have implemented our method, which is an extension of the one - to - one module, and the three string comparison method proposed by # refr", "cit": "it is worth noting that this algorithm is used in many modern unification grammar - based systems, e. g., the lkb system [SEP]"}
{"pre": "# refr use a tagger to find part - whole relations. [SEP] patterns of both identified by a list of ambiguous name. [SEP] subjectivity [SEP]", "cit": "for example, our goal in this project is to extract he binding predications in ( 2 ) from the text in ( 1 ). ( [SEP]"}
{"pre": "finally, we are investigating several avenues for extracting paraphrases from twitter # otherefr ; # refr. [SEP] the source [SEP] [SEP] [SEP]", "cit": "also relevant is recent work on collecting bilingual parallel data from twitter # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr used supervised learning algorithms on a parallel corpus for wsd. [SEP] english, both supervised learning algorithms. [SEP] features and [SEP] [SEP] features [SEP]", "cit": "for instance, salaam has been used to bootstrap the wsd process for arabic as illustrated in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "morphology - based pos tagging of some languages like turkish # otherefr, czech # refr, modern greek # otherefr has been tried [SEP]", "cit": "the work on hindi pos tagging # refr comes closest to our approach which showed that using a detailed linguistic analysis of morphosyntactic phenomena [SEP]"}
{"pre": "in addition, we used a bilingual language model # refr to generate the source - side bigram language model. [SEP] the [SEP] [SEP] [SEP] [SEP] the", "cit": "therefore, different approaches to increase the context available during decoding have been presented # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in # refr, bikel # otherefr are good in the conll? 09 shared task, which mainly focuses on domain adaptation, [SEP]", "cit": "many approaches based on memm # refrb ), crfs # otherefr and hybrid models have been tried for hindi named entity [SEP]"}
{"pre": "among the latter, there are nlp applications such as the detection of lexical errors # otherefr, paraphrase detection # refr, parap", "cit": "among the latter, there are nlp applications such as the detection of lexical errors # otherefr and bias detection # refr. [SEP] [PAD] [PAD]"}
{"pre": "we parse the sentences with the stanford parser # refr and extract dependency relations. [SEP] sentences # otherefr are constrained by the stanford parser # [SEP]", "cit": "the articles were parsed using the stanford parser # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we drop the general state behavior of mbot and replace it by the common locality tests that are also present in stsg, stsg, [SEP]", "cit": "# refr and graehl et al # otherefra ) show that the additional expressive power of treesequences helps the translation process. [SEP]"}
{"pre": "nielsen # otherefr manually built a sentiment lexicon specialized for twitter, while others have tried to induce such lexica automatically with good results # [SEP]", "cit": "though classifiers built with machine learning algorithms have become commonplace in the sentiment analysis literature, e. g., # refr, the core of [SEP]"}
{"pre": "this is often approached as a problem in unsupervised learning, where the only information available is a large corpus of text ( e. g., [SEP]", "cit": "the objective of this research is to extend previous work in discrimination by # refr, who developed an approach using agglomerative clustering. [SEP] [PAD] [PAD]"}
{"pre": "while these approaches have been shown to improve the performance of supervised machine learning approaches for natural language processing # otherefr ; # refr, discourse [SEP]", "cit": "3. 3. 1 evaluating meeting summaries to evaluate meeting summaries we use the weighted f - measure metric # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "because of the cost and difficulty in treebank construction, researchers have also investigated the utilization of unannotated text, including the unsupervised parsing [SEP]", "cit": "because of the cost and difficulty in treebank construction, researchers have also investigated the utilization of unannotated text, including the unsupervised parsing [SEP]"}
{"pre": "this has led to considerable interest in unsupervised relation discovery # otherefr ; # refr. [SEP] distributional semantics # otherefr [SEP] [SEP] [SEP] [SEP]", "cit": "1http : / / wiki. answers. com / research in ie has been moving towards the goal of extracting facts from large text corpora [SEP]"}
{"pre": "wacholder and choi, 1997 ; cucerzan and yarowsky, 1999 ) and word sense disambiguation ( wsd ) [SEP]", "cit": "wacholder and choi, 1997 ; # refr and word sense disambiguation # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the best system in senseval - 3 # otherefr achieved 72. 9 % fine grained, 79. 3 % [SEP] [SEP] [SEP] [SEP]", "cit": "we also consider the system ku, which uses a very large language model and an advanced treatment of smoothing, and which performed well at els [SEP]"}
{"pre": "we parse the english side of our parallel corpus with the berkeley parser # refr. [SEP] the berkeley parser # otherefr. [SEP] the [SEP] [SEP]", "cit": "by annotating syntactic categories with their distributional representation, the method emulates lexicalized approaches # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "three strategies have been proposed : # otherefr ; # refr to recover empty nodes and identify their antecedents ; 1 # otherefr.", "cit": "rich annotations of corpora has allowed for the development of techniques for recovering deep linguistic structures : syntactic non - local dependencies # refr and semantic arguments # [SEP]"}
{"pre": "in smt, the performance of bilingual lm adaptation has been well studied extensively # otherefr ; # refr ). [SEP] the source [SEP] [SEP]", "cit": "these schemes are overall limited by the quality of the translation hypotheses # refr, and better initial translation hypotheses lead to better selected sentences # otheref [SEP]"}
{"pre": "thus, the ability to distinguish different semantic relations is crucial if approaches to the composition of distributional representations of meaning that are currently receiving considerable interest # [SEP]", "cit": "besides, there exists some research focusing on word sense subjectivity disambiguation, which aims to classify a word sense into subjective or objective # other [SEP]"}
{"pre": "the user response, or a similar question, but disallow need to combine by allowing us to use of decision discussions # refr. [SEP] the [SEP]", "cit": "the notion of a cooperative response has been the focus of considerable research in natural anguage and spoken dialogue systems # otherefr ; # refr [SEP]"}
{"pre": "# refr proposed a method that combines the gibbs sampler of global inference procedures. [SEP] a gibbs sampler to model in the past two tasks : word segmentation", "cit": "recently, the hierarchical dirichlet process ( hdp ) model has been used as a smoothed bigram model to conduct word segmentation # refr. [SEP] [PAD]"}
{"pre": "we use minimum error rate training # refr to tune the feature weights to maximize the system? s bleu score on the development set. [SEP] [SEP]", "cit": "the feature weights were tuned on the wmt newstest2008 development set using mert # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the pdtb, we evaluate the approach of discourse connectives in english and chinese # otherefr and the the the english discourse [SEP] [SEP]", "cit": "other important contributions to automatic discourse connective classification and feature analysis has been provided by # refr and elwell and baldrige # otherefr [SEP]"}
{"pre": "for chinese, we use the stanford word segmenter # refr and pos tagger # otherefr. [SEP], we used [SEP] [SEP] [SEP] [SEP]", "cit": "we use kytea # otherefr to tokenize the japanese data and stanford word segmenter # refr to tokenize the chinese data [SEP]"}
{"pre": "to identify explicit opinion holders, we used the subjectivity lexicon provided by mpqa opinion # refr. [SEP] the opinion polarity lexicon. [SEP] [SEP]", "cit": "we first combine three popular sentiment lexicons to form a single sentiment lexicon : the lexicon used in hu and liu # otherefr, mp [SEP]"}
{"pre": "in addition, we use the mpqa subjectivity lexicon # refr, which contains approximately 8000 words which may be used to express opinions. [SEP]", "cit": "a growing nlp subfield detects private states such as opinions, sentiment, and beliefs # refr from text. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use a phrase - based smt system # refr to translate the german source sentence and target word sequence as features. [SEP] [SEP] the [SEP] [SEP]", "cit": "in this evaluation, we used two extensions to this work as shown in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper, we focus on the subjectivity classification of sentiment polarity ( a ) and a particular word, as well as the subjectivity [SEP]", "cit": "independently of any specific task, # refr present a completely unsupervised method for determining the polarity of adjectives in a large corpus. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "scfs can be used, for example, in the system of # refr, which acquire scfs an important grammar for scf disambiguation [SEP] the", "cit": "automatic acquisition of scfs has therfore been an active research area since the mid - 90s # otherefr ; # refr. [SEP] [PAD]"}
{"pre": "we use nombank # refr for the general nlp tool. [SEP] these features to annotate the sentence and annotate them. [SEP] the [SEP]", "cit": "second, recent extension of semantic role labeling to the argument structure of nouns # refr increases the interest in lexicographic methods for the extraction of noun [SEP]"}
{"pre": "while such data contains noise, it has been shown to be useful in practice # refr. [SEP] for relation extraction. [SEP] supervision [SEP] text [SEP] [SEP]", "cit": "# refr also used a small seed set and a search engine, but they collected sentences via queries containing both the question and the answer entities, [SEP]"}
{"pre": "we combine this model with a sparse prior technique # refr and propose mixture model interpolation techniques to combine translation features from two sources : data [SEP] domain and", "cit": "as domain - aware benchmark systems, we use the phrase table fill - up method # otherefr which preserves the translation scores of phrases from [SEP]"}
{"pre": "in the area of document summarization, paraphrase recognition is arguably one of the most important lexical and syntactic transformations # otherefr or [SEP]", "cit": "this is related to the wellstudied problem of identifying paraphrases # otherefr ; # refr and the more general variant of [SEP]"}
{"pre": "we parse the english side of our parallel corpus with the berkeley parser # refr. [SEP] the berkeley parser # otherefr. [SEP] the [SEP] [SEP]", "cit": "samt and ghkm grammar extraction require a parse tree, which are produced using the berkeley parser # refr, or can be done outside the [SEP]"}
{"pre": "the recent approaches considering ts as an mt task, such as specia # otherefr, and transformationbased learning # refr, may be used", "cit": "as in confirmation with the text simplification definition as the? process for reducing text complexity at different levels? # otherefr ; # refr, [SEP]"}
{"pre": "in particular, abstraction mechanisms ( cf. # refr ) calculate thesaurus structure for two types of entities. [SEP] the [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "ill a way, our idea is the mirror image of # refr, who used wordnet to identify lexical chains that would coincide with cohesive [SEP]"}
{"pre": "two different metrics helped estimate the quality of a dataset : windowdiff # otherefr and b3 # refr. windowdiff is computed by [SEP]", "cit": "it is quite possible that a better metric than the one proposed here can be devised ; see, for example, # refr # otherefr [SEP]"}
{"pre": "in addition, while their use in machine learning algorithms, so we show that the learned decision trees # otherefr, # refr, [SEP] features", "cit": "datasets : ace 2004 contains 443 documents? we used a standard split of these documents into 268 training, 68 development, and 106 testing documents [SEP]"}
{"pre": "the co - occurrence algorithm of the large vocabulary of text with words # refr. [SEP] the window size of word alignment. [SEP] the [SEP] [SEP] the", "cit": "use of roughly aligned corpora has also been proposed in ( dagan and # refr for word alignment in bilingual corpora, where statistical techniques have been [SEP]"}
{"pre": "in addition, factored translation models # otherefr are also used as part of the factors which are more informative when they are merged later [SEP]", "cit": "factored model # refr : we tried to integrate a target pos factored model into our system with a 9 - gram pos language model to [SEP]"}
{"pre": "several other approaches have recently been developed specifically for learning from inference # otherefr ; # refr. [SEP] this paper ) grounding [SEP] [SEP] [SEP]", "cit": "recent work # refr has developed learning algorithms for the problem of mapping sentences to their underlying semantic representations. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the second international chinese word segmentation bakeoff # otherefr, two of the highest scoring systems in the closed track competition were based [SEP]", "cit": "by analyzing the top results in the first and second bakeoffs, # refr and # otherefr, we found the top results were [SEP]"}
{"pre": "# refr used mdl for word segmentation. [SEP] languages to learn from a semi - supervised morfessor for japanese. [SEP] languages, [SEP] [SEP]", "cit": "especially, methods that perform morphological segmentation have been studied extensively # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for assessment of content, the focus is traditionally on content assessment for question answering # otherefr ; # refr. [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "to that end, we present results with the comic - en content assessment system # refra ) on the dataset published by mohler et [SEP]"}
{"pre": "several learning systems have been developed for semantic parsing, many of them recently # otherefr ; # refr. [SEP] the availability of annotated corpora [SEP]", "cit": "many supervised learning frameworks have been applied to the task of learning a semantic parser, including inductive logic programming # otherefr ; # refr, [SEP]"}
{"pre": "we parse the chinese sentences with a chinese treebank # otherefr and parse the chinese sentences with the berkeley parser # refr. [SEP] the word", "cit": "we word - aligned the training data using giza + + with refinement option? grow - diag - and? # otherefr, and [SEP]"}
{"pre": "in petrov and klein # otherefr, # refr, latent head - corner parsing is used to induce latent variable grammars for pcfg [SEP]", "cit": "in latent variable parsing # refr, we learn rule probabilities on latent annotations that, when marginalized out, maximize the likelihood of the unann [SEP]"}
{"pre": "nivre? s parser has been tested for swedish # otherefr, english # refr, german # otherefr. [SEP]. [SEP] [SEP]", "cit": "the conll - x shared task # refr made a wide selection of standardized treebanks for different languages available for the research community and allowed [SEP]"}
{"pre": "we will show how correctly disambiguation the senseval - 3 english lexical substitution task we used semeval - 2007 # refr and semeval", "cit": "existing hand - annotated corpora like semcor # refr, which is annotated with wordnet senses # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the msa pos tagging and the arabic morphological analyzer mada # otherefr ; # refr. [SEP] a prefix dependency analyzer and then [SEP] [SEP] [SEP]", "cit": "# refr show that unsupervised methods for learning da tokenization can outperform msa tokenizers on mt from levantine arabic to english. [SEP] [PAD] [PAD]"}
{"pre": "in the context of machine translation, itg has been explored for statistical word alignment in both unsupervised # otherefr ; # refr and supervised [SEP]", "cit": "on each iteration of em, we perform two passes : a coarse pass using a low - order language model, and a fine pass using a [SEP]"}
{"pre": "# refr use morphological analysis on the target side to improve translation quality. [SEP] languages, which are designed for building a morphological analyzer [SEP] [SEP] [SEP] [SEP]", "cit": "prepositions attach to the head - word of their 4 # refr uses the first four letters of german words after morphological stripping and compound [SEP]"}
{"pre": "we use minimum error rate training # refr to tune the feature weights to maximize the system? s bleu score on the dev2008 data,", "cit": "in order to highlight the data selection work, we used an out - of - the - box moses framework using giza + + # [SEP]"}
{"pre": "several studies have shown that the web search can be efficiently trained with the help of an nc interpretation # otherefr ; # refr. [SEP] [SEP]", "cit": "# refra ) used pattern clusters to disambiguate nominal compound relations. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr applied the log - linear model ( i. e., linear ) to estimate the probability of a word as a distribution over [SEP] a", "cit": "guevara # otherefr and # refr explore a full form of the additive model ( fulladd ), where the two vectors entering [SEP]"}
{"pre": "in the repubblica - deppath model, we preserve the paths as part of the features # refr. [SEP] the distributional similarity and [SEP]", "cit": "in addition, work in automatic lexical acquisition is based on the proposition that distributional similarity correlates with semantic similarity # otherefr ; # refr. [SEP]"}
{"pre": "2. 1. 2 supervised approaches this line of research work approaches this relation prediction problem by recasting it as a classification problem. # [SEP]", "cit": "many multi - task learning methods have been proposed in recent years, # refra ), # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr showed that for spelling, unknown words are not very useful in speech processing tasks, but rather several language modeling [SEP]. [SEP].", "cit": "nevertheless, clear improvements over a word baseline have been achieved for serbo - croatian # otherefr, finnish, estonian # [SEP]"}
{"pre": "we evaluated our joint model on syntactic and semantic dependency relations ( and # refrb ) by comparing the conll 2003 shared tasks on syntactic and semantic", "cit": "some dependency parsing systems prefer two - stage architecture : unlabeled parsing and dependency classification # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr and # otherefr. [SEP] distributional models correlations between two words, compared to a simple string in a phrase - based model [SEP] [SEP]", "cit": "tfp # refr? s model is also sensitive to selectional preferences, but to two degrees. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this model has been shown to be effective for segmentation of morphology # otherefr and multilingual learning # refr. [SEP] languages [SEP] the [SEP] [SEP]", "cit": "minimum description length # otherefr ; # refr attempted word segmentation and joint segmentation of related languages using bayesian approach. # otherefr explored [SEP]"}
{"pre": "we used bleu # refr, ter # otherefr to evaluate the quality of the translation output. [SEP] the current n - gram [SEP] [SEP]", "cit": "including about 1. 4 million sentence pairs extracted from the gigaword data, we obtain a statistically significant improvement from 42. 3 to 45 [SEP]"}
{"pre": "in particular, we extend the lda model of # refr, which has been applied to a large number of tasks, including document - specific topic [SEP]", "cit": "our particular model, linklda, has been applied to a few nlp tasks such as simultaneously modeling the words appearing in blog posts and users [SEP]"}
{"pre": "this is in line with # refr and it has been tested on a number of systems working with grammatical functions. [SEP] natural language processing [SEP] [SEP] [SEP]", "cit": "the conceptual input into the formulatorin short : cs for \" conceptual structure \" - is represented in the refo / retn format # [SEP]"}
{"pre": "the only comparable architecture so far was described by # refr, but they did not produce a deep parser for german with real - world german, but", "cit": "# refr and frank et al # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the baseline system is trained using the discriminative word alignment model of # refr. [SEP] - crfs a discriminative word alignment model, which can model [SEP]", "cit": "in recent years several authors # otherefr ; # refr proposed discriminative word alignment frameworks and showed that this leads to improved alignment quality. [SEP] [PAD]"}
{"pre": "we will show how our approach can be applied to a semantic parser, similar to a semantic parser # refr. [SEP] system of the task of learning", "cit": "learning to interpret language from a situated context has become a topic of much interest in recent years # otherefr ; # refr. [SEP] [PAD] [PAD]"}
{"pre": "in? 1, the algorithm of charniak and johnson? s # otherefr, a self - training technique for a two - stage", "cit": "uses for k - best lists include minimum bayes risk decoding # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this approach is inspired by recent studies # otherefr ; # refr, which have shown that for semi - supervised learning, [SEP] features [SEP] such", "cit": "pcfg parsing # otherefr and dependency parsing # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the penn treebank # refr, the scheme is to identify discourse structure, and measure discourse coherence. [SEP] in order to determine the similarity between", "cit": "in addition, those approaches that do handle hierarchical segmentation do not address automatic unification methods # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "a similar idea has been studied for mds # otherefr ; # refr, but they do not require an annotation. [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "the task is complex in nature due to a broad range of linguistic constraints which ultimately requires wide - coverage of language understanding beyond the capabilities of current [SEP]"}
{"pre": "for example, # refr demonstrated that sentiment analysis is a subject of research, and much recent work in sentiment analysis, a sentence is the field [SEP]", "cit": "pang et al proposed a method of classifying movie reviews into positive and negative ones # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in recent years, there has been an increased interest in the task of learning to recognize named entities # refr. [SEP] this problem could be applied to", "cit": "various methods have been investigated to address this problem, such as? counter - training? # refr and committee agreement # otherefr ; how [SEP]"}
{"pre": "paraphrase acquisition is mostly understood as a preprocessing step of techniques, such as syntactic transformations, are reported in # refr, although the authors [SEP]", "cit": "there has been a rich body of research on automatically deriving paraphrases, including equating morphological and syntactic variants of technical terms # refr, [SEP]"}
{"pre": "we use the web, as the benchmark test set for this task, and we used a manually created rule - based engine because [SEP] [SEP] [SEP] [SEP]", "cit": "while several studies propose relationship identification methods using distributional analysis of feature vectors # otherefr, the majority of the proposed open - domain relations extraction [SEP]"}
{"pre": "we train the parameters of the model using averaged perceptron # refr modified for structured outputs, but can easily fit into a max - margin or [SEP]", "cit": "feature weights are learned using the averaged structured perceptron algorithm # refr, an intuitive structured prediction technique. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for example, in the icsi meeting recording corpus # otherefr, # refr for english, and # otherefr investigate whether [SEP] [SEP]", "cit": "previous ythis work was performed while the author was at icsi. work on detecting # otherefr, # refr used spurt - [SEP]"}
{"pre": "morphological disambiguation there has been a lot of work on arabic pos tagging and morphological disambiguation # otherefr ; # refr. [SEP] the prefix", "cit": "since some inflected forms have several possible analyses, there has been a great deal of work on selecting the intended one in context # otheref [SEP]"}
{"pre": "several ml techniques have been applied to nlp tasks, such as part of speech tagging # otherefr, opinion expression extraction # [SEP] [SEP] [SEP]", "cit": "we evaluate the sequential output with precision, recall and f - score as defined in # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in error correction, most classifiers are built on previous work on discriminative classifiers ( e. g. # refr ). [SEP] features [SEP] training [SEP] models", "cit": "the classification approach has been used to deal with the most common grammatical mistakes made by esl learners, such as article and preposition errors # [SEP]"}
{"pre": "in english, a japanese morphological analyzer is built using a japanese morphological analyzer # refr. [SEP]. [SEP]. [SEP]. [SEP] the word boundaries in japanese", "cit": "there are two approaches to solve this problem : to increase the coverage of the dictionary # otherefr and to design a better model for unknown [SEP]"}
{"pre": "the unsupervised grammar induction task has been extensively studied # otherefr ; # refr. [SEP]ly defined a word sequence of tags learned by a grammar", "cit": "the unsupervised grammar induction task has been extensively studied # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the case of dependency parsing, previous work has used parsing to train a dependency parser for english # otherefr ; # refr. [SEP] the", "cit": "recently, # refrb ) formalized dependency parsing as a maximum spanning tree ( mst ) problem, which can be solved in quadratic time relative to [SEP]"}
{"pre": "# refr used a monolingual parallel corpus to find paraphrases. [SEP] a monolingual parallel corpus, a monolingual comparable corpus of two sentences", "cit": "note that our aim is to automatically capture general paraphrase patterns of the kind that have sometimes been manually described # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "in this work, we aim to combine the expected return templates from the translation model described in # refr. [SEP] a sentence [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "in this paper we present the improved version of the hybrid system we developed last year? s shared task # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr use svms to answer validation on the web, while jitch et al. # otherefr use the pairwise similarity measure [SEP]", "cit": "so far, people have been doing qa researches on the cqa and the forum datasets separately # otherefr ; # refr, and no [SEP]"}
{"pre": "for machine translation, the n - best reranker is trained by the reranking parser described in # refr. [SEP] 1 [SEP] 1 [SEP]", "cit": "other training algorithms include perceptron - style algorithms # otherefr, maxent # refr, and boosting variants # otherefr. [SEP] [PAD]"}
{"pre": "in order to maintain consistency in the representation of single word equivalence classes, we use the head transducer described in # refr and show that the general -", "cit": "i in t roduct ion in this paper we describe an experimental machine translation system based on head transducer models and compare it to a related transfer [SEP]"}
{"pre": "our approach contrasts with common approaches, such as ccg grammars # otherefr ; # refr, giving us more flexibility in the composition of such", "cit": "other work has learnt semantic analyses from text in the context of interactions in computational environments # refr, vogel and jurafsky # otheref [SEP]"}
{"pre": "in order to extract such relations, we followed the similarity measure by lin similarity # refra ), defined as cosine similarity. [SEP] ( w2", "cit": "another candidate is given by dependency trees # otherefr which are equal to similarity trees # refr : for a given root x, the nodes [SEP]"}
{"pre": "in spoken dialogue systems, researchers have been a number of techniques for automatic speech recognition and dialogue systems # otherefr ; # refr. [SEP] this", "cit": "such action may include verifying the user is input, reprompting for fresh input, or, in cases where many errors have occurred, changing [SEP]"}
{"pre": "the lexicalized probabilistic tree adjoining grammar ( ltag ) formalism ( joshi, adjoining ramshaw, and # refr [SEP]", "cit": "in this section i briefly discuss two proposals that could be considered \" hybrid \" approaches, making use of both grammatical structure and lexical co - occurrence [SEP]"}
{"pre": "this has led to the development of various data - driven dependency parsers, such as those by yamada and matsumoto # otheref [SEP]", "cit": "this has led to the development of various data - driven dependency parsers, such as those by yamada and matsumoto # otheref [SEP]"}
{"pre": "in addition, we will apply a bayesian model of the pos tagger described in # refr. [SEP] a nonparametric bayesian model of [SEP]. [SEP] [SEP]", "cit": "a different approach in evaluating nonparametric bayesian models for nlp is statesplitting # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr showed that a variety of signals are effective on the topic models, i. e., how well a target expression in the [SEP] online", "cit": "in # refr, we explored this dimension and found that candidates with higher power introduce significantly more topics in the debates, but attempt to shift topics [SEP]"}
{"pre": "# refr used a maximum spanning tree ( mst ) parser to detect non - projective dependencies. [SEP] non - projective dependencies ). [SEP] [SEP] the likelihood", "cit": "the model is enhanced for non - projective languages by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for example, nlp components such as parsers and co - reference resolution algorithms could be integrated in terms of how they could be used [SEP] [SEP]", "cit": "this study makes preliminary steps towards detection of decision style, based on an annotated dataset of image - based clinical reasoning in which speech data were collected [SEP]"}
{"pre": "sentence boundary detection is a problem that has received limited attention in the text - based computational linguistics community # otherefr ; # refr, but [SEP]", "cit": "in the last decade, a large amount of research # otherefr ; # refr has been conducted on structural event detection ( i. e [SEP]"}
{"pre": "we also define the substring kernel # refr to encode nlp in our framework. [SEP] kernel # otherefr by defining a kernel for [SEP]", "cit": "to assess the benefit of our approach, we carried out comparative experiments with previous work : especially with the method described in ( zanzotto [SEP]"}
{"pre": "in the algorithms presented in this paper, the test set is included in the training set which is a common practice in unsupervised manner # otherefr", "cit": "similarly, approaches to coreference resolution # refr use clustering to identify groups of references to the same entity. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in contrast, # refr proposed a supervised method for named entity linking within a relation mentions. [SEP] features which they only use entity mentions [SEP]", "cit": "the significant portion of recent work in the literature # otherefr ; # refr focuses solely upon the entity linking problem. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the parsers used were the berkeley parser # otherefr, stanford parser # refr and danlosky # otherefr. [SEP] [SEP] [SEP]", "cit": "these include malt parser # otherefr, stanford parser # refr and c & c parser # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "a concept analogous to our notion of meta sense ( i. e., senses ) has been used in previous work on class - line with a", "cit": "our use of monosemous words to represent meta senses and meta alternations goes beyond previous work which uses monosemous words to disambiguate [SEP]"}
{"pre": "for example, the scheme used in this study was partly due to the issues that it has been manually designed by many researchers # otherefr [SEP]", "cit": "the scheme has served as the basis for a number of annotation projects, such as the development of the gnome corpus # refra ) and [SEP]"}
{"pre": "in this paper, we present the definition of the definition of the association for the tasks involved in the 2010 competitions shared task # refr that addresses", "cit": "# refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "historically, the structures of natural languages have been described by a cfg and most parsers # otherefr ; # refr are based on [SEP]", "cit": "although wordbased parsers are proposed in # otherefr ; # refr, they do not build bunsetsus and are not compatible with [SEP]"}
{"pre": "miller et al # refr describe a hidden markov model ( hmm ) that hmms ( hmm ), and he decision processes ( see section [SEP] [SEP]", "cit": "indeed, several studies have shown that f - measure and wer are strongly correlated : 0. 7 points of f - measure lost for each additional [SEP]"}
{"pre": "# refr and chen et al # otherefr show that their proposed algorithm is able to learn structural correspondence learning, and they only consider only a", "cit": "learning then reduces to finding a set of parameters that are estimated by identifying a local maximum of an objective function such as the likelihood # otheref [SEP]"}
{"pre": "in bitext parsing, burkett and klein # otherefr and # refr used parse context free grammars to parse dependency parsers with a straightforward", "cit": "our work falls into the final category : we wish to use bilingual data to improve monolingual models which are already trained on large amounts of data [SEP]"}
{"pre": "the maximum - entropy model used for pos tagging was trained on semeval dependency parsing # refr. [SEP] features [SEP] the pos tagger [SEP] [SEP]", "cit": "in all of our experiments, each input pair of text and hypothesis sentence is preprocessed as following : sentences were first tokenized by [SEP]"}
{"pre": "the high level data trend acquires more sophisticated information, such as context rules, or decision trees # refr. [SEP] the [SEP] of a [SEP] [SEP]", "cit": "for instance, we may learn that the trigram tagger is most accurate at tagging the word up or that the unigram tagger does [SEP]"}
{"pre": "in addition, the model of # refr applies a discriminative log - linear model to obtain the target string. [SEP] ( i. e., [SEP]", "cit": "both yamada and knight # otherefr and # refr use scfgs as the underlying model, so their translation schemata are syntax [SEP]"}
{"pre": "in addition, we use the lexas - free word order # refr. [SEP] subjectivity was a passive - aggressive classifier. [SEP]. [SEP] the", "cit": "early work on determiner selection focuses on rule - based systems # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in # refr, pre - ordering rules are allowed for the source parse trees. [SEP] the source to a target language sentence, then order to [SEP]", "cit": "applied both in the training and decoding step, # refr describe a method for introducing syntactic information for reordering in smt. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "there have been several proposed measures for similarity between words # otherefr ; # refr. [SEP] the prefix distribution of verbs, [SEP] [SEP] [SEP] [SEP]", "cit": "this is similar to work by several other groups which aims to induce semantic lasses through syntactic co - occurrence analysis # otherefr ; # [SEP]"}
{"pre": "in addition, we are aware of two existing approaches : the dirt collection # otherefr and the entailment rule - based approach # refr", "cit": "current work on inference rules focuses on making such resources more precise. # otherefr and # refr propose attaching selectional preferences to inference [SEP]"}
{"pre": "for srl, high accuracy has been achieved by : # otherefr ; # refr ; toutanova et al, 2005 ; [SEP]", "cit": "to avoid explicit feature engineering on trees, # refr used convolution kernels on selective portions of syntactic trees. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "factored language models ( flms ) are mostly part - of - speech ( pos ) of - speech information ) of words, as [SEP],", "cit": "another approach is to use the factored language models ( flms ) which are powerful models that combine multiple sources of information and efficiently integrate them [SEP]"}
{"pre": "it has been previously shown by socher et al. # otherefr and # refrb ) among others that rnn can effectively deal [SEP]", "cit": "in # refrb ) the authors propose the recursive neural tensor network ( rntn ) architecture, which represents a phrase through word vectors and a [SEP]"}
{"pre": "in this paper, the part of the speech tagging and word similarity are computed using the stanford log - linear model # refr. [SEP] ( srl", "cit": "efforts in this area usually focus on the content, arrangement and language usage # otherefr ; # refr of the text written by the learner [SEP]"}
{"pre": "these data - driven parsing approaches obtain state - of - the - art results on the de facto standard wall street journal data set # other [SEP]", "cit": "the body of work on mrls that was accumulated through the spmrl workshops2 and hosting acl venues contains new results for arabic # [SEP]"}
{"pre": "in # refr, we showed that a method that combines supervised learning with a support vector machines ( svm ) model to the task with a support vector", "cit": "it is thus an attractive alternative to use transfer learning # otherefr, which improves performance by generalizing from solutions to? similar? learning [SEP]"}
{"pre": "ng and # refr describe a first - order probabilistic model that determines a set of features, including cluster - based features, and a probability model.", "cit": "we follow soon et al # otherefr and ng and # refr to generate most of our features for the pairwise model. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "in recent years, event temporal expressions have been used as a task of the development of several nlp tasks such as temporal linking [SEP] the time [SEP]", "cit": "in mirza and # refr we have shown that a simpler approach, based on lexico - syntactic features, can achieve comparable results. [SEP] [PAD]"}
{"pre": "in contrast, bootstrapping techniques # otherefr ; # refr to automatically predict the appropriate domain of a word of a given a given target [SEP]", "cit": "another alternative, unsupervised or semisupervised learning, usually requires clever formulations of bias that guide the learning process # otherefr ; # refr [SEP]"}
{"pre": "we use the stanford arabic pos tagger # refr to train a 4 phrase - based system. [SEP] the operation sequence model by adding the operation sequence", "cit": "# refr applied this method to the language pair english - german with an additional special focus on word formation issues such as the splitting and merging of [SEP]"}
{"pre": "wiktionary ( meyer and # refr ) are a viable alternative, especially for smaller languages # otherefr, but they are still far simpler", "cit": "in earlier work, we presented the large - scale resource uby # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the task of learning a senseval - 3 used a random sample ( xi ) # refr algorithm is that of yarowsky is a process the", "cit": "in this paper we focus on a self - training style bootstrapping algorithm, the yarowsky algorithm # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for instance, at the syntactic level, we find metrics that measure the structural similarity between shallow syntactic sequences ( gime? nez and ma `", "cit": "many metrics # otherefr ; gime? nez and ma? # refr ; lo and wu, 2011, for instance ) have [SEP]"}
{"pre": "we measure the performance of two similarity metrics : # refr, compare the similarity between two words with a 5 - gram # otherefr and b", "cit": "other applications include cross - lingual information retrieval # otherefr, detection of confusable drug names # refr, and lexicography # [SEP]"}
{"pre": "for example, # refr found that acoustic spelling error rates for acoustic excer studies have shown that human judgments do not necessarily correlate well with", "cit": "previous research suggests that this acoustic feature predicts misrecognitions because users modify their pronunciation i response to system rejection messages in such a way [SEP]"}
{"pre": "the latter is related to the system of # refr. [SEP] ( i. e., syntactic, semantic, textual ) is a preprocessing module.", "cit": "pattern - based relation extraction methods # otherefr ; # refr ) could in theory be used to extract relations represented by commas. [SEP] [PAD]"}
{"pre": "to evaluate our lexicon we use mace # refr, which is the benchmark we created a lexicon that contains the two target words which [SEP] emotion associations", "cit": "there are various studies both in computational linguistics and cognitive science that build resources associating words with several cognitive features such as abstractness - concreteness [SEP]"}
{"pre": "in information extraction, inference methods can be categorized into iterative scaling methods, and regularization strength with information from the amount of unlabeled data # otherefr", "cit": "most semi - supervised learning algorithms rely on marginals # otherefr or map assignments ( codl, # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "there have been many attempts to model extract content structure from a corpus # otherefr ; # refr, which treats texts as well as [SEP] [SEP]", "cit": "document models for summarisation : our content model has some similarities with content modelling using global sentence ordering # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we have implemented a combination of the performance of lexical knowledge - rich lexical inference # otherefr and general nlp applications, including e. g", "cit": "we have implemented plug - ins for the following resources : the english lexicon wordnet # otherefr, a categorial variations database, wikipedia [SEP]"}
{"pre": "in addition, their system was the topic model used by # refr for coreference resolution. [SEP] it has been [SEP] by elson and [SEP] [SEP]", "cit": "one pre - processing step we do perform is pronominal anaphora resolution # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "especially challenging is the task of mining semantically similar words from comparable data without any external knowledge source such as machine - readable seed bilingual lexicons [SEP]", "cit": "especially challenging is the task of mining semantically similar words from comparable data without any external knowledge source such as machine - readable seed bilingual lexicons [SEP]"}
{"pre": "statistical parsing models have been shown to be successful in recovering labeled constituencies # otherefr ; # refr. [SEP] a statistical pcfg [SEP] [SEP]", "cit": "treebank - based probabilistic parsing has been the subject of intensive research over the past few years, resulting in parsing models that achieve both broad coverage [SEP]"}
{"pre": "several approaches have been proposed to address this problem, including bayesian approaches that use context - free grammars # otherefr ; # refr, decision trees", "cit": "recent work on dop estimation also seeks to address these problems, drawing from estimation theory to solve the consistency problem # otherefr, or incorporating [SEP]"}
{"pre": "as more and more conversation data becomes available, researchers have investigated automated processing of conversation data to acquire useful information, for example, related to opinions [SEP]", "cit": "as more and more conversation data becomes available, researchers have investigated automated processing of conversation data to acquire useful information, for example, related to opinions [SEP]"}
{"pre": "in addition, by selecting the most appropriate corpus for training a good translation model on the target side, we incorporate a parallel corpus that contains exactly [SEP]", "cit": "# refr introduced assigning a pair of binary features to each training sentence, indicating sentences? genre and collection as a way to capture domains. [SEP] [PAD]"}
{"pre": "we use the genia tagger # refr as a base - v tagger. [SEP] # otherefr for bidirectional inference of svms [SEP]", "cit": "in the final stage, each extracted fragment of text was pos - tagged using the genia tagger # refr and was only retained, if [SEP]"}
{"pre": "to overcome this, we plan to use an unsupervised dependency parser to generate the parse trees, and then used the dependency tree representation of char [SEP] sentences", "cit": "this includes work on sentence compression which regenerates sentences from surface dependency trees derived from parsing the initial text # refr ; surface realisation approaches [SEP]"}
{"pre": "# refr used em to learn hidden variables in an attempt to map verbs, and assign to parts of speech. [SEP] sentences, and we propose to", "cit": "1993 ; rooth 1995 ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "most of the unsupervised dependency parsing has been based on generative models that can be trained for the firstand second - order models # otherefr [SEP]", "cit": "and the hybrid approach of # refr, which combines a constituency and a dependency model, leads to a further increase of 77. 6 % [SEP]"}
{"pre": "# refr developed a system for identifying noun compounds ( otherefr ) which uses a corpus of minimal scopes ( [SEP] disambiguation ) to [SEP]", "cit": "other researchers have identified other sets of semantic relations # otherefr, # refr, # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, since the latest release of non - projective constructions often contain long - distance dependencies, the use factored models that allow nonprojective", "cit": "at first most algorithms were restricted to projective dependency trees and used pseudo - projective parsing # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "many alternative methods have been proposed based on the algorithms in machine learning, such as averaged perceptron # otherefr ; # refr, margin [SEP]", "cit": "these methods differ by the objective function or training mode : their objective functions are based on either evaluation - directed loss # otherefr or online [SEP]"}
{"pre": "in most cases, the accuracy of the source and target sentences were assigned using the giza + + implementation of the training corpus. # refr,", "cit": "phrase - based models # otherefr, and finite - state conditional random fields # refr exemplify the former, and hierarchical phrase - based [SEP]"}
{"pre": "# refr use latent semantic analysis ( lsa ) to determine the similarity between a verb and its components. [SEP] a noun to determine the meaning [SEP]", "cit": "relying on previous work on compositional semantics of multi - word - expression # otherefr ; # refr we defined a set of hand - written [SEP]"}
{"pre": "we use a hierarchical phrase - based translation grammar # refr to obtain the phrase - base translation grammars. [SEP] the suffix array extraction process. [SEP] (", "cit": "# refr use a disk - based prefix tree, enabling efficient access to phrase tables much too large to fit in main memory. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "a first version of the ibm model 1 was trained on the europarl corpus # otherefr ; # refr. [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "for example, the candide system # refr was trained on ten years? worth of canadian parliament proceedings, which consists of 2. 87 million [SEP]"}
{"pre": "in bitext parsing, # refr and fraser et al # otherefr used feature functions defined on triples of ( parse tree in language [SEP]", "cit": "# refr describe a system for simultaneously improving chinese and english parses of a chinese / english bitext. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "several wide - coverage statistical parsers have recently been developed for combinatory categorial grammar # otherefr ; # refr ; clark and [SEP] [SEP]", "cit": "one shortcoming of treebank parsers such as collins # otherefr and # refr is that they typically produce phrase - structure trees containing [SEP]"}
{"pre": "the most common approach is to use a statistical model that determines the form of syntactic parse trees # otherefr ; # refr. [SEP] [SEP] [SEP]", "cit": "the results we have presented here are given solely for this harder part, which may explain why at roughly 70 points of f - score, they [SEP]"}
{"pre": "in addition, we use the parser described in # refr as well. [SEP] ( 1 ) =? i. e., np ) [SEP] [SEP]", "cit": "the most crucial modification was to add np internal bracketing to the wsj # refr, since the three other treebanks contain that information [SEP]"}
{"pre": "in a different approach, # refr suggest that different data sets are taken for lexicalized. [SEP] ( 1 ) reranking [SEP] [SEP] the [SEP]", "cit": "the factors used in the algorithms and the algorithms themselves are evaluated on a german corpus annotated with syntactic and coreference information ( negra ) # [SEP]"}
{"pre": "for example, the \" ltag - spinal \" ltag grammar \" ltag'\"'\"'\"'\"'\"'\" '", "cit": "in recent years, a machine learning technique known as explanation - based learning ebl # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in a different approach, # refr report that of 0. 8 % over f - score is an attempt to evaluate the probability distribution over clustering [SEP]", "cit": "orig with fixed hyperparameters performs best, with the highest vm score ( a clustering measure, # refr ) and a level of segmentation close to [SEP]"}
{"pre": "iii, 2007 ; # refr. [SEP] if a domain is considered as a source, target domain, and target domain is usually accommodated as a", "cit": "versions of this problem include adapting using only unlabeled target domain data # otherefr ; # refr, and learning across multiple domains simultaneously in an [SEP]"}
{"pre": "to this end, the grammar matrixtree is a synchronous tree - to - tree transducers tree transducers which is also used to capture the synchronous tree substitution", "cit": "so far, most of them have been based on synchronous context - free grammars # otherefr, tree substitution grammars ( tsg ) # [SEP]"}
{"pre": "in this work, we aim at answering this question by focussing on reordering during decoding with the last few years # otherefr ; [SEP]", "cit": "we refer to # refr and gojun and fraser # otherefr for a detailed description of the german clause structure. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "the input text and the input sentence f1 are available from the version of the gate framework of the alevene toolkit # refr. [SEP] [SEP]", "cit": "general architecture for text engineering # otherefr and the alembic workbench # refr ) as well as nlp tools and resources that [SEP]"}
{"pre": "v - measure # refr is an information theoretic measure that is relevant for the summarization that partitions that are selected from each output ( [SEP] [SEP]", "cit": "the first measure used is the v - measure # refr, which compares the clusters of target contexts to word classes. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "leveraging information from one language for the task of disambiguating another language has received considerable attention # otherefr ; # refr. [SEP] the [SEP]", "cit": "to our knowledge, the only grammar induction work on non - parallel corpora is # refr, but their method does not model a common grammar, [SEP]"}
{"pre": "recent work by # refr has shown that the yield process of projective structures for parse discontinuous constituents ( henceforth kb ) can be exactly once in a", "cit": "unlike ( van # refr, our objective is not to obtain a? coarse? grammar for the purpose of coarse - to - fine parsing. [SEP]"}
{"pre": "while this method has been successfully applied in many nlp tasks, such as word sense disambiguation # otherefr, and sentence compression # [SEP]", "cit": "second, the ability to have rules deeper than one level provides a principled way of modeling lexicalization, whose importance has been emphasized # other [SEP]"}
{"pre": "the corpus was preprocessed in standard ways and word aligned by running giza + + # otherefr in both directions and the [SEP]", "cit": "hmm is one of the effective translation models # refr, which is easily scalable to very large training corpus. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the model is trained using the structured perceptron algorithm # refr, similar to that of # otherefr, so we will only give better [SEP]", "cit": "a derivation in our model is a pair? e, d? where e is a set of spines, and d is a set of dependencies [SEP]"}
{"pre": "word - level alignment is a critical component of a wide range of nlp applications, such as construction of bilingual lexicons # otherefr [SEP]", "cit": "it is crucial for the development of translation models and translation lexica # otherefr, as well as for translingual projection # refr. [SEP]"}
{"pre": "there have been some recent attempts at the unconstrained problem of generating a sentence from a multi - set of input words # otherefr ; # [SEP]", "cit": "this perspective has been observed by other works of learning - guided - search # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in hierarchical phrase - based translation # otherefr ; # refr, the fundamental translation model is still a left - to - right order. [SEP]", "cit": "approximate methods based on beam search and cube - pruning have been widely studied for phrasebased # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "to evaluate the deep readability on test data, we use the tnt system # refr. [SEP] text processing spoken language model ( tutor [SEP] [SEP]", "cit": "the deepread system # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the last few years, many studies on the automatic extraction of sense - annotated data have been reported in the trec - 8 ontology # other", "cit": "1 # refr shows that wikipedia can indeed be used as a sense inventory for sense disambiguation. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, some studies have been done in the trec - 40 % of the questions # otherefr, # refr, de [SEP] [SEP]", "cit": "for example, in trec qa track, definition questions are intended to provide a user with the definition of a target item or person # refr [SEP]"}
{"pre": "in addition, several researchers have focused on the web people search, either by detecting decential fragments of non - english # otherefr ;", "cit": "following # refr, we collect short deceptive and truthful essays for three topics : opinions on abortion, opinions on death penalty, and [SEP]"}
{"pre": "we use approximate randomization test # refr with 1000 repetitions to determine score the total of the total distances. [SEP] at the word level. [SEP] it [SEP]", "cit": "in the area of statistical machine translation # otherefr has become popular # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "these methods differ by the objective function or training mode : their objective functions are based on either evaluation - directed loss # otherefr ; # [SEP]", "cit": "it firstly introduced in # otherefr, and then was improved in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in a similar vein, # refr adopts a constraint defining bottom - up chart that is learned by a hypothesis h [ h ] 2 ] is a", "cit": "work on reference to sets has also proceeded within this general framework # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use approximate randomization test # refr with 1000 repetitions to determine score difference significance : results in bold are significant with p? 0. 05. [SEP]", "cit": "for significance testing, the toolkit includes an implementation of the permutation test of # refr, which was shown to be less susceptible to type - i [SEP]"}
{"pre": "we use a log - linear model # refr for the linear models, and train the linear models model using the averaged perceptron algorithm # otheref", "cit": "as an alternative to maximum - likelihood method, we propose the following training algorithm inspired by the work of # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in a later study, # refr reported that one of the focus on resolving the syntactic structure of the preceding or noun, is on the same topic", "cit": "of the major syntactic constituents of a sentence, e. g. noun phrases, verb phrases, and prepositional phrases, we assume that [SEP]"}
{"pre": "both systems use a statistical representation of the discourse representation of the dialogue lexical and syntactic cues # otherefr ; # refr. [SEP] the [SEP] characteristics", "cit": "you will find them in the designing office. ) > m. jasper : bonne chance! | | quit # otherefrb ; [SEP]"}
{"pre": "in this work, we evaluate the sentiment polarity ( positive versus negative ) and # refr. [SEP] polarity ( i. e., positive [SEP] )", "cit": "finally, other approaches rely on reviews with numeric ratings from websites # otherefr ; # refr and train # otherefr. [SEP] [PAD] [PAD]"}
{"pre": "for instance, # refr used the em algorithm to train a 4. 2 lm trained on the training section of the corpus. [SEP] [SEP] [SEP] [SEP]", "cit": "# refr used a log - linear model with features from ibm models. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the tiffr # otherefr # refr, the corpus has been annotated with rhetorical relations, and has the properties of [SEP] phenomena", "cit": "but discourse structures cannot always be described completely, either due to genuine ambiguity # refr or to the limitations of a discourse parser. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "however, the? fixed - list? ( or the best reported here is a very high accuracy on the wsi task # refr. [SEP] (", "cit": "# refr explored the use of two graph algorithms for unsupervised induction and tagging of nominal word senses based on corpora. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "fbk [ irst ] # refr [ 2008 ]. [SEP] kernel + scope, i. e. a kernel that includes syntactic kernel [SEP] features", "cit": "fbk - irst # otherefrc ) fbk - irst, italy hybrid kernel + scope of negations and semantic roles nil [SEP]"}
{"pre": "in order to train the dependency parsers, we use the malt parser # otherefr and the dependency parser of # refr for our experiments.", "cit": "the dependence on the beam - size k is because one needs to do k - times the number of basic operations ( feature - extractions, [SEP]"}
{"pre": "taking chinese word segmentation for example, the state - of - the - art models # otherefr ; # refr are usually trained on human [SEP]", "cit": "taking chinese word segmentation for example, the state - of - the - art models # otherefr ; # refr are usually trained on human [SEP]"}
{"pre": "many corpus based statistical methods have been proposed to solve this problem, including supervised learning algorithms # otherefr, unsupervised learning algorithms # refr, semi", "cit": "many corpus based statistical methods have been proposed to solve this problem, including supervised learning algorithms # otherefr, unsupervised learning algorithms ( or word [SEP]"}
{"pre": "paraphrase acquisition is mostly done at the sentence - level, e. g., # otherefr ; # refr, which is [SEP]", "cit": "for our experiments, we use the berkeleyaligner4 # refr by feeding it a dictionary of pairs of identical words along with the paired sentences [SEP]"}
{"pre": "in particular, link, link, v1 # otherefr measure # refr and lin # otherefr describe similar methods. [SEP] [SEP] [SEP]", "cit": "they also introduced a socalled disambiguation graph, a representation that has also been utilized by the method of # refr, where she applied a [SEP]"}
{"pre": "mst - parsing # refrb ) and transition - based parsing, e. g. the maltparser # otherefra ). [SEP] higher", "cit": "for the mst - parsing mira # otherefra ; # refr and for transition - based parsing support - vector machines # otherefrb [SEP]"}
{"pre": "in the recent years, ensemble methods have been applied to obtain the performance of bilingual dictionaries # otherefr ; # refr. [SEP] this paper", "cit": "improving the syntax - based approach for synonym identification using bilingual dictionaries has been discussed in lin et al # otherefr and wu and [SEP]"}
{"pre": "in addition, rather than deriving features ( e. g., ng and # refr ), we aim to assess the amount of emotion [SEP] text", "cit": "# refr were among the first to use mechanical turk to collect deceptive and truthful opinions? personal stances on issues such as abortion and [SEP]"}
{"pre": "in contrast to many previous approaches to automated essay grading # refr, our goal is not to assign a letter grade to student essays. [SEP] analysis", "cit": "however, powers et al. # otherefr invited writing experts to trick the scoring capabilities of an earlier version of e - rater # [SEP]"}
{"pre": "many natural language models can be captured by weighted loss functions # otherefr ; # refr, which offer several benefits :. [SEP] [SEP] [SEP] [SEP]", "cit": "iii, 2007 ), active learning # otherefr, and approaches that treat unlabeled data as labeled, such as bootstrapping # refr, [SEP]"}
{"pre": "we use the idea of pre - ordering for decoding in translation, which is implemented in reordering rules are described in # refr. [SEP] the [SEP]", "cit": "this decision can be delayed to decoding time by presenting several reordering options to the decoder as a lattice # refr or as an n - best [SEP]"}
{"pre": "we use a simple dictionary plays an important role in improving the computational complexity of pos tagging task # otherefr ; # refr. [SEP] features [SEP]", "cit": "recently, studies have explored dialog act tagging in written interactions such as emails # otherefr ; # refrb ), instant messaging # [SEP]"}
{"pre": "in statistical machine translation, the task of deterministic annealing ( daume? and # refr performed a reference translation ). [SEP] it takes a [SEP] solution", "cit": "woodland, 2002 ) and more recently has been applied to mt # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "while automated resolution of entity coreference has been an actively researched area # otherefr ; # refr, there has been relatively little work on [SEP]", "cit": "each word list lr is generated by first drawing a list length from fr and then independently populating that list from the property? s word distribution [SEP]"}
{"pre": "additionally, the long distance distortion model is the entire sequence of # refrb ). [SEP] the linear functions for local maximum entropy of [SEP] the latent", "cit": "third, the? correct? alignment annotation for different tasks may vary : for example, relatively denser or sparser alignments may be optimal for [SEP]"}
{"pre": "the basic concept of combining the distributions of a word - based translation model was trained by # refr. [SEP] the latter by combining [SEP] [SEP] [SEP] [SEP]", "cit": "approaches to combination generally either select one of the hypotheses produced by the different systems combined # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this measure has been shown to correlate well with human judgements # refr. [SEP] the noisy - channel model is an important component of [SEP] [SEP] [SEP]", "cit": "many algorithms exploit parallel corpora # otherefr ; # refr to learn the correspondences between long and short sentences in a supervised manner, typically using [SEP]"}
{"pre": "parser accuracy # refr 80. 1 mcdonald et al # otherefr 85. 2 dep1c 86. 07 dep3k [SEP] swedish 17", "cit": "the maltparser is a dependency parser generator, with three parsing algorithms : nivre? s arc standard, nivre? s arc ea [SEP]"}
{"pre": "the first one, known as data - driven parsers, is a pos tagging model, which has been widely used recently # refr. [SEP] features", "cit": "syntactic question parsing models were trained from the combination of 10 copies of # refr? s question dataset and one copy of the ccgbank the [SEP]"}
{"pre": "one of the earliest and most successful attempts to model the relation have been made available ( e. g., # refr ), by [SEP] et", "cit": "although this study falls under the general topic of discourse modeling, our work differs from previous attempts to characterize text in terms of domainindependent rhetorical [SEP]"}
{"pre": "in this paper, we focus on the syntax - semantics interface provided by the treebank - banks for the english treebank of both linguistics [SEP] research", "cit": "a slightly different approach has been followed by krotov et al # refr, where they extract the grammar from the penn treebank like char [SEP]"}
{"pre": "this includes work on phrasestructure parsing # otherefr ; # refr, dependency parsing # otherefr. [SEP] the source sentence to [SEP] the", "cit": "this observation has led to a vast amount of research on unsupervised grammar induction # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the test set was split into english - french ( msa ) using the? methodology, and the case of [SEP] 1 ) [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "for instance, # refr show that small amounts of data from the right dialect can have a dramatic impact on the quality of dialectal [SEP]"}
{"pre": "in this study, we use english zero pronouns, which is a well - defined and, using the features that have been studied extensively # other", "cit": "many previous studies # refr have treated only zero endophora, which is a phenomenon that a referent is mentioned in a document, such [SEP]"}
{"pre": "# refr improved spelling correction by introducing the noisy channel model. [SEP] a latent variable, which they use an explicit approach based [SEP] edits", "cit": "the first work that had a significant performance improvement over the previous research was by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the inference ( referred to as hereafter as hereafter as here, our method maximizes the expected probability distribution over trees, we use the parse tree - rewriting", "cit": "# refr discusses parsing with probabilistic tree substitution grammars, which, unlike simple pcfgs, do not have a one - to - one mapping [SEP]"}
{"pre": "# refrb ) evaluate the quality of a translation model by comparing the translation quality of a translation output sentence and provides a correlation with human judgement of", "cit": "token - based qe models, such as those in gandrabur et al # otherefr and # refr fail to assess the overall [SEP]"}
{"pre": "# refr focused on identifying verbs and nouns. [SEP] their polarity to are related. [SEP]. [SEP]. [SEP] the states of two words ( [SEP] [SEP]", "cit": "semantic orientation lexicon # refr : we used the words listed as having positive or negative polarity to produce + / - affect states, when they occur [SEP]"}
{"pre": "in a similar vein, # refr use linear integer linear programming ( ilp ) to generate image captions. [SEP] the similarity of text [SEP] [SEP]", "cit": "farhadi et al # otherefr, # refr ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in a paper, the contextual information is obtained from a tree adjoining grammar # otherefr ; # refr. [SEP] this procedure [SEP] [SEP]", "cit": "2see berwick and weinberg # otherefr, # refr, htgria and stallard # otherefr. [SEP] [PAD] [PAD]"}
{"pre": "these rules are often tailored to the source side, and include the translation model # refr, which is a central to a translation model. [SEP] non", "cit": "more formally, the upper bound on parsing complexity is always at least linear in the size of the grammar constant g, where g is often loosely [SEP]"}
{"pre": "we use a statistical machine translation model # otherefr ; # refr. [SEP] the procedure by training the tnt. [SEP] the source [SEP] [SEP]", "cit": "it seems to be a universal truth that lm performance can always be improved by using more training data # refr, but only if the training data [SEP]"}
{"pre": "in the case of relation extraction, # refr proposed a rule - based system that recognizes the elements between two entities. [SEP] and [SEP] natural [SEP] [SEP]", "cit": "therefore, we decided to employ a conditional random fields # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "to address this, we use the same coreference resolution system described in # refr. [SEP] 48. [SEP] 48 % [SEP]. [SEP] [SEP] [SEP] [SEP]", "cit": "machine learning - based methods # otherefr ; ng and # refr train a classifier or search model using a corpus annotated with anaphoric pairs [SEP]"}
{"pre": "the procedures used to find b7 hypernyms in definition disambiguation # otherefr, and ( using the definitional ) of [SEP] (", "cit": "as a starting point we examine the potential of definition sentences as a source for lr rules # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "for example, # refr used nlp tools to automatically generate pos tags. [SEP] phenomena observed relative to 10, 000 word [SEP], [SEP], [SEP]", "cit": "finally, mirroring noteworthy progress in other nlp fields involving data - driven methods, recent work has involved essay grading via exemplar - based [SEP]"}
{"pre": "in # refr, the authors use nlp techniques to classify documents in wikipedia and wikipedia, and to classify class words as features of [SEP] [SEP] [SEP]", "cit": "web encyclopedias and scholarly publications are two examples of document domains where network structures have been used to assist classification # refr. [SEP] [PAD] [PAD]"}
{"pre": "since the conll 2007 shared tasks on hedge scope detection, the number of hedge scopes # otherefr ; # refra ), supervised", "cit": "recently, there have been several corpora published with manual sentence -, eventor token - level annotation for negation, certainty and factuality in [SEP]"}
{"pre": "we also compare the proposed trescal model to # refr and all participating systems in the multilingual and domain - independent of mwetoolkit [SEP]", "cit": "in order to facilitate human analysis of candidate lists, we used the mwetoolkit4 : a tool that has been developed specifically to extract [SEP]"}
{"pre": "nonetheless, during the last decade, there has been a steady flow of new work on content selection that employed machine learning # otherefr ; [SEP]", "cit": "# refr were the first to propose a method for learning content selection rules automatically, thus going beyond mere corpus analysis. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "generative models ( such as models 1 - 5, and the hmm model # refr ) motivate a narrative where the probabilities are computed across all [SEP] [SEP]", "cit": "we perform mt ex - 1we refer to the hmm mt model in # refr as m - hmm to avoid any confusion. mf1 a [SEP]"}
{"pre": "in this work, we use the features presented in # refr. [SEP] this work is the current system of # otherefr. [SEP] [SEP] [SEP]", "cit": "the baseline that we choose for this task has similar definition with # refr which is? do nothing?. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "nivre? s parser has been tested for swedish # otherefr, english # refr, czech # otherefr. [SEP]. [SEP] [SEP]", "cit": "as linguistic tradition supports dependency - based syntactic formalisms for the two languages # otherefr, it should be noted that they have not participated [SEP]"}
{"pre": "# refr use a probabilistic model with lexical chains, and extend their work by re - ranking that uses wordnet classes to predict verbs that perform the", "cit": "for example, in summarization, # refr and lin and hovy # otherefr focus on multiword noun phrases. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "the last decade has seen significant progress in statistical parsing techniques # otherefr ; # refr. [SEP] the data - driven parsing strategy of pruning [SEP]", "cit": "bilexical context - free grammars have been presented in # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this work, we penalize the objective function by adding the commonly used metrics of bleu # refr. [SEP] the optimization framework of [SEP] [SEP]", "cit": "we need to define a segment - wise loss, in contrast to the standard crf loss, which is sometimes referred to as an # otheref [SEP]"}
{"pre": "we used the stanford pos tagger # refr for pos tagging. [SEP] the tokens of the tokens of the tokens. [SEP] features to mention ( for", "cit": "the qa - sys performs part of speech tagging using stanford pos tagger # refr, and named entity recognition using stanford ner # otherefr [SEP]"}
{"pre": "in an early attempt to exploit part of speech ( pos ) tags ( in ) tags for both syntactic and lexical and syntactic parse structures ; the [SEP]", "cit": "because the gloss line aligns with words and morphemes on the target line, and contains glosses that are similar to words on the translation [SEP]"}
{"pre": "dependency parsing has been intensively studied in recent years # otherefr ; # refr. [SEP] this work is in many nlp, and it has", "cit": "we used the mstparser # refra ; mcdonald et al., 2005b ) as the basic dependency parsing model. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "# refr showed that a naive sentence classifier from tweets were used to determine the sentiment polarity of a tweet that is pos - tagged with the sentiment", "cit": "there has been some research on the use of positive and negative emoticons and hashtags in tweets as a proxy for sentiment labels # [SEP]"}
{"pre": "we use the memory based tagger # refr trained on the wall street journal corpus. [SEP] a freely available state - of - the [SEP] [SEP] [SEP]", "cit": "the english data was automatically labeled with part - of - speech and chunk tags from the memory - based tagger and chunker # refr, [SEP]"}
{"pre": "in addition, by exploiting the world - wide data # otherefr ; # refr, it has been shown that there are good [SEP] [SEP] [SEP]", "cit": "previous systems have turned either to ontologies # otherefr ; # refr to help solve these errors. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "early event extraction systems used handcrafted patterns # otherefr ), or unsupervised learning # refr. [SEP] features ( 1 ) are two [SEP]", "cit": "research has also been done on relation extraction # otherefr ; # refr ), but that task is different from event extraction because it focuses [SEP]"}
{"pre": "in addition, before the plan - based model of # refra ), the authors model of the plan - based model of dialogue by [SEP] [SEP]", "cit": "thus, a good response may also have to # otherefr ; ( ii ) answer a query that results from an inappropriate plan indirectly by [SEP]"}
{"pre": "we start from 2 training instances ; results were the same or slightly better with 10 or 100 instances. work has also focused on projecting syntactic annotations [SEP]", "cit": "bilingual data has been used to resolve a range of ambiguities, from pp - attachment # otherefr, to full dependency parsing # refr [SEP]"}
{"pre": "several approaches rely on bilingual parallel data # otherefr ; # refr, while others leverage distributional similarity in order to determine the meaning of the [SEP]", "cit": "we show that the monolingual distributional scores yield significant improvements over a baseline that scores paraphrases only with bilinguallyextracted features # refr [SEP]"}
{"pre": "a similar idea has been addressed in previous work, e. g. # refr, word sense disambiguation # otherefr. [SEP] [SEP] effort", "cit": "# refr evaluated multiple annotation strategies for gathering framenet sense annotations, ultimately yielding high ( > 90 % ) accuracy for most terms after filtering. [SEP]"}
{"pre": "the majority of the previous work on pp - attachment disambiguation has considered one of the application of a statistical parser to the wsj # otheref", "cit": "within the spectrum of appraoches to natural language parsing, xle can be considered a hybrid system combining a hand - crafted grammar [SEP]"}
{"pre": "pg shows its importance in many areas, such as question expansion in question answering # otherefr, and sentence similarity computation in the text [SEP] [SEP]", "cit": "nlg - based methods : nlg - based methods # otherefr ; # refr generally involve two stages. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use a phrase - based translation model # refrb ), which is based on a log - linear framework in order to obtain the word alignments", "cit": "we used a log - linear approach # refr in which a foreign language sentence f j1 = f1, f2,... [SEP]"}
{"pre": "in a similar setting, # refr use a more sophisticated classifier to predict the narrative chains. [SEP] discourse. [SEP] events, based on a [SEP] [SEP]", "cit": "we do not believe word ambiguities to be a primary concern, and previous work also defines events to be the same if they have the same [SEP]"}
{"pre": "this approach is similar to the ones presented by # otherefr ; # refr which represent the training data by means of the word [SEP] the [SEP]", "cit": "as used in this work, arguing is a type of linguistic subjectivity, where a person is arguing for or against something or expressing a belief [SEP]"}
{"pre": "we parse the english data using the berkeley parser # refr. [SEP] the penn treebank # otherefr. [SEP] features [SEP] the split [SEP] [SEP]", "cit": "automatically - derived grammars, such as the split - and - merge model, have proven helpful in parsing # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we follow # refr and distinguish between compositionality based on compositional distributional semantics. [SEP] models. [SEP] the representations of this work is composed. [SEP] [SEP]", "cit": "# refr and guevara # otherefr also proposed linear transformation models for composition and address the issue of estimating large matrices with least squares [SEP]"}
{"pre": "# refr showed that the similarities among contexts are correlated with their literal or figurative usage. [SEP] the compositionality of mwe. [SEP] a", "cit": "identifying non - compositional # otherefr, and significant attention has been paid to practical methods for solving this problem in recent years # refr. [SEP]"}
{"pre": "in particular, we use a version of the earley - style parser # refr. [SEP]'~ lnln ll [SEP]'~ [SEP]'[SEP]", "cit": "alternatively, one could adopt a pure bottom - up strategy like the one which has been proposed in \\ [ # refr \\ ] and which is [SEP]"}
{"pre": "in the last decade, both noun phrase coreference resolution, etc., # otherefr ; # refr. [SEP] & [SEP] ( 1 )", "cit": "lastly, # refrb ) presents a case - based learning approach for relative pronoun disambiguation. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in # refr, empty categories have been used for hindi. [SEP] # otherefr also built on the hindi data [SEP] [SEP] [SEP] [SEP]", "cit": "there have been many approaches for the recovery of empty categories in the treebanks like penn treebank, both ml based # otherefr [SEP]"}
{"pre": "nc bracketing determines the syntactic structure of an nc as expressed by a binary tree, or, equivalently, a binary bracketing # refra [SEP]", "cit": "to our knowledge, three approaches have been studied in previous works : mi # otherefr, supervised learning approach # refr and em optimization approach [SEP]"}
{"pre": "figure 1 : dependency tree for an english sentence # otherefr, and a dependency parser, a 4 - 1. b ) we use the", "cit": "# refr proposed probabilistic models of dependency parsing. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this measure, which is defined in the next section, is particularly attractive because it is corpus - based, does not assume any synonymy,", "cit": "recently, researchers developed measures which evaluate the semantic coherence of topic models # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr proposed a multi - class classification method to predict the relation occurrences. [SEP] the verb classification. [SEP] the verb classification. [SEP] it takes too", "cit": "# refr proposed a novel unsupervised method based on model order selection and discriminative label identification to address this problem. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "while these approaches have been shown to improve coreference performance in recent years # otherefr ; # refr, the use of deterministic coreference [SEP]", "cit": "the use of semantic knowledge for coreference resolution has been studied before in a number of works, among them # otherefr, and # [SEP]"}
{"pre": "this clustering, in which words share dependency structures, has been shown to be useful in a number of natural language processing # otherefr, and", "cit": "the use of syntacticngrams holds promise also for improving the accuracy of core nlp tasks such as syntactic languagemodeling # otheref [SEP]"}
{"pre": "with the availability of the readability model, the ace 2005 model has been reported by # otherefr, # refr. [SEP] criteria [SEP] [SEP]", "cit": "with the success of using readability in education ( franc? ois and # refr, readability has been used in a range of domains [SEP]"}
{"pre": "the weights of the log - linear model were tuned using minimum error rate training ( mert ) # refr on the ted development set and [SEP] [SEP]", "cit": "we obtain weights for the combinations of the features by performing minimum error rate training # refr on held - out data. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "following # refr, we encode the basic model of # otherefr, which states that the word similarity between two words can be defined [SEP] [SEP]", "cit": "this seems consistent with previous works, where narrow windows of the order of two words performed well # otherefr ; # refr and in particular [SEP]"}
{"pre": "integer linear programming # otherefr ; # refr. [SEP] ( i. e., sentences ) are constrained [SEP] ( e. g. [SEP]", "cit": "integer linear programming # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the cmu twitter part - of - speech tagger # refr to define the tags of the tags of the tagset. [SEP] this", "cit": "more specifically, we had lay annotators on the crowdsourcing platform crowdflower re - annotate the training section of # refr. [SEP]"}
{"pre": "levin is \\ [ 1993 \\ ] semantic lasses for verbs have been found to be useful for verbs # otherefr ; # refr. [SEP]", "cit": "verb classifications have, in fact, been used to support many natural language processing # otherefr, document classification # refr, word sense disambig [SEP]"}
{"pre": "# refr proposed a method based on decision trees for tree - based translation. [SEP] the space of permutations. [SEP] a probability distribution, which is modeled", "cit": "some of these studies have concentrated on finite - state or extended finite - state machinery, such as # otherefr and # refr. [SEP] [PAD]"}
{"pre": "# refr and langkilde - geary # otherefr report results using the ranker channel model, and ranking models [SEP] [SEP] [SEP]", "cit": "we implemented the forest - based statistical sentence generation method of # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the mcclosky - charniak parser # refr for self - training, trained biomedical parsing. [SEP] the parser of charniak", "cit": "the re - ranking parser of charniak & johnson adapted to the biomedical domain # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr used subtrees in semi - supervised dependency parsing as features. [SEP] the word class model. [SEP] this representation of semi - supervised features,", "cit": "we also demonstrate that our approach and other improvement techniques # refr are complementary and that we can achieve very high accuracies when we combine our method with [SEP]"}
{"pre": "the relationship between topic boundaries have been successfully applied in several related tasks, including segmentation of multi - document summarisation # otherefr, and multi", "cit": "to further study the effectiveness of our model, we would like to compare it with other methods, like sits # otherefr and to [SEP]"}
{"pre": "in this paper, we evaluate the performance of the systems on word pairs ( i. e., bleu ) and two datasets # refr and", "cit": "we use two semantic relation datasets : bless # refr and sn. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr used this technique for dependency parsing by adding more linguistic information to improve performance. [SEP] the representation of the representation of the same labels, then", "cit": "7the radical of a chinese character can be found at : www. unicode. org / charts / unihan. html ner # other [SEP]"}
{"pre": "in addition to domain mainstays such as support vector machines, we also find a? hard? model of relation extraction? ( e. g", "cit": "leuven # otherefr, tees - 2. 1 ( bjo? # refr, irisa - texmex # other [SEP]"}
{"pre": "this model can be used for parameter estimation, including the conditional log - linear model # otherefr ; # refr. [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "in addition to the hpylm for n - gram language modelling # otherefr ; # refr and speech recognition # otherefr. [SEP]"}
{"pre": "this has led to various tasks in natural language processing, including relation extraction # otherefr, and question answering # refr. [SEP] textual entailment", "cit": "# refr augment mirkin et alfeatures with web - based features for the task of entity extraction. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the most common approach is to use log - linear models for inference based on maximum entropy markov models ( mle ) # refr. [SEP] [SEP] [SEP]", "cit": "similar dynamic programming techniques that are variants of the ioa have been applied for related tasks, such as parse selection # otherefr ; # [SEP]"}
{"pre": "detection of self corrections on transcriptions before parsing has been explored # refr, but it is not clear that it will be feasible on whgs [SEP]", "cit": "detection of self corrections on transcriptions before parsing has been explored # otherefr ; # refr, but it is not clear that it will [SEP]"}
{"pre": "the classification approach has been used to deal with the most common grammatical mistakes made by esl learners, such as article and preposition errors # other", "cit": "system output is scored with the m2 scorer # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "on the other hand, it is hardly possible to ignore non - deterministic rules or more sophisticated lms # otherefr ; # refr. [SEP] the", "cit": "to overcome these limitations, many syntaxbased smt models have been proposed # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we will show in the next section that our model can be trained on semcor # refr and the sense of the semcor corpus [SEP] [SEP] [SEP]", "cit": "the model is trained using subject - verb and object - verb associations extracted from semcor, a corpus # refr tagged with wordnet word - [SEP]"}
{"pre": "we use a model of the features introduced by # refr. [SEP] this method of multi - instance learning. [SEP] it [SEP] it [SEP] it [SEP] [SEP]", "cit": "following this, hoffmann et al. # otherefr and # refr propose models that consider the mapping as that of multi - instance multi [SEP]"}
{"pre": "we use the stanford pos tagger # refr to obtain the perspectives p and l. [SEP]. [SEP] features ( i. e. [SEP] a constituent", "cit": "this is essentially a simple version of the strategy mooted by # refr that the traditional order of ner and tagging be reversed. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "tees was also used for the bionlp 2011 shared task ( st ) # refr, where the event annotation guidelines were converted into [SEP] [SEP]", "cit": "the cg task is a domain - specific event extraction task targeting the recovery of information related to cancer # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr developed a supervised sequence model that model for argumentative zoning. [SEP]ion is trained on a corpus of argumentative zoning. [SEP]", "cit": "also in the educational domain, # refr train a supervised classifier to detect the? shell? language that learners use to organise the high - [SEP]"}
{"pre": "to train the classifiers, we use the same training set as in # refr. [SEP] the posterior probability distribution p ( e | f ) [SEP] [SEP]", "cit": "this approach can be considered related to n - gram posteriors # refr or minimum bayes risk decoding # otherefr ) in the context of [SEP]"}
{"pre": "# refr proposed to use syntactic similarity to estimate the similarity between pairs of phrases. [SEP] text, with the word - pair similarity model is shown in", "cit": "while early work was mostly based on hand - crafted rules # otherefr ; # refr, rosario and hearst # other [SEP]"}
{"pre": "# refr use a verb - noun combination strategy extracted from the phrase table and show that these are similar to the ones used by # otherefr", "cit": "such techniques either do not use any information regarding the linguistic properties of mwes # refr, or mainly focus on their noncompositionality # [SEP]"}
{"pre": "verbs, nouns, verbs, adjectives, and adverbs, and adverbs, as inferencing # refr. [SEP] - taking [SEP] [SEP] [SEP]", "cit": "tinguish the verb classes ~ in exploring these quesuons, we focus on verb classlficauon for several reasons verbs are [SEP]"}
{"pre": "variations of this algorithm were proposed by # otherefr ; # refr. [SEP] the decision list was extracted from the monolingual corpora. [SEP] [SEP]", "cit": "for hebrew, closed - class words that are attached to the succeeding word ( e. g.,? the?,? [SEP]"}
{"pre": "in addition to the translation model, our approach can be applied to other related tasks, such as word alignment ( alignment and # refr, we computed", "cit": "a significant source of errors in statistical machine translation is the word reordering problem # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "several wide - coverage statistical parsers have recently been developed for combinatory categorial grammar # otherefr ; # refrb ). [SEP] this", "cit": "we present a number of models over syntactic derivations of combinatory categorial grammar # otherefr and # refr, this conference, for introduction [SEP]"}
{"pre": "centre - embedding it should be noted that the focus is on the introduction of a sentence x, as follows \\ [ # refr \\ ]. [SEP]", "cit": "the logic is similar, but more general, than that used in axiomatic grammar # refrf the deduction rule is again called sequencing. [SEP]"}
{"pre": "# refr presented an unsupervised method that combines a word representation f - score of a target word by incorporating it as a measure of meaning. [SEP] a", "cit": "word - sim has been used as a benchmark for distributional semantic models in numerous studies ( see e. g. # refr ). [SEP] [PAD] [PAD]"}
{"pre": "# refr used unigrams to detect negation dependencies. [SEP] negation features, unigrams, bigrams, etc. [SEP] features to detect sentiment in", "cit": "new techniques for detection of the negation scope such as the one proposed by # refr might also be helpful in citations. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr used a measure of the precision of a system that used the recall - up set of paired words extracted from the web by counting the precision", "cit": "# refr uses a rule? based technique that scores a compound on possible semantic interpretations, while jones # otherefr implements a graph? based [SEP]"}
{"pre": "al - onaizan et al # otherefr, and # refr manipulate language model 4. 5 - gram language model # [SEP] [SEP]", "cit": "this is similar to lexicalized reordering in conventional phrase - based models # otherefr ; al - onaizan and # refr [SEP]"}
{"pre": "we parse the english side of the training data with the berkeley parser # refr, trained on the penn treebank # otherefr. [SEP] [SEP]", "cit": "these features include : pcfg features : we parse the text with a pcfg grammar # refr and we derive the counts of all node labels [SEP]"}
{"pre": "therefore, studies have recently resorted to other resources for the enhancement of parsing models, such as large - scale unlabeled data # otherefr [SEP]", "cit": "therefore, studies have recently resorted to other resources for the enhancement of parsing models, such as large - scale unlabeled data # otherefr [SEP]"}
{"pre": "for example, the paradise framework allows designers to predict user satisfaction from a linear combination of objective metrics such as mean recognition score # refr or task", "cit": "the paradise framework # refr proposes distinct measurements for dialogue quality, dialogue efficiency and task success metrics. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the stanford part - of - speech tagger # refr to obtain the noun phrases of verb, and the noun phrases [SEP] [SEP] [SEP] [SEP]", "cit": "we run all questions through the stanford corenlp pipeline ( toutanova and # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for instance, tu and roth # otherefr and # refr focused only on true light verb constructions while only object? verb constructions occurence [SEP]", "cit": "tu and # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "syntactic features have been shown to provide a strong discriminative signal of an unlabelled information, but the performance of natural language processing tasks, such as relation", "cit": "indeed, syntactic features have long been an extremely useful source of information for relation extraction systems # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use stanford part - of - speech tagger # refr to obtain the sentences of the training data. [SEP] the stanford tagger # otheref", "cit": "the pos tagger ( adapted version of the stanford tagger # refr ) achieves 90. 54 % token accuracy, which is a very good [SEP]"}
{"pre": "comparable corpora have been studied extensively in the literature # otherefr ; # refr ), but transliteration in the context of comparable corpora [SEP]", "cit": "comparable corpora have been studied extensively in the literature? e. g., # refr, but transliteration in the context of comparable corpora [SEP]"}
{"pre": "we use the features of # refr, except that we are able to define the proportion of the training data, and train a ranker, [SEP]", "cit": "it is important to realize that the output of all mentioned processing steps is noisy and contains plenty of mistakes, since the data has huge [SEP]"}
{"pre": "vector space models form the basis of modern information retrieval # otherefr ; # refr. [SEP] the vector space model by latent semantic analysis [SEP] [SEP]", "cit": "existing approaches can be roughly categorized into two kinds : knowledge - based and corpusbased, where the former includes graph - based algorithms and similarity measures [SEP]"}
{"pre": "incremental processing for spoken dialogue systems # otherefr ; bu? and # refr. [SEP] versions of speech recognition [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "figure 1 illustrates this process for the first few words of the example sentence? nimm den winkel in der dritten reihe? [SEP]"}
{"pre": "in spelling correction, # refr proposed employing a generative model for candidate generation and a hierarchy of trie structures for fast candidate retrieval [SEP] [SEP]", "cit": "methods of selecting spelling and correction pairs with maximum entropy model # otherefr or similarity functions # refr have been developed. [SEP] [PAD] [PAD]"}
{"pre": "adaptor grammars have been applied to a wide variety of tasks, including segmenting utterances into words # otherefr, and morphological analysis # refr,", "cit": "we evaluate our results with two measures : segment border f1 - score ( sbf1 ) and emma # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "for example, # refr used a combination of word phonetic and orthographic features to capture the meaning of the phoneme and lexical items. [SEP]", "cit": "in order to mitigate the problem of false alarms, we also use # refr? s continuous version, where each pair of phones is characterized by [SEP]"}
{"pre": "the log - linear model # refr, which allows a straightforward integration of syntactic constraints in order to predict the probability of a log - linear model.", "cit": "the phrase - based smt framework which we used is based on the log - linear model # refr, where the decision rule is expressed as [SEP]"}
{"pre": "in machine translation, paraphrases can be extracted from bitext or automatically # otherefr ; # refr. [SEP] the source [SEP] [SEP] [SEP]", "cit": "in a similar vein, # refr used a corpus of alternative english translations of chinese news stories in combination with a syntax - based algorithm that automatically [SEP]"}
{"pre": "in addition, we compared the performance of cross document coreference resolution system # refr. [SEP] if we need to use machine translation candidates to automatically detect", "cit": "we base our work partly on previous work done by bagga and baldwin # refr, which has also been used in later work # other [SEP]"}
{"pre": "we show that the model can be applied to dependency parsing, in particular, we show state - of - the - art dependency parsers such as", "cit": "without them, the model is arc - factored, and exact inference in it is well studied : finding the most probable parse tree takes o [SEP]"}
{"pre": "in recent years, there have been many studies on hedge detection # otherefr ; # refr and on the availability of annotated corpora # [SEP] [SEP]", "cit": "previous works such as # otherefr ; # refr present research on hedge mainly as a linguistic phenomenon. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "syntactic features have been previously used for several nlp tasks # otherefr ; # refr. [SEP] features sequence labeling # otherefr [SEP] [SEP]", "cit": "examples include # refr for semantic role labeling and kwiatkowski et al # otherefr for semantic parsing to logical forms. [SEP] [PAD] [PAD]"}
{"pre": "we use tinysvm2 along with yamcha3 # refr as the svm training and test software. [SEP] kernel # otherefr to segment [SEP]", "cit": "figure 1 : a word dependency tree ferent tasks of natural language processing # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the output of the systems capable of integrating both syntactic and semantic representations into the systems of # otherefr ; # refr. [SEP] a [SEP] system", "cit": "the shallow text processing system sprout # refr developed at dfki is a complex platform for the development and processing of multilingual resources. [SEP] [PAD]"}
{"pre": "weakly supervised learning methods for semantic lexicon generation have utilized co - occurrence statistics # otherefr, syntactic information # refr, syntactic [SEP] [SEP] [SEP] [SEP]", "cit": "the knowitall system # otherefr also uses hyponym patterns to extract class instances from the web and evaluates them further by computing [SEP]"}
{"pre": "the annotation of anaphoric relations have been developed in the linguistics community ( e. g., # refr ), and the automatic annotation of anaph", "cit": "m? # refr ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use a state - of - the - art phrase - based translation system developed by # refr which uses a gibbs sampler for learning, though they", "cit": "the seminal model 1 # otherefr has proved very powerful, performing nearly as well as more complicated models in some phrasal systems # refr [SEP]"}
{"pre": "# refr, # otherefr. [SEP] this approach, a semi - supervised sequence model which learns a probability distribution over tokens ( [SEP] [SEP] [SEP]", "cit": "the work on morphologically rich languages suggests that using comprehensive morphological dictionaries is necessary for achieving good results # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the similarity measure is calculated by using the multi - word similarity metric # refr, as calculated by correlation pearson? s correlation for the mean5 [SEP]", "cit": "following # refr, these measures have also been shown to be good for assessing semantic similarity between pairs of sentences. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr used syntactic patterns to extract polar atoms. [SEP] subjectivity and verb ( object ) -. [SEP] subjectivity. [SEP] subjectivity, [SEP]", "cit": "# refr achieved high - precision opinion phrases extraction by using relaxation labeling. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr use svm to determine whether newswire articles are positive and negative. [SEP]. [SEP]. [SEP] subjectivity. [SEP] subjectivity. [SEP] subject", "cit": "although the negative sentiment is very explicit in the ipod review # otherefr ; # refr and dialogue systems. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "significant research has examined the extent to which syntax can be usefully incorporated into statistical tree - based translation models : string - to - tree # [SEP]", "cit": "significant research has examined the extent to which syntax can be usefully incorporated into statistical tree - based translation models : string - to - tree # [SEP]"}
{"pre": "we use nombank # refr for training the ccbank parser for the nombank annotation scheme # otherefr. [SEP] this algorithm [SEP] the training", "cit": "to the best of our knowledge, this combination represents the current state - of - the - art for semantic role labelling following the prop - bank [SEP]"}
{"pre": "mindnet # refr provides a general dictionary - based approach to information extraction ( e. g., # refr ). [SEP] natural [SEP] natural [SEP]", "cit": "one early example was mindnet # refr, which was based on collecting 24 semantic role relations from mrds such as the american heritage dictionary. [SEP]"}
{"pre": "in the experiments presented in this paper, we evaluate the learned models on dependency parsing, using the pseudoprojective dependency trees # refr, and we", "cit": "recently, dependency parsing has gained popularity as a simpler, computationally more efficient alternative to constituency parsing and has spurred several supervised learning approaches # [SEP]"}
{"pre": "greedy local search # otherefr ; # refr. [SEP] the lcfr, beam - search algorithm, n2, [SEP] : k, [SEP]", "cit": "beam search incremental parsers # otherefr ; # refr provide very competitive parsing accuracies for various grammar formalisms ( cfg, ccg [SEP]"}
{"pre": "the mrss mrs is based on the general definition of semantic formalisms, e. g. # refr. [SEP] natural language processing [SEP] [SEP] natural", "cit": "we use this parser to parse the defining sentences into a full meaning representation using minimal recursion semantics ( mrs : # refr ). [SEP] [PAD] [PAD] [PAD]"}
{"pre": "the fnwn subset has 189 manually mapped the syntax of senses from framenet 1. 5 # refr to framenet 3. 5 # otheref", "cit": "for our experiments, we use the framenet database # refr which contains frame - specific se -? this research was partially supported by the ar [SEP]"}
{"pre": "id participant cmu carnegie mellon university, usa # otherefr rali rali rali, university of montreal, canada #", "cit": "the official results were slightly better because a lowercase evaluation was used, see # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in recent years, there has been growing interest in metaphor and metonymy resolution that is either corpus - based or evaluated on larger datasets # [SEP]", "cit": "2 and 3, bmw, the name of a company, stands for its index on the stock market, or a vehicle manufactured by bm [SEP]"}
{"pre": "in addition to the reordering model, hierarchical phrase - based models # refr show state - of - the - art reordering of [SEP] the [SEP]", "cit": "for translation experiments, we used cdec # otherefr, a fast implementation of hierarchical phrase - based translation models # refr, which represents [SEP]"}
{"pre": "treating the new lm as an additional feature function has the advantage that its weight can be directly optimized for smt quality together with all other feature [SEP]", "cit": "these approaches, however, have mostly focused on english # otherefr ; # refr with only recent exceptions # otherefr. [SEP] [PAD] [PAD]"}
{"pre": "the automatic detection of discourse relations, such as causal, contrast or temporal relations, is useful for many nlp applications such as automatic summarization #", "cit": "this includes work in the framework of rst # otherefr ; # refr, sdrt # otherefr. 3 the task is challenging [SEP]"}
{"pre": "in recent years, there has been an increasing interest in the task of paraphrase generation # otherefr ; # refr. [SEP] this [SEP]", "cit": "many of these metrics have been shown to correlate better with human judges than bleu # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this work also naturally draws on earlier work on the unsupervised learning of verbal arguments and semantic roles # otherefr ; # refr and unsupervised relation [SEP]", "cit": "this work also naturally draws on earlier work on the unsupervised learning of verbal arguments and semantic roles # otherefr ; # refr and unsupervised relation [SEP]"}
{"pre": "we use the subjectivity lexicon of # refr, 2available? 0. 3 subj - based emotion lexicon # otherefr. [SEP] subjectivity", "cit": "finally, the general inquirer lexicon # otherefr provides a binary classification ( positive / negative ) of 4k sentimentbearing words, [SEP]"}
{"pre": "in contrast, # refr use a cosine measure to find the similarity between a source and target words. [SEP] it differently [SEP] at [SEP] the [SEP] [SEP]", "cit": "recently, co - occurrence based measures of semantic similarity between terms has been shown to improve performance on such tasks as the synonymy test, [SEP]"}
{"pre": "for instance, # refr have used a similar method to detect the degree of verb - particle constructions in order to distinguish the coverage of verb - object", "cit": "mccarthy et al # otherefr and # refr ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the srilm toolkit # otherefr to train the lm and rely on kenlm # refr for language model scoring during decoding. [SEP]", "cit": "we use kenlm because it has been shown # refr to be faster and use less memory than srilm # otherefr. [SEP] [PAD] [PAD]"}
{"pre": "most recently, # refr used textual patterns for extracting hyponymy relations, i. e., relation extraction of relations from text. [SEP] [SEP]", "cit": "harvesting algorithms either ignore generic patterns # refr # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the berkeley word alignment model described in # refr. [SEP]onstitut to denote alignment links. [SEP]. [SEP] the posterior probability p (", "cit": "alignment with giza + + # otherefr and the berkeley aligner # refrb ) are supported. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "to evaluate the performance of different methods, we use a standard n - gram language model, namely unigrams as bigram model # otherefr", "cit": "there is ample work on analyzing the sentiments of online - review communities where users comment on products # otherefrb ; # refr ; hu [SEP]"}
{"pre": "the only supervised machine learning approach is to treat each term extraction as a classification problem as a classification problem. # refr. [SEP] the keyword extraction problem", "cit": "the keyword extraction discussed in this paper is based on work presented in # refra ) and hulth # otherefrb ). [SEP] [PAD]"}
{"pre": "# refr use machine translation techniques to learn the training parameters for a large number of parallel data. [SEP]. [SEP] it improves when they use [SEP] [SEP]", "cit": "accurate and efficient automated decipherment can be applied to other problems, such as optical character recognition # otherefr, bilingual lexicon induction # [SEP]"}
{"pre": "the underlying assumption is that the probability of entailment is proportional to the number of words in the input sentence # otherefr ; # [SEP] [SEP]", "cit": "however, such datasets cannot directly support our application, since the rte datasets are often composed of longer wellformed sentences and paragraphs # otheref [SEP]"}
{"pre": "a system is usually trained on wellformed native english text # otherefr ; # refr, but several works incorporate into training error - tagged [SEP]", "cit": "in particular, classifiers trained on artificially generated data outperformed those trained on native error - free text # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper, we aim to detect hedges rather than that the grammatical rules, we do not apply the syntactic patterns [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "# refr address this by assigning weights to hedging cues. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper, we focus on the following four of the efforts : # otherefr ; # refr for disambiguate adj [SEP] natural [SEP] [SEP]", "cit": "in a recent paper, # refr reported experiments on the acquisition of syntactic subcategorisation patterns for english adjectives. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "several methods have been proposed for singleand multi - document summarization # otherefr ; # refr. [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "in # refr submodular functions were recently applied to extractive document summarization. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in fact, many different part factorizations have been developed including neural network - to - speech tags # otherefr, and more recently [SEP] (", "cit": "for example, jiampojamarn and kondrak # otherefr develop a method for accurate letter - to - phoneme conversion [SEP]"}
{"pre": "in recent years, conditional random fields # otherefr have shown success on a number of nlp tasks, including [SEP] realisation [SEP] [SEP] [SEP]", "cit": "in particular, we show that by quarantining gazetteer features and training them in a separate model, then decoding using a logarithmic opinion [SEP]"}
{"pre": "mcclosky et al. # otherefr report an f - score of 92. 1 % using selftraining applied to the rerank [SEP]", "cit": "self - training has been shown capable of improving on state - of - the - art parser performance # refr despite the conventional wisdom on the matter [SEP]"}
{"pre": "# refr propose a model that model sense induction for wsi and evaluated the performance of a word sense disambiguation task of sense disambiguation based on", "cit": "this accords with results from wsd evaluations, where the first - sense heuristic is roughly 75 - 80 % accurate ( e. g. [SEP]"}
{"pre": "most approaches to automatically categorizing textual entailment # otherefr ; # refr, and # otherefr are unsupervised techniques. [SEP] the [SEP]", "cit": "however, previous work on review summarization # otherefr ; # refr in product or service domains focused on summarizing evaluative information? more [SEP]"}
{"pre": "# refr use discourse relations, but have not only lookeds capturing subjective or objective expressions ( e. g. [SEP] ). [SEP] subjectivity [SEP]", "cit": "several researchers have recognized the important role discourse plays in opinion analysis # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the english corpus, we evaluate the recognizer # otherefr # refr. [SEP] ( 1 ) corpus - based [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "we also ran the system on the 100 - thousand - word chinese penn treebank # refrb ) and on a 30 - thousand - word [SEP]"}
{"pre": "this kind of restriction is known to be np - hard # refr. [SEP] computational linguistics is a procedure that uses synchronous grammars of stags [SEP] [SEP]", "cit": "for example, the method of # refr synchronizes elementary trees of a prescribed form to handle translation of clauses ( verbs plus their arguments ) essentially [SEP]"}
{"pre": "in phrase - based models # otherefr ; # refr, phrase structure trees are designed for reordering the orientation of och and ney [SEP]", "cit": "using these chinese grammatical relations, we improve a phrase orientation classifier ( introduced by # refr ) that decides the ordering of two phrases when translated into [SEP]"}
{"pre": "it performs cubic time parsing for arc - factored models # otherefr ; koo and # refr. [SEP] this algorithm [SEP] [SEP] [SEP] [SEP]", "cit": "93. 03 87. 07 turboparser # otherefr 93. 79 n / a # refr 93. 5 n / a chen [SEP]"}
{"pre": "several recent works have tried to improve this model using bayesian estimation # otherefr, sophisticated initialization # refr, induction of an initial random fields #", "cit": "the common practice in the literature is to report mean results over several random initializations of the algorithm # otherefr ; # refr ). [SEP]"}
{"pre": "sentence compression has been explored in previous studies # otherefr ; # refr. [SEP] this article / a sentence is easier to use ilp [SEP]", "cit": "in later years, there has been more interest in problems such as sentence compression # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the training phase, a hidden markov model # otherefr ( hmm ), # refr is a hidden markov model for tag that is used", "cit": "# refr, in contrast, reports an accuracy of 75. 49 %, 80. 87 % and 79. 12 % for unsupervised word - [SEP]"}
{"pre": "there have been several proposed measures for similarity between two concepts # otherefr ; # refr. [SEP] the wordnet similarity in the sense for the", "cit": "for example, in the wsd task, mccarthy et al presented a method to find predominant noun senses automatically using a thesaurus [SEP]"}
{"pre": "we use nltk # refr for word sense disambiguation. [SEP] the current implementation of the nltk word similarity package # otherefr [SEP] [SEP]", "cit": "to identify content words, we used the nltk - lite tagger to assign a part of speech to each word # refr. [SEP] [PAD]"}
{"pre": "to avoid this problem, # refr proposed cross - lingual information retrieval in the multilingual lexical sample task in multiple languages. [SEP] the same domain", "cit": "because chinese words are less anibiguolls tmn english ones ( chen, bian anti # refr, we translate nouns and verbs [SEP]"}
{"pre": "in the second international chinese word segmentation bakeoff # otherefr, two of the highest scoring systems in the closed track competition were based [SEP]", "cit": "this word - by - word approach ranges from naive maximum matching # otherefr to complex solution based on semi - markov conditional random fields ( [SEP]"}
{"pre": "multiple solutions are also used for reranking # otherefr ; # refr, tuning # otherefr. [SEP] the reranking framework", "cit": "unfortunately, m - best lists are a poor surrogate for structured output spaces # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in contrast, several strategies have been proposed to learn such as restaurant on the basis of their simulated dialogue management # otherefr ; # refr", "cit": "in contrast, we learn the reward model from data, using a modified version of the paradise framework # otherefr, following pioneering [SEP]"}
{"pre": "in addition, # refr propose an unsupervised method for learning narrative schemas, chains of events whose arguments are filled with participant semantic roles defined over words,", "cit": "reference information provided by discourse is also useful for text understanding tasks such as question answering # otherefr, as well as for the acquisition of [SEP]"}
{"pre": "significance - based reordering has been performed by # refr, who applied the reordering model to score, and we also report the reordering model", "cit": "a nice property of this parsing algorithm is that it does not worsen the asymptotic running time of beam - search decoders such as moses [SEP]"}
{"pre": "this measure, which is defined in the next section, will be the most informative of the graded definition of word sense in # refr. [SEP] a", "cit": "the subtleties of sense distinctions captured by wordnet # otherefr are helpful for language learners # refr and in machine translation of languages as [SEP]"}
{"pre": "this work has focused on normalization, with many social media text, and other languages # refr. [SEP] the text written by different languages. [SEP] the", "cit": "while this diversity itself is an important resource for studying, e. g., sociolinguistic variation # otherefr ; # refr [SEP]"}
{"pre": "in this paper, we focus on the sentiment analysis of domain adaptation # otherefr ; # refr. [SEP] ( source [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "there has been a lot of work in domain adaption for nlp # otherefr and # refrb ). [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "social network extraction has recently been applied to literary theory # refr, but we do not attempt to induce social relationship types. [SEP] phenomena that are [SEP]", "cit": "we distinguish social acts from? social events? as described in # refr : social events correspond to types of interactions among people, whereas a social [SEP]"}
{"pre": "in addition, several studies have been proposed that hmm - based approaches have been proposed for this task # otherefr ; # refr. [SEP] the", "cit": "it is not surprising that opinion mining technologies have been witnessed a great interest in recent years # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "# refr describes a? lexicalized approach that is built by a ccg parser. [SEP] if two distinct derivations readings are used. [SEP]. [SEP]", "cit": "other normal form parsers, e. g. that of # refr, have the same problem. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in order to make different natural language processing tasks be able to help each other, jointly modeling methods become popular recently, such as distributional similarity [SEP] [SEP]", "cit": "this definition follows the definitions of bootstrapping in existing nlp papers # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the secondorder model, # refr proposed a dependency parser which incorporates a graph - based model with sibling dependencies, as grandparent factors # other", "cit": "our decoding models are the viterbi algorithm on crf # otherefr, and the secondorder parsing model proposed by # refr for ner [SEP]"}
{"pre": "the second approach involves generating backoff from the communicative goals of the question by # refr. [SEP] ( 2 % ) to [SEP] the chart edges [SEP]", "cit": "we follow a bottom - up chart generation approach # refr for production systems similar to # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use a support vector machine # otherefr ; # refr. [SEP] kernel expansion # otherefr, which has been widely adopted by [SEP]", "cit": "segmentation performance has been improved significantly, from the earliest maximal match # otherefr, support vector machine ( svm ) # refr, conditional random [SEP]"}
{"pre": "we evaluated translation quality using case - insensitive bleu metric # refr. [SEP] bleu # otherefr on the iwslt05 [SEP] [SEP]", "cit": "figure 2 : results of data selection and linear interpolation ( bleu ) represents the automatic metric of translation quality ( bleu score # refr in [SEP]"}
{"pre": "# refr describes a method for unsupervised dependency parsing by using the srilm toolkit. [SEP] his cluster german texts. [SEP] system. [SEP] the [SEP] [SEP]", "cit": "# refr extended brown clustering to cluster not only words but also phrases using hierarcical clustering and uses them to improve supervised partof - speech [SEP]"}
{"pre": "morphological features : both are lemmatized using the morphological analyzers described in # refr. [SEP]. [SEP]. [SEP] ( 1 ) [SEP] ) [SEP] [SEP]", "cit": "the english tagger was trained on the penn treebank and uses the english morphological database from the xtag project # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "verb errors occur as often as article and preposition errors # otherefr ; # refr. [SEP] the classification algorithm plays a role in japanese [SEP]", "cit": "for esl applications, this includes the detection of errors involving articles # otherefr, verb forms # refrb ), mass / count [SEP]"}
{"pre": "in phrase - based translation, the synchronous grammars of the translation model can be represented as a synchronous context free grammar # otherefr, and phrase", "cit": "as a baseline, we compared against the publicly available implementation of the cpu - based algorithms described by lopez # otherefr extension of the cd [SEP]"}
{"pre": "we use turbo parser # refr and the turbo parser # otherefr trained on the tiger treebank, and use it to tag the parser", "cit": "we trained 21 dependency parsing models with different configurations # otherefr models, two turboparser # refr models, and one mate - tools [SEP]"}
{"pre": "for english, we used the stanford parser # refr. [SEP] english # otherefr to get dependency parsing. [SEP] the penn treebank [SEP] [SEP]", "cit": "rather than relying on smoothing and suffix analysis alone, we also utilize treebank transformations # otherefr ; # refr instead of a grammar induced [SEP]"}
{"pre": "bleu # refr, nist # otherefr. [SEP] the similarity between two sentences in machine translation and a reference string comparison. [SEP] [SEP] [SEP]", "cit": "current automatic metrics of machine translation, such as bleu # refr, meteor # otherefrb ), which have greatly accelerated progress in mt [SEP]"}
{"pre": "we use a machine learning approach # refr which combines japanese and english base our chunk as a classification task. [SEP] a japanese expression ( as a [SEP]", "cit": "# refr have proposed a method based on machine learning to identify functional expressions. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the stanford parser # refrb ), which consists of about 1. 8. 5 % of the training corpus. [SEP] [SEP] [SEP] [SEP]", "cit": "all documents are tagged with pos tags using the stanford parser # refr, from the documents in the training data, a list of all pos big [SEP]"}
{"pre": "to solve the lexical gap problem, most researchers focused on translation - based approaches since the relationships between words # otherefr ; # refr. [SEP]", "cit": "# refr have shown superior performance compared to word - based translation models. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this scheme has proven to be effective for various tasks such as named entity recognition # refr, syntactic chunking # otherefr. [SEP] this [SEP]", "cit": "this scheme has proven to be effective for various tasks such as named entity recognition # otherefr or syntactic dependency parsing # refr. [SEP] [PAD] [PAD]"}
{"pre": "margin - based techniques such as perceptron training # otherefr and mira # refr have also been shown to be able to tune mt [SEP]", "cit": "many alternative methods have been proposed based on the algorithms in machine learning, such as averaged perceptron # otherefr ; # refrb ) [SEP]"}
{"pre": "multilingual unsupervised morphology induction of morphology learning has also been also adopted by # refr who train a variety of morphological segmentation models from multilingual corpora.", "cit": "unsupervised morphological segmentation unsupervised morphology is an active area of research # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "quantization # otherefr ; # refr uses a simple hash table including a phrase table extracted from a web corpus. [SEP] bleu on [SEP],", "cit": "# refr show that the performance of an smt system does not suffer if lm parameters are quantized into 256 distinct classes ( 8 bits per value [SEP]"}
{"pre": "we use the stanford sentiment dataset provided by # refr. [SEP] this dataset consists of short movie reviews from http : / / www. cs. [SEP]", "cit": "neural networks in general have also been applied to part - of - speech tagging, chunking, named entity recognition # otherefr, and [SEP]"}
{"pre": "in the same manner, # refr provides buse. [SEP]. [SEP]. [SEP]. [SEP]. [SEP] % of the tokens in the dialogue, [SEP]", "cit": "1work done while at at & t labs - research on the other hand, pomdp - based dialogue managers improve on traditional approaches by ( [SEP]"}
{"pre": "tempeval 2013 # otherefr ; # refr. [SEP] the representation of the problem of temporal expressions in the nlp community has been done", "cit": "tempeval - 2 # refr extended tempeval - 1, growing into a multilingual task, and consisting of six subtasks rather [SEP]"}
{"pre": "the penn treebank ( ptb ) # refr has been used for the word segmentation of english and a sentence. [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "the wsj subset of the penn treebank ii corpus incorporates selected stories from the wall street journal, year 1989 # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "we can find some other approaches that use bayesian inference techniques to avoid overfitting # refra ). [SEP] this problem as a pcfg over [SEP]", "cit": "instead, blocked sampling over sentence pairs allows much faster mixing, but done in the obvious way ( following # refr ) would incur a o ( [SEP]"}
{"pre": "this model is trained on the entire document in order to produce a set of clusters than an underlying model # refr. [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "current systems cope with this by either dividing the data into blocks to reduce the search space # otherefr, using fixed heuristics to greedi [SEP]"}
{"pre": "in addition, entity mentions are often used for use in email extraction, where they are proper names and their strings are used. # otheref", "cit": "we have annotated this dataset with two additional attributes : date and title. 2 we consider this corpus as an example of semi - structured text, [SEP]"}
{"pre": "we use the giza + + toolkit # refr to learn word classes, again in both directions. [SEP] the original word - alignment # otheref", "cit": "recent trends in machine translation illustrate that highly accurate word and phrase translations can be learned automatically given enough parallel training data # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "# refr, banik # otherefr ). [SEP] the decision to be sense of the choice. [SEP] ( s ) or [SEP] [SEP] [SEP]", "cit": "among the work that reported quantitative valuation results, most are not based on learning from an annotated corpus # otherefr ; # refr. [SEP] [PAD]"}
{"pre": "we used the stanford ner tagger # refr to detect named entities. [SEP] if the entities captures the entities of the entities of the entities of the", "cit": "most well - known is the stanford named entity recognition ( ner ) tagger # refr which assigns coarse - grained types like person, organization [SEP]"}
{"pre": "for example, the cubic grandparent edges in second - order dependency parsing slow down dynamic programs # refr can be integrated after incrementally in a dependency", "cit": "approximate parsers have therefore been introduced, based on belief propagation # refr, dual decomposition # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used the mstparser # refra ; mcdonald et al., 2005b ) as the basic dependency parsing algorithm for dependency parsing. [SEP]", "cit": "starting from # refr, it has been widely used in recent statistical dependency parsing frameworks. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "conditioning on wider syntactic contexts than simply individual head - modifier relationships improves parsing accuracy in a wide variety of parsers and frameworks # other [SEP]", "cit": "conditioning on wider syntactic contexts than simply individual head - modifier relationships improves parsing accuracy in a wide variety of parsers and frameworks # other [SEP]"}
{"pre": "we build on a number of existing algorithmic ideas, including using ccgs to build meaning representations # otherefr, building derivations to transform the output", "cit": "this includes learning from question - answer pairs # otherefr, with distant supervision # refr, and from sentences paired with system behavior # other [SEP]"}
{"pre": "we will show how # refr can be used for binarization # otherefr. [SEP] this technique. [SEP]. [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "for example, we can? train them [ see graehl et al # otherefr ; # refrb ),? parse them [SEP]"}
{"pre": "this algorithm adjusts the algorithm and its many variants are widely used in the statistical machine translation ( smt ) # refr. [SEP] ( the [SEP]", "cit": "inspired by a trick in ( li and # refr and # otherefr for oracle or hope extraction, we use a very simple metric to [SEP]"}
{"pre": "in # refr, the performance of statistical parsers were trained on the penn treebank wall street journal. [SEP] newspaper text ( wsj )", "cit": "it is also known that the most beneficial data to parse a given domain is data that matches the domain # otherefr ; # refr. [SEP]"}
{"pre": "examples of these approaches include morphological analysis # otherefr, and generation of arabic # refr. [SEP] languages # otherefr. [SEP] [SEP] [SEP]", "cit": "examples include morphology # refr and tense # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in order to overcome this limitation, we adopt the methods proposed by bannard and callison - burch # otherefr and # refr.", "cit": "recently, there have been many advances in srl # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "to evaluate the system we use the paradise evaluation framework # refr. [SEP] system ( version 1 ), which was inspired in speech recognition [SEP] [SEP]", "cit": "first work on deriving subjective metrics automatically has been performed by # refr resulting in the paradise framework, which is the current quasi - standard in [SEP]"}
{"pre": "in the case of textual entailment, te systems apply the same textual entailment framework # otherefr ; # refr. [SEP] [SEP] [SEP] [SEP]", "cit": "# refr computed automatically from collections of documents relevant to a scenario in order to approximate the semantic content of a scenario, # otherefr employed [SEP]"}
{"pre": "in this paper, we assume the socalled search engine ( henceforth abbreviation ) tool ( imdb ), which defined a [SEP] textual [SEP]", "cit": "textrank and its variants # otherefr ; # refr are graph - based text ranking models, which are derived from google? s page [SEP]"}
{"pre": "nonetheless, it is possible to perform non - projective parsing in expected linear time because the amount of nonprojective dependencies is notably smaller # other [SEP]", "cit": "for transition - based parsing, state - of - the - art accuracies have been achieved by parsers optimized on multiple transition sequences using beam search [SEP]"}
{"pre": "the model scaling factors? 1,..,.,? m? 1, n? 1,.,? 1,? 1,", "cit": "the hallucination process is motivated by the use of null alignments into markov alignment models as done by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the berkeley parser # refr for both pos tagging and cfg parsing. [SEP] the berkeley parser # otherefr trained with a pos tag", "cit": "this is in stark contrast to the best parsers based on pcfg models, such as the brown parser # otherefr ; # refr [SEP]"}
{"pre": "recently, algorithms have been developed to learn such parsers for many applications, including question answering # otherefr, relation extraction # refr, question", "cit": "interestingly, recent works # otherefr ; # refr have shown that such systems can be efficiently trained under indirect and imperfect supervision and hence scale [SEP]"}
{"pre": "the lexicalized pcfg that sits behind model 2 of # refr has rules. [SEP] this generative model, was partially done in [SEP] [SEP] [SEP]", "cit": "however, most broad - coverage statistical parsers # refr ; charniak, 2000, and others ) which are trained on the penn tree [SEP]"}
{"pre": "in the graph - based parsing literature, the main thrust of research has been on extending the eisner chart - parsing algorithm # otherefr [SEP]", "cit": "the most common approach is to use beam search # otherefr ; # refr, but more principled dynamic programming solutions have been proposed # [SEP]"}
{"pre": "one novelty this year is the work of # refr. [SEP] it uses textual summaries to find a good position of sentences. [SEP] it instead, [SEP]", "cit": "from early in the field, it was pointed out that a purely extractive approach is not good enough to generate headlines from the body text [SEP]"}
{"pre": "in addition to the mt shared task, we also report scores for estimating an alignment model ( see # refr. [SEP] this system ) [SEP] [SEP] [SEP]", "cit": "our starting point for the wmt13 qe shared task was the feature set used in the system we submitted to the wmt12 qe task [SEP]"}
{"pre": "in addition, a number of other language models have been proposed that can utilize linguistic features # otherefr ; # refr. [SEP] the [SEP] the", "cit": "we adopt the technique used in factor language models # refr to estimate the probability of a k - gram p ( e? i | c ) [SEP]"}
{"pre": "in addition, the bionlp 2009 shared task was mainly concerned with the aim of the biomedical event extraction task # otherefr [SEP] ( bio", "cit": "most previous tasks on biomedical information extraction focus on identifying interactions and events among bio - molecules # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "in tempeval 2007, 2010 # otherefr ; # refr. [SEP] a classifier trained on a larger number of events, [SEP] [SEP] [SEP]", "cit": "a classification model is trained for each category of entity pair, i. e. event - event, event - timex and timex - [SEP]"}
{"pre": "we used the estimate software for estimation, which implements the lmvm algorithm # refr and was kindly provided by rob malouf. [SEP], as", "cit": "in particular, we use the open source tadm tool for parameter estimation # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr, for example, use paraphrases to improve translation quality. [SEP] coverage in a monolingual parallel corpus, which is a foreign language", "cit": "# refr derive paraphrases from monolingual data using distributional similarity metrics. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "another line of work attempts to use syntactic information to reordering model morphology # otherefr ; # refr. [SEP] the source [SEP] [SEP] [SEP] [SEP]", "cit": "among all the languages in the europarl data - set, finnish is the most difficult language to translate from and into, as was demonstrated [SEP]"}
{"pre": "griffith # otherefr ; # refr points out the same problem and proposes a compilation solution i reynar compiler ~ w ~ w ~ w", "cit": "many algorithms for etticient mfitication of lea tare structures with dependent disjunctions have been propose. d # otherefr [SEP]"}
{"pre": "to compute the similarity between vectors, we use the cosine similarity ( using the cosine similarity ) defined by # refr. [SEP] sentences [SEP] [SEP] [SEP] [SEP]", "cit": "this suggests that distributional models and logicbased representations of natural language meaning are complementary in their strengths # refr, which encourages developing new techniques to combine [SEP]"}
{"pre": "in this paper, we describe a new system that adds a memory based learning approach to the grammatical error correction task, as described in # refr.", "cit": "we follow # refr in defining the head of a noun phrase as the rightmost noun, or if there is no noun, the rightmost [SEP]"}
{"pre": "commandtalk # otherefr, circuit fix - it shop # refr and tl : tains - 96 # otherefr are spoken language [SEP]", "cit": "commandtalk # otherefr, circuit fix - it shop # refr and trains - 96 # otherefr are spoken language systems but they [SEP]"}
{"pre": "the training data released by the task organizers comes from the nucle corpus # refr, which contains essays written by learners of english as a sentence", "cit": "the training data provided in our shared task is the nucle corpus, the nus corpus of learner english # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition to the english - chinese language, we also use the japanese dependency parsing framework of hierarchical structures # refr. [SEP] the source [SEP] [SEP] [SEP]", "cit": "as a kind of constituent structure, hpsg # otherefr and chinese - japanese # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the pos tagger is trained with the tagger described in # refr. [SEP]. [SEP] the tagger of # otherefr. [SEP] his", "cit": "models based on maximum entropy are therefore well suited to the sentence extraction task, and furthermore, yield competitive results on a variety of language tasks # [SEP]"}
{"pre": "ppi extraction methods use manually annotated text corpora # otherefr ; # refr, and machine learning approaches are still applied to extract ppi extraction and [SEP]", "cit": "overfitting remains a severe problem in ml based methods as these results are inferior to those measured in cross - validation # otherefr, though [SEP]"}
{"pre": "# refr developed an approach that combines a unified rte theory and the entailment features based on the entailment rules for rte that are dependency", "cit": "recent studies have also investigated how complex sentence - level entailment relations can be broken down into smaller consecutive steps involving fragment - level entailment # [SEP]"}
{"pre": "we use the model of # refr, which is a tag that is applicable only in a derivation of like? x ~ x. [SEP] y?", "cit": "in addition to adjunction, we also use sister adjunction as defined in the ltag statistical parser described in # refr. 1 the tree [SEP]"}
{"pre": "# refr showed that unsupervised methods achieve better performance than those of the unsupervised pos tagging accuracy. [SEP] 84. 54 % accuracy when applied to pp attachment", "cit": "the dominance becomes even more obvious if we consider that the following 6this is actually what has been done in some research on english pp attachment disambig [SEP]"}
{"pre": "most work on sentiment analysis consider either the or sentence - level # otherefr ; # refr, or sentence - level # other [SEP] [SEP] [SEP]", "cit": "although sentence - level annotations are easier to obtain, the analysis at this level cannot cope with sentences conveying relations of multiple types # refr. [SEP]"}
{"pre": "id participant cmu carnegie mellon university # otherefr cu - bojar charles university # refr cu - bojar # otheref", "cit": "the difference with respect to all the other submissions is statistically significant at p = 0. 05, using pairwise bootstrap resampling # refr. [SEP]"}
{"pre": "we used the syntagrus treebank # refr. [SEP] english verb /, constructed manually annotated with syntactic relations. [SEP] [SEP] manuals derived from", "cit": "treebanks constructed with detailed linguistic information play an important role in various aspects of natural language processing ; for example, grammatical knowledge acquisition ; world [SEP]"}
{"pre": "in the past, subsections of the penn treebank # otherefr have been annotated for english, and there are some evaluation techniques [SEP] [SEP] [SEP]", "cit": "to our knowledge, only # refr and ma et al # otherefra ) experimented with other kinds of statistical models. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "# refr used integer linear programming ( ilp ) to find the best - link inference using integer linear programming ( ilp ). [SEP] ( il", "cit": "our inference model follows constraint - based formulations that were introduced in the nlp community and were shown to be very effective in exploiting declarative background knowledge [SEP]"}
{"pre": "the corpora are the preposition sense disfluency detection shared task in the english writing of esl corpus # refr. [SEP] english [SEP] [SEP] [SEP]", "cit": "for example, determiner mistakes usually occur in 5 % to 10 % of noun phrases in various annotated esl corpora # refra ). [SEP]"}
{"pre": "in addition to the portability problem, we have used thesaurus - based word sense disambiguation # refr, and thesaurus construction [SEP]", "cit": "this is based on a technique for disambiguating noun groups using wordnet by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we also evaluate our approach on english and french, using the well - known treebanks, and the pos tags that we use in [SEP] [SEP]", "cit": "the treebank sources are # otherefr, ( 3 ) : # refr, # otherefr. from the forest - to - [SEP]"}
{"pre": "# refr combine a separate translation model interpolation with feature weights trained on the source domain and the target data. [SEP] - domain data are optimized jointly trained", "cit": "so far, this challenge has been addressed by repurposing techniques developed for more clear - cut domain adaptation scenarios, such as linear mixture models [SEP]"}
{"pre": "# refr used a supervised machine readable linguistic ( discourse ) system to predict the syntactic cue phrases to predict the meaning of text complexity. [SEP] sentences", "cit": "5similar features have been used for automatic essay grading as well # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use a maximum - entropy model, based on the regularized averaged perceptron # refr. [SEP] features # otherefr applied to accommodate the", "cit": "our baseline system is a faithful implementation of the perceptron tagger in collins # otherefr, i. e., a trig [SEP]"}
{"pre": "for example, the introduction of global training or complicated features # otherefr ; # refr. [SEP] the word sequence labeling problem plays an important role", "cit": "for example, the introduction of global training or complicated features # otherefr ; # refr, and the semisupervised and unsupervised technologies utilizing raw [SEP]"}
{"pre": "# refr use biographical facts from the web as a semantic network. [SEP] a person name leading to a word, an aid [SEP] [SEP] [SEP]", "cit": "this model is used to find the similarity among referents, and thereby identify the same referent that occurs in multiple documents. # refr take [SEP]"}
{"pre": "in the context of the speaker? s speaker, we propose a model for the speaker interpreting language that is trained on the basis of the speaker?", "cit": "moving away from full supervision, the work of # refr uses a game - theoretic model to explicitly model the roles of dialogue participants. [SEP] [PAD] [PAD]"}
{"pre": "in statistical parsing literature, it is common to see parsers trained and tested on the wsj corpus, but they have therefore lead to a much", "cit": "for example, statistical parsers from magerman # otherefr on use features based on head - dependent relationships. ( the parsers developed [SEP]"}
{"pre": "the treebanks that have been used in various ways in the penn treebank # otherefr, and in general # refr ), but", "cit": "as well as evaluating the quality of our extracted semantic forms, we also examine the rate at which they are induced. # otherefr and [SEP]"}
{"pre": "a plethora of prior work has exploited orthographic, topic, and contextual similarity, to name a few # refr. [SEP], [SEP],", "cit": "that the extrapolation to more ab - stract notions is possible has been claimed by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "to translate the mwe candidates, some researchers have focused on extending the dictionary to use all of them, including the definition of [SEP] a [SEP] a", "cit": "in both cases, translations of the mwe and its components are sourced from panlex # refr, and if there is greater similarity between [SEP]"}
{"pre": "lexico - syntactic patterns # refr a substring occurring between a two segments extracted from text in a domain. [SEP] a pattern and [SEP] [SEP] [SEP]", "cit": "this works quite well, as the information extraction component supplies regular output. # refr motivated the acquisition of hyponyms by applying pattern matching to [SEP]"}
{"pre": "in the case of communication - oriented dialogue, this approach has been addressed in numerous previous work # otherefr ; # refr. [SEP] this problem", "cit": "similar issues arise in semantic authoring systems # refr, where at each step of the sentence creation process, the system offers possible symbols for a [SEP]"}
{"pre": "we use our n - gram language model in our experiments, using the method described in # refr. [SEP]. [SEP] 1 1 1 1 1 1", "cit": "we use our own implementation of these methods to report optimal solutions to 1 : 1 substitution ciphers for language model orders n = 2 and n [SEP]"}
{"pre": "the main differences between the results are that all reported in # refr and perplexity of the best systems, which were computed from the five [SEP]", "cit": "some recent works # otherefr ; # refr related to corpus weighting, make use of data selection, data weighting, and translation model adaptation [SEP]"}
{"pre": "the model is trained using the online learning algorithm of conditional random fields # otherefr and unsupervised models # refr. [SEP] criteria [SEP] [SEP] [SEP] [SEP]", "cit": "these include biases like the size principle # otherefr ; # refr, or innate prespecifications like universal grammar in the principles and parameters [SEP]"}
{"pre": "rhetorical structure theory # otherefr ; # refra ) can be used to guide the summary of a document to convey the important sentences [SEP]", "cit": "# refra ) uses rhetorical structure analysis to guide the selection of text segments for the summary ; similarly teufel and moens # [SEP]"}
{"pre": "intensionally existing ilp - based approaches to nlp ( e. g. # refr ) belong to the class of zero - one [SEP]", "cit": "the approaches used are integer linear programming 1typically a pair of coreferential mentions mi and mj # otherefr ; klenner and [SEP]"}
{"pre": "previous methods for content selection include reinforcement learning # otherefr ; statistical methods # refr, and multi - objective metrics # otherefr. [SEP]", "cit": "# refr found similar results when performing a study on generation of emphatic facial displays. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "entrainment has been shown to occur for numerous aspects of spoken language, including speakers? choice of referring expressions # otherefr, and [SEP]", "cit": "this study, previously presented in ( levitan and # refr, creates a cohesive view of entrainment by directly comparing entrainment [SEP]"}
{"pre": "the terp - st? ted, ter # refr, ter # otherefr, among others. [SEP] the cross - lingual [SEP] the", "cit": "we were drawn to the terp ( translation edit rate plus ) translation metric # refr for our initial study because of its particular approach toward capturing [SEP]"}
{"pre": "1993 ; wu & tseng 1993 ; # refr. [SEP]. [SEP]. [SEP] this work : e. g. [SEP] t. [SEP] t.", "cit": "the corpus was sentence - aligned statistically # otherefr ; chinese words and collocations were extracted # refr ; then translation pairs were learned via [SEP]"}
{"pre": "previous work in sentiment analysis includes # refr, who employed a conditional random field ( crf ) - based probabilistic sequence model # otherefr. [SEP]", "cit": "we hypothesize that these, and other, examples will be difficult for the tagger unless the context surrounding each sentence is considered and in the absence [SEP]"}
{"pre": "to evaluate the effectiveness of our language model, we use the berkeley language model3 # refr to train a 6 phonetiz [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "we have carried all our experiments on the icampus corpus # refr prepared by mit csail. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in a second study, # refr used the csl corpus of essays written by callison - burch and osborne # other [SEP] [SEP]", "cit": "more recently, # refr and chen and zechner # otherefr have measured syntactic competence in speech scoring. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "cohen et al # otherefr, # refr, and covington et al # otherefr ). [SEP] a linear model [SEP] [SEP] [SEP]", "cit": "computational linguistics volume 39, number 1 frequently annotates them because it has no way of checking whether the function has already been annotated ( see also [SEP]"}
{"pre": "the pdtb team reported interannotator agreement in the lower 90 % for explicit discourse relations # refr. [SEP] the penn discourse treebank #", "cit": "assessment of inter - annotator agreement groups these annotations into five coarse classes # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, we also show that the system of # refr can be applied to our task. [SEP] text similarity by comparing the [SEP] [SEP] [SEP] [SEP]", "cit": "although these implications are uncontroversial, their automatic recognition is complex if we rely on models based on lexical distance ( or similarity ) [SEP]"}
{"pre": "this technique has been found to be effective for dependency parsing # refr. [SEP] the word - pair similarity calculation operations we use the first [SEP] [SEP] [SEP]", "cit": "research in the field of unsupervised and weakly supervised parsing ranges from various forms of em training # otherefr to feature - based enhancements of discriminative [SEP]"}
{"pre": "therefore, a variety of techniques have been developed to enrich pcfg # otherefr ; # refr. [SEP] this approach is [SEP] [SEP] [SEP] [SEP]", "cit": "the knowledge contains content words semantic resources base # otherefr ; # refr, named entity cues # otherefr and so on. [SEP] [PAD]"}
{"pre": "we use the berkeley word alignment model described in # refr. [SEP]. [SEP] a variant of the model performs slightly better than the unsupervised probability [SEP] [SEP]", "cit": "we aligned both bitexts with the berkeley aligner # refr configured with standard settings. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used bleu # refr, which is the geometric mean of the n - gram precisions in the output of a reference translation [SEP] [SEP] [SEP]", "cit": "the empirical evaluation of all our systems on the two standard metrics bleu # refr and ter # otherefr is presented in table 5. [SEP]"}
{"pre": "in addition to the translation model, we incorporate a linguistically - motivated language model features that are significantly more commonly used in smt pipeline, including", "cit": "syntax - based pre - ordering by employing constituent parsing have demonstrated effectiveness in many language pairs, such as english - french # otherefr, [SEP]"}
{"pre": "in order to utilize several natural language processing tools ( nlp ) tools ( e. g., machine learning techniques [SEP] [SEP] text processing # refr", "cit": "the ability to tag proper names such as organization, person, and place names in multilingual texts has great value for tasks like information extraction, [SEP]"}
{"pre": "we use a conditional random fields # otherefr, shallow parsing # refr and named entity recognizers # otherefr. [SEP] this [SEP] [SEP]", "cit": "specifically, to account for skip - edges, we used a technique inspired by # refr, in which multiple state dependencies, such as an order [SEP]"}
{"pre": "we used the mada atb segmentation for extracting new pairs from the english parallel corpus. # refr and using the technique used in # otheref", "cit": "the dictionary based features are language dependent and are computed using bilingual dictionaries which are created with giza + + # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "bootstrapping method # otherefr ; # refr can be considered as a way to automatically in which the given context in order to classify named entities", "cit": "indeed, although the algorithm has been applied successfully to natural language processing # otherefr and named entity classification # refr ), there has been [SEP]"}
{"pre": "phrase - based translation models # refr are hierarchical in english machine translation. [SEP]. [SEP] a synchronous context - free grammar ( scfg ) model #", "cit": "bilingual phrases are cornerstones for phrasebased smt systems # otherefr ; # refr and existing translation systems often get? crowd - [SEP]"}
{"pre": "in addition to the traditional readability assessment, we incorporate text segmentation features provided by the sentence segmenter # otherefr ; # refr [SEP] [SEP]", "cit": "we used crfsbased japanese dependency parser # otherefr and named entity recognizer # refr for sentiment extraction and constructing feature vectors for read [SEP]"}
{"pre": "we used a hidden markov model # otherefr and the hmm model # refr for pos tagging and performed taggers. [SEP] this model [SEP] [SEP]", "cit": "recent work # otherefr ; # refr explored the task of part - of - speech tagging ( pos ) using unsupervised hidden markov models ( [SEP]"}
{"pre": "one way to approach rerank this is to use syntactic features, either by adding structural features # otherefr, formal # refr, formal #", "cit": "works using syntactic features to extract topics and holders of opinions are numerous # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we tokenized and part - of - speech tagged the tweets with the carnegie mellon university ( cmu ) twitter nlp tool [SEP]", "cit": "table 3 : orthographic styles induced from automatically normalized twitter text ics must be left to future research, but they offer a promising generalization of [SEP]"}
{"pre": "figure 1 : graphical models of lexicalized functional information in the world, including part of speech tagging, and speech tagging, etc. [SEP] the dialogue", "cit": "the eleon authoring tool # refr can be used to annotate owl ontologies with linguistic and content - selection resources and inter - operates with [SEP]"}
{"pre": "zanzotto et al # otherefr and # refr also proposed linear transformation models for composition and address the issue of estimating the degree [SEP]", "cit": "# refr and zanzotto et al. # otherefr propose a full form of the additive model ( fulladd ), where [SEP]"}
{"pre": "previously, unlabeled data is explored to derive useful local - context features such as word clusters # otherefr, subtree frequencies # refr, and [SEP]", "cit": "for syntactic features, we adopt those of # refr which include two categories corresponding to the two types of scoring subtrees in fig. 2. [SEP]"}
{"pre": "for instance, the description of the document in the document, it is based on the v - measure # refr. [SEP] the frequencies of named [SEP]", "cit": "wacholder et al 1997, # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr have recently shown that creating a pos tagger could be applied to a wide range of languages, such as english and french ( and [SEP]", "cit": "our efforts described here were inspired by some recent work on low - density languages # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we can also use the posterior probability of a word as defined by an ibm model # refr. [SEP] the word sequence over the sentence to denote the", "cit": "in addition, # refr define a graph distance as a loss function for minimum bayes - risk word alignment, riesa and marcu # other [SEP]"}
{"pre": "parser uas las # otherefr 93. 26 t ( baseline ) 92. 7 g2a ( baseline ) 92. 89 [SEP] [SEP] features", "cit": "third, we take into account two groups of complex structural features that have not been previously used in transition - based parsing : nonlocal features # [SEP]"}
{"pre": "over the years, several approaches for mining translations from non - parallel corpora have emerged # otherefr ; # refr, all sharing the same [SEP]", "cit": "over the years, several approaches for mining translations from non - parallel corpora have emerged # otherefr ; # refr, all sharing the same [SEP]"}
{"pre": "in recent years, with the advent of the timeml markup language # otherefr ; # refr. [SEP] this approach has been [SEP] [SEP]", "cit": "in recent years, with the advent of the timeml markup language # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "parsing accuracy has been used since the lately event - to the dependency structure, but there has been a lot of work on the dependency structure of", "cit": "since we cannot try em on mcdonald? s conditional model, we ran some pilot experiments using the generative dependency model with valence ( dmv ) [SEP]"}
{"pre": "# refr use a latent variable model to find a topics over words, instead of those that are syntactic structure should be obtained. [SEP] [SEP] [SEP] [SEP]", "cit": "like # refr, # otherefr, we model words as being generated from latent distributions. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr. [SEP] distributional semantics of compositionality, as well as a binary classification task ( sf ), as a multiplicative framework [SEP] [SEP] [SEP] [SEP]", "cit": "the shared task distributional semantics and compositionality # otherefr shows a variety of techniques for this task, mainly association measures and vsm # [SEP]"}
{"pre": "this is related to the algorithm of # refr. [SEP] the minimum bayes risk ( mbr ) procedure maximizes the expected possible sampling of the [SEP] [SEP]", "cit": "we use the phrase - based gibbs sampler of # refr at training time to compute the gradient of our minimum risk training objective in order to apply [SEP]"}
{"pre": "we use tinysvm2 along with yamcha3 # refr as the svm training and test software. [SEP] kernel # otherefr to segment [SEP]", "cit": "we use the yamcha # otherefr ; # refr chunker for our text chunking. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this approach, the approach of # refr and haghighi and klein # otherefr are all used in nlp tasks [SEP] [SEP] [SEP]", "cit": "other approaches for solving inference include the use of cutting plane inference # otherefr ; # refr and the related method of lagrangian relaxation # other [SEP]"}
{"pre": "we build a hierarchical translation grammar that uses the ghkm transducer rules and lexicalized tree - to - string rules # otherefr ; [SEP] all", "cit": "setup we tested these features on two machine translation systems : a hierarchical phrasebased # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr find the average continuity sentence : an example sentence to identify the sentence level of coherence of text segments whose parts is known to predict the [SEP]", "cit": "other work has shown that co - occurrence of words # otherefr and discourse relations # refr also predict coherence. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "often, methods for opinion, sentiment, and subjectivity analysis rely on lexicons of subjective # otherefr ; # refr ). [SEP] [SEP]", "cit": "for this paper, subjectivity sense - tagged data was obtained from the mturk workers using the annotation scheme of # refr. [SEP] [PAD] [PAD]"}
{"pre": "in this paper, we describe the notion of semantic roles across a set of verbs, and their occurrences were acquired using a small number of patterns [SEP]", "cit": "in the pattern - mining mode we use the general pattern subject? verb? object, where the components may have any semantic type and are constrained [SEP]"}
{"pre": "this is mainly drawn from the ace 2005 shared task # otherefr ; # refr. [SEP] this approach is to transfer learning [SEP] [SEP] [SEP] [SEP]", "cit": "this technique is used in many recent works including dependency parsing and ner # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we parse the input using the trpost parser # refr. [SEP]uator \\ [ re iterr \\ ], is used to define a coordination", "cit": "so tile goal can be usefblly approximated witl ~ formalisms which make some limited distincfions between informatio ~ a pp [SEP]"}
{"pre": "we train the model using the averaged perceptron algorithm # refr. [SEP] - crf - based model, which learns a distribution p ( w | [SEP]", "cit": "several different learning methods are available for structured prediction models including structured perceptron # refr, max - margin models # otherefr. [SEP] [PAD] [PAD]"}
{"pre": "in addition, the features of the entity - level features have been employed # otherefr ; # refr. [SEP] this work [SEP] the [SEP] [SEP]", "cit": "7. 1. 2 cluster - ranking model the cluster - ranking # otherefr ) and the mention - ranking model ( e. g [SEP]"}
{"pre": "this result suggests that the conventional averaged perceptron model trained with beam search decoders outperform the perceptron algorithm # refr. [SEP] bleu [SEP]a", "cit": "in future work, we will explore a combination of large - scale discriminative training # refr with multi - task learning for smt. [SEP] [PAD] [PAD]"}
{"pre": "graph - based methods have been successfully used for textrank # refr and graph - based approaches # otherefr. [SEP] the graphranking algorithm", "cit": "unsupervised approaches have also been proposed, e. g. by # refr and liu et al # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper, we evaluate the systems using the content scoring program, which we use a measure of word similarity, which was computed from the sw", "cit": "most previous research on automated grading of written text focuses on short, factual text # otherefr ; # refr, whereas save science? [SEP]"}
{"pre": "previous work mainly studies the attitudes in spoken meetings # otherefr or broadcast conversations # refr using conditional random fields # otherefr. [SEP] features", "cit": "while detecting agreement and disagreement in conversations is useful on its own, it is also a key component for related tasks, such as stance prediction # [SEP]"}
{"pre": "translation hypotheses are scored according to the following features :? 4 phrase - table scores : phrasal translation probabilites with kneser - ney [SEP]", "cit": "new learning algorithms # refr ; cherry and foster, 2012, for instance ) finally make it possible for pbsmt to reliably learn from many [SEP]"}
{"pre": "morphological analysis or segmentation is crucial to the performance of several applications : machine translation # otherefr ; # refr ; habash and sadat [SEP]", "cit": "many researchers have tried to employ morphology in improving word alignment techniques # otherefr, # refr, among others, for various languages ; gold [SEP]"}
{"pre": "while many works # otherefr ; # refr focus on predicting how discourse properties are available in an utterance representation. [SEP] student dialogues the [SEP]", "cit": "they may help lessen the student? s cognitive load # otherefr by drawing attention to what is most important in what the student said [SEP]"}
{"pre": "over the last decade, # refr has emerged that the applicability of referring expression, to the problem of referring expression generation in natural language generation, [SEP]", "cit": "over the last decade, # otherefr, # refr, and others 2 have contributed to this issue # otherefr ). [SEP] [PAD]"}
{"pre": "# refr proposed a method that uses clustering to learn the contexts of words for a given target word. [SEP] it takes the first account for the vector", "cit": "the use of dimensionality reduction techniques, for instance latent semantic analysis in # otherefr, the multi - prototype # refr or examplar [SEP]"}
{"pre": "we use the senserelate : : : : : : : : : : similarity # refr to perform all the words in the sentence. [SEP]", "cit": "sr - aw finds the sense of each word that is most related or most similar to those of its neighbors in the sentence, according to any [SEP]"}
{"pre": "in 2006, the shared task was multilingual dependency parsing, where participants were evaluated within the parsers of nivre # otherefr, and", "cit": "by default, the conversion tool outputs a treebank using the annotation style of the conll - 2008 shared task # refr ; however we wanted [SEP]"}
{"pre": "the features are computed during the decoding, and we use the lowercased ( section 4. 6 ) [SEP] features into a development set [SEP] [SEP]", "cit": "these fourteen scores are weighted and linearly combined # otherefr ; # refr ; their respective weights are learned on development data so as to maximize [SEP]"}
{"pre": "simultaneously, mounting efforts have been directed towards smt models employing linguistic syntax on the source side # otherefr ; # refr or both # [SEP]", "cit": "later work # refr takes a more flexible approach, influencing translation output using linguistically motivated features, or features based on source - side linguistically [SEP]"}
{"pre": "the xerox implementation of the general nlp approach has been well - formed from the subject of much more complex information retrieval tasks such as [SEP] (", "cit": "a similar technique for handling both syntactic and semantic variations can be found in # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "textrank # refr is a graph - based ranking model that showed that a word sense disambiguation process derived from a word? s position can improve", "cit": "specifically, we apply tfidf ranking and textrank # refr keyword extraction on twitter messages after a series of text preprocessing steps. [SEP] [PAD] [PAD]"}
{"pre": "note that this contrasts with binarization algorithms # otherefr ; g? omez - rodr? # refr that are applied after [SEP] to", "cit": "see # refr for discussion of the relation between constituent and dependency structures and see # otherefr for a comparison of discontinuity and non - project [SEP]"}
{"pre": "in this work, we reordering model using a constituency parser # refr. [SEP] the source parse to each source sentence, and we add a", "cit": "these methods also try to leverage syntax, typically by applying hand - coded or automatically induced reordering rules to a constituency or dependency parse of [SEP]"}
{"pre": "significant progress has also been made in paraphrase extraction, where most recent methods produce large numbers of paraphrasing rules from multilingual parallel [SEP]", "cit": "in question answering, for example, paraphrase generators can be used to paraphrase the user? s queries # otherefr ; [SEP]"}
{"pre": "few have attempted to use, or approximate, diathesis features directly for verb classification although manual classifications have relied on them heavily, and there [SEP]", "cit": "we used the spectral clustering # otherefr which is frequently used in verb clustering experiments # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the language use, a natural language processing tool for text categorization has been successfully used for document classification # otherefr, and part - of", "cit": "word shape token processing has been proven to be of use for european language identification # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for example, one needs to identify summarization systems ( tsg ) is unsupervised extractive summarization as a model of [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "other methods include clustering based on sentence similarity and choosing the centroids # otherefr or choosing the best connected sentences # refr. [SEP] [PAD] [PAD]"}
{"pre": "for example, the centering algorithm # otherefr ; # refr allows for the straightforward sampling of the center of salience, [SEP] phenomena [SEP] [SEP]", "cit": "a notable exception is # refr, which used an annotated corpus to compare the performance of two variants of centering theory. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the second set of features has been well explored in the context of machine translation systems # otherefr ; # refr. [SEP] the [SEP] [SEP] [SEP]", "cit": "the chinese text was segmented using a crf - based word segmenter # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "topic segmentation approaches range from simple heuristic methods based on lexical similarity # otherefr to more intricate generative models and supervised methods # refr, [SEP]", "cit": "modeling individuals? perspective # otherefr,? side? # refr, or personal preferences for topics # otherefr would enrich the model [SEP]"}
{"pre": "the chinese texts were word segmented using the morfessor tool # refr. [SEP] system. [SEP] segmented decision trees. [SEP] ( [SEP]a ) [SEP]", "cit": "for each state, the character identity features # otherefr, # refr are represented using feature functions that key off of the identity of the [SEP]"}
{"pre": "# refr describe a statistical model that is trained on corpora of verbs, and tested on the penn treebank. [SEP] arguments of verbs, [SEP] [SEP]", "cit": "function tags were assigned using a simple probability model trained on the wall street journal data from the penn treebank, in a technique similar to that [SEP]"}
{"pre": "in recent years, there has been a growing interest in recognizing deception in opinion detection # otherefr ; # refr. [SEP] ( 1 )", "cit": "the mihalcea - strapparava mturk dataset was further used in a study by # refr which employs lexicalized and [SEP]"}
{"pre": "the part of speech ( pos ) tagger # refr involves the input to our knowledge, but also using this information. [SEP]. [SEP]. [SEP]", "cit": "the use of concept spotting is common in spokenlanguage information systems # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in sentiment analysis, detecting negation has been studied, and studied in # otherefr # refr. [SEP] negation modeling # otherefr [SEP] [SEP]", "cit": "negation has also been studied in sentiment analysis # refr as a means to determine the polarity of sentiments and opinions. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in recent years, statistical surface realisation have been described by # refr. [SEP] a statistical model of stochastic unification - based ranking. [SEP] the", "cit": "fergus # refr used the penn treebank as a corpus, requiring a more substantial transformation algorithm since it requires a lexical predicate - argument structure [SEP]"}
{"pre": "affixes have been shown to be useful in part - of - speech tagging # otherefr ; # refr. [SEP] [SEP] the [SEP] [SEP]", "cit": "the lorg parser is very similar to the berkeley parser # otherefr, the main difference being its unknown word handling mechanism # refr. [SEP]"}
{"pre": "# refr use a machine learning approach to determine whether a candidate? s citation has a long history and often addressed in citation context. [SEP] it has", "cit": "a more sophisticated, discourse - aware citation indexer which finds these sentences and associates them with the citation would add considerable value to the researcher? [SEP]"}
{"pre": "2013 ; poon, 2013 ; artzi et al, 2013 ; # refr ; then, the answers are retrieved from existing kbs using [SEP]", "cit": "most previous systems tackle this task in a cascaded manner : first, the input question is transformed into its meaning representation # otherefr ; [SEP]"}
{"pre": "we used the stanford parser to obtain the pos frequencies. # refr for the pos - tagging. [SEP] # otherefr. [SEP] the [SEP] [SEP]", "cit": "we used the stanford parser # refr with its default chinese grammar for its pos - tagging as well as finding the head / dependent words of all [SEP]"}
{"pre": "nonparametric methods instead have the flexibility of automatically deciding thesaurus construction for wsd # otherefr ; # refr. [SEP] the [SEP] [SEP] [SEP]", "cit": "as in prior work including b & l, we rely on the intuition that the senses of words are hinted at by their contextual information # [SEP]"}
{"pre": "charts have been used in information retrieval systems to detect the grammatical information in natural language input sentence, e. g., # otherefr,", "cit": "cf - psgs, dcgs # otherefr, patr - ll # refr ), then there is a possibility of constructing other [SEP]"}
{"pre": "previous research on domain adaptation for smt includes data selection and weighting # otherefr ; # refr, and semi - supervised transductive learning [SEP]", "cit": "previous research on domain adaptation for smt includes data selection and weighting # otherefr ; # refr, and semi - supervised transductive learning [SEP]"}
{"pre": "topic models have been applied previously for a number of tasks # otherefr ; # refr. [SEP] text documents # otherefr [SEP] [SEP] [SEP]", "cit": "we point to examples of previous work such as # refra ) where image annotations generated from a topic model are used to help generate full sentences [SEP]"}
{"pre": "in the last years, several authors have proposed to improve the performance of word alignment and alignment techniques # otherefr ; # refr. [SEP] [SEP]", "cit": "previously proposed approaches to extend the hmm alignment model include och and ney # otherefr? s use of word classes and smoothing, and [SEP]"}
{"pre": "we used the five groups of features, namely : i ) questqe : 17 qe features provided by the quest toolkit6. [SEP] [SEP] [SEP]", "cit": "we have re - implemented a particular filtering scheme based on bm25 # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "several approaches have been proposed to deal with this problem, namely, the automatic acquisition of large corpora # otherefr ; # refr. [SEP] [SEP]", "cit": "most of the work up to now has aimed at english # otherefr and # refr ), however # otherefr presented automatic learning [SEP]"}
{"pre": "we use the kbp # otherefr parser which were trained on freebase # refr. [SEP] sentences of newswire text # otheref [SEP]", "cit": "previous work on semantic parsing on freebase uses a combination of manual rules # otherefr, distant supervision # refr, and schema matching # [SEP]"}
{"pre": "from this perspective, one can employ an improved dependency parser # refr. [SEP] ( 1 ) models in this form x is [SEP]. [SEP] [SEP] [SEP]", "cit": "for example, smith and smith # otherefr ; mi and # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "to obtain the pos information, we use the reranker of # refr for preprocessing and non - syntactic annotations. [SEP] readers with [SEP] features [SEP]", "cit": "the current work follows the same approach as other n - best list re - rankers # refr ; specia et al. # otheref [SEP]"}
{"pre": "our system is based on centering theory # otherefr, which has been used for several discourse processing ( such as information retrieval [SEP] ( [SEP]", "cit": "information status ( as defined by # refr ) of the de,. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we have been impressed by the success of yarowsky? s wu and # refr similarity measure # otherefr. [SEP] [SEP] [SEP] [SEP]", "cit": "in parallel corpora, this feature could be the positional co - occurrence ofa word and its translation in the other language in the same sentences # [SEP]"}
{"pre": "the results from conll shared tasks in 2005 and 2008 # otherefr ; # refr, further show that srl pipeline may be one [SEP]", "cit": "here, the same features are used, though all dependency pairs rather than short dependency pairs are extracted along with the dependency direction from training data rather [SEP]"}
{"pre": "this approach has successfully been applied to the classification task # refr. [SEP] classification of verb classification. [SEP] disambiguation. [SEP] the results in a word", "cit": "clustering methods have also been extensively researched for verb classification # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in fact, many different parsers have been developed, including neural networks # otherefr, semisupervised pos tagging # refr, parsing [SEP] [SEP]", "cit": "co - training # otherefr and classifier combination # refr are two technologies for training improved dependency parsers. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we chose svms as they have been shown to perform well on a variety of datasets, including twitter # otherefr ; # refr. [SEP]", "cit": "this task is related to, but distinct from, several other studies that have been made using comments and discussions in political communities, or analysis of [SEP]"}
{"pre": "in this paper we discuss how we discuss how we discuss how we could be used for learning from document - level dialogue, e. g. #", "cit": "# refr show how to compute automatically preference representations for a whole stretch of dialogue from the preference representations for elementary discourse units. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the senseval - 3 english lexical sample data # refr to estimate the frequencies of the probability of a lexical entry for the occurrence of the", "cit": "here attested frequencies from semcor # refr are used, so all ancestors are considered. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in recent years, several dependency parsing algorithms # otherefr ; # refr have been proposed and achieved high parsing accuracies on several treebanks [SEP]", "cit": "following plank and van noord # otherefr shared task # refr which are also from wsj sections 2 - 21 but converted into dependency [SEP]"}
{"pre": "we use a neural network # otherefr ; li and # refr. [SEP] features in order to classify questions into a binary classification framework. [SEP]", "cit": "trec : trec question dataset? task involves classifying a question into 6 question types ( whether the question is about person, location, numeric [SEP]"}
{"pre": "in this paper, we focus on the annotation study presented by # refr. [SEP] the recognition hypothesis that a single annotation scheme called user will be [SEP]", "cit": "recent emphasis has been placed on evaluating the effectiveness of active learning # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "most of the state - of - theart systems have been proposed # otherefr ; # refr. [SEP] this assumption [SEP] this assumption [SEP] the", "cit": "this capability is very desirable as shown by the success of the rule - based deterministic approach of # refr in the conll shared task 2011 # [SEP]"}
{"pre": "log - linear models are used in the penn treebank ( ptb ) # refr. [SEP] the training data ; a log - linear model ;", "cit": "discriminative log - linear models are now becoming a de facto standard for probabilistic disambiguation models for deep parsing # otherefr ; # refr [SEP]"}
{"pre": "this information is also consistent with prior work on semantic analysis has exploited to provide useful the development of large databases of semantically annotated databases # otherefr", "cit": "finally, srl requires hand - constructed semantic resources like propbank and framenet # otherefr ; # refr as input. [SEP] [PAD] [PAD]"}
{"pre": "to determine the polarity of sentences, we first determine the polarity value using a set of only minimal frequency, which is a common [SEP]. http :", "cit": "another problem that should be addressed is the scope of the downward entailment, generalizing work being done in detecting the scope of negation # refr [SEP]"}
{"pre": "we used the mxpost tagger # refr trained on the part - of - speech tags which removed text. [SEP] the tagger of [SEP] [SEP]", "cit": "both systems rely on the opennlp maximum - entropy part - of - speech tagger and chunker # refr, but knowitall [SEP]"}
{"pre": "we use tinysvm2 along with yamcha3 # refr as the svm training and test software. [SEP] kernel # otherefr to encode [SEP]", "cit": "by using other kernel functions, such as polynomial or radial basis function # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "tree and sequence kernels have been successfully used in many nlp applications, e. g., parse reranking and adaptation, # refr [SEP]", "cit": "their ability to capture lexical similarity is well established in wsd tasks # otherefr ), thesauri harvesting # refr, semantic role [SEP]"}
{"pre": "in addition, we show that the proposed approach can be applied to lexical bilingual lexicon extraction from comparable corpora # refr. [SEP] languages like arabic [SEP] english", "cit": "generally, an association measure like the mutual information # otherefr, the log - likelihood # refr or the discounted odds - ratio # other [SEP]"}
{"pre": "trigger - pair modelling research as been pursued within the field of language modelling for speech recognition over the last decade # otherefr ; # refr [SEP]", "cit": "when the tagger is trained in tested on the upenn treebank # otherefrb ) adopted a two - stage approach to prediction, [SEP]"}
{"pre": "rapp # otherefr, # refr, haghighi et al. # otherefr ). [SEP] ( e. g [SEP] [SEP]", "cit": "in # refr, we used comparable corpora to estimate several features for a given phrase pair that indicate translation equivalence, including contextual, temporal, and [SEP]"}
{"pre": "it differs from the many approaches where # otherefr ; # refr and from transfer - based systems defined by context - free grammars # other [SEP]", "cit": "a similar soft projection of dependencies was used in supervised machine translation by # refr, who used a source sentence? s dependency paths to bias the [SEP]"}
{"pre": "we used the french - english part of the europarl corpus # refr.. [SEP] the current implementation of the ibm model 4 [SEP] [SEP] [SEP]", "cit": "it is today common practice to use phrases as translation units # refr and a log linear framework in order to introduce several models explaining the translation process [SEP]"}
{"pre": "in addition to the well - known phrase - based approach # otherefr ; # refr, it has been shown that a relatively standard em training", "cit": "for instance, # refr proposed to translate the training data, using forced alignment and a leave - one - out technique, and to use the [SEP]"}
{"pre": "in order to obtain the linguistically plausible rightcor underspecified representation of single sentences, the transfer module are also processed with a compositional [SEP] natural", "cit": "the translation task of the sics - sri l : / ilin - - gnal conversation interpreter, bci # refr is quite similar [SEP]"}
{"pre": "for example, # refr show that zhang et al # otherefr show the results of a combinatory categorial grammar, which is much more", "cit": "however, the parsing work by clark and curran # otherefr and # refr, has only considered chart - parsing. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "we investigate several filtering techniques for backoff lms # otherefr and the lms trained on the same data using the web [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "a more recent method, which can be considered the state - of - the - art, is moore - lewis # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "a generative phrase model trained with the expectation maximization ( em ) algorithm and ( denero and # refr. [SEP] a latent log p ( [SEP] [SEP]", "cit": "a variety of unsupervised models refined this initial work with priors # otherefr and inference constraints # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "figure 1 : architecture of porting the domains of the man - learning system # otherefr and the technology components of [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "iracq \\ [ # refr \\ ] supports learning lexical semantics from examples with only one unknown word. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the early dependency grammar ( xdg ) used for training, in particular, # refr, is a generative model of natural language processing. [SEP] phenomena", "cit": "the price we pay for restricting ourselves to trees is that we derive fewer dependencies than the more powerful approach by # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "a few recently developed approach for unsupervised learning of semantic parsers, for example by # refr and roark # otherefr extended word representations to", "cit": "other works # otherefr ; # refr use a rather large word window around target words and compute similarities between clusters comprising instances of word windows [SEP]"}
{"pre": "various parsers based on this approach now exist for various languages # otherefr ; # refr. [SEP] the hpsg / [SEP] [SEP] [SEP] [SEP]", "cit": "various parsers based on this approach now exist for various languages # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the remaining chunks are pruned based on the normalized accuracy of the complete parse trees ( as described in # refr ). [SEP] ( [SEP] ( [SEP]", "cit": "as a result, they are being used in a variety of applications, such as question answering # otherefr ; # refr. [SEP] [PAD] [PAD]"}
{"pre": "in our experiments, we use the stanford dependency parser ( de marneffe and # refr. [SEP] because it is a sentence to provide a [SEP]", "cit": "for example, they have been used as a basic meaning representation for the recognizing textual entailment task proposed by dagan et al. # other [SEP]"}
{"pre": "we evaluate our system on the coreference resolution system of # refr, a coreference resolution system that incorporates lexical information to improve coreference resolution and", "cit": "table 2 : summary augmented with syntactic annotations for grid computation. we employ a state - of - the - art noun phrase coreference resolution system [SEP]"}
{"pre": "we parse the data using the charniak parser # refr. [SEP] senseval - 2 ) tagging scheme to determine the most likely sense of a", "cit": "in order to extract the linguistic features necessary for the model, all sentences were first automatically part - of - speech - tagged using a maximum entropy [SEP]"}
{"pre": "to derive knowledge from unlabeled data, our knowledge is explored to derive useful semantic knowledge # refr from external knowledge sources and wordnet # otherefr", "cit": "we used 600 million japanese web pages # otherefr parsed by knp # refr as a corpus. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we evaluate using the multi - modal dataset # refr. [SEP] kernel # otherefr. [SEP] the dataset consists of 106. [SEP] [SEP] [SEP] [SEP]", "cit": "we first consider the cornell sentence polarity dataset by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "future work includes exploring more direct supervision from human edited sample generalization # otherefr, # refr ) galley et al # otherefr.", "cit": "with this insight, we opt for decoding based on dynamic programming with dynamically adjusted beam. 4 alternatively, one can find an approximate solution using integer [SEP]"}
{"pre": "we show that our approach can be applied to other good results, namely the smoothed markov grammars to be obtained ( see for instance # refr ).", "cit": "their grammars were learned in a bayesian setting with dirichlet process priors, which have simple formal specifications ( c. f., # refr, appendix [SEP]"}
{"pre": "another alternative, which we do not explore in this work, is to use cascaded translation using a pivot language # otherefr ; [SEP]", "cit": "in fact, this is a more general problem, which arises with informal sources like sms messages and tweets for just any language # otherefr [SEP]"}
{"pre": "while this heuristic estimator gives good empirical results, it does not seem to optimize any intuitively reasonable objective function of the ( wordaligned ) parallel [SEP]", "cit": "a major component in phrase - based statistical machine translation # otherefr ; # refr is the table of conditional probabilities of phrase translation pairs. [SEP]"}
{"pre": "we compare lda - sp to several state - ofthe - art methods achieving an 85 % increase in recall at 0. 9 precision over mutual information [SEP]", "cit": "iii and marcu, 2006 ), document alignment and segmentation # refr, and inferring class - attribute hierarchies # otherefr. [SEP] [PAD] [PAD]"}
{"pre": "for example, the english language can be found in the new domain of the cl # refr. [SEP] this paper was conditioned on [SEP] [SEP] [SEP] [SEP]", "cit": "translation into another language obviates the need for the usual resource - intensive approaches to linguistic analysis that require syntactic treebanks along with semantic [SEP]"}
{"pre": "in addition, we use the non - local dependency tree ( mcdonald ) # refr, which is a stochastic model of # otherefr [SEP] all", "cit": "a similar modification was used by # refr for the study of dependency parsing models. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the proposed classifier was evaluated by applying the memory learning method proposed by # refr to detect unreliable noisy words. [SEP] if they could be improved by means", "cit": "since information in text posted by hundreds of millions of those people covers every space and time in the real world, analyzing such a text stream tells [SEP]"}
{"pre": "in addition to the fine - grained task, wsi has been applied to wsi # otherefr ) and [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "recent work has addressed this issue by proposing a general evaluation framework for injecting wsi into web search result clustering and diversification # refr. [SEP] [PAD] [PAD]"}
{"pre": "future work includes exploring more direct supervision from human edited sample generalization # otherefr, # refr ) galley et al # otherefr.", "cit": "several recent studies presented approaches to automatic caption generation for images # otherefr, # refr, li et al # otherefr ) [SEP]"}
{"pre": "in the second international chinese word segmentation bakeoff # otherefr, two of the highest scoring systems in the closed track competition were based [SEP]", "cit": "# refr, zhang et al. # otherefra ) experiment with co - training for semi - supervised chinese word segmentation. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "we also compare two lexical substitution systems : the semeval 2007 lexical substitution task # refr and the english lexical substitution task for evaluating systems ( as", "cit": "evaluation on unt uses a framework originally developed for the semeval lexical substitution task # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in all experiments, we use a standard log - linear framework # refr for minimum error rate training # otherefr. [SEP] the loss function [SEP]", "cit": "these include the average per - label marginal likelihood for sequence labeling # otherefr, minimum error - rate training for machine translation # refr, [SEP]"}
{"pre": "natural language applications have benefited from this type of part - of - speech # otherefr ; # refr. [SEP] the tag elementary trees [SEP]", "cit": "graehl et al # otherefr present an em training procedure for top down tree transducers, but while there are bayesian approaches to string [SEP]"}
{"pre": "the high level data can be used for part - of - speech tagging \\ [ brill, 1994 \\ ]. \\ [ # refr \\ ]", "cit": "much research as been done to improve tagging accuracy using several different models and methods, including : hidden markov models # otherefr ; memory - [SEP]"}
{"pre": "in an attempt to approximate the human effort, both supervised \\ [ bruce & weibe, 1994 ; etc. \\ ], [SEP] phenomena [SEP] [SEP]", "cit": "it is a balanced corpus and it has more than 200k words that are manually sense tagged as a product of the semantic oncordance ( sem [SEP]"}
{"pre": "in srl, high accuracy has been achieved by : # otherefr ; # refr ; punyakanok et al, 2005a [SEP]", "cit": "for srl, high accuracy has been achieved by : # otherefr ; # refra ), # otherefrb ). [SEP] [PAD]"}
{"pre": "finally, there has been a lot of work on measuring the general sentiment polarity of words # otherefr ; # refr. [SEP] this approach takes", "cit": "previous work on information extraction from limited - sized raw text corpora revealed that coverage is often limited # otherefr ; # refr. [SEP] [PAD] [PAD]"}
{"pre": "italicized text is used to indicate fragments that are semantically identical. valid intersections that follows the basic framework of previous unsupervised fusion systems # other [SEP]", "cit": "this distinguishes our approach from traditional sentence fusion approaches # refr ; barzilay and mckeown, 2005 ; filippova and strube [SEP]"}
{"pre": "the weights of the log - linear interpolation were optimized via minimum error rate training ( mert ) # refr. [SEP]. [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "the weights? m are optimized for system performance # refr as measured by bleu # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "current state - of - the - art machine translation systems # otherefr ; # refr use mt methods to perform analysis on a translation task,", "cit": "subjective # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr proposed a joint inference framework based on averaged perceptron and an ilp method. [SEP] the former based on ilp method. [SEP] the", "cit": "parallel bilingual data is often exploited to solve well - known tasks such as part - of - speech tagging # otherefr, and semantic role [SEP]"}
{"pre": "in the training phase, all the classifiers are optimized in the context of the named entity recognition task # refr. [SEP] ( ne ) [SEP]a [SEP]", "cit": "there are two major approaches to ne recognition : the handcrafted approach # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in # refr, the authors propose to recognize lexical and contextual cues, to recognize fine - grained sentiments and tweet tweets. [SEP] the", "cit": "this leads to increasing number of interests on sentiment analysis in microblog data # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "it is similar in many respects to the task of lexical simplification # refr. [SEP] a simplified version of the task is defined as a set of [SEP]", "cit": "uow - shef - simplex : the system # refr uses a linear weighted ranking function composed of three features to produce a ranking. [SEP] [PAD]"}
{"pre": "ccae # otherefr 79. 4????? 86. 4???? 86. 4? 93. 79 [SEP]", "cit": "it is thus not surprising that a bag - of - words based method can perform well on this task # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "much of the previous work in cross - document coreference # otherefr ; # refr groups mentions into entities with some form of greedy [SEP]", "cit": "while significant progress has been made in within - document coreference # otherefr ; # refr, the larger problem of cross - document core [SEP]"}
{"pre": "the features were tuned using the minimum error rate training procedure introduced by # refr. [SEP] bleu score # otherefr. [SEP] the [SEP] [SEP]", "cit": "in addition, we do not use any discriminative training methods such as mert for optimizing the feature weights # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "several other semantic parsers have been developed # otherefr ; # refr. [SEP] this problem in nlp applications, such as semantic [SEP] [SEP]", "cit": "several works # otherefr ; # refr have addressed this issue explicitly by manually defining syntactic transformation rules that can help the learned parser generalize better [SEP]"}
{"pre": "most of the previous msc approaches rely on syntactic parsers for producing summaries, e. g. # otherefr or as well as [SEP] [SEP]", "cit": "the ilp model can be straightforwardly augmented with discourse constraints similar to those proposed in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we tuned with minimum errorrate training # refr. [SEP] bleu # otherefr. [SEP] the mert procedure of the margin infused relaxed algorithm", "cit": "however, as researchers started using models with thousands of parameters, new scalable optimization algorithms such as mira # otherefr ; # refr and [SEP]"}
{"pre": "this model outperforms the competitive baseline model of # refr in a log - linear model, which outperforms a number of segmentation features. [SEP] the linear models", "cit": "unsupervised segmentation by itself has garnered considerable attention in the computational linguistics literature # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr used syntactic features on the basis of sla theory that posits that the features may have a variety of features, including support vector machines (", "cit": "as a possible approach that would improve the classification accuracy over just the three manually detected syntactic errors, wong and dras # otherefr ; [SEP]"}
{"pre": "the most widely known criteria for pruning phrasebased smt systems are the phrase pairs # otherefr ; och and # refr. [SEP] a [SEP]", "cit": "the word alignment was trained with six iterations of ibm model 1 # otherefr and 6 iterations of the hmm alignment model # refr using a [SEP]"}
{"pre": "# refr showed that a corpus - based model for identifying noun - noun compounds and their verb - noun combinations are highly correlated with features, they could", "cit": "for example, # refr have used some of the same informativeness measures ( denoted by inf above ) to predict pitch accent placement in word bi [SEP]"}
{"pre": "in addition, # refr used integer linear programming ( ilp ) to find the best entity mentions. [SEP] the [SEP] solution described in [SEP] [SEP]", "cit": "joint inference techniques # refr can transform the integration of multi - media into a benefit by reducing the errors in individual stages. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, we used the first 100 vocabulary ( oov ) corpus # refr. [SEP] the documents for training and testing. [SEP] [SEP] [SEP] [SEP]", "cit": "about 6, 000 words are automatically classified into one of 12 domain categories by distributions in web sites # refr and 10 % of them are manually [SEP]"}
{"pre": "for example, in the context of syntactic smt, # refr proposed a rule - based system for dependency parse trees with a constituency tree.", "cit": "in recent years, syntax - based smt has made promising progress by employing either dependency parsing # otherefr ; mi and # refr on [SEP]"}
{"pre": "the tempeval challenge series # otherefr ; # refr. [SEP] the representation of a temporal expression classification approach. [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "# refr ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "online learning algorithms have been successfully applied in several natural language processing # otherefr ; # refr. [SEP] this approach by finin [SEP] [SEP] [SEP]", "cit": "# refr compared two online em algorithms, stepwise online em # otherefr which they use to update the alignment models ( the generative component of [SEP]"}
{"pre": "to alleviate this, we used the easy - first parser of # refr. [SEP] the srl system of # otherefr. [SEP] the [SEP]", "cit": "supervised methods deliver reasonably good performance with f - scores in the low eighties on standard test collections for english # otherefr ; bj? [SEP]"}
{"pre": "# refr applied part - of - speech tagging to arabic dialectal arabic ( 15 ), which achieved an accuracy of 97 % on the arabic", "cit": "tagging is often the first step towards parsing or chunking # otherefr, and knowledge of pos tags can benefit statistical language models for speech [SEP]"}
{"pre": "# refr use dependency trees and graph - based features to determine whether a given expression is a positive or negative. [SEP]. [SEP] if they are [SEP]", "cit": "other work has focused on the social network structure of online forums # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "moreover, it provides a basis of nlp applications that include measures based on the posterior probability of phrase alignment # otherefr, and syntactic [SEP]", "cit": "we evaluated alignment quality on a hand - aligned portion of the nist 2002 chinese - english test set # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in particular, we show that the system of # refr is equivalent to the semantic - head construction of lfg - head - driven generation. [SEP]", "cit": "in particular, generation from grammars with recursions whose welbfoundedness relies on lexical information will terminate ; top - down generation regimes such [SEP]"}
{"pre": "dependency trees are representations for ie in the syntactic analysis of the sentences # refr. [SEP] the information extraction algorithm was done in a dependency parser which [SEP]", "cit": "several recent approaches to ie have used patterns based on a dependency analysis of the input text # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "we use a statistical tagger # refr to find the most probable chunker. [SEP] training sequence. [SEP] the word sequence for the sequence labeling problem", "cit": "we followed the iob tagging scheme # refr for all the three languages ( english, hindi and telugu ). [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "more recently, kernel functions, which implicitly represent data in some high dimensional space, have been employed to study and further improve many natural language systems [SEP]", "cit": "more recently, kernel functions, which implicitly represent data in some high dimensional space, have been employed to study and further improve many natural language systems [SEP]"}
{"pre": "lexically cohesive words are traced through the text, forming lexical chains or graphs, and these representations are used in a variety of applications, [SEP]", "cit": "for example, the fact that a text segmentation algorithm that uses information about patterns of word co - occurrences can detect sub - topic shifts in a [SEP]"}
{"pre": "in addition to the algorithm, we show experiments in which show that the algorithm can be successfully used to parse and reranking # otherefr", "cit": "uses for k - best lists include minimum bayes risk decoding # otherefr ; # refr, and discriminative training # otherefr. [SEP] [PAD]"}
{"pre": "for german, we used the negra corpus of collins parser # refr. [SEP] 710 sentences of collins # otherefr to determine the [SEP]", "cit": "# refr reported how serious this problem can be when he coupled a tagger with a subsequent parser, and noted that tagging errors are by far [SEP]"}
{"pre": "pereira, tishby, and # refr used a maximum entropy model to distinguish the above,. [SEP] the conditional probability distribution over the", "cit": "specially, it can be used as an alternative to grammatical part - ofspeech tagging # otherefr ; # refr ; merialdo, [SEP]"}
{"pre": "we use the giza + + toolkit # otherefr, mkcls # refr, carmel, 1 and a phrase model [SEP] [SEP] [SEP]", "cit": "we present a morphologically - enhanced version of the classic phrase - based smt model # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition to their use in machine translation # otherefr, translation grammars are similar to our method use in order to extract translation grammars [SEP] [SEP]", "cit": "it is interesting toconstrast this method with the \" parse - parse - match \" approaches that have been reported recently for producing parallel bracketed [SEP]"}
{"pre": "in this paper, we describe the stanford dependency parser ( de marneffe and # refr, a deep parser for biomedical domain, and [SEP] [SEP]", "cit": "in such situations, we first group theme arguments by the label of the first stanford dependency ( marneffe and # refr from the head word [SEP]"}
{"pre": "tempeval # otherefr ; # refr. [SEP] textual inference # otherefr takes as a classification problem. [SEP] filtering [SEP] [SEP] [SEP]", "cit": "the tempeval # otherefr challenge has led to a number of works on temporal relation extraction # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in a final step, sentences were taken from syntactic representations # refr trained on syntactic tree structures trained on the british national corpus ( bnc [SEP] [SEP]", "cit": "this issue has been addressed by recent work that shows that current natural language processing techniques can be applied to automate the computation of these metrics, [SEP]"}
{"pre": "# refr use a maximum entropy model to score word importance. [SEP] the word order of a word ( e. g., a word? 1", "cit": "we use wilcoxon signed - rank test to examine the statistical significance as advocated by # refr for both tasks, and consider differences to be significant if [SEP]"}
{"pre": "in a parallel strand of work, # refr has shown how to define the notion of implicative grammars can be found in the underlying [SEP] [SEP]", "cit": "two contrasts hould be emphasized in this regard. # otherefr construct a simultaneous derivation of syntax and semantics but they do not construct he [SEP]"}
{"pre": "depending on the type of input, these efforts can be divided into two broad categories : the string - based systems whose input is a string to [SEP]", "cit": "for 1 - best search, we use the cube pruning technique # otherefr ; # refr which approximately intersects the translation forest with the [SEP]"}
{"pre": "this can be viewed as a simplified version of the maximum spanning tree ( mst ) problem, which can be trained on the shift - reduce parsing [SEP]", "cit": "# refr reports that when arc scores have been precomputed, the dynamic programming component of his 1st - order parser can process an amaz [SEP]"}
{"pre": "in recent years, the pyramids evaluation method # refr has been shown to yield the summaries of single sentences that can be used to create [SEP] [SEP]", "cit": "in.? 1997, t ipster sponsored a conference ( sum - mac ) where various text summarization algorithms were evaluated for their performance in [SEP]"}
{"pre": "in particular, we focus on extracting new lexicalized tree structures from the grammar writer : if they have the grammar is dependency structures # otherefr", "cit": "in particular, # refr try to induce a cw - grammar from the ptb with the underlying assumption that some derivations that were supposed to be [SEP]"}
{"pre": "in the last few years, there has been a number of papers on parallel text categorization # otherefr ; # refr. [SEP] the source [SEP]", "cit": "the most common approach to deriving translation lexicons from empirical data # otherefr ; # refr is to use some variant of the following procedure [SEP]"}
{"pre": "in recent years, there has been a growing interest in discourse processing with promising results # otherefr ; # refr. [SEP] this approach is to", "cit": "now, \\ [ webber 88 \\ ] argues that demonstrative r ference of this type is sensitive to the right frontier of the discourse [SEP]"}
{"pre": "we used the precomputed results for our experiments, the muc - 6 # refr and the muc - 6 # otherefr, and the", "cit": "in coreference resolution, typical performance measure functions include muc # otherefr and ceaf # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "classical methods are either pattern - based # otherefr ; # refr or classifierbased # otherefr ). [SEP] representations [SEP] [SEP] [SEP] [SEP]", "cit": "we also plan to develop a hybrid methodology, to combine the presented corpus - driven analysis with opendomain techniques for pattern acquisition, # otheref [SEP]"}
{"pre": "# refr use statistical methods for automatic error correction. [SEP] spelling errors per error correction. [SEP] the use of two training [SEP] models to [SEP]", "cit": "while wikipedia revision history has shown promise for other nlp tasks including paraphrase generation # otherefr and spelling correction # refr [SEP]"}
{"pre": "we only train senseval - 3 all - words wsd systems on the english lexical sample task # refr. [SEP] the sense of the wordnet", "cit": "our procedures for performing this task and our results were largely unchanged from senseval - 2 # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "bender and ney, 2003 ; florian et al, 2003 ; mccallum and li, 2003 ; # refr and hybrid solutions [SEP]", "cit": "domain customization of rule - based ner has not received much attention in the recent literature with a few exceptions # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this is similar to the coreference resolution system described in # refr and # otherefr. [SEP] this mentions much harder [SEP] [SEP] [SEP] [SEP]", "cit": "the entity detection and tracking task # otherefr ; ng and # refr, and have been at the center of several evaluations : muc - [SEP]"}
{"pre": "in combination with dependency parsers, several parsers have been reported # otherefr ; # refr. [SEP] this paper, [SEP] [SEP] [SEP] [SEP]", "cit": "in combination with machine learning methods, several statistical dependency parsing models have reached comparable high parsing accuracy # otherefrb ; # refrb ). [SEP]"}
{"pre": "in # refr, a reranking approach is proposed to use a probabilistic model for parsing reranking. [SEP] the trees as features to be", "cit": "in particular, most of the work on parsing with kernel methods has focussed on kernels over parse trees # otherefr ; # refr. [SEP]"}
{"pre": "in 2012, it was initially defined for the semantic textual similarity ( sts ) ( sts ) task # refr. [SEP] the semantic equivalence between two sentences", "cit": "the annual series of semeval sts tasks # refr is an important platform where sts systems are evaluated on common data and evaluation criteria. [SEP] [PAD]"}
{"pre": "we used the minimum bayes risk rescoring lattices # refr to tune the model parameters for the model 4. 5 - gram language model : [SEP] [SEP]", "cit": "one method for using these probabilistic automata that has been successful in large - vocabulary speech recognition # otherefr and machine translation # refr applications and [SEP]"}
{"pre": "the secondorder parser is a simplified version of the parsing pipeline by # refr, and we modified the parser of zhang and clark # otheref [SEP]", "cit": "as a special case of this approach, we simply predict whether the number to add should be zero or greater than zero, in which case the [SEP]"}
{"pre": "in this paper, we describe the centering theory # otherefr and will focus on the level of discourse structure, # refr. [SEP] [SEP]", "cit": "# refr for discussions of this parameter. l lth is parameter may be tied to the \" intentional \" aspect of discourse as proposed by grosz [SEP]"}
{"pre": "hence, several methods for dimension reduction were tested in this context : from thesaurus acquisition of synonym questions # otherefr ; [SEP] the", "cit": "however, most of the work related to this issue has focused on the fact that the? traditional? representation of distributional contexts is very sparse and [SEP]"}
{"pre": "nltk, the natural language toolkit, is a suite of nlp texts from the natural language toolkit # refr. [SEP] the [SEP] [SEP] [SEP] [SEP]", "cit": "first we discuss aspects of the design of the toolkit that 1 # otherefr ; # refr arose from our need to teach computational linguistics to [SEP]"}
{"pre": "in particular, resources annotated with the surface realization of semantic roles, like framenet # otherefr, and framenet # refr have shown [SEP]", "cit": "in particular, resources annotated with the surface realization of semantic roles, like framenet # otherefr and shallow semantic parsing # refr. [SEP] [PAD]"}
{"pre": "in # refr, a hierarchical orientation model is introduced that captures some non - local reordering by a shift reduce algorithm. [SEP] the distortion cost of", "cit": "lexicalized phrase orientation models # otherefr ; # refr predict the orientation of a phrase with respect to the last translated one. [SEP] [PAD] [PAD]"}
{"pre": "in spoken dialogue systems, incremental parsers have been a popular technique for speech recognition and speech recognition # otherefr ; # refr. [SEP] this", "cit": "# refr report f - measures of 84 % using prosodic features only, but they use left? right - windows for feature calculation, where our [SEP]"}
{"pre": "on the other hand, models that deal with structures or phrases instead of single words have also been proposed : the syntax translation models are described in [SEP]", "cit": "many works # otherefr ; # refr have adopted different types of stack - based algorithms to solve the global search optimization problem for statistical machine [SEP]"}
{"pre": "recent studies on relation extraction have shown that by supervised machine learningbased methods outperform unsupervised approaches # otherefr ; # refr. [SEP] this approach [SEP]", "cit": "this is typically carried out by applying supervised learning, e. g. # otherefr ; # refr by using a handlabeled corpus. [SEP]"}
{"pre": "for instance, # refr adopt his results on the mwe acquisition framework that can be seen as a non - compositional mwes. [SEP] the mw", "cit": "information retrieval : when mwes like pop star are indexed as a unit, the accuracy of the system improves on multiword queries # refr. [SEP]"}
{"pre": "to avoid this problem, # refr proposed a bottom - up strategy for generation that is based on based on based on based on based on based on", "cit": "the problem of finding suitable identifying properties # otherefr ; # refr will not be addressed here, although as will be shown our approach could [SEP]"}
{"pre": "recently, compact representations of the language model have attracted the attention of the research community, for instance in # refr. [SEP] the natural anguage [SEP]", "cit": "liu et al, # otherefr estimate the link probabilities from n - best lists, while # refr learn the alignment posterior probabilities directly from [SEP]"}
{"pre": "this idea has been developed and applied to a wide variety tasks, including morphological analysis # otherefr ; # refra ; de [SEP]a [SEP]", "cit": "non - heuristic filtering techniques, on the other hand, employ reliability measures ( often unrelated to the task ) to predict high - precision data points [SEP]"}
{"pre": "recently, algorithms have been developed to learn such parsers for many applications, including question answering # otherefr ; # refr, relation extraction #", "cit": "examples include question answering # otherefr ; # refr, dialog systems # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used hunpos ( hal? # refr to improve the output of a morphological analyzer. [SEP] this model ). [SEP] it performs more [SEP] [SEP]", "cit": "these tags were obtained using the hunpos tagger ( hala? # refr trained on the wall street journal section of the penn treebank [SEP]"}
{"pre": "log - linear models have been used in parsing by # refr # otherefr. [SEP] this procedure, a log - linear model for [SEP] [SEP]", "cit": "discriminative log - linear models are now becoming a de facto standard for probabilistic disambiguation models for deep parsing # otherefrb ; # refr [SEP]"}
{"pre": "we parse the chinese sentences with the berkeley parser # refr and the pos tagging model using the berkeley parser # otherefr. [SEP] [SEP] [SEP] [SEP]", "cit": "in order to train a syntax - based model for grammar correction, the correct version of the sentences are parsed with the berkeley parser # refr [SEP]"}
{"pre": "different from the soft constraint modeling adopted in # otherefr ; # refr, our approach encodes syntactic information in translation rules. [SEP] the context of", "cit": "different from the soft constraint modeling adopted in # otherefr ; # refr, our approach encodes syntactic information in translation rules. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "this approach is inspired from work done by # refr who uses paradigms to organize morphological information, and string equations to handle string operations. [SEP] complex [SEP]", "cit": "2related proposals are made by flickinger # otherefr, ch. 5 ). generalizations or stratification # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "the log - linear model # refr, a general log - linear model # otherefr can be estimated by a discriminatively represented in a log", "cit": "they are enhanced by the maximum entropy approach and the posterior probability is calculated as a loglinear combination of a set of feature functions # refr. [SEP]"}
{"pre": "we used the mxpost tagger # refr for english and the pos tagger of # otherefr for chinese and english [SEP] english [SEP] [SEP]", "cit": "given the parallel corpus, we tagged the english words with a publicly available maximum entropy tagger # refr, and we used an implementation of the [SEP]"}
{"pre": "the perceptual information in such models is generally mined directly from images # otherefr ; # refr or from data collected in psychological studies # [SEP]", "cit": "one way to do this grounding in the context of distributional semantics is to obtain representations that combine information from linguistic corpora with information from another modality [SEP]"}
{"pre": "the lexicalized probabilistic grammar for german has been explored in the context of german grammar ( pcfg ) for german # refr, and for processing [SEP]", "cit": "this indicates that some degree of unlexicalized initialization is necessary, if a good lexica \\ ] ized model is to be obtained [SEP]"}
{"pre": "entity mention extraction # otherefr ; # refr ) have drawn much attention in recent years but were model entity mention # otherefr - [SEP]", "cit": "following the above intuitions, we introduce a joint framework based on structured perceptron # otherefr ; # refr with beam - search to [SEP]"}
{"pre": "# refr use lda to learn a multi - document set multi - document topics, and use topics as well as topic biased by a discriminative multi -", "cit": "in the short time since its inception, topic modelling # otherefr has become a mainstream technique for tasks as diverse as multidocument [SEP]"}
{"pre": "in a related paper # refr, we found that the similarities between documents by incorporating various language models. [SEP] ( w1 ) [SEP] ( w3", "cit": "as shown in # otherefr and then # refr, simple distance measures using the representations derived from this process are both useful for assessing word [SEP]"}
{"pre": "see also # refr for details of the parsers, which were trained on the same corpus, in which the same part of speech tags are discussed", "cit": "the algorithms of both parsers are based on parallel parsing algorithms for cfg # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "guevara # otherefr and # refr propose the full form of the additive model ( fulladd ), where the two vectors entering [SEP]", "cit": "selectional preferences are computed as in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "however, as researchers started using models with thousands of parameters, new scalable optimization algorithms such as mira # otherefr and pro # refr [SEP]", "cit": "sa - pro pot, however, does not work out of the box when we use the entire nist02 as the tuning set, which might [SEP]"}
{"pre": "in addition, the model selection problem for tag is significantly more complicated than for tsg since one must reason about many more combinatorial options with two [SEP]", "cit": "given the embryonic status of grammatical statistical models and the difficulties of accurately estimating the parameters of such a model, it seems more prudent to prefer [SEP]"}
{"pre": "in addition to the features of the entity features, we also ran the entity features on the entity features of the entity features, we follow # refr", "cit": "more recently, we have improved nissim? s learning - based approach by augmenting her feature set, which comprises seven string - matching and [SEP]"}
{"pre": "we evaluated the performance by measuring the semantic role labelling task, as defined in # refr. [SEP]. [SEP] the full representation of text is [SEP].", "cit": "for the scope of this experiment we developed a simple rte system, which uses the f1 optimized logistic regression classifier of # refr with two [SEP]"}
{"pre": "cross - lingual annotation projection # otherefr, dependency parsing # refr or temporal relation prediction # otherefr. [SEP] the source [SEP] [SEP]", "cit": "cross - lingual model transfer methods # otherefr ; s? # refr have also been receiving much attention recently. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the bllip corpus # refr with pos - tagged as a self training tool. [SEP] filtering. [SEP] 1 to improve [SEP] 1 - training", "cit": "while these simpler structured prediction models are faster, we compensate for the model? s simplicity through uptraining # refr, yielding auxiliary tools that are [SEP]"}
{"pre": "in addition to dependency treebanks, we use maltparser # otherefr, a transitionbased model with non - projective dependency [SEP] [SEP]", "cit": "table 2 shows the results on the conll 2006 / 2007 data sets # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "amazon has a large number of distinct tasks, including emotion recognition # otherefr, and sentiment analysis # refr. [SEP] emotion classification # [SEP] [SEP]", "cit": "a detailed set of color - concept - emotion associations # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this is similar in spirit to work on learning entailment rules # otherefr ; # refr. [SEP] this approach is [SEP] in [SEP] [SEP] [SEP]", "cit": "yao et al. # otherefr and # refr present a related line of work, inferring new relations between freebase entities via inference over [SEP]"}
{"pre": "we show that the proposed method can be applied to nlp tasks like part - of - speech tagging # refr, and chunking # [SEP] [SEP]", "cit": "sgd was recently used for nlp tasks including machine translation # otherefr and syntactic parsing # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, the decision rule extraction we use as the minimum bayes risk ( mbr ) framework # refr. [SEP] the [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "weights for each component score were optimized to maximize bleu - score on the development set using mer optimization as described in # refr. [SEP] [PAD] [PAD]"}
{"pre": "we use the similarity measure described in # refr, with the senseval - 3 english lexical sample dataset. [SEP] the corpus itself ( [SEP] [SEP] [SEP]", "cit": "# refr extended the method of lau et al. to incorporate knowledge of the expected domains of new wordsenses, but did not conduct a rigorous [SEP]"}
{"pre": "the features include : a maximum sentence length of 80, growdiag - final - and symmetrization of giza + + alignments, [SEP]", "cit": "rwth # otherefr employs both the phrase - based ( rwth scss ) and the hierarchical ( rwth hiero ) decoder [SEP]"}
{"pre": "in unsupervised dependency parsing, sentenceinternal punctuation has been ignored # otherefr ; # refr. [SEP]. [SEP] this cross - lingu [SEP] [SEP]", "cit": "in dependency grammar induction, unsupervised methods achieve continuous improvements in recent years # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in # refr, we proposed an efficient method that uses word - based alignments, rather than a single word representation. [SEP] in the training corpus.", "cit": "giza + + / mkcls # otherefr ; # refr for word alignment.. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in # refr, an alternate distance model is modeled as a hidden markov model ( hmm ) =? i. e., j [SEP] [SEP] [SEP]", "cit": "while classical approaches for word alignment are based on generative models # otherefr and hmm # refr ), word alignment can also be viewed as [SEP]"}
{"pre": "we are aware of only one work that has been observed for co - occurrence extraction of collocations, such as # refr and # otherefr", "cit": "co - occurrence based measures # refr simply rely on unigram and bigram frequencies of the words in a pair. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in contrast, approaches to the joint task have been proposed by erk and pado? # otherefr, # refr, and semantic similarity [SEP]", "cit": "semantic similarity can then be approximated by vector similarity using a wide range of similarity metrics # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this kind of lexical knowledge can be harnessed for the automatic extraction of predicate senses # otherefr, # refr ) [SEP] this relation [SEP].", "cit": "motivation : this paper addresses the task of discovering and organizing paraphrases of relations between entities # otherefr ; # refr. [SEP] [PAD] [PAD]"}
{"pre": "much of the current research explores this task # otherefr ; # refr involved thesaurus extraction from large corpora. [SEP] this corpus. [SEP]", "cit": "automatic approaches to creating a semantic orientation lexicon and, more generally, approaches for word - level sentiment annotation can be grouped into two kinds : # [SEP]"}
{"pre": "in recent years, the new evaluation metric has been explored by # refr. [SEP] this metric to automatically generate the reference sentences by comparing the [SEP] [SEP]", "cit": "a similar approach has been used by # refr in the application of machine translation metrics, where they use a gradient optimization method to solve the maximization [SEP]"}
{"pre": "we adopt the methodology used in previous wsi # otherefr ; # refr. [SEP] this problem : given a target word e [SEP] [SEP] [SEP]", "cit": "the university of melbourne ( unimelb ) team submitted two wsi systems based on the approach of # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "finding the optimal tree in the set of projective trees can be done efficiently # otherefr ; # refr. [SEP] ( 1 ) [SEP] ( [SEP]", "cit": "gap inheritance degree 0 requires that there are no child nodes with descendants in more than one of their parent? s blocks. # refr gap [SEP]"}
{"pre": "statistical techniques, both supervised learning from tagged corpora # otherefr, # refr, have been investigated. [SEP]. [SEP]. [SEP] [SEP] [SEP] [SEP]", "cit": "the techuique used to address data si ) arsity, as first proposed by # refr, treal ; s the internet as [SEP]"}
{"pre": "this tutorial discusses a framework of online global discriminative learning and beam - search decoding for syntactic processing # otherefr, dependency parsing # refr, [SEP]", "cit": "in addition, due to its high efficiencies, it has also been applied to a range of joint structural problems, such as joint segmentation and pos [SEP]"}
{"pre": "in part - of - speech tagging, the accuracy of the conll - 2007 shared tasks on domain adaptation, achieved comparable since multiple versions of the", "cit": "# refr used structural correspondence learning and unlabeled data to adapt a part - of - speech tagger. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the second set is related to the factorial crf learning algorithm # refr as a feature space with maximum a conditional random field. [SEP] ( crf ) [SEP]", "cit": "erma is attractive for nlp because the freedom to use arbitrarily structured graphical models makes it possible to include latent linguistic variables, predict complex structures [SEP]"}
{"pre": "# refr use a graph - based model in which vertices correspond to a target word selection model are co - occurrence vectors. [SEP]. [SEP] the similarity", "cit": "a classic propagation algorithm that has been suitably modified for use in bilingual lexicon induction # refr is the label propagation # otherefr. [SEP] [PAD] [PAD]"}
{"pre": "in addition, a number of researchers have tried to take the same data split as used in different languages, e. g., english # other", "cit": "unsupervised srl models # refr cluster the arguments of predicates in a given corpus according to their semantic roles. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper, we assume a system that we have developed in a separate module # otherefr and for automated nlp components of natural language", "cit": "in a future stage, we plan to use what barr and klavans # refr call component performance evaluation which consists of assessing the performance of [SEP]"}
{"pre": "we use constituency - to - string model # refr as the syntax - based model baseline which make use of composed rules # otherefr.", "cit": "we obtain the word alignments by running giza + + # otherefr on the corpus in both directions and applying? grow - diag - [SEP]"}
{"pre": "for tree kernels, we used svm - light - tk # otherefr, with the accuracy of # refr, with the common accuracy of [SEP]", "cit": "c & j features the parse - tree reranking feature set of # refr, extracted from the berkeley parse trees. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr describe an empirical tradition of lexical cohesion based on lexical cohesion based on semantic networks ( lcs ) to measure lexical cohesion. [SEP] structure [SEP]", "cit": "# refr had 16 subjects egment a simplified short story, developed an algorithm based on lexical cohesion, and qualitatively compared the results. [SEP] [PAD] [PAD]"}
{"pre": "in this paper, we apply a rule - based semantic parser # refr to parse sentences with a straightforward semantic parser. [SEP] syntactic parser [SEP] semantic [SEP]", "cit": "shi and mihalcea # refr propose a rule - based approach for semantic parsing using framenet and wordnet. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr use a dictionary and a pos tagger to jointly learn disambiguation for pos tagging. [SEP] a dictionary. [SEP] training objective ( e.", "cit": "early work showed much promise for this strategy # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the features described in # refr which include the features of both the source and target language. [SEP] features, we use are designed for the", "cit": "this is our first foray into nli, although we have recently described experiments aimed at identifying the gender of unknown twitter authors # refr. [SEP]"}
{"pre": "sentence compression has been considered before in contexts outside of summarization, such as headline, title, and subtitle generation # otheref [SEP]", "cit": "while several methods have been proposed for sentence compression # otherefr ; # refr, this paper focuses on knight and marcu? s [SEP]"}
{"pre": "in addition, we are planning to use the general architecture of the language generator described in # refr. [SEP] this system. [SEP] this important [SEP] this", "cit": "tempora l st ructure the input used to compute the temporal structure of a situation consists of the grammatical aspect of the verb, that [SEP]"}
{"pre": "in addition, most related work deals with discovery of hypernymy # otherefr, but not # refr, [SEP] this problem [SEP] the [SEP]", "cit": "to this end, patternbased approaches have long been used to induce type systems # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the basic type is also mapped onto a type ( or set of types ) in the concept ontology used for sentence generation, a version of pen [SEP]", "cit": "mapping domain taxonomy onto upper model : ilex uses an upper model ( a domainindependent semantic taxonomy, see # refr ), which supports the [SEP]"}
{"pre": "the features are the subject of most commonly used in native english preposition usage # otherefr ; # refr. [SEP] features [SEP] this problem [SEP]", "cit": "the majority of previous papers in this area have presented machine learning methods with models being trained on well - formed native english text # otherefr [SEP]"}
{"pre": "there has been a lot of research on event extraction, where the goal is to extract facts about events from text # otherefr ; # refr", "cit": "more recently, some research has incorporated event region detectors into event extraction systems to improve extraction performance # otherefr ; # refr. [SEP] [PAD] [PAD]"}
{"pre": "previous work on nlg systems that address more than one user group use different versions of a system for each different user group # otherefr [SEP]", "cit": "prior work on content or attribute selection has used a? summarize and refine? approach # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper, we evaluate the performance of the conll 2008 shared task on joint parsing and semantic role labeling # refr. [SEP] the [SEP] [SEP]", "cit": "some models have been well evaluated in conll 2008 and 2009 shared tasks # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for example, the average f1 of the stanford models # refr, which are considerably inferior when compared to simpler features are applied to a sentence [SEP]", "cit": "within natural language processing, much of the work with deep learning methods has involved learning word vector representations through neural language models # otherefr ; [SEP]"}
{"pre": "in this paper, we focus on the english language, and the subject of a question ( answer fragment retrieval ), which was designed to [SEP] the", "cit": "the webclopedia project at the usc information sciences institute # refr pursues a semantics - based approach to answer pinpointing that [SEP]"}
{"pre": "several gre algorithms have addressed the issue of generating locative expressions # otherefr ; # refr. [SEP] a sentence'or in nlg [SEP]", "cit": "while the task of constructing singular definite descriptions on the basis of positive properties has received much attention in the generation literature # otherefr ; # [SEP]"}
{"pre": "we used the same head projection of dependency annotations as the penn treebank ( ptb ) # refr, the dependency grammar ( right ) [SEP] [SEP]", "cit": "seginer? s # otherefr would be to gold versus unsupervised tags, since the magerman - collins rules # refr agree with gold [SEP]"}
{"pre": "in addition, since there are several methods of large unannotated corpora, thesaurus construction for disambiguating the verb - noun number #", "cit": "however, our system is the unsupervised learning with small pos - tagged corpus, and we do not restrict the word is sense set within either binary [SEP]"}
{"pre": "morphological analysis has successfully used morphological analysis and disambiguation to smt by # refr. [SEP] morphological analyzers to improve translation quality. [SEP] the [SEP]", "cit": "# refr improved czech - english translation by applying different heuristics to increase the equivalence of czech and english text. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the subjectivity lexicon of # refr, 2 which contains approximately 8000 words which may be used to express opinions. [SEP] the opinion [SEP]", "cit": "this parallels findings for polarity expressions in subjective texts # refr, and shows that the border between affective and neutral is fuzzy. ( affect perception [SEP]"}
{"pre": "we show that this system outperforms a state - of - the - art phrase - based system which uses a discriminative log - linear model # refr,", "cit": "this algorithm is really an extension of viterbi to the case when scores factor over dynamic substrings of the text # otherefr ; [SEP]"}
{"pre": "in addition, we are planning to use the term? automatic? interactive machine translation? the general noun phrase translation process described in \\ [ # refr", "cit": "other technologies such as lexical - transfer mt # otherefr provide lowerquality general - purpose translations, unless they are incorporated into human - assisted [SEP]"}
{"pre": "the development of the ideas described above has been implemented in the trec - idf framework # refr, which has been used for the development and", "cit": "discourse studies the potsdam commentary corpus, pcc # refr, consists of 173 newspaper commentaries, annotated for morphosyntax, [SEP]"}
{"pre": "since the initial release of the penn treebank # otherefr ; # refr ). [SEP] a constituent in order to [SEP] the constituent [SEP] it", "cit": "for modern hebrew, # refr show that a simple treebank pcfg augmented with parent annotation and morphological information as state - splits significantly [SEP]"}
{"pre": "because such mert # refr tuning may be unstable for higher n, several methods were proposed where the n + 1 phrase tables are merged into [SEP]", "cit": "# refr, dugast et al # otherefr ) is a popular method 1http : / / www. statmt. org [SEP]"}
{"pre": "in recent years several techniques have been developed for opinion analysis # otherefr ; # refr ). [SEP] this framework [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "evidence from the surrounding context has been used previously to determine if the current sentence should be subjective / objective # refr ) and adjacency pair information has [SEP]"}
{"pre": "to obtain syntactic dependency structures, we apply the stanford parser # refr on the target word identities. [SEP]. [SEP] sentences. [SEP] [SEP] [SEP] natural [SEP]", "cit": "the richly annotated gigaword data comprises automatic parses obtained with the stanford parser # refr so that we easily have access to the lemma [SEP]"}
{"pre": "we use the annotation study of # refr for our annotator. [SEP] automatic mode, which uses a combination of mutually exclusive categories, which we will", "cit": "in their work, the only context used was the animacy of the verb in the np, for heads of subject nps ( e. g [SEP]"}
{"pre": "previous work on syntax projection mostly focuses on unsupervised grammar induction where no labeled data exists for target language # otherefr ; # refr. [SEP] [SEP]", "cit": "# refr propose a reranking based method for joint constituent parsing of bitext, which can make use of structural correspondence features in both languages [SEP]"}
{"pre": "ccg parsers often produce ccg parses # otherefr ; # refr, which usually take dependency structures that can provide only complete parse", "cit": "syntactic information is provided by ccgbank, a conversion of the penn treebank into the ccg formalism # refra ). [SEP] [PAD] [PAD]"}
{"pre": "te reduces the inference requirements of many natural language processing applications, like information extraction, summarization # otherefr, question answering # refr, textual", "cit": "this evaluation provides useful cues for researchers and developers aiming at the integration of te components in larger applications ( see, for instance, the use of [SEP]"}
{"pre": "most often, such pairs are extracted from small bilingual lexicons # otherefr ; # refr. [SEP] this technique is already designed for [SEP] [SEP]", "cit": "the main assumption behind translation extraction from comparable corpora is that a source word and its translation appear in similar contexts # otherefr ; # refr [SEP]"}
{"pre": "in the second experiment, the disambiguation algorithm # refr is used to disambiguate the senseval - 3 corpus : given a word [SEP] sense disambig", "cit": "among the various knowledge - based # otherefr ; # refr word sense disambiguation methods that have been proposed to date, supervised systems have [SEP]"}
{"pre": "# refr annotated a portion of each citation function ( y ) and a measure of 12pos ( the log - linear ) and a measure of [SEP]", "cit": "that means that parts of the az scheme are similar to citation function classification schemes from the area of citation content analysis # otherefr ; # [SEP]"}
{"pre": "vector space models form the basis for a variety of nlp tasks # otherefr ; # refr. [SEP] the senses of syn [SEP] [SEP] [SEP]", "cit": "we found no improvement on svs in a straightforward extension to additional syntactic context items # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the decision list consists of surrounding words, pp, prepositions, and determiners, thus they use their morphological disambiguation approach to determine the", "cit": "in de felice and # refr, we described some of the preprocessing required and offered some motivation for this approach. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in # refr, and le nagard & sterat # otherefr, the analysis of collocations are expressed in a sentence. [SEP] [SEP]", "cit": "pairwise associations # otherefr \\ ], \\ [ church and # refr \\ ] ) as well as n - word # otherefr [SEP]"}
{"pre": "to find the hypernym relation, we use the supersense - xml # refr. [SEP] ontology # otherefr. [SEP] the [SEP] [SEP]", "cit": "one notable study was conducted by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "our approach to this problem is based on the well - known parsing algorithm that can be effectively performed by compiling a sentence rewriting systems # otheref", "cit": "this simplifies semantics construction, and current algorithms support the efficient enumeration of the individual semantic representations from an usr # refrb ). [SEP] [PAD] [PAD]"}
{"pre": "we use the ibm model 1 # otherefr and the hidden markov model ( hmm ) alignment model # refr. [SEP] [SEP] [SEP] into [SEP] [SEP]", "cit": "the only assumption of most current statistical models # otherefr ; # refr is that the aligned sentences in such corpora should be segmented into sequences [SEP]"}
{"pre": "in nlp, sampling is important for many real tasks, such as : word segmentation, pos tagging # otherefr ; # [SEP] [SEP] [SEP]", "cit": "in this paper, we demonstrate that fast and accurate crf training and tagging is possible for large tagsets of even thousands of tags by approximating the [SEP]"}
{"pre": "# refr used a monolingual parallel corpus to obtain paraphrases. [SEP] sentences in a parallel corpus. [SEP] the same texts, [SEP] the [SEP]", "cit": "sentential paraphrase collection has been tackled from specific resources increasing the probability of sentences being paraphrases # otherefr ; # [SEP]"}
{"pre": "in contrast, lexas uses supervised learning from tagged sentences, which is also the approach taken by most recent work on wsd, including # [SEP]", "cit": "semcor # otherefr and the dso collection ( ng & # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we also measure the quality of the translation output with the automatic evaluation metrics bleu # refr and nist # otherefr. [SEP] the [SEP] the", "cit": "since human evaluation is costly and difficult to do reliably, a major focus of research has been on automatic measures of mt quality, pioneered by [SEP]"}
{"pre": "in this paper, we assume the socalled graph - based approach # otherefr ; # refr ; here we presented here implemented [SEP] [SEP] [SEP]", "cit": "in recent years, graph - based ranking algorithms have been successfully used for document summarization # refr and keyword extraction # otherefr. [SEP] [PAD]"}
{"pre": "the tokenisation and partof - speech tagging consists of the sentence structure analyzers that we have analyzed the sentence - level ( e. g.", "cit": "it starts with sentence boundary detection ( sbr ) and regular expression - based tokenization using its built - in component jtok, followed by [SEP]"}
{"pre": "in fact, several popular weakly supervised learning algorithms such as self - training # otherefr ; # refr, co - training # other [SEP] [SEP]", "cit": "in fact, several popular weakly supervised learning algorithms such as self - training, co - training # otherefr ; # refr. [SEP] [PAD] [PAD]"}
{"pre": "transliteration methods typically fall into two categories : generative approaches # otherefr that try to produce the target transliteration given a source [SEP]", "cit": "this has been shown both in supervised settings # otherefr ; # refr in which constraints are used to bootstrap the model. # otheref [SEP]"}
{"pre": "the bionlp - st 2009 # refr focused on the recognition of biomedical events. [SEP] ( bionlp ) [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "the bionlp? 09 shared task on event extraction # refr, the first task in the present shared task series, involved the extraction of [SEP]"}
{"pre": "the sentences were pos - tagged with the mxpost tagger # otherefr, and parsed with the charniak parser # refr.", "cit": "in order to extract the linguistic features necessary for the model, all sentences were first automatically part - of - speech - tagged using a maximum entropy [SEP]"}
{"pre": "we build on previous work on semantic parsing # otherefr ; # refr that exploits ccg # otherefr. [SEP] supervision [SEP] [SEP] [SEP]", "cit": "there are many approaches to supervised semantic parsing, including inductive logic programming # otherefr ; # refr, and automatically learned transformation rules # other [SEP]"}
{"pre": "the features include : a maximum sentence length of 80, growdiag - final - and symmetrization of giza + + alignments, [SEP]", "cit": "for the overall sentence structure experiment, translations are additionally part - of - speech tagged with mxpost tagger # refr, and parsed with [SEP]"}
{"pre": "3techniques for automatic vocalization have been studied # otherefr ; # refr. [SEP] this appears in nlp is in [SEP] [SEP] [SEP]", "cit": "we compare the manually annotated grammar, which we incorporate into the stanford parser, to both the berkeley # refr and bikel # otherefr [SEP]"}
{"pre": "these three of types of information have proved useful for natural language processing # otherefr ; # refr, and word sense disambiguation # other [SEP]", "cit": "scf acquisition most current works induce scfs from the output of an unlexicalized parser ( i. e. a parser trained without scf [SEP]"}
{"pre": "the determiner system is a maximum entropy model trained on the preposition usage # refr. [SEP]osition error - rate # otherefr [SEP] [SEP]", "cit": "most of these methods use large corpora of well - formed native english text to train statistical models, e. g. # otherefr and [SEP]"}
{"pre": "using comparable corpora to automatically extend bilingual dictionaries is becoming increasingly popular # otherefr ; # refr. [SEP]. [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "the english corpus nhtsa was pos - tagged and stemmed with stepp tagger # otherefr and dependency parsed using the [SEP]"}
{"pre": "# refr observed that much of the language acquisition ( esl ) does not take advantage of modeling speech information from language technologies, [SEP] the [SEP] [SEP]", "cit": "previous work in call error correction includes identifying word choice errors in toefl essays based on context # refr, correcting errors with a generative lattice [SEP]"}
{"pre": "# refr created a manually prepared set of manually selected sentiment lexicons for english. [SEP] languages ( mrds ) for english. [SEP] languages ( for", "cit": "a multilingual parallel news corpus annotated with opinions towards entities was presented in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition to the regular distance distortion limit, there is also evidence that the system has been an impact of the system to be an automatic evaluation of", "cit": "reordering has also been identified as a major factor in determining the difficulty of statistical machine translation between two languages # refr hence bleu scores may [SEP]"}
{"pre": "# refr use a pcfg variety of lexical cues to detect disfluencies. [SEP] text, switchboard, and add contextual cues. [SEP] features", "cit": "# refr ) and psycholinguistics ( e. g. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for the evaluation of translation quality, we used the bleu metric # refr with a single reference translation. [SEP] the [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "results are presented in terms of bleu # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition to cross - lingual resources, # refr have shown that in a number of languages, english are effective for detecting the [SEP] [SEP] [SEP]", "cit": "a broad - coverage corpus such as the human language project envisioned by # refr would be a powerful resource for the study of endangered [SEP]"}
{"pre": "the third line, propbank column of table 1 reports such measures summarised for the five best semantic role labelling systems # otherefr ; # [SEP]", "cit": "semantic roles were automatically annotated using the swirl package # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in recent years, nombank # otherefr, # refr, # otherefra ) have shown promising results. [SEP] this approach [SEP] [SEP]", "cit": "so far we are aware of only one english nombank - based srl system # otherefr and on framenet by # refr using [SEP]"}
{"pre": "in addition, the topic of the visualr ; the thematic., ~ is the method of # refr, and it is used to identify [SEP]", "cit": "different types of text and of images have been considered, for example : narrative text and motion pictures # otherefr, spatial descriptions and 3 [SEP]"}
{"pre": "# refr use the same set of dependency structures for question. [SEP] english. [SEP] dependency trees, and it could be important for questionbank. [SEP]", "cit": "for our target domain experiments, we evaluate on the questionbank # refr, which includes a set of manually annotated questions from a trec question [SEP]"}
{"pre": "# refr used a similar technique for wsd in which the wsd dataset consists of 20000 annotated sentences are similar to the ones are the ones", "cit": "previous work shows that current state - of - theart wsd systems are not able to obtain better results on the adaptation scenario compared to the [SEP]"}
{"pre": "we use a perceptron like algorithm # refr. [SEP] the training algorithm of collins and roark # otherefr. [SEP] the [SEP] the [SEP]", "cit": "hence we use a beam - search decoder during training and testing ; our idea is similar to that of # refr who used a beam - search [SEP]"}
{"pre": "gi # refr built a system that automatically extracted relationships between nouns and verbs that are indicative of the semantics of the lexico - syntactic relation [SEP] (", "cit": "there is growing research on relations between nominals # otherefr ; gi # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the work of ge and mooney # otherefr and # refr is similar to ours in that it uses both local and global context [SEP] [SEP]", "cit": "in the related problem of translating database queries to logic, # refr and wong and mooney # otherefr consider the scope of adjectives [SEP]"}
{"pre": "in a recent nlp community, # refr used a maximum - entropy model to generate candidates that predict the same objective parts of speech, [SEP] [SEP]", "cit": "identifying contrasting word pairs ( or short phrase pairs ) is also useful for detecting humor # refr, as satire and jokes tend to [SEP]"}
{"pre": "based on the pdtb, a number of studies have provided insightful analysis of the use of discourse connectives in english news text and have [SEP]", "cit": "following the release of the pdtb, smaller corpora annotated with discourse relations have been developed for hindi # otherefr, and the effort [SEP]"}
{"pre": "we report two translation measures : the system of # otherefr, and the log - linear interpolation method # refr. [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "intuitively, sentence models for domain relevance p ( d | e, f ) are somewhat related to data selection approaches # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "in this paper, we present an application of grammatical compression ( robustly, summarization ), an analysis of grammatical compression, and # refra", "cit": "# refr studied what edits people use to create summaries from sentences in the source text. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the features are computed during the decoding, and we use giza + + # refr to align the corpus. [SEP] training to align the training data", "cit": "this leaves us with the question of how to set the weights for the log - linear model ; in this work, we use the zmert [SEP]"}
{"pre": "in # refr, information - theoretic measure of semantic similarity between a word is defined by a wordnet tree. [SEP] the information of a word within", "cit": "in # refr, ic was used to measure semantic similarity between words and it is shown to be more effective than traditional measurements of semantic distance within [SEP]"}
{"pre": "most of the reported work on paraphrase generation from arbitrary input sentences uses machine learning techniques trained on sentences that are known or can be inferred [SEP]", "cit": "most of the reported work on paraphrase generation from arbitrary input sentences uses machine learning techniques trained on sentences that are known or can be inferred [SEP]"}
{"pre": "many works have been proposed to address this problem, e. g., supervised learning algorithms # otherefr ; # refr, and unsupervised learning", "cit": "some of them rely on a large set of text documents to compute semantic orientations of words in an unsupervised manner # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, several other prosodic cues # otherefr ; # refr have been proposed for sentence segmentation, due to the spontaneous speech [SEP] [SEP] [SEP]", "cit": "comparable behavior has been observed at other discourse boundaries such as story boundaries in newswire speech. # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the most commonly used mt evaluation metric in recent years has been ibm? s bleu score # refr. [SEP]. [SEP] ble [SEP] ( 1 )", "cit": "on the other hand, standard automatic mt evaluation metrics such as bleu # refr and meteor # otherefr are considerably cheaper and provide faster [SEP]"}
{"pre": "transliteration methods typically fall into two categories : generative approaches # otherefr that try to produce the target transliteration given a source [SEP]", "cit": "several papers have followed up on this basic approach and focused on semi - supervised approaches to this problem or on extracting better features for the discriminative classifier [SEP]"}
{"pre": "# refr use an n - gram language model to find the good tweets. [SEP] the noisy words. [SEP] the new word stems [SEP] the whole of", "cit": "the social text serves as a very valuable information source for many nlp applications, such as the information extraction # otherefr, summarization [SEP]"}
{"pre": "statistical parsers reap dramatic gains from transcribed spoken language understanding ( cf. # refr ), and parsers # otherefr [SEP] [SEP] [SEP]", "cit": "each of these scores can be calculated from a provided syntactic parse tree, and to generate these we made use of the charniak parser # [SEP]"}
{"pre": "we have discussed this mechanism, and we have constructed the semantic representation of the discourse representational \\ [ # refr \\ ]. \\ [ 3 a", "cit": "by associating natural language with concepts as they are entered into a knowledge a model of semant ic ana lys i s all of the following [SEP]"}
{"pre": "we performed a more thorough investigations of the mert procedure # otherefr ; # refr on the other hand, or both sides of the [SEP]", "cit": "we performed language model interpolation and batch - mira tuning # refr using newstest2010 ( 2, 849 sentence pairs ). [SEP] [PAD] [PAD]"}
{"pre": "more recently, # refr find that using document boundaries were significantly improved by training models on domain adaptation. [SEP] genre classification, using the same distribution of", "cit": "more recently, the development of genre - dependent models for a variety of natural language processing # otherefr ; # refr, speech recognition # [SEP]"}
{"pre": "we use the features from # refr. [SEP] the former based on svm model for all the features, and we adopt the approach of # otheref", "cit": "the feature set used here is as same as the feature set used in # refr except that we did not use syntactic relations. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "we will show in the next section that we are aware of are aware of are only evaluated in specific cases where we are aware of is # refr", "cit": "to evaluate the utility of the graph - based kernels described in section 2 for computing lexical similarity, we use the dataset developed for the task on [SEP]"}
{"pre": "to our knowledge, the c & c ccg parser # refr is a dependency parser that uses a combinatory categorial grammar. [SEP] ( cc", "cit": "we use a robust wide - coverage ccg - parser # refr to generate fine - grained semantic representations for each t / h - pair [SEP]"}
{"pre": "in contrast, bootstrapping approaches # otherefr ; # refr to namedentity recognition # otherefr have been shown to outperform word [SEP] [SEP]", "cit": "although a rich literature covers bootstrapping methods applied to natural language problems # otherefr ; # refr several questions remain unanswered when these [SEP]"}
{"pre": "the parser of # refr had been applied to the penn treebank # otherefr, as well as on other treebank [SEP] [SEP] [SEP] [SEP]", "cit": "to investigate whether the performance of mst - parser and maltparser on questions could also be improved by adding more questions to the training data, [SEP]"}
{"pre": "in consequence, agent / patient relations between roles were generally treated as a human - computer interaction # otherefr ; # refr. [SEP] [SEP] [SEP]", "cit": "a number of projects are working on producing such corpora through manual annotation, among which are framenet # otherefr, and salsa # [SEP]"}
{"pre": "# refr showed that cohesion is important for a variety of language independent translation, such as word - aligned bilingual corpora. [SEP] the berkeley parser # other", "cit": "dependencies were found to be more consistent than constituent structure between french and english by # refr, though this study used a tree representation on the english [SEP]"}
{"pre": "the training set contains the top 100 web search results of 49 names from the web03 corpus # refr. [SEP] features of the disambiguation [SEP] [SEP]", "cit": "2. 2. 1 preliminaries traditionally, hard clustering algorithms ( where uij? { 0, 1 }, ) such as complete linkage hierarchical [SEP]"}
{"pre": "in this paper, we evaluate the performance of the undirected planar and covington parsers # refr. [SEP] the results of [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "instead, the dependency tree is built stepwise and the decision about what step to take next ( e. g. which dependency to insert ) can [SEP]"}
{"pre": "recently, some research have been focused on deriving different sense groupings for this area # otherefr ; # refr. [SEP] the [SEP] [SEP] the", "cit": "thus, some research has been focused on deriving different word - sense groupings to overcome the fine? grained distinctions of wn # otheref [SEP]"}
{"pre": "to evaluate our system we use domain - independent techniques ( event ), which is based on the output of the berkeley parser # refr [SEP] system [SEP]", "cit": "they provide essential guidance in extracting information related to events from free text # otherefr, and can also aid in other nlp tasks, [SEP]"}
{"pre": "leveraging from structural and linguistic information from parse trees, these models are believed to be better than their phrase - based counterparts in source target examples [SEP]", "cit": "here we choose five popular features used in syntactic mt systems, including the bi - directional phrase - based conditional translation probabilities # otherefr and [SEP]"}
{"pre": "we used the mxpost tagger # refr and parsed with the charniak parser # otherefr. [SEP] the latent variable [SEP] [SEP]", "cit": "the procedure is explained in detail in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this is especially interesting since much previous work has used gold pos tags, e. g., annotating new sentences with their morphological [SEP] [SEP] [SEP]", "cit": "standard sequence prediction models are highly effective for supertagging, including hidden markov models # otherefr, and conditional random fields # refr. [SEP]"}
{"pre": "meanwhile, work on semantic parsing has focused on producing semantic parsers for answering simple natural language questions # otherefr ; # refr. [SEP] [SEP]", "cit": "meanwhile, work on semantic parsing has focused on producing semantic parsers for answering simple natural language questions # otherefr ; # refr. [SEP] [PAD]"}
{"pre": "in addition, open information extraction # otherefr ; # refr. [SEP] this technique tends to be effective for [SEP] filtering of [SEP] [SEP] [SEP] [SEP]", "cit": "textrunner # otherefr, reverb # refr and nell # otherefr are some examples of open - domain systems that [SEP]"}
{"pre": "the use of machine transliteration has been studied extensively in the context of machine transliteration field # otherefr ; # refr. [SEP]", "cit": "from this perspective it is possible to directly employ a phrase - based smt system in the task of transliteration # otherefr ; [SEP]"}
{"pre": "the use of cross - lingual word sense disambiguation has been extensively studied # otherefr ; # refr. [SEP] the decision to be [SEP]", "cit": "many studies have already shown the validity of a cross - lingual approach to word sense disambiguation # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition to the well - known bilingual language models # otherefr ; # refr show that bilingual information to improve translation quality. [SEP] the [SEP]", "cit": "finally, we report a last experiment which uses a bilingual language model to enrich the context representation in pbsmt # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "names of these kinds, generalized names # otherefr ; # refr. [SEP] the text in nombank, [SEP]a [SEP] la que [SEP] la", "cit": "figure 1 : system architecture of promed - plus acquisition, # refr requires a large corpus of domain - specific and general - topic texts. [SEP]"}
{"pre": "dp beam search for phrase - based smt was described by # refr. [SEP] # otherefr. [SEP] the dp - based [SEP] [SEP] [SEP]", "cit": "two of them are based on the documentlevel decoder docent # refr ; hardmeier et al., 2013a ). [SEP] [PAD] [PAD] [PAD]"}
{"pre": "for instance, the dependency relations were automatically by the framenet project # refr. [SEP] the framenet project. [SEP] this problem of english [SEP] [SEP]", "cit": "as the role - semantic paradigm, we used framenet # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "consequently, substantial effort has been made to learn such rules # otherefr ; # refr. [SEP] this has been done while the use of [SEP]", "cit": "semantic inference applications such as qa and ie crucially rely on entailment rules # otherefr ; # refr or equivalently inference rules, that [SEP]"}
{"pre": "the use of lossy data structures that can be used for smt by a minimum bayes - risk system # otherefr ; # refr.", "cit": "the system we submitted corresponds to the? giza + + and sblitg ( only news )? system, but with randlm # [SEP]"}
{"pre": "recent work by haghighi and klein # otherefr and # refr challenges the appropriateness of syntactic features in the target. [SEP] and [SEP] [SEP]", "cit": "rather than relying on fully supervised data, we took the approach of # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we evaluated our joint decoder that integrated a hierarchical phrase - based model # refr and a tree - to - string model # otherefr chinese [SEP]", "cit": "while others have worked on combining rules from multiple syntax - based systems # refr or using posteriors from multiple models to score translations # otheref [SEP]"}
{"pre": "statistical parsing models have recently been developed for combinatory categorial grammar # otherefr ; # refr. [SEP] this work was done while the author", "cit": "log - linear models have previously been applied to statistical parsing # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "different techniques to widen the search space have been described # otherefr ; # refr. [SEP] the problem of component two different mt systems [SEP]", "cit": "both best 3 # refr studied up to 10000 - best and show that the use of 1000 - best candidates is sufficient for mbr decoding. [SEP]"}
{"pre": "in particular, we use a shallow semantic tree kernel ( sstk ) # refr and a tree kernel # otherefr for qa [SEP] [SEP] [SEP]", "cit": "notice that with this representation the tree kernel can easily be extended to find subtree matches at the word level, i. e., by including [SEP]"}
{"pre": "previous work in nlg includes work on discriminative natural language generation that models for dialogue generation # otherefr ; # refr. [SEP] this assumption [SEP]", "cit": "more recently, there have been several approaches towards using reinforcement learning # otherefr ; # refr or hierarchical reinforcement learning # otherefr for [SEP]"}
{"pre": "finally, the natural language generation algorithm has been implemented in many dop implementations that have been successfully applied to a natural language processing ( nlg ) [SEP]", "cit": "earlier work on concept to text generation mainly focuses on generation from logical forms using rule - based methods. # otherefr introduces a head - [SEP]"}
{"pre": "in a related but independent effort, # refr proposed a transliteration method which applied machine learning techniques to the transliteration field. [SEP] the", "cit": "their method is not only applicable to japanese ; it has already been used for korean # otherefr, and persian # refr. [SEP] [PAD]"}
{"pre": "in this paper, we extend the ghkm rule - based smt framework # refr to obtain the improvements of japanese - english [SEP] [SEP] [SEP] [SEP]", "cit": "it? s often the case that preordering methods are based on rule - based approaches, and these methods have achieved great success in ameliorating [SEP]"}
{"pre": "this has led to a vast amount of research on unsupervised grammar induction # otherefr ; # refr, which appears to be a natural solution to", "cit": "syntactic universals are a well studied concept in linguistics # otherefr, and were recently used in similar form by # refr for multilingual [SEP]"}
{"pre": "the surprisal # refr at word wi refers to the negative log probability of wi given the preceding words, computed using the prefix probabilities of the prefix", "cit": "syntax can readily be approximated using simple pcfgs # refr, which can be easily tuned # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the stanford ner tagger # refr to determine the name entity recognizer # otherefr. [SEP]. [SEP] the [SEP] [SEP] [SEP] [SEP]", "cit": "# refr and finkel et al # otherefr incorporate label consistency information by using adhoc multi - stage labeling procedures that are effective but [SEP]"}
{"pre": "the supertagger was trained using the adaptive supertagging paradigm approach of # refr. [SEP] a selftraining applied to pos tagging model and [SEP]", "cit": "the same grammar assigns an average of 22 lexical categories per word # refra ), resulting in an enormous space of possible derivations. [SEP] [PAD] [PAD]"}
{"pre": "the weight vector w is tuned on a development set of error - annotated sentences using the pro ranking optimization algorithm # otherefr. 1 [SEP] [SEP]", "cit": "the gradient ascent optimization of the xbleu appears to be more stable than the gradient - free direct 1 - best bleu tuning or n [SEP]"}
{"pre": "traditionally, entirely different approaches have been used for lexical # otherefr ; # refr and syntactic simplification # otherefr. [SEP] the classification [SEP]", "cit": "automated sentence simplification has been investigated mostly as a preprocessing step with the goal of improving nlp tasks, such as parsing # otherefr, [SEP]"}
{"pre": "in addition, new research on the topic has explored the translation of sentences into many domains, including database query # otherefr, # refr,", "cit": "various techniques were applied to the problem including machine translation # otherefr ; # refr, probabilistic push - down automata # otherefr. [SEP]"}
{"pre": "# refr, bethard et al # otherefr ) as well as subjectivity analysis for the subjectivity analysis of subjective and objective sentences [SEP]", "cit": "as shown in previous work, a high - precision classifier can be used to automatically generate subjectivity annotated data # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper we focus on the reordering problem within the hiero system # refr and show that a particular variant of the reordering [SEP] [SEP]", "cit": "several approaches have been proposed to address these issues : from filtering the extracted synchronous grammar # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used the dataset by # refr. [SEP] the text t2 system in the semeval - 2012 shared task of textual entailment [SEP] [SEP]", "cit": "we participated in the first evaluation of this task in 2012 # otherefr, achieving third place on average among 29 participating systems # refr. [SEP]"}
{"pre": "in addition to the verb, many studies aimed to address this problem, e. g. # otherefr ; # refr, inter alia", "cit": "relationship classification is known to improve many practical tasks, e. g., textual entailment # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for instance, the lexicon is obtained from an annotation tool # refr. [SEP]ly trained on the same data, as in # otherefr [SEP]", "cit": "the interaction of morphological nalysis with spelling correction # refr is another possibly fruitful area of work. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in nlp, e. g., # otherefr ; # refr, and e. g., the raters were the [SEP]", "cit": "while the efficiency of al has already been shown for many nlp tasks based on measuring the number of tokens or sentences that are saved in comparison [SEP]"}
{"pre": "the highest - scoring # otherefr acl workshop on parsing wsj training, with the # refr they had an applied [SEP] optimal parameter [SEP] 1", "cit": "the two main approaches to data - driven dependency parsing are transition based dependency parsing # otherefr and maximum spanning tree based dependency parsing # refr [SEP]"}
{"pre": "we can find a way of representing the posterior probability # otherefr ; # refr. [SEP] ( 1 ) [SEP] ( s ) [SEP] [SEP] [SEP]", "cit": "previous research has used a variety of sampling methods to learn bayesian phrase based alignment models # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this tutorial discusses a framework of online global discriminative learning and beam - search decoding for syntactic processing # otherefr ; # refr, combinational [SEP]", "cit": "this tutorial discusses a framework of online global discriminative learning and beam - search decoding for syntactic processing # otherefr and machine translation # refr, [SEP]"}
{"pre": "# refr also use syntactic features to identify idiomatic expressions ( e. g., part - of - speech ) of - speech ( pos [SEP]", "cit": "diab and bhutada # otherefr, li and # refr ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition to domain - independent knowledge, supervised learning has also been used to reduce the ambiguity resolution problem of fine - grained definitional [SEP] sentences", "cit": "glossary acquisition approaches in the literature are mostly focused on pattern - based definition extraction # otherefr ; # refr, among others ) and [SEP]"}
{"pre": "in nlg, in the context of the air traveler information system ( de # refr ) is used to compare the results of two different versions", "cit": "this methodology was first used in nlg in the mid - 1990s by # refr and lester and porter # otherefr, and [SEP]"}
{"pre": "f1 baseline 66. 5 79. 9 mihalcea et al2006 ) 70. 3 81. 3 rus et al200 [SEP]", "cit": "f1 has also been used over unigrams # otherefr and bigrams # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the stanford parser # refr to obtain the dependencies for each of the training data. [SEP]. [SEP] the results of the pcfg model.", "cit": "the reordering rules are based on parse output produced by the stanford parser # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the third experiment was on the combination task, in which the system uses the combination scheme of # refr. [SEP] the entailment scores factor [SEP] [SEP]", "cit": "the observation that standard logical entailment and textual entailment deviate in certain respects is not surprising and has also been addressed in a discussion initiated by [SEP]"}
{"pre": "in the last decade, ltag has been used in several natural language processing tasks, such as question answering # otherefr, and text semantic", "cit": "single word vector spaces are widely used # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for example, in the context of syntactic disambiguation, black # otherefr and # refr for sentence - level parsing, [SEP] [SEP] [SEP] [SEP]", "cit": "i introduction the application of decision - based learning techniques over rich sets of linguistic features has improved significantly the coverage and performance of syntactic # otheref [SEP]"}
{"pre": "in the pos tagging of the tagged sentences, # refr reported high precision data with an accuracy of 97. 15 %. [SEP] %. [SEP] %", "cit": "in the meantime, # refra ) # otherefrb ) proposed a method to acquire contcxt - dcpendent pos disambig [SEP]"}
{"pre": "therefore, researchers have proposed alternative approaches to learning synchronous grammars directly from sentence pairs without word alignments, via generative models # otherefr ; # [SEP]", "cit": "therefore, researchers have proposed alternative approaches to learning synchronous grammars directly from sentence pairs without word alignments, via generative models # otherefr ; # [SEP]"}
{"pre": "zero anaphora resolution has remained a very active area of study for researchers working on japanese, because of the prevalence of zeros in such languages1 [SEP]", "cit": "the approach builds on tile ttleory of discourse segment # refr, incorporating ideas from the research on information retrieval # otherefr. [SEP] [PAD]"}
{"pre": "we use tinysvm2 along with yamcha3 # refr as the svm training and test software. [SEP] ( 1 ) we propose to learn [SEP]", "cit": "various machine learning approaches have been proposed for chunking # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in recent years several techniques have been successfully applied to nlp tasks # otherefr ; # refr ). [SEP] this problem [SEP] [SEP] [SEP] [SEP]", "cit": "there has been a large and diverse body of research in opinion mining, with most research at the text # otherefr ; # refr or [SEP]"}
{"pre": "# refr propose an unsupervised model that allows the selectional preference to be used for the selectional preferences, allowing us to explore the application of met", "cit": "inspired by recent advances in modeling selectional preferences with latent - variable models # otherefr ;? o se? # refr, we propose [SEP]"}
{"pre": "we tested whether statistical significance tests for student years on a complete semantic interpretation, and report performance for the best performance of statistical classifiers ( [SEP] [SEP] [SEP]", "cit": "unless otherwise specified, all performance differences discussed in the text are significant on an approximate randomization significance test with 10, 000 iterations # refr. [SEP] [PAD]"}
{"pre": "in contrast, # refr proposed a model which extends the above by allowing all possible pos tags, but rather than on the training set of [SEP] features", "cit": "first, we use the standard approach of greedily assigning each of the learned classes to the pos tag with which it has the greatest overlap [SEP]"}
{"pre": "graphbased models parameterize the parsing problem by the structure of the dependency graph and normally use dynamic programming for inference # otherefr ; # [SEP]", "cit": "higher uas is reported by joint tagging and parsing # refr or system integration # otherefr which benefits from both transition based parsing and graph based [SEP]"}
{"pre": "the task of clause alignment is closely related to that of sentence alignment # otherefr and phrase alignment # refr. [SEP] ( f ) [SEP] (", "cit": "these findings have inspired growing research into clause - to - clause machine translation involving clause splitting, alignment and word order restructuring within the clauses # refr [SEP]"}
{"pre": "in the last decade, many successful systems extractive summarization that summarize each system are available in the domains of content and even if in the text", "cit": "the earliest work to consider open - domain speech summarization seriously from the standpoint of text summarization technology # otherefr ; # refr approached [SEP]"}
{"pre": "# refr analyzed the effectiveness of using agreement in a segmenter optimized on segmenter, and found that the synthetic segmentation is over time [SEP], [SEP]", "cit": "indeed, much of the work on automatic recognition of discourse structure has focused on linear, rather than hierarchical segmentation # otherefr ; # refr [SEP]"}
{"pre": "neural language models # otherefr, # refr, and other areas such as part - of - speech tagging # otherefr are popular [SEP]", "cit": "in nlp, such methods are primarily based on learning a distributed representation for each word, which is also called a word embeddings # refr. [SEP]"}
{"pre": "we adopt the log - linear model # refr as follows : p ( e | f ) =? j? i? i? i? i", "cit": "the source - channel approach has been often used for word - based language tasks, such as speech recognition and machine translation # otherefr ; [SEP]"}
{"pre": "the features are the same as those in # refr. [SEP] 1 % dependency trees, obtained using a maximum spanning tree algorithm # otherefr.", "cit": "we implemented this method in an annotation projection framework to create training data for two dependency parsers representing different parsing paradigms : the mst - parser # [SEP]"}
{"pre": "the second classification approach has been used to deal with the question classification task # refr. [SEP] the question classification task is to generate the part of a", "cit": "they compare the obtained results with other algorithms, such as nearest neighbors, naive bayes, decision tree or sparse network of winnows ( snow [SEP]"}
{"pre": "in addition, we use the corpus - based approach described in # refr, which has subsequently been applied to obtain the semantic [SEP] text [SEP] ( [SEP]", "cit": "at lexical level, li and # refr identify formal and informal synonyms in chinese. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, we plan to incorporate the highly ambiguous word clusters, and instead of a future work to induce a new word sense disambiguation problem #", "cit": "recently, however, # refr have shown that latent dirichlet allocation # otherefr can be successfully applied to perform word sense induction from small word [SEP]"}
{"pre": "this has led to the development of various data - driven dependency parsers, such as those by yamada and matsumoto # otheref [SEP]", "cit": "dynamic programming algorithms for nonprojective parsing have been proposed by kahane et al. # otherefr and # refr, but they [SEP]"}
{"pre": "a system developed for interpretation has been developed in # otherefr ; # refr. [SEP] ( 1 ) a. [SEP] ( a. [SEP] )", "cit": "# refr have implemented a database interface based on gfsg. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "to take advantage of this information to take advantage of more sophisticated semantic resources like latent variable models # refr, wease the document similarity given [SEP] (", "cit": "sentence similarity [ ss ] is emerging as a crucial step in many nlp tasks that focus on sentence level semantics such as word sense disambiguation [SEP]"}
{"pre": "therefore, studies have recently resorted to other resources for the enhancement of parsing models, such as large - scale unlabeled data # otherefr [SEP]", "cit": "li11 refers to the second - order graph - based model of li et al # otherefr, whereas z & n11 is the [SEP]"}
{"pre": "reranking approaches have given improvements in accuracy on a number of nlp problems including parsing # otherefr, and natural language processing # [SEP]", "cit": "brown et al # otherefr or # refr ) have typically leveraged distributional similarity. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the l - bfgs algorithm # otherefr, which has been shown to perform well for the identification of source and targeti [SEP]", "cit": "our transliteration system was directl # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the score column is the percentage of correctly extracted mentions in the conll - 2011 shared task # refr. [SEP] this metric [SEP] [SEP] [SEP] [SEP]", "cit": "we evaluate the systems on english conll? 12 development data and compare it with the winning system of the conll? 12 shared task # [SEP]"}
{"pre": "although checking whether a word alignment can be generated by itg is far simpler than for arbitrary synchronous grammars, there is a striking variation in the [SEP]", "cit": "although checking whether a word alignment can be generated by itg is far simpler than for arbitrary synchronous grammars, there is a striking variation in the [SEP]"}
{"pre": "we use the similarity measure described by # refr. [SEP] the similarity of w ( w1 ) can be the candidate in the nli [SEP] [SEP]", "cit": "it has behaved well in the context of language processing applications # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "previous work in nlp has focused on using the implicit syntactic information available in part - of - speech # otherefr ; # refr, [SEP]", "cit": "our work is based on # refr? s bayesian version of the dependency model with valence # otherefr, using interpolated backoff techniques to [SEP]"}
{"pre": "for this task, we automatically extracted paraphrase pairs from parallel corpora # otherefr ; # refr, which are then used to obtain sentence", "cit": "accordingly, many researchers have recognized that automatic paraphrasing is an indispensable component of intelligent nlp systems # otherefr ; # refr. [SEP]"}
{"pre": "previous work on identifying the polarity of a word has either been done in the context of debates based on the mpqa corpus # otherefr,", "cit": "in previous work, we proposed a method that uses participantto - participant and participant - to - topic attitudes to identify subgroups in ideological discussions [SEP]"}
{"pre": "while these approaches have been shown to improve nlp tasks # refr, machine translation # otherefr. [SEP] this work was done [SEP] [SEP] [SEP]", "cit": "using the rst treebank as training and evaluation data, # refr demonstrated that their automatic sentence - level discourse parsing system could achieve near - human [SEP]"}
{"pre": "bayes # otherefr 74. 1 svm - na? # refr 73. 1 # otherefr 72. 9 [SEP] the [SEP] [SEP] [SEP]", "cit": "in # refr, the classifier is trained using grouped senses for verbs and nouns according to wordnet top - level synsets and thus effectively pooling [SEP]"}
{"pre": "in addition, it has been shown that named entity recognition ( ner ) ( ner ) ( poorlys ) ( poorlys ) ( ner ) (", "cit": "it uses named entity recognition # otherefr ; # refr as a subroutine to identify named person entities, though we are also interested [SEP]"}
{"pre": "1http : / / www. nist. gov / speech / tests / ace / ace / 2http : / [SEP] manual / [SEP] [SEP]", "cit": "coercions are obtained as paths of meronyms or hypernyms. # refr discusses a coercion methodology based on wordnet and treebank [SEP]"}
{"pre": "we used the features generated by the svm - light - tk # refr for the experiments. [SEP] system. [SEP] kernel # otherefr for our", "cit": "this choice is justified by previous studies # refrb ) showing that the accuracy of classification is higher for lower nodes ;? if only two nodes [SEP]"}
{"pre": "# refr proposed to use a probabilistic model for identifying agreement and disagreement in a post process. [SEP] model to predict the semantic orientation. [SEP] polarity classification", "cit": "our work is closely related to recent studies on detecting subgroups from online discussions # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "margin - based techniques such as perceptron training # otherefr and mira # refr have also been shown to be able to tune mt [SEP]", "cit": "our results add to a growing body of evidence # otherefr ; # refr that mira is preferable to mert across languages and systems [SEP]"}
{"pre": "we use the iob tagging scheme # refr. [SEP] ( iob ) is a sequence labeling algorithm for np chunking of np chunking and", "cit": "there are 45 different pos labels, and the three np labels : begin - phrase, inside - phrase, and other. # refr to reduce [SEP]"}
{"pre": "there are several text planning methods for information extraction ( e. g., # refr, # otherefr ). [SEP] domain information retrieval tasks", "cit": "knowledge - rich methods models employing manual crafting of ( typically complex ) representations of content have generally captured one of three types of knowledge # [SEP]"}
{"pre": "with regard to lexical features, the situation is more complex in that there are a number of works that have been a [SEP] relationship between categorial grammar", "cit": "we have also been encouraged by the success of the unlexicalized parsers reported recently # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "recently, approaches that address the problem of word order differences between the source and target language without requiring a high quality source or target parser have been [SEP]", "cit": "phrase based systems # otherefr use lexicalized distortion models ( al - onaizan and # refr and scores from the target language [SEP]"}
{"pre": "paraphrase generation can be used for paraphrase the representation of # refr. [SEP] the second international chinese expressions, the source [SEP] [SEP] [SEP]", "cit": "while there have been efforts pursuing the extraction of more powerful paraphrases # otherefr ; # refr ; cohn and lapata, [SEP]"}
{"pre": "previous work on natural language generation that uses statistical methods to induce machine learning from parallel data has been presented in # refr. [SEP] natural [SEP] natural [SEP]", "cit": "report generation from time - series data has been researched widely and existing methods have been used in several domains such as weather forecasts # refr, clinical [SEP]"}
{"pre": "in addition to the averaged perceptron model with beamsearch decoding, our model is similar to that of # refr. [SEP] % [SEP] the [SEP] [SEP]", "cit": "as # refr discuss, in ccg it is not feasible to use features in the grammar to ensure that balanced punctuation ( e. g [SEP]"}
{"pre": "in this paper, we take a different approach and induce a probabilistic model which would be passed to the model, and the model is [SEP] [SEP] [SEP]", "cit": "there has been much recent work on latent variable models ( e. g. # refr ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "these include syntactic similarity measures ( for example, # refr, # otherefr ), and semantic similarity measure ( for example ). [SEP] [SEP]", "cit": "because lexical information is highly sensitive to domain variation, approaches that can identify vcs, scfs and sps in corpora have become increasingly popular, [SEP]"}
{"pre": "in # refr, two versions of wikipedia and semi - supervised machine learning methods are used to extract large te data sets similar to the ones provided [SEP]", "cit": "# refr present an approach for generating sentence level paraphrases, learning structurally similar patterns of expression from data and identifying paraphrasing pairs among [SEP]"}
{"pre": "in the penn treebank ( pdtb ) project # refr, a lexicalized treebank grammar that is trained on the penn discourse treebank #", "cit": "dltag # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "most of the previous research on sentence compression focuses on deletion using syntactic information, # otherefr, # refr, galanis and andr [SEP]", "cit": "character lengths have been used for document summarization # otherefr, and subtitling # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in unsupervised wsd, graph - based methods have been applied to wsi # otherefr ; # refr. [SEP] the problem of wsd", "cit": "current approaches have used clustering # otherefr or statistical graph models # refr to identify sense - specific subgraphs. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the same data set as # refr, using the svm - light - tk3k algorithm # otherefr. [SEP] [SEP] [SEP] [SEP]", "cit": "svmlight - tk10 # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in contrast, other statistical approaches to paraphrase generation have been proposed that consider sentence pairs of sentences # otherefr ; # refr. [SEP]", "cit": "similar work is described in [ # refr ], who describe a syntax - based algorithm that builds word lattices from parallel translations which can be used [SEP]"}
{"pre": "we rescore the asr et al information ; # refr, as implemented in moses # otherefr. [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "we utilize the cube pruning algorithm # refr for decoding and optimize the model weights with mert. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "while many models of text coherence have been developed in recent years # otherefr, # refr, soricut and marcu # other [SEP]", "cit": "models of coherent discourse are central to several tasks in natural language processing : such models have been used in text generation # otherefr ; # [SEP]"}
{"pre": "margin - based techniques such as perceptron training # otherefr ; # refr or perceptron learning # otherefr have also been shown to", "cit": "recently, researchers have proposed a large number of additional features # otherefr ; # refr and parameter tuning methods # otherefr which are [SEP]"}
{"pre": "the story detection of code - switching from interjection corpora # otherefr ; # refr, and speech summarization # otherefr. [SEP]", "cit": "in many cases, previous story segmentation research has focused on single stream analysis techniques, utilizing only one of the information sources present in news broadcasts [SEP]"}
{"pre": "it has been argued that this system is an extension of uby and hanks, that enables efficient computation of thesaurus and [SEP] [SEP] [SEP]", "cit": "in order to generate metaphors, we start with the set of properties determined by the user and adopt a similar technique to the one proposed by [SEP]"}
{"pre": "several methods have been proposed to address different aspects of the coverage problem, ranging from automatic data expansion and semi - supervised semantic role labelling # other [SEP]", "cit": "however, the srl task is known to be especially hard for the framenetstyle representations for a number of reasons, including, the [SEP]"}
{"pre": "we tuned the system by using mert # refr. [SEP] well - known optimization. [SEP] the minimum error rate training ( mert ) [SEP] [SEP]", "cit": "the combination weights for these combinations are obtained using # refr minimum error - rate training ( mert ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we report results on two measures : bleu # refr and ter # otherefr. [SEP] the former word error rate ( wer ), [SEP]", "cit": "case - sensitive bleu scores4 # refr for the europarl devtest set # otherefr are shown in table 1. [SEP] [PAD]"}
{"pre": "crfs have been successfully applied to many sequence labeling tasks # otherefr ; # refr. [SEP] this paper is in sequence [SEP]. [SEP] [SEP]", "cit": "in the nlp literature, crfs are often decoded by choosing y to be the maximum posterior probability assignment ( e. g., # [SEP]"}
{"pre": "existing efficient algorithms ignore word identities and only consider sentence length # otherefr ; # refr. [SEP] the link of a arg max t of a", "cit": "several papers have discussed the first issue, especially the problem of word alignments for bilingual corpora # otherefr, # refr, # otheref [SEP]"}
{"pre": "in addition, several authors compared two methods : a single state - of - the - art phrase - based system # otherefr and a [SEP]", "cit": "the training data comes from the europarl corpus as distributed for the shared task in the naacl 2006 workshop on statistical machine translation # refr [SEP]"}
{"pre": "in recent years, syntax - based semantic parsers have been shown to improve performance in natural language understanding # otherefr ; # refr [SEP] [SEP]", "cit": "our learning algorithm design combines aspects of previously studied approaches into a batch method, including gradient updates # otherefr and using weak supervision # refr [SEP]"}
{"pre": "in the second international chinese word segmentation bakeoff # otherefr, two of the highest scoring systems in the literature [SEP]a [SEP]a [SEP]", "cit": "in this paper, we propose a statistical approach based on the works of # refr, in which the chinese word segmentation problem is first transformed into [SEP]"}
{"pre": "we use a conditional random field # otherefr and a crf # refr for the sequence labeling tasks of with l2 output sentences and [SEP] (", "cit": "# refr examined randomized tests for estimating the significance of f scores, and in particular the bootstrap over the test set # otherefr. [SEP] [PAD]"}
{"pre": "there have been many studies on polarity lexicon induction # otherefr ; # refr, sentiment analysis # otherefr. [SEP] the word sense [SEP]", "cit": "there are two lines of work on sentiment polarity lexicon induction : corpora - based # refr and dictionary - based # otherefr. [SEP] [PAD] [PAD]"}
{"pre": "in the absence of a good stopping criterion, the performance of a single model can be improved by measuring the performance of a semantic representation that is learned", "cit": "firstly, some models? especially those aiming to extract representations composed of psychologically meaningful semantic feature units, such as # refr? have been evaluated [SEP]"}
{"pre": "we train a trigram language model with kneser - ney smoothing # refr. [SEP] the srilm toolkit # otherefr. [SEP] [SEP]", "cit": "this was done using the sri language modelling toolkit # otherefr employing linear interpolation and modified kneser - ney discounting # refr. [SEP]"}
{"pre": "in 2007, tempeval 2007 # otherefr ; # refr, and on the other tasks, can be found that only increased [SEP] [SEP]", "cit": "a first attempt to standardize this task was the 2007 tempeval competition # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used the same split as # refr. [SEP] ( sn ) =? k. [SEP]. [SEP]. [SEP] the intuition that [SEP] [SEP] [SEP] [SEP]", "cit": "previous work has used monte carlo techniques to sample for one of the maximum probability parse # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "however, as noted by # refr, most previous research focus on sentiment analysis and aspect identification # otherefr, most approaches are discourse - based", "cit": "however, this has been achieved by either using a subset of relations that can be found in discourse theories # otherefr ; # refr or [SEP]"}
{"pre": "in addition, the twitter api maintains a reference from each reply to the post it responds to the user? s utterance, so unlike the current question", "cit": "additionally, there has been work on generating more natural utterances in goal - directed dialogue systems # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "for instance, the disambiguation of dcs relies on the principle of the disambiguation of dcs # refr. [SEP] the comparison of the pdtb sense", "cit": "the stateof - the - art for recognizing all types of explicit connectives in english is therefore already high, at 97 % accuracy for disambig [SEP]"}
{"pre": "this was overcome by a probabilistic model which provides probabilities of discriminating a correct parse tree among candidates of parse trees in a log - linear model or [SEP]", "cit": "an interesting approach to the problem of parsing efficiency was using supertagging # otherefr ; # refr, which was originally developed for lexical [SEP]"}
{"pre": "# refr used parallel corpora to train multilingual source languages from the target monolingual web as well as multilingual projection. [SEP]. [SEP] the model", "cit": "joint unsupervised learning # otherefr ; # refr is yet another research direction that seeks to learn models for many languages at once, exploiting linguistic [SEP]"}
{"pre": "the identified events are often represented using a set of keywords. # refr proposed an algorithm based on integer linear programming # otherefr model [SEP] the", "cit": "in contrast, the twitter messages ( a. k. a., tweets ) are very short and noisy, containing nonstandard terms [SEP]"}
{"pre": "in machine translation, the well - known formalism has been introduced by # refr, who propose a synchronous cfg grammar as a synchronous cfg #", "cit": "successful experiments such as those of # refr using synchronous context - free grammar are a good first start. 4 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the smt weighting parameters were tuned by mert # refr on the development data. [SEP] the news commentary corpus for each domain. [SEP] [SEP] [SEP]", "cit": "the smt systems are tuned on the dev # otherefr development set with minimum error rate training # refr using bleu # otheref [SEP]"}
{"pre": "we parsed the english side of the corpus with the charniak parser # refr. [SEP] english ( training ) and extracted from the penn [SEP]", "cit": "although the childes annotation scheme proposed by sagae et al # otherefr, such work relied mainly on a statistical parser # refr trained [SEP]"}
{"pre": "we used the same set of features as used in previous work # refr. [SEP] features defined below the sentence f = e. [SEP] [SEP] [SEP] [SEP]", "cit": "additionally, features are used to implement auxiliary distributions for selectional preferences # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, in their method was used in the evaluation of the summaries required to estimate the quality of the summaries generated by [SEP] the [SEP] it [SEP]", "cit": "for example, edmundson # otherefr give the number of sentences and # refr give the number of pages. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "the second one has been to use a dependency model with valence # otherefr, a, a, a dependency model with valence ( dmv", "cit": "unsupervised learning of natural language has received a lot of attention in the last years, e. g., # refr, bod # otheref [SEP]"}
{"pre": "we use the same tag induction method of # refr as our work. [SEP] the unsupervised pos induction system of # otherefr. [SEP] a hidden", "cit": "despite considerable research effort, progress in fully unsupervised pos induction has been slow and modern systems barely improve over the early brown et al # otheref [SEP]"}
{"pre": "in an attempt to address this problem, a great deal of recent research has focused on identifying, generating, and harvesting phraseand sentence - level [SEP]", "cit": "# refr proposes a unified approach to handling analogies, synonyms, antonyms and associations by transforming the last three cases into cases of [SEP]"}
{"pre": "unsurprisingly, independent selection of tokens for an output sentence does not lead to fluent or meaningful compressions ; thus, compression [SEP]", "cit": "although abstractive methods have also been proposed # otherefr, and they may shed more light on how people compress sentences, they do not [SEP]"}
{"pre": "among the many others, # refr proposed a method for inducing ccgs for disambiguating non - noun compounds. [SEP] languages by various language pairs.", "cit": "david yarowsky, known for his early work on word sense disambiguation, has since focused on applying word sense disambiguation techniques in a [SEP]"}
{"pre": "the data was processed by the method of # refr. [SEP] subjectivity analysis. [SEP] the word sense. [SEP] system # otherefr. [SEP]", "cit": "to operationalize selectional preference, # refr introduced selectional preference strength to measure the disposition or? preference? of a verb, v : [SEP]"}
{"pre": "reranking approaches have been successfully applied to many nlp tasks # refr including parsing, named entity recognition # otherefr. [SEP] this strategy", "cit": "the same idea appears also, in a slightly different form, in early work about reranking, e. g. # refr. [SEP] [PAD]"}
{"pre": "the ghkm syntax - based statistical machine translation # otherefr ; # refr. [SEP] a simple rule ( x, [SEP] ) [SEP] [SEP] [SEP]", "cit": "in this paper, we take the framework for acquiring multi - level syntactic translation rules of # refr from aligned tree - string pairs, and present [SEP]"}
{"pre": "morphological analysis or segmentation is crucial to the performance of many nlp tasks # otherefr ; # refr. [SEP] the [SEP] [SEP] the [SEP] [SEP]", "cit": "this removes information that is redundant for translation and can be performed as a preprocessing step for input to a conventional surface form based translation model # other [SEP]"}
{"pre": "for example, in the english chinese language, # otherefr used the dependency parser, the stanford pos tagger # refr, and the pos", "cit": "on one hand, there have been multiple reports # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we evaluate on two nlg tasks that generate natural - language generation ( nlg ) data ( reg ), and ( 2 [SEP] [SEP] [SEP] [SEP]", "cit": "this has 3https : / / github. com / nltk / nltk contrib / blob / master / nltk contrib [SEP]"}
{"pre": "in this work, we take advantage of similaritybased smoothing techniques # otherefr ; # refr and # otherefr. [SEP] the distributional [SEP]", "cit": "wn sense numbers encode sense frequencies )? binary features for synset ids of the hypernyms of the synset containing t and si ( [SEP]"}
{"pre": "in smt, the smt model was used to obtain the reordering of the smt workshop # refr. [SEP] the smt system [SEP]", "cit": "the n - gram - based system follows a maximum entropy approach, in which a log - linear combination of multiple models is implemented # refr, [SEP]"}
{"pre": "the taggers we use are wellknown # refr and those used by brill and resnik # otherefr. [SEP] features [SEP] assumptions [SEP]", "cit": "word - sense disambiguation \\ [ # refr, brown et ai., 1991b, church and gale, 1991 \\ ].. [SEP]"}
{"pre": "in addition, the distance between the reordering and the distance between different language pairs, we use the cosine and the distance between the two language models", "cit": "specifically, we use the expected bleu objective function # otherefr ; # refr which allows us to train models that use training data and [SEP]"}
{"pre": "default unification has been investigated by many researchers # otherefr ; # refr in the context of developing lexical semantics. [SEP]. [SEP] [SEP] [SEP]", "cit": "studies of robust parsing within unification - based grammars have been explored by many researchers # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in statistical parsing literature, it is common to see parsers trained and tested on the same textual domain # otherefr ; # refra [SEP]", "cit": "this is similar to the max - rule - sum algorithm of # refr and maximum expected recall parsing # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "thus, some researchers have focused on deriving different approaches to derive knowledge sources for relation extraction from the source text # otherefr ; # [SEP] [SEP]", "cit": "early studies in cross - lingual annotation projection were accomplished for various natural language processing tasks # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "while these may be head - driven # refr, our current system uses an early version of the model which is speaking [SEP], and the discourse [SEP]", "cit": "np constituents, referred to as basenps, are automatically identified using # refr lexical dependency parser. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we will show how discourse phenomena can be used to account of an event or ', as well as resolution of the text [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "likewise, from the standpoint of interpretation, if one is to make use of aspectual information in processing successive sentences in discourse # otherefr [SEP]"}
{"pre": "we use the features of # refr. [SEP] this model : score ( i ) the candidate for each mention or pair of mentions [SEP] the [SEP]", "cit": "iii and marcu, 2005 ) grammatical features : pronoun, demonstrative noun phrase, embedded noun, gender agreement, number agreement # otheref [SEP]"}
{"pre": "in an early work, # refr used a monolingual parallel corpus to obtain paraphrases. [SEP] a source language sentence to our work is two", "cit": "paraphrase pattern generation is to automatically extract semantically equivalent patterns # otherefr ; # refr or sentences # otherefr. [SEP] [PAD] [PAD]"}
{"pre": "in english, # refr proposed a reranker using k - best parses from the propbank and, with a state - [SEP] parser [SEP]", "cit": "it has been shown to be effective for various natural language processing tasks, such as syntactic parsing # otherefr ; # refr, semantic parsing [SEP]"}
{"pre": "we use pointwise mutual information ( pmi ) # refr to weight the contexts, and select the top 1000 pmi contexts for each adj [SEP]", "cit": "some of these are mutual information # refr, distributed frequency # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used the stanford parser to extract dependency features for each sentence, as described in # refr. [SEP] the source to target word order for each [SEP]", "cit": "we used the stanford parser # refr for both languages, penn english treebank # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr describe a multi - tape approach which handles discontinuous constituents, and the korean - english. [SEP]. [SEP]. [SEP]. [SEP]. [SEP] a", "cit": "multi - tape two - level morphology # otherefr, the arabic broken plural phenomenon # refra ), and error detection in non - [SEP]"}
{"pre": "this model is trained on the margin infused relaxed algorithm, which has been shown to be more accurate than generative models # otherefr ; # refr", "cit": "while batch learning algorithms adapted for structured learning such as crfs # otherefr, parsing # refr and statistical machine translation # otherefr [SEP]"}
{"pre": "a generative model is discriminatively trained with the model, which has proven useful for many natural language processing # otherefr [SEP] ( ravi [SEP]", "cit": "we use multiple restarts to try to reduce search errors. # otherefr ; # refr have some similar operations without the head word distinction [SEP]"}
{"pre": "we evaluated translation quality using the bleu metric # refr. [SEP] bleu # otherefr. [SEP] the optimization criterion. [SEP] [SEP] [SEP] [SEP]", "cit": "we plan to implement lexicalized reordering in future work ; without this, the test system is 0. 53 bleu # refr point behind [SEP]"}
{"pre": "in a similar vein, # refr investigated how well - known entities, and graphs not show the fact that it is possible to obtain the [SEP] ble", "cit": "this is not a surprise ; comparisons of content - based metrics for summarization in # refr have led the authors to the conclusion that such metrics [SEP]"}
{"pre": "topic signatures ( ts ) are word vectors related to a particular topic # refr. [SEP] the topic of a topic. [SEP] the words appearing in [SEP]", "cit": "topic signatures ( ts ) are word vectors related to a particular topic # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr, he addresses the problem of determining the similarity of a language, and hebrew. [SEP] a morphological analyzer, a morphological analyzer,", "cit": "following # refr and habash and pos # tokens % tokens noun 25836 28. 92 punctuation 13793 15. 44 proper noun 72 [SEP]"}
{"pre": "senseval - 3 used this for the semeval 2007 task of preposition senseval - 3 # refr # otherefr [SEP] [SEP] [SEP]", "cit": "this task has been the subject of a previous senseval task ( automatic semantic role labeling, # refr ) and two shared tasks on semantic role [SEP]"}
{"pre": "we describe the challenges of the first timex2 # otherefr and organization names ( stroppa ) and # refr. [SEP] text [SEP]", "cit": "the linguistic modules in the current demonstration system include tokenization, sentence segmentation, part - of - speech tagging, named entity detection, temporal extraction [SEP]"}
{"pre": "the n - best parser uses an efficient algorithm of # refr. [SEP] the n2 space of the tree - to - string transducer. [SEP] the", "cit": "following practices used in parsing models such as # refr, beam search is performed. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the wsd system expands both the word context and the sense clusters using the wsj / constructed by # refr. [SEP] ( 1 ) [SEP] [SEP]", "cit": "the method we use to predict the first sense is that of mc - carthy et al # otherefr, which was obtained using a [SEP]"}
{"pre": "the natural language processing ( nlp ) tools that are already very quickly, such as the indexing of dependencyparsed by that documents provide [SEP] the", "cit": "recent work # otherefr ; # refr has suggested that some tasks will benefit from using significantly more data. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for instance, the majority of previous work in this area has focused on factoid the web as a separate task # otherefr ; # refr", "cit": "because of the characteristics of the web, it is necessary to develop efficient algorithms able to learn from unannotated data # otherefr [SEP]"}
{"pre": "we used the modified version of the osm model # refr trained on the europarl corpus. [SEP]. [SEP] [SEP] the approach of [SEP] [SEP] [SEP]", "cit": "we used two sets of language models, one where we first trained two models on europarl and news commentary, which we then interpolated 1 [SEP]"}
{"pre": "the model is trained with the gradient descent algorithm described in # refr. [SEP] - bfgs ( ig ) with the limited memory variable ). [SEP]", "cit": "this technique has been shown to be very effective in a variety of nlp tasks # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "most of the previous research on sentence compression focuses on deletion using syntactic information, # otherefr, # refr, cohn and lapata [SEP]", "cit": "# refr applied an adaptable paraphrasing pipeline to sentence 2taken from the main page of http : / / wsj. com [SEP]"}
{"pre": "error - tagged learner corpora are crucial for developing and evaluating error detection / correction algorithms such as those described in # otherefr ; # refr [SEP]", "cit": "learner corpora have been essential for developing error correction systems and intelligent tutoring systems ( e. g., # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for this year, the 2012 shared task was held as a new task on grammatical error correction # refr. [SEP] the [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "most of the systems in the hoo 2011 and 2012 shared tasks # otherefr ; # refr fall under this broad approach. [SEP] [PAD] [PAD]"}
{"pre": "we use a sentence segmentation program # otherefr and a multi - thread summarization framework # refr. [SEP] the thread structure of the thread [SEP]", "cit": "community question answering ( cqa ) is the task of identifying question? answer pairs in a given thread, e. g. for the purposes [SEP]"}
{"pre": "in order to find a solution using the dependency parser, we use the eisner algorithm # refr. [SEP] decision trees algorithm # otherefr.", "cit": "the best projective parse tree is obtained using the eisner algorithm # refr with the scores, and the best non - projective one is obtained using [SEP]"}
{"pre": "in fact, several other systems have been developed for part - of - speech tagging # otherefr ; # refr. [SEP] this approach is [SEP]", "cit": "the french nerc system has been implemented with the use of a rule - based inference engine # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the second parser is a chinese treebank which was trained on the berkeley parser # refr, # otherefr. [SEP] [SEP] [SEP] [SEP]ly [SEP]", "cit": "6ilk. uvt. nl / conll / software / eval. pl our finding does not contradict the main qualitative result of [SEP]"}
{"pre": "in this paper, we describe some dependency parsers that make it available to the publically mapping of predicate - argument relations # refr. [SEP] this", "cit": "the method is similar to that of # refr, who produce rmrs from detailed german dependencies. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "there have been several multimodal interfaces for understanding and processing understanding components, such as the multimodal understanding conference series # otherefr, and # refr.", "cit": "when multiple selection gestures are present an aggregation technique # otherefr is employed to overcome the problems with deictic plurals and numerals [SEP]"}
{"pre": "licence details : http : / / creativecommons. org / licenses / by / 4. 0 / mooney, 1996 ; [SEP]", "cit": "krisp was later extended to do semisupervised semantic parsing # otherefra ), and to transform the mrl grammar to improve semantic parsing [SEP]"}
{"pre": "# refr achieve this approach, with a much recent work on ordering of modifiers for modifiers by making according to the [SEP] [SEP] [SEP]", "cit": "shaw and hatzivassiloglou, 1999 ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "dependency parsing, the task of inferring a dependency structure over an input sentence, has gained a lot of research attention in the last couple of years [SEP]", "cit": "recent reports by # refr delineated a class of richly - inflected languages with relatively free word - order ( including greek, basque [SEP]"}
{"pre": "in tempeval # otherefr ; # refr, the machine learning approach is to classify relation pairs in timebanks. [SEP] [SEP] [SEP]", "cit": "after the publication of timebank # otherefra ), supervised learning techniques have been tested in the temporal relation identification task with different types of [SEP]"}
{"pre": "leveraging from structural and linguistic information from parse trees, these models are believed to be better than their phrase - based counterparts in source target examples [SEP]", "cit": "3admissible set # refr is also known as? frontier set? # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in order to train the different approaches already discussed, we have constructed a training corpus made up of two datasets : the training data provided by the [SEP]", "cit": "umelb [ cross - lingual, pivoting, compositional ] # refr adopts both pivoting and cross - lingual approaches. [SEP] [PAD]"}
{"pre": "maximum - entropy models have been used for dependency parsing # otherefr ; # refr. [SEP] this framework is simple for non - local [SEP] [SEP]", "cit": "an alternative way of doing simple voting is to let the parsers vote on membership of constituents after each parser has produced its own parse tree # [SEP]"}
{"pre": "# refr used a supervised method to predict the polarity of a word as an off of the english product. [SEP] dictionary. [SEP] dictionary to determine the", "cit": "we use opinionfinder # refra ) to identify polarized words and their polarities. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use mkcls, an unsupervised method for word class induction which has been studied by several researchers # refr. [SEP] the source [SEP] l [SEP] [SEP]", "cit": "# refr described a method for determining bilingual word classes, used to improve the extraction of alignment templates through alignments between classes, not only between words [SEP]"}
{"pre": "for example, the unsupervised dependency parsing # otherefr which is totally based on unannotated data, and the semisupervised dependency parsing [SEP]", "cit": "supervised dependency parsing achieves the stateof - the - art in recent years # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the emphasis has been on automatically learning paraphrases from corpora # otherefr ; # refr. [SEP] ( 1 ) [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "in recent work, # refr demonstrated through psycholinguistic experiments that domain experts and lay readers show significant differences in which formulations of causation they find [SEP]"}
{"pre": "iii and marcu, 2004 ; toutanova et al, 2004 ; kazama and torisawa, [SEP], [SEP], [SEP],", "cit": "iii and marcu, 2004 ; giuglea and moschitti, 2004 ; toutanova et al, 2004 ; kaz [SEP]"}
{"pre": "in addition, while the system described in # refr uses an incremental parser trained on the penn treebank to produce a set of results, [SEP] annotations", "cit": "reranking has previously been applied to semantic role labeling by # refr, from which we use several features. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, the bionlp 2009 shared task was one of the community - wide efforts to address the problem of the bionlp [SEP] event", "cit": "the recent bionlp 2009 shared task ( bionlp09st ) on event extraction # refr focused on event types of varying complexity. [SEP]"}
{"pre": "as a result, researchers have focused on the principle of irony? le nagard and ironi # otherefr ; # refr. [SEP]", "cit": "there has recently been a flurry of interesting work on automatic irony detection # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for instance, the hierarchical model of # refr extends the syntactic smt by allowing all the same parser as specified in the same manner as the re", "cit": "in this paper, we discuss a new hierarchical phrase - based statistical machine translation system # refr, presenting recent extensions to the original proposal, new [SEP]"}
{"pre": "this approach is inspired by the earlier work of # refr who describe a finite - state transducer that is trained on corpus statistics derived from a corpus.", "cit": "# refr uses multi - ~ tape two - level morphology to analyze some arabic data, butdespite the suggestive titlemust simulate prosodic [SEP]"}
{"pre": "we tuned maxent scores using bleu # otherefr, meteor # refr, and ter # otherefr. [SEP]. [SEP] [SEP] [SEP]", "cit": "phrasal includes java implementations of bleu # otherefr and meteor # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the centering approach, centering theory # refr and constructs a constraint model by centering theory # otherefr to that they are [SEP]", "cit": "the main assumptions of the theory as presented by # otherefr ( gjw ), # refr rare : [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this is useful for literature on learning from word aligned parallel corpora # otherefr ; # refr ). [SEP] it has been shown to [SEP] [SEP]", "cit": "this is useful for literature on learning from word aligned parallel corpora # otherefr ; # refr ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the proposition bank # otherefr is a technique for english, while in the penn treebank # refr is used to train [SEP] the penn [SEP]", "cit": "the penn english and chinese treebanks consist of several semantic roles ( e. g., locative, temporal ) annotated on top of [SEP]"}
{"pre": "in generation, a referent of reg is that it is difficult to assign a set of properties that can generate locally coherent output. ( for a", "cit": "previous work on reference in sentence generation, e. g., \\ [ appelt1985, dale1992, dale and [SEP]"}
{"pre": "the state - of - the - art word alignment models, e. g. # otherefr ; # refr, have achieved relative success,", "cit": "additional linguistic knowledge sources such as dependeny trees or parse trees were used in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "several studies have focused on the acquisition of hypernymy # otherefr ; # refr. [SEP] distributional methods # otherefr. [SEP] [SEP]", "cit": "in the concept extension part of our algorithm we adapt our concept acquisition framework # otherefr ; # refra ; davidov and rappop [SEP]"}
{"pre": "treebank - based constituency detection models have been developed in the last decade for dependency parsing # otherefr ; # refr, and [SEP] [SEP]", "cit": "it is well - known that constituency parsing models designed for english often do not generalize easily to other languages and treebanks. 1 explanations [SEP]"}
{"pre": "we used the mxpost tagger # refr trained on the penn treebank. [SEP] training, to assign pos tags, and we used the mx", "cit": "# refr, a single inconsistency in a test set tree will very likely yield a zero percent parse accuracy for the particular test set sentence. [SEP] [PAD]"}
{"pre": "in a vast body of related work, automated methods have been explored for the generation of descriptions of images # otherefr ; # refr. [SEP]", "cit": "we employ integer linear programming ( ilp ) as an optimization framework that has been used successfully in other generation tasks ( e. g., [SEP]"}
{"pre": "iii, 2007 ; dredze and crammer, 2008 ; # refr, and generalized to a particular domain adaptation problem. [SEP] [SEP] [SEP]", "cit": "iii and marcu, 2006 ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "recent years have witnessed increased interest on a simpler instantiation of the compression problem, namely word deletion # otherefr ; # refr. [SEP] it [SEP]", "cit": "popular approaches to text extraction essentially collapse interpretation and transformation into one step, with generation either being ignored or consisting of postprocessing techniques such as sentence [SEP]"}
{"pre": "this model is similar to the one described in # refr. [SEP] ( 1 ) =? i log1? i log2, of [SEP] [SEP]", "cit": "more recently, this task has been considered by # refr and lee et al # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "paraphrases extracted from bilingual parallel corpora have been used to estimate the distribution of query expansion # refr. [SEP] retrieval # otherefr are [SEP]", "cit": "several solutions to this problem have been proposed including query expansion # otherefr ; # refr and semantic information retrieval # otherefr. [SEP] [PAD]"}
{"pre": "several alternatives now exist : mira # otherefr and # refr among others. [SEP] the linear decision trees [SEP] ( in sm [SEP] [SEP] [SEP]", "cit": "several alternatives now exist : mira # otherefr, linear regression # refr and oro # otherefr among others. [SEP] [PAD] [PAD]"}
{"pre": "then, after tagging, chunking # refr was chosen in order to create an english semantic parser for chinese. [SEP] the word [SEP] [SEP] it [SEP]", "cit": "based on the lexicalized grammars, # refr attempts at combining parsing and word sense disambiguation in a unified model, using a subset of sem [SEP]"}
{"pre": "bootstrapping was initially proposed by riloff and jones # otherefr and jones # refr, biomedical entities # otherefr. [SEP] [SEP]", "cit": "the basilisk system developed by # refr almost paralleled our effort. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use stanford named entity recognizer # refr to identify named entities in each person, and we recognize in our named entity recognizer [SEP]. [SEP]", "cit": "inference in these models can be performed, for example, with loopy belief propagation # otherefr or gibbs sampling # refr. [SEP] [PAD] [PAD]"}
{"pre": "we use tinysvm2 along with yamcha3 # refr as the svm training and test software. [SEP] ( 1 ) of svms ) [SEP]", "cit": "in this paper, we employ tiny svm along with yamcha # refr for chinese chunking, and crf + + 2 for srl. [SEP]"}
{"pre": "instead, expressions populate a continuum between two extremes : idioms and free word combinations # otherefr ; # refr. [SEP] [SEP] [SEP] [SEP]", "cit": "besides that, there are other nlp applications that can benefit from knowing the degree of compositionality of expressions such as machine translation # otheref [SEP]"}
{"pre": "in particular, we test different variants of the classical a * algorithm # otherefr ; # refra ; pauls and klein, 2009 [SEP]", "cit": "variations on this approach drive the widelyused, broad coverage c & c parser # otherefr ; clark and # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "# refr \\ ] has argued that discourse relations can be used to model discourse structure in a discourse. [SEP] ( \\ [ # refr \\ ].", "cit": "a collection of related events and states constitutes an event / state network analogous to # refr \\ ] event / situation structure. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use brill? s tagger # refr to pos - tag the english pronoun from japanese texts. [SEP] the japanese / english pronoun [SEP] [SEP]", "cit": "and the i r antecedents the method to extract japanese zero pronouns and their english equivalents consists of the following steps 1. 1 ) analysis [SEP]"}
{"pre": "the feature weights were tuned on the development set by applying minimum error rate training ( mert ) # refr. [SEP]. [SEP] the weights of the", "cit": "we use the minimum - error rate training procedure by # refr as implemented in the moses toolkit to set the weights of the various translation and [SEP]"}
{"pre": "# refr present a model for compositionality based on vector representations. [SEP] distributional vectors for larger phrases, using compositional operations such as the cosine similarity [SEP]", "cit": "one strand attempts to model compositionality with ds methods, representing both primitive and composed linguistic expressions as distributional vectors # otherefr ; # refr [SEP]"}
{"pre": "we use the standard conditional maximum entropy taggers # otherefr ; # refr to estimate the conditional probabilities of different classes. [SEP] training [SEP] features", "cit": "the frequency counts have been obtained from 1 billion words of english newspaper text collected by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the second strategy is to use stochastic disambiguation, in parsing # otherefr ; # refr. [SEP] the likelihood of a preprocessed", "cit": "the weights of newly derived constituents are computed exactly as in a pcfg algorithm, the only difference being that the weights don? t necessarily add [SEP]"}
{"pre": "we show that for three leading unsupervised parsers # otherefr ; # refra ), a combination of ones that have been successfully applied to", "cit": "we show relative error reductions of 7. 0 % over the second - order dependency parser of mcdonald and pereira # otherefr, [SEP]"}
{"pre": "social network extraction from text has recently been gaining a considerable amount of attention # otherefr ; # refr. [SEP] the noisy text normalization system #", "cit": "in recent work, normalization has been shown to yield improvements for part - of - speech tagging # otherefr, and machine translation # refr [SEP]"}
{"pre": "in this section, we evaluate the performance of the conll shared tasks on multilingual dependency parsing, where the task on multilingual dependency parsing [SEP]", "cit": "yet, even though some of these mappings have been developed for the same conll dataset # refr, they are not identical and yield different parsing [SEP]"}
{"pre": "approaches include the use of maximum marginal relevance # otherefr, covering weighted scores of concepts # refr, formulation of coherence # otheref [SEP] [SEP]", "cit": "although coherence has been studied widely in a field of multi - document summarization # otherefr ; # refr, it has not been studied [SEP]"}
{"pre": "after numerous attempts by various researchers # otherefr ; # refr, the recent work of yu et al # otherefr finally reveals a [SEP]", "cit": "this section mostly follows # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr presented a method that can be used to identify idiomatic expressions, i. e., how likely they are to take modifiers", "cit": "for our task, we need to model a wide range of semantic relations # refr, for example, relations based on some kind of functional or [SEP]"}
{"pre": "in addition, most of these unsupervised approaches are based on distributional similarity # otherefr. # refr proposes a wsd algorithm for [SEP] [SEP] [SEP]", "cit": "we can see that the recall has increased significantly, and is now closer to the mfs baseline, which is a very hard baseline for unsupervised [SEP]"}
{"pre": "finding the optimal tree in the set of projective trees can be done efficiently # otherefr ; # refr. [SEP] the score of a tree depends", "cit": "many edges can be ruled out beforehand, either based on the distance in the sentence between the two words # otherefr, or the [SEP]"}
{"pre": "# refr use a noisy channel model, which make use of a word to solve the error model. [SEP] a word by considering a latent spell", "cit": "# refr characterise the error model by computing the product of operation probabilities on slice - by - slice string edits. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the second international chinese, # otherefr, # refr found that the semantic relations between nouns are useful in an analysis of semeval", "cit": "# refr propose a two - level hierarchy with 5 classes at the upper level and 30 at the lower level. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "bek 1958 ), non - associative lambek calculus # otherefr, and # refr ). [SEP]'approach wsj [SEP] [SEP] [SEP]", "cit": "d # otherefra ; moortgat and # refr \\ ] : 4 a : : t, c / rib hf - a. [SEP]"}
{"pre": "methods for topic segmenation emply semantic, lexical and referential similarity or, more recently, language models # otherefr ; # [SEP]", "cit": "methods for topic segmenation emply semantic, lexical and referential similarity or, more recently, language models # otherefr ; # [SEP]"}
{"pre": "in # refr, we proposed a reordering model that uses part - of - speech tags to add reorderings to make them highly consistent with", "cit": "# refr also use lattices to encode different alternative reorderings of the source sentence which results in an improvement of 2. 0 % bleu [SEP]"}
{"pre": "in particular, we compare with four most recent state of the art answer sentence reranker # otherefr ; li and # refr, a", "cit": "our question taxonomy is derived from the uiuic dataset ( li and # refr which defines 6 coarse and 50 fine grain classes. [SEP] [PAD] [PAD]"}
{"pre": "we will show in the next section that our choice of the pltag language model can be applied to any syntactic analysis ; we consider also [SEP] it", "cit": "finally, the syntactic model underlying # otherefr, which due to its parsing strategy fails to predict human processing difficulty that arises in certain cases [SEP]"}
{"pre": "the corresponding mapping between pos categories and the tokens of each other is then converted to a category as input spaces and the pos tag that are labeled with", "cit": "in this setup, finding the mapping between various pos annotation schemes was not essential ; instead, the transfer algorithm could induce it directly from the parallel [SEP]"}
{"pre": "# refr use svms to determine the degree of noisy words. [SEP] well - formed and word usages ; they propose a classifier called noisy [SEP]", "cit": "more insight could be obtained by performing experiments with advanced methods of tweet normalization, such as those of # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we borrow ideas from the inside - outside algorithm # refr, and compare it with the traditional left - to - right order. [SEP] decoding [SEP] it", "cit": "lr - decoding algorithms exist for phrasebased # otherefr ; # refr models and also for hierarchical phrasebased models # otherefr, [SEP]"}
{"pre": "to evaluate the correct sentence alignment we use the semeval - 2007 dataset # refr. [SEP] the procedure of starting with the sense [SEP] [SEP] sentences", "cit": "following the traditional bag - of - words approach that has been applied in related tasks # refr, we consider the 2, 000 most frequent context [SEP]"}
{"pre": "domain event extraction has been popularized in particular by the bionlp shared task # otherefr # refr. [SEP] event extraction [SEP] [SEP] [SEP]", "cit": "with recent progress in biomedical natural language processing ( bionlp ), automatic extraction of biomedical events from texts becomes practical and the extracted events have [SEP]"}
{"pre": "in particular, we have developed a system which uses natural language generation ( nlg ) for which uses a natural language generation system [SEP] text [SEP] [SEP]", "cit": "our firs / prototype for corect will be based on the tool for authoring knowledge bases which was developed as part of the idas [SEP]"}
{"pre": "to address this, we propose an application of topic - oriented c from the document - oriented c & c # refr to reordering of [SEP] sentences", "cit": "light verbs such as? take?,? give?, etc. # refr are removed. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "it has been widely used in compressive summarization # otherefr ; # refr. [SEP] ( 1 ) sum ) [SEP] ( [SEP] ) [SEP] [SEP]", "cit": "in this paper, our choice of? is the same as # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "while several machine learning approaches have been proposed for coreference resolution # otherefr ; ng and # refr ; ng, 2011 ; ng, inter", "cit": "the link classifier is a decision tree and the clustering algorithm a variant of best - first clustering ( ng and # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "finite - state models of arabic # refr have been in the context of finite - state methods for morphology. [SEP] it, finite - state methods,", "cit": "the paper assumes knowledge of multi - tape two - level morphology # otherefr ; # refrc ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "joint inference has been applied successfully 10percentages for? unknown? are omitted here. to other nlp problems # otherefr ; # [SEP]", "cit": "connectivity our ilp formulation for enforcing connectivity is a minor variation of the one suggested by # refr for dependency parsing. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr. [SEP] a word sense disambiguation system, e. g., the mpqa ( part of speech ) [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "see # refr for an overview of the problem. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "there have been various attempts to use a crfs for a variety of tasks, including part - of - speech tagging # otherefr, [SEP]", "cit": "this model is similar to the logarithmic opinion pool ( lop ) crf suggested by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "bayesian inference methods have become popular in natural language processing # otherefr ; # refr. [SEP] this problem to our approach. [SEP] this [SEP] [SEP]", "cit": "# refr use the expectation maximization # otherefr to search for the best probabilistic key using letter n - gram models. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use stratified shuffling test # refr to determine the statistical significance of the results. [SEP] ( r. [SEP] ) [SEP] ( p ( [SEP] )", "cit": "statistical significance is tested using randomised estimation # refr with p < 0. 05. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the berkeley parser # refr for both parsing and cfg parsing, although the authors have achieved speed of a pcfg model, [SEP] [SEP]", "cit": "their system uses a grammar based on the berkeley parser # refr ( which is particularly amenable to gpu processing ),? compiling? the grammar [SEP]"}
{"pre": "recent work has shown that eye gaze in facilitating spoken language processing varies among different aspects # otherefr, spoken language understanding # refr, spoken dialogue", "cit": "recent work has explored incorporating eye gaze into automated language understanding such as automated speech recognition ( qu and # refr, automated vocabulary acquisition # otheref [SEP]"}
{"pre": "joint methods have also been proposed that invoke integer linear programming ( ilp ) formulations to find the best or joint inference problem that are usually applied to", "cit": "dual decomposition # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the very timely, the acquisition of paraphrase patterns has been actively studied in recent years : manual collection of paraphrases in the context of", "cit": "most of the modification methodologies have been focused on simplifying the original texts and decreasing their complexity # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the stanford dependency parser ( de marneffe and # refr to provide a sentence description of the penn treebanks. [SEP] natural language", "cit": "specifically, we use labeled dependency trees following the? basic? variant of the stanforddependencies scheme ( de marneffe and # refrb [SEP]"}
{"pre": "in a first step, it was to use the natural language toolkit ( nltk, # refr. [SEP] ( 5 ) to denote as [SEP] [SEP]", "cit": "first we discuss aspects of the design of the toolkit that 1 # otherefr ; # refr arose from our need to teach computational linguistics to [SEP]"}
{"pre": "in this work, we leverage the sentiment analysis methodology to make use of the reviews domain adaptation task # refr. [SEP] 1 in order to classify reviews", "cit": "proach to create rating information for raw review texts as in # refr, so that we can create mappings from reviews without ratings. [SEP] [PAD] [PAD]"}
{"pre": "the most common approach is to use a log - linear framework in # refr. [SEP] the problem of learning translation pairs. [SEP] the [SEP] the [SEP]", "cit": "various definitions for the context have been used : distance - based context ( e. g. in a sentence # refr, in a paragraph # [SEP]"}
{"pre": "# refr classify noun compounds using the mesh hierarchy, with the mesh hierarchy, defined by # otherefr. [SEP] ( v ) =? [SEP]", "cit": "# refr reported 90 % accuracy with a? descent of hierarchy? approach which characterizes the relationship between the nouns in a bioscience noun - noun compound [SEP]"}
{"pre": "in combination with appropriate confidence estimation, a hybrid strategy has been well studied and studied in the multi - word alignment problem of multi - word alignment #", "cit": "besides continued research on improving mt techniques, one line of research is dedicated to better exploitation of existing methods for the combination of their respective advantages # [SEP]"}
{"pre": "the feature weights? i are trained using the lattice - based minimum error rate training procedure described in # refr. [SEP] - rate training # otheref", "cit": "we are currently in the process of implementing and testing other parameter tuning methods ( in addition to manual tuning and pro ), specifically lattice - based [SEP]"}
{"pre": "we used the mxpost tagger # refr trained on the wall street journal corpus ( wsj ) partof - speech ( pos ) tagged and", "cit": "the part of speech tags for the development and test data were automatically assigned by mxpost # refr, where the tagger was trained on the [SEP]"}
{"pre": "yarowsky # refr used heuristics to train an unsupervised bootstrapping algorithm for word sense disambiguation. [SEP] the results in a self - training process", "cit": "1. for iteration = 0... n do 2. pool 1000 examples from unlabeled data ; 3. annotate all 1000 examples with [SEP]"}
{"pre": "we use the publicly available coreference resolution tool suite # refr to link and syntactic errors. [SEP] errors. [SEP] the method of building a machine [SEP]", "cit": "# refr present an algorithm that transforms a predicted coreference clustering into a gold clustering and records the necessary transformations, thereby quantifying different types of errors [SEP]"}
{"pre": "# refr used a rule - based dependency parser to generate the seed set of sentences annotated with negation. [SEP] sentiment expressions based on the original wordnet", "cit": "slanting of texts can be achieved in a number of ways, the most popular of which is the lexical substitution of semantically related words with [SEP]"}
{"pre": "one way to do this is to use crowdsourcing, which has been used to process noisy annotations # otherefr ; # refr. [SEP]", "cit": "a sizable body of work exists on using noisy labeling obtained from low - cost annotation services such as amazon? s mechanical turk # other [SEP]"}
{"pre": "in recent years, a number of systems have been proposed to address these issues by only considering only a single model to include i. e. [SEP]", "cit": "previous research # otherefr ; # refr has identified many useful features for local identification and classification. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use a pos tagger # refr designed specifically for tweets. [SEP] the pos tagger of tweets. [SEP] 1 in tweets. [SEP] [SEP] [SEP]", "cit": "for the features that rely on part - of - speech ( pos ) tags, we used the english twitter pos tagger by # refr and [SEP]"}
{"pre": "another related area is clause grammar # otherefr ; # refr. [SEP] the whole derivation of a sentence while retaining most of the important [SEP] [SEP]", "cit": "support for any style of synchronous context free grammar ( scfg ) including syntax augment machine translation ( samt ) grammars # refr. [SEP] [PAD] [PAD]"}
{"pre": "we follow a long line of research in improving the efficiency of smt models, which are very few years, has been shown to be a lot", "cit": "f - measure is an important metric because it has been shown to be correlated with bleu scores # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr use syntactic dependencies to predict the meaning of words by vectors for the words in context of a sentence. [SEP] a word as a mixture of", "cit": "# refr, thater et al # otherefr lexical substitution task dataset. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper, we show that a method for extractive summarization relying on sentence compression # refr, a graph - based approach that falls [SEP]", "cit": "automatic text summarization approaches have offered reasonably well - performing approximations for identifiying important sentences # otherefr ; # refr ; daume [SEP]"}
{"pre": "sentence compression has been considered before in contexts outside of summarization, such as headline, title, and subtitle generation # otheref [SEP]", "cit": "extraction there is a growing amount of work on automatic extraction of paraphrases from text corpora # otherefr ; # refr. [SEP] [PAD] [PAD]"}
{"pre": "we use the open - source toolkit jane # refr. [SEP] the srilm toolkit # otherefr to train the lm and test data. [SEP]", "cit": "2. 7. 1 5 - gram lm lattice rescoring we build a sentence - specific, zero - cutoff stupidbackoff # refr [SEP]"}
{"pre": "while the lack of a large monolingual corpus, they contain many words and phrases that are compatible with the fact that contain phrases that are [SEP] coverage", "cit": "models that employ syntax or syntaxlike representations # otherefr ; # refr handle long - distance reordering better than phrase - based systems # [SEP]"}
{"pre": "while ner over formal text such as news articles and webpages is a well - studied problem # otherefr, there has been recent [SEP]", "cit": "the concept of ner originated in the 1990s in the course of the message understanding conferences # refr, and since then there has been a steady [SEP]"}
{"pre": "while protein modifications have been considered in numerous ie studies in the domain # otherefr follow - up event # refr, event extraction efforts have brought", "cit": "the results of these tasks were promising, suggesting that the single ptm type could be extracted at over 80 % f - score # otheref [SEP]"}
{"pre": "# refr describe a machine learning approach for identifying part - of - speech tags and context - free grammars. [SEP] ( gen ) [SEP] ( recognition )", "cit": "variations of this approach are used in the context of several nlp problems, including pos tagging ( schu? tze and # refr, [SEP]"}
{"pre": "many alternative methods have been proposed based on the algorithms in machine learning, such as averaged perceptron # otherefr ; # refrb ) [SEP]", "cit": "mert has been successfully used in practical applications, although, it is known to be unstable # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the two most common knowledge sources are : the framenet project # otherefr and framenet # refr. [SEP] annotations ( 1 ) [SEP] [SEP]", "cit": "uby is an integration of multiple resources, such as wordnets, wikipedia, wiktionary ( wkt ), framenet ( fn [SEP]"}
{"pre": "in biomedical text, sentences are parsed using charniak? s parser # refr and mcclosky # otherefr. [SEP]? [SEP]", "cit": "we used the charniak - johnson parser # refr with david mcclosky? s biomodel # otherefr trained on the gen [SEP]"}
{"pre": "in this section, we describe the phrase - based statistical machine translation approach, where a continuous alignment model is applied and lexicalized local in the source", "cit": "this approach is not dependent on the underlying translation model, and similar methods could certainly be devised based on more elaborate models, such as ibm models [SEP]"}
{"pre": "we trained a 5 - gram language model using the sri language modeling toolkit # otherefr from the english monolingual training data and the english monol", "cit": "conventional smoothing techniques, such as kneser - ney and witten - bell back - off schemes ( see # refr for an empirical overview [SEP]"}
{"pre": "# refr use latent alignment models to predict morphemes to capture non - inflectional phrases. [SEP] a finite set of meaning [SEP] words [SEP] it", "cit": "# refr perform supervised lemmatization on basque, english, irish and tagalog ; like us they include results when the set of lemmas is [SEP]"}
{"pre": "this aspect of the bild project was revisited by # refr. [SEP]a ). [SEP] the processing of text we need to record the [SEP] [SEP] [SEP]", "cit": "geolocation : # refr first looked at the problem of using latent variables to explain the distribution of text in tweets. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used an early update version of averaged perceptron algorithm # refr for training of shift - reduce and top - down parsers. [SEP] the [SEP]", "cit": "it is used for word segmentation # otherefr, syntactical parsing # refr, semantical parsing # otherefr and other nlp [SEP]"}
{"pre": "previous approaches to the srl task have made use of a full syntactic parse of the sentence in order to define argument boundaries and to determine the [SEP]", "cit": "experiments performed combining the best and second output of the joint parser and enforcing domain constraints via ilp # refr showed no significant improvements. [SEP] [PAD]"}
{"pre": "wsd ( ds ) is the fundamental component of a wsd system # refr and has been widely used in wsd and natural language processing (", "cit": "# refr performed supervised domain adaptation on a manually selected subset of 21 nouns from the dso corpus. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "sw made most of her contribution while at nyu. is relevant to finite - state phrase - based models that use no parse trees # other [SEP]", "cit": "# refr found that their alignment method, which did not use external syntactic constraints, outperformed the model of yamada and knight # other [SEP]"}
{"pre": "we automatically extracted coreference patterns from the training data # otherefr ; # refr. [SEP] the documents we use swirl [SEP] [SEP] [SEP]", "cit": "iii and marcu, 2005 ) or structured knowledge bases such as wikipedia # refr and yago # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in \\ [ # refr \\ ] a system which uses a natural anguage component, is built \\ [ pollard \\ ], in \\ [", "cit": "guided composition is done by partial synthesis of sentences, a principle discussed in \\ [ sabatier 1989 \\ ], \\ [ # refr \\ [SEP]"}
{"pre": "this approach has been shown to be beneficial for a variety of natural language processing # otherefr ; # refr. [SEP] this approach is [SEP] [SEP]", "cit": "in another research, # refr studied the problem of extracting technical paraphrases from a parallel software corpus. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition to the translation model, eleven feature - based reordering model has been shown to be significantly effective in various language modeling tasks including syntactic re", "cit": "in addition, we generalize lattice decoding algorithmically, extending it for the first time to hierarchical phrase - based translation # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "much of the work in sentiment analysis has been well studied and studied in the literature # otherefr, # refr ) and [SEP] [SEP] [SEP] [SEP]", "cit": "we use linear svms, which have been shown to be effective text classifiers # refr, and set the svm parameters to match those used in [SEP]"}
{"pre": "active learning # otherefr ; # refr ). [SEP] the nlp techniques over the last several years, here, [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "active learning # otherefr ; # refr ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "to investigate this, # refr modified the reranker of the charniak parser, the self - training algorithm used in the context of pos", "cit": "here, we note that the 89. 1 % wsd accuracy we obtained is comparable to state - of - the - art syntactic parsing accuracies [SEP]"}
{"pre": "almost all of the smt models, not only phrase - based # otherefr ; # refr, derive translation knowledge from large amount bilingual training", "cit": "almost all of the smt models, not only phrase - based # otherefr, but also syntax - based # refr, derive translation [SEP]"}
{"pre": "we used the minimum bayes risk rescoring lattices # refr. [SEP] bleu score # otherefr to tune the decoder for the best system.", "cit": "minimum bayes - risk ( mbr ) mbr decoding # refr aims to minimize the expected loss of translation errors. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr, malouf # otherefr. [SEP] this problem is the first to use syntactic features in the text of the text written by", "cit": "more recently, attention has been paid to native language identification # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use a nonparametric generative model based on the 2 - parameter pitman - yor process # otherefr and # refr. [SEP] [SEP] [SEP]", "cit": "thus, many researchers have switched to the hmm model # refr and variants with more parameters # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, the model selection problem for tag is significantly more complicated than for tsg since one must reason about many more combinatorial options with two [SEP]", "cit": "recent work that incorporated dirichlet process ( dp ) nonparametric models into tsgs has provided an efficient solution to the problem of segmenting training data trees [SEP]"}
{"pre": "# refr and suzuki et al. # otherefr have applied self - training to parsers trained on the wsj section of the penn tree", "cit": "more recently, # refr improved the performance of the c & c parser on a domainadaptation task ( adaptation to wikipedia text ) using self [SEP]"}
{"pre": "we use the open source toolkit jane # refr. [SEP] the training framework of phrase table including the hierarchical translation model. [SEP] [SEP] the [SEP] [SEP] [SEP]", "cit": "one motivation for such representations is to capture word semantics ( tur # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the feature weights?? m are trained discriminatively in concert with the language model weight to maximize the bleu score # otherefr, minimum", "cit": "a related mbr - inspired approach for hypergraphs was developed by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "abstractive summarization, on the other hand, is proposed in # refr, and is study the potential of multi - document summarization # [SEP]", "cit": "for future work, it is necessary to extend our method to involve paraphrasing for extracted key sentences to reduce the gap between automatically generated summaries [SEP]"}
{"pre": "the vital / okay distinction has been identified as a binary classification task # refr. [SEP] filtering the extracted from the extracted sentences in a window [SEP]", "cit": "the vital / okay distinction has been identified as a weakness in the trec nugget - based evaluation methodology # refr. [SEP] [PAD] [PAD]"}
{"pre": "in recent years, several dialogue systems have been developed # otherefr ; # refr. [SEP] this approach is to use grammars [SEP] [SEP] [SEP] [SEP]", "cit": "an approach taken in both dialogue systems and dictation applications is to write a grammar for the particular domain and generate an artificial corpus from the grammar [SEP]"}
{"pre": "in the tradition of stochastic taggers, the probabilistic tree adjoining grammars # otherefr, # refr, and the probabilistic tree - adj", "cit": "most instantiations of this idea estimate the probability of a parse by assigning application probabilities to context free rewrite roles # otherefr, or by [SEP]"}
{"pre": "in works such as # otherefr ; # refr, reordering decisions are done? deterministically?, thus placing these decisions outside the [SEP]", "cit": "syntactic reordering approaches are an effective method for handling systematic differences in word order between source and target languages within the context of statistical machine translation # [SEP]"}
{"pre": "in # refr, the authors show that the diversity of a document can be effectively extracted from tweets, and we apply the dependency path based features [SEP]", "cit": "recent works tried to model the sentiment in tweets # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the semeval - 2007 task 4 the classification dataset consists of all relations ( gi # refr. [SEP] the relation [SEP] the relation [SEP] subjectivity", "cit": "a notable exception is semeval - 2007 task 4 classification of semantic relations between nominals ( gi # refr, the first to offer a [SEP]"}
{"pre": "as trees are used in many nlp applications, such as relation extraction # otherefr, semantic role labeling # refr, srl # other", "cit": "# refr presented a hybrid tree kernel which combines a constituent and a path kernel. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we then perform the phrase tables using the method described in # refr. [SEP] a method of och, with an additional smoothing technique in [SEP]. [SEP]", "cit": "we use a version from # refr, modified from # otherefr, which is an average of pairwise word translation probabilities. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "we use the dependency parser of # refrb ) and the turkish tagger # otherefr. [SEP] the dependency grammar and the [SEP] [SEP] [SEP]", "cit": "comparing to pf - ccg # refr, there is different in that their pf - ccg dependency markers are fixed to the direction of sla [SEP]"}
{"pre": "in fact, many unsupervised pos taggers have been proposed recently, including part - of - speech ( pos ) tagging # refr, dependency parsing [SEP]", "cit": "the selected sentences were pre - processed using cross - lingual taggers # refr and parsers # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr use morphological information on the comma tagger to recognize the commas and train a trigram model using the suffix array extraction tool [SEP]", "cit": "# refr explore restoring commas to the wall street journal ( wsj ) section of the penn treebank ( ptb ). [SEP] [PAD] [PAD]"}
{"pre": "# refr used a semi - supervised method to find the optimal polarity of a seed lexicon and a large amount of dictionary. [SEP] research focused on the", "cit": "there are a number of previous work that focus on building polarity lexicons # otherefr, # refr, rao and ravichandran [SEP]"}
{"pre": "in addition, the reg algorithm was part of the tuna - reg # refr, where it contains multiple realizations of the original speaker [SEP] ( [SEP]", "cit": "that size of the training set may have an impact on the performance of a reg algorithm was already suggested by # refr, who used the english [SEP]"}
{"pre": "those systems with the f1 measures # otherefr, # refr and lapponi et al. # otherefr all use [SEP] [SEP]", "cit": "the reason why sys is not identical with tp + fp is that partial matches are 1note that the cue classifier applied in the current paper is [SEP]"}
{"pre": "thesaurus extraction # refr is used to extract and lexical semantic relations that correspond to the dependency relations allowed for thesaurus extraction. [SEP] [SEP]", "cit": "our previous work # refr has evaluated thesaurus extraction performance and efficiency using several different context models. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the stanford nlp framework # refr to process the entire inference. [SEP] it has been shown to be effective in nlp [SEP] tasks [SEP]", "cit": "we compare our crf model integrated with ve with two state - of - the - art models, i. e., constraintdriven learning # [SEP]"}
{"pre": "among the machine learning algorithms studied, rule based systems have proven effective on many natural language processing tasks, including part - of - speech tagging # [SEP]", "cit": "nb - count and svm - normf for perspective classification ; # refr consider most and yu et al # otherefr all of the above [SEP]"}
{"pre": "# refr defines a head - corner parser which extends the constraint of grammars to be efficient chart parsing. [SEP] the chart - based on the eisner", "cit": "in # refr i define a head - driven parser # otherefr ) for a class of constraint - based grammars in which the construction of [SEP]"}
{"pre": "statistical translation methods can be divided into word - based # otherefr ; # refr. [SEP] the source reordering step consists of [SEP], [SEP]", "cit": "in this framework, the source language, let? s say english, is assumed to be generated by a noisy probabilistic source. 1 most of [SEP]"}
{"pre": "we used the reordering model as a step of the translation process which are central to many potentially reordering models have been proposed. # refr [SEP]", "cit": "we followed the approach of # refr by training language models from each sub - corpus separately and then linearly interpolated them using srilm with weights optimized [SEP]"}
{"pre": "to evaluate our approach, we use the data from the berkeley framenet # refr. [SEP] english ( word ) to [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "these typically map words onto senses in ontologies such as word - net, verbnet # otherefr and framenet # refr. [SEP] [PAD] [PAD]"}
{"pre": "in a similar vein, # refr use statistical data and machine learning techniques to predict the unit of language - independent features. [SEP] linguistic properties [SEP] [SEP]", "cit": "in recent years, visual analytics systems have increasingly been used for the investigation of linguistic phenomena in a number of different areas, starting from literary analysis [SEP]"}
{"pre": "bender and ney, 2003 ; florian et al, 2003 ; mccallum and li, 2003 ; # refr and hybrid solutions [SEP]", "cit": "# refr and hybrid solutions # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition to the regular distance distortion model, we incorporate a new reordering model, as well as a permutation automaton # refr. [SEP] a [SEP]", "cit": "these methods also try to leverage syntax, typically by applying hand - coded or automatically induced reordering rules to a constituency or dependency parse of [SEP]"}
{"pre": "we formalize the problem as a factored translation model # refr, integrating both surface and lexical information into the translation process as described in # other", "cit": "it can be therefore seen as a novel method to add morphological information to smt, as factored translation models do # refr. [SEP] [PAD] [PAD]"}
{"pre": "these include hierarchical models # otherefr ; # refr. [SEP] the source reordering of a source sentence to order translation. [SEP] the source sentence", "cit": "phrase based systems # otherefr rely on a lexicalized distortion model ( al - onaizan and # refr and the target language [SEP]"}
{"pre": "we take a fresh look on this problem and turn our focus to one particular class of hebrew, a finite - state transducer, char [SEP]", "cit": "this analyzer setting is similar to that of # otherefr, and models using it are denoted nohsp, parser and grammar we used bit [SEP]"}
{"pre": "in # refr, a phrase - based translation system is used to translate the english sentence from the one of the following models :. [SEP] ( [SEP]", "cit": "for our first example of a translation logic we consider a simple case : monotone decoding # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use a log - linear model # refr for the translation model. [SEP] bleu score. [SEP] the likelihood of the translation hypotheses [SEP] [SEP] [SEP]", "cit": "however, the field is moving fast, and a number of steps help to improve upon the provided baseline setup, e. g., larger [SEP]"}
{"pre": "reranking approaches have given improvements in accuracy on a number of nlp problems including parsing # otherefr ; # refr, and machine translation", "cit": "optimization problems of this form are by now widely known in nlp # refr, and have recently been used for machine translation as well # other [SEP]"}
{"pre": "rapp? s approach was based on the simple and elegant assumption that if words af and bf have a higher than chance cooccurrence frequency in [SEP]", "cit": "rapp? s approach was based on the simple and elegant assumption that if words af and bf have a higher than chance co - occurrence frequency [SEP]"}
{"pre": "we adopt the methodology used by # refr to automatically generate a training set of new word patterns from the corpus. [SEP] the corpus. [SEP] the [SEP]", "cit": "# refr introduced the task of novel sense identification. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "co - occurrence information between eighboring words and words in the same sentence has been used in phrase extraction # otherefr ; # refr [SEP]", "cit": "co - occurrence information between eighboring words and words in the same sentence has been used in phrase extraction # otherefr ; # refr [SEP]"}
{"pre": "in the latter, the latter is currently dominating in ner amongst which the most popular methods are decision tree # otherefr, and support vector machines", "cit": "the latter is currently dominating in ner amongst which the most popular methods are decision tree # otherefr, maximum entropy # refr, and support [SEP]"}
{"pre": "dependency trees are converted to dependency trees by following # refr. [SEP] the word order of the tokens is reduced to a word order of pos tag [SEP]", "cit": "we used the same rules for conversion and created the same data split as # refr : files 1 - 270 and 400 - 931 as training [SEP]"}
{"pre": "in addition to the averaged perceptron model with beam - search # refr as an extension to direct translation model. [SEP]ing the [SEP]ing of the", "cit": "to this end, recent advances in tackling complex search tasks for text generation offer some solutions # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the second model is a probabilistic context free grammar ( pcfg ) # refr. [SEP] ( 2 ) for example, whose constituent is [SEP] [SEP] [SEP]", "cit": "# refr? s constituent context model ( ccm ) obtains 51. 2 % f - score on atis part - of - speech strings. [SEP]"}
{"pre": "in a related sense disambiguation system # otherefr experiments ( wsd ) integrated the disambiguation algorithm had been found to be the disambiguated", "cit": "this was, for instance, one of the reasons for the somewhat disappointing results obtained by # refr when the output of a wsd [SEP]"}
{"pre": "for part - of - speech tagging, the accuracy of the 97. 33 adaboost is 97. 33 # otherefr 97. 15", "cit": "supervised learning approaches have advanced the state of the art on a variety of tasks in natural language processing, often resulting in systems approaching the level of [SEP]"}
{"pre": "we use the same as # refr. [SEP] ( 1 ) alignmentgizableu the probability p ( e. g. [SEP] [SEP] [SEP] [SEP]", "cit": "previously # refr also presented a symmetric method for training alignment parameters. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used the bleu score # refr to evaluate the quality of the translation output. [SEP] the brevity penalty # otherefr. [SEP] the", "cit": "among all the automatic mt evaluation metrics, bleu # refr is the most widely used. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in particular, we analyze the wikipedia data by using the taxonomy of the wiktionary patterns from the wiki qa system # otherefr ;", "cit": "by gathering large amounts of topically relevant text and by employing semantic role labeling ( srl ) as a means for fact extraction and representation # [SEP]"}
{"pre": "in previous work, we presented a conditional model that has been used to parse the sentence # refr. [SEP] lnln structural patterns of the [SEP] [SEP]", "cit": "because of these kinds of results, the vast majority of statistical parsing work has focused on parsing as a supervised learning problem # refr. [SEP] [PAD] [PAD]"}
{"pre": "we use the de? enron algorithm # refr to train the phrase - based model. [SEP] the maxent reordering model of och et al", "cit": "the emergence of phrase - based statistical machine translation ( psmt ) # refra ) has been one of the major developments in statistical approaches to [SEP]"}
{"pre": "in this paper we present a novel approach that combines the strengths of multiple languages ( bruce and # refr. [SEP] similarity - [SEP] ( wsd )", "cit": "wsd is fundamental to natural language understanding and is a useful intermediate step for many other language processing tasks # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the probabilities are estimated by the frequency of concepts in semcor # refr, a sense - tagged subset of the brown corpus. [SEP] [SEP] [SEP] [SEP]", "cit": "vided by machine readable dictionaries # otherefr, # refr, # otherefr ; [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "several projects have investigated unsupervised # otherefr ; # refr and semi - supervised # otherefr approaches. [SEP] training ig [SEP] [SEP] [SEP] [SEP]", "cit": "consequently, it is important that the production rules in the mrg mirror the structure of natural language # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, we plan to use crowdsourcing to obtain the polarity of subjectivity and object has recently received much attention # otherefr ;", "cit": "closer to our work is the large body of work on the automatic, context - independent classification of words according to their polarity, i. e [SEP]"}
{"pre": "in addition, by doing so we provide a solid foundation for named entity recognition, tagger # refr, a state - of - the - art", "cit": "we use supersensetagger # refr7 as our ner tagger. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper, we use the penn treebank # refr. [SEP] this scheme to annotate the trees of the penn treebank # otheref", "cit": "the propbank superimposes an annotation of semantic predicate - argument structures on top of the penn treebank # otherefr ; # refr. [SEP]"}
{"pre": "in the case of the c & c parser, the * algorithm # refr, is trained with a * parsing time, and [SEP] (? [SEP]", "cit": "because our algorithm is very similar to ka?, which is in turn an extension of the ( 1 - best ) a? parsing algorithm of [SEP]"}
{"pre": "collocation extraction methods have been used not only for english, but for many other languages : french # refr, german # otherefr, [SEP]", "cit": "the various extraction measures have been discussed in great detail in the literature # otherefr ; # refr, and the methods have been combined to [SEP]"}
{"pre": "in particular, we show that the product - of - grammars, trained on the english data, and show that their products of the discriminative estimation improves", "cit": "our model leverages multiple automatically learned latent variable grammars, which differ only in the seed of the random number generator used to initialize the em learning [SEP]"}
{"pre": "finally, our work is similar in spirit to sentiment analysis # otherefr, and semantic parsing by images and nugues # refr, and", "cit": "for example, there has been work on learning to execute instructions # otherefr ; # refr, provide sports commentary # otherefr, [SEP]"}
{"pre": "the most popular algorithm for this weight vector is the line - search based on a complete probabilistic framework of multi - scale data [SEP] lexical cohesion # other", "cit": "lexical cohesion has provided the inspiration for several successful systems # otherefr ; # refr, and is currently the dominant approach to unsupervised topic segmentation [SEP]"}
{"pre": "in addition, supertagging is a common problem for automatically building lexicalized parsers # otherefr ; # refr. [SEP] the [SEP] [SEP]", "cit": "a recent theme in parsing research has been the application of statistical methods to linguistically motivated grammars, for example lfg # otherefr ; [SEP]"}
{"pre": "in addition, the textual entailment task # otherefr and # refr. [SEP] textual entailment # otherefr improves the [SEP] [SEP] [SEP]", "cit": "thus the cross - lingual textual entailment task ( clte ) was created using textual entailment ( te ) to define cross - lingu [SEP]"}
{"pre": "megyesi # refr and kuba # otherefr were used for document tagging. [SEP] the word sense disambiguation ; [SEP] [SEP] [SEP] [SEP]", "cit": "the telri corpus # refr was the first corpus that was used for testing different pos tagging methods. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr uses confusion networks to compute the probability of a noisy channel model, and # otherefr use the noisy channel model, [SEP] [SEP] [SEP]", "cit": "the second is a slightly modified version of the spelling correction model of # refr. 3 this model allows many - to - many edit [SEP]"}
{"pre": "the only joint inference framework that has been applied to srl is the first token order in # refr, # otherefr. [SEP] this [SEP]", "cit": "previous research has shown the benefit of jointly learning semantic roles of multiple constituents # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for example, the biographical patterns will be 2http : / / www. cs. cs. ualberta. ca / [SEP]", "cit": "the method we apply to the extraction of modifier? part pairs when they co - occur with the target concept in a large window is [SEP]"}
{"pre": "we will show in the next section that our reordering can be applied to our task, we use the minimum bayes - risk ( mbr )", "cit": "to combine these systems, we first use the minimum bayes - risk ( mbr ) # refr decoder to obtain the 5 best hypothesis as the [SEP]"}
{"pre": "2. 2. 2 extraction patterns for both syntactic parsing, we use the method of # refr, as our varied subcategorization f1 measure", "cit": "# refr ; see figure 65. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the third column reports on the method of disambiguating whether the subject of a sentence is grammatical or not in the context of a sentence, previous phrase", "cit": "we have implemented this method on an english - to - japanese machine translation system called shalt2 # refr, and conducted experiments to evaluate the [SEP]"}
{"pre": "# refr proposed a method that is based on a word alignment between pairs of bilingual phrases. [SEP] ( not necessarily helping fixingly viewed as an extension", "cit": "figure 1 : an example of typical korean - english alignment. machine translation # otherefr and bilingnal lexicography # refr. [SEP] [PAD]"}
{"pre": "in this work, we compare the performance of a bag - of - words model, which has been shown to deliver state - of - the -", "cit": "the sentiment detection task was modeled after a well - known document analysis setup for sentiment classification, introduced by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr has argued that this is a very unordered of anaphoric i. e., which ellipsis resolution assuming that a referential role", "cit": "syntactic accounts # otherefr ; # refr claim this material is retrieved from semantic representations. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the charniak parsing model was trained on the penn treebank, and tested on the most probable parse treebank, using a max - [SEP]", "cit": "the collins parser # refr does use dynamic programming in its search. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we also plan to incorporate paraphrase probabilities into a single token representation by using multiple source language, such as the target language, and [SEP] [SEP]", "cit": "researchers have used stemming # otherefr, or direct clustering ( talbot and # refr to identify such groups of words and use them as [SEP]"}
{"pre": "work in automated ontology construction has created lexical hierarchies # otherefr ; # refr, and learned semantic relations such as meronymy # other [SEP]", "cit": "work in automated ontology construction has created lexical hierarchies # refr, and learned semantic relations such as meronymy # otherefr. [SEP] [PAD] [PAD]"}
{"pre": "this type of reasoning has led to significant attention recently # otherefr ; # refr. [SEP] the automatic detection of the discourse relations, [SEP] [SEP]", "cit": "subsequently, prasad et al # otherefrb ) used callison - burch? s technique for identifying syntax - constrained paraphrases [SEP]"}
{"pre": "while transfer learning was proposed more than a decade ago # otherefr ; # refr, and its application in relation extraction is still unexplored [SEP]", "cit": "while transfer learning was proposed more than a decade ago # otherefra ; # refr, and its application in relation extraction is still unexplored [SEP]"}
{"pre": "# refr show that for a morphological analysis of the english dialectal words ( and disambiguation ) can be disambiguated in parsing accuracy by using", "cit": "# refr showed that using a beam of pos tags as features in the supertagger and parser mitigated the loss of accuracy from pos tagging [SEP]"}
{"pre": "most research conducted in the nlp community focuses on extracting local relations between concept pairs # otherefr ; gi # refr. [SEP] ( [SEP] )", "cit": "although traditional research on taxonomy construction focuses on extracting local relations between concept pairs # otherefr ; gi # refr, more recent efforts has been [SEP]"}
{"pre": "this idea of computing the dependency structure for a sentence was proposed by # refr. [SEP] the results in the context of a chunking [SEP] it [SEP]", "cit": "in related research, ( crocker and # refr1 present evidence that an incremental stochastic parser based oll cascaded markov models # other [SEP]"}
{"pre": "in japanese, the similarity is defined as the next that is the most important for the zero pronoun resolution algorithms # otherefr ; # refr [SEP]", "cit": "for instance, # refr attempted to resolve japanese ellipsis in the source language analysis of j - to - e mt, despite utilizing targetdependent [SEP]"}
{"pre": "in addition, we showed that using morphological features, a certain model for unsupervised morphological disambiguation improves accuracy of disambiguation # refr. [SEP] this [SEP]", "cit": "surprisingly, the research in this area is relatively sparse, despite multiple results that demonstrate the connection between morphology and syntax in the context of part - [SEP]"}
{"pre": "crowdsourcing can allow inexpensive and rapid data collection for various nlp tasks # otherefr ; # refr. [SEP] the data [SEP] training to", "cit": "crowdsourcing can allow inexpensive and rapid data collection for various nlp tasks # otherefr ; # refr, including human evaluations of nl [SEP]"}
{"pre": "the feature weights w = { m1,., are optimized with minimum error rate training ( mert ) # refr to maximize the bleu", "cit": "we evaluate the translation quality using case - insensitive bleu metric # otherefr without dropping oov words, and the feature weights are tuned [SEP]"}
{"pre": "it has been shown that a strong alignment framework with phrase alignment # refr. [SEP] this does not serve as the presence of an ilp model to", "cit": "more recently, several works # otherefr ; # refr have presented more unified phrasebased systems that jointly align and weight phrases, though these [SEP]"}
{"pre": "in related joint work, it has been shown that incorporating domain adaptation # otherefr ; # refr and machine translation # otherefr. [SEP]", "cit": "the idea of jointly training parsers to optimize multiple objectives is related to joint learning and inference for tasks like information extraction # otherefr and [SEP]"}
{"pre": "distributional paraphrasing # refr generates paraphrases using a distributional semantic distance measure introduced by # otherefr. [SEP] ( 1 ) [SEP] (", "cit": "the general inquirer # otherefr has 11, 788 words labeled with 182 categories of word tags, such as positive and negative [SEP]"}
{"pre": "the only difference between two rrr et al. # otherefr used the head - corner parser to capture definite clause grammars # refr, and", "cit": "in the analysis of the australian free word - order language guugu yimidhirr, mark johnson uses a'combine'predicate in a [SEP]"}
{"pre": "we use a simplified version of the algorithm of the algorithm described in # refr. [SEP]k algorithm 1 was reduced to [SEP] the [SEP] [SEP] [SEP] [SEP]", "cit": "compound concept detection : using a classifier based on wordnet syntactic parsing : using an in - house implementation of collin? s parser # refr [SEP]"}
{"pre": "in the case of the 1 - best parsing, the * algorithm plays an important role in a * parsing # refr, or even 3 - best", "cit": "our algorithm, tka? is a variant of the kbest a? ( ka? ) algorithm of # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, a number of researchers have built systems to take reading comprehension examinations designed to evaluate children? s reading levels # otherefr ; [SEP]", "cit": "we evaluates quarc on the same data set that was used to evaluate the deepread reading comprehension system # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for example, # refr proposed a method to detect sub - permutations of a sentence compression task. [SEP] the noisy - channel model, which has [SEP]", "cit": "we assessed the compression results by the f1 - score of grammatical relations ( provided by a dependency parser ) of generated compressions against the gold [SEP]"}
{"pre": "for example, in the bionlp 2009 and 2011 shared tasks, the bionlp 2009 and 2011 # otherefr ; # refr [SEP]", "cit": "much of the work was conducted within the framework of the bionlp 2009 shared task sub task on uncertainty detection focusing on biomedical datasets # refr [SEP]"}
{"pre": "consequently, accurate corpus annotation has been intensely investigated # otherefr ; # refr. [SEP] and linking wikipedia infoboxes to [SEP] [SEP] [SEP]", "cit": "consequently, accurate corpus annotation has been intensely investigated # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr present a machine learning approach to negation cues and their scope in biomedical text. [SEP] scope, using bioscope # otherefr. [SEP]", "cit": "# refr and? ozgu? r and radev # otherefr propose scope detectors using the bioscope corpus. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "much of the current research in sensevalar # otherefr ; # refr ), ~ e. g., ~ e. g [SEP]", "cit": "ldoce syntactic subcategorization codes,, li ) oce boxcodes the program uses a taxonomic lassification of these codes based on # [SEP]"}
{"pre": "this representation can be achieved in different languages other than english # refr, or even more has been shown to be highly effective in the context [SEP] [SEP]", "cit": "similarly, # refr investigate the use of multilingual contexts for word sense disambiguation. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, the twitter api maintains a reference from each reply to the post it responds to, so unlike irc, there is no need [SEP]", "cit": "to perform the generation task, we build a statistical response generator by following # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the cdec decoder # refr with the framework of minimum error rate training # otherefr. [SEP]. [SEP] ( lattice - [SEP] )", "cit": "we use cdec # refr as our decoder and perform mira training to learn feature weights of the sentence translation model # otherefr. [SEP]"}
{"pre": "we used the mada atb segmentation for arabic # refr and truecasing for english, and we used the standard minimum error rate training #", "cit": "for stability # refr, we performed three reruns of each experiment ( tuning + evaluation ), and we report averaged scores. [SEP] [PAD] [PAD]"}
{"pre": "this idea has been developed and applied to a wide variety tasks, including morphological analysis # otherefr ; # refra ; de [SEP] [SEP] [SEP]", "cit": "unsupervised segmentation by itself has garnered considerable attention in the computational linguistics literature # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the experiment, we have experimented with the method of finding the subcategorization frames # otherefr ; # refr. [SEP] [SEP] [SEP]", "cit": "for our corpus of sentences we selected a subset of a corpus developed previously ( see # refr for investigating the perceptual role of prosodic information in disambig [SEP]"}
{"pre": "in addition, we have used a wide - coverage morphological analyzer, which is designed for english ( c ) lexical and # refr. [SEP] a [SEP]", "cit": "using an algorithm similar to # refr and uematsu et al. # otherefr, they first created a hindi ccgbank [SEP]"}
{"pre": "sentence compression is the task of producing a shorter form of an input sentence, so that the new form will still be grammatically related to the new", "cit": "the task of the sentence reduction module, described in detail in # refr, is to remove extraneous phrases from extracted sentences. [SEP] [PAD] [PAD]"}
{"pre": "in this paper, we evaluate the grammatical categories based on wiki co - occurrence # otherefr ; # refr. [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "online games with a purpose, originally conceived by von ahn and dabbish # otherefr has been used to gather annotations on anaph [SEP]"}
{"pre": "we tune the feature weights for all systems using pro # refr with pro # otherefr. [SEP]. [SEP]. [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "the weight vector w is tuned on a development set of error - annotated sentences using the pro ranking optimization algorithm # refr. 1 1we also [SEP]"}
{"pre": "the importance of coreference resolution has led to the ability to identify a coreference resolution task # refr. [SEP] this problem, however, only a", "cit": "this has made it hard to gauge the improvement in algorithms over the years # refr, or to determine which particular areas require further attention. [SEP] [PAD]"}
{"pre": "the first measure of semantic relatedness among words with the contexts used by # refr, which computes word overlap between two words in a sentence. [SEP] the", "cit": "this seems to be a reasonable compromise between the approach of # refr, in which none normalization of words is done, and the more widespread use [SEP]"}
{"pre": "we have discussed this issue, by replacing raw data as a preceding as a set of unordered words, estimated by # refr. [SEP] it [SEP]", "cit": "we can mention here only part of this work : # otherefr ; # refr for monolingual extraction, and # otherefr for [SEP]"}
{"pre": "glossary has been used in a variety of nlp tasks, such as relation extraction # otherefr, ontology learning # refr, and [SEP]", "cit": "examples include natural language processing tasks such as question answering # otherefr, word sense disambiguation # refr and ontology learning # otherefr [SEP]"}
{"pre": "in addition to the regular distance distortion model, we incorporate a log - linear model # refr as follows : p ( w | w? | w", "cit": "among all possible target language sentences, we will choose the sentence with the highest probability : e? i? 1 = argmax i, ei [SEP]"}
{"pre": "there has been a lot of recent work on anaphoricity determination # otherefr, # refr, ng # otherefr ). [SEP]", "cit": "the automatic identification of information status # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition to the system described in # refr, we used the first - order probabilistic model of the 2012 test sentences as defined by [SEP] ( ms", "cit": "syntactic information has proven useful for the paraphrase identification task over msrpar, as demonstrated in studies such as # refr and # other [SEP]"}
{"pre": "in fact, much recent work has demonstrated that learning cross - lingual dependency trees, including multilingual syntactic parsing # refr, [SEP] this approach #", "cit": "the stanford scheme, partly inspired by the lfg framework, has emerged as a de facto standard for dependency annotation in english and has recently [SEP]"}
{"pre": "in our experiments, we use the multitask learning algorithm # refr. [SEP] the algorithm of al. [SEP] al. [SEP] al. [SEP] the [SEP]", "cit": "active learning has been shown, for a number of different nlp tasks, to reduce the number of manually annotated instances needed for obtaining a consistent [SEP]"}
{"pre": "corpus - based or example - based mt # refr and statistical mt # otherefr systems provide the easiest customizability, since they have [SEP]", "cit": "to resolve this problem, example - based machine translation # refr has recently been proposed. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "it has been demonstrated to be highly effective in a wide range of nlp tasks, including sentiment analysis # refr, semantic parsing # otheref [SEP]", "cit": "4http : / / www. metaoptimize. com / projects / wordreprs / 5http : / / mpqa. cs [SEP]"}
{"pre": "for example, in the english - chinese system of # refr, the main parallel training data is target - sided and simultaneously parsed [SEP] the", "cit": "there are many ways of incorporating syntax into mt systems, including the use of string - to - tree translation ( s2t ) to ensure [SEP]"}
{"pre": "to measure the best of our entailment, we use the following steps : given the english similarity of # refr. [SEP] a standard similarity score [SEP]", "cit": "in addition, an alignment - based approach has the advantage of generality : almost all existing rte models align the linguistic material of the premise and [SEP]"}
{"pre": "in addition, we show that the system outperforms the joint inference model by the joint task of anaphora and the antecedent candidates provided by the conll", "cit": "but the most common approach to coreference resolution # otherefr ; ng and # refr, etc. ) is to use a single classifier [SEP]"}
{"pre": "we use nltk # refr for pos tagging. [SEP] the corpus of news articles. [SEP] the corpus of the corpus of 20. [SEP] a big", "cit": "the stemmed model is a slight variation on the word - form model, where the same statistics are aggregated after applying lancaster stemming # other [SEP]"}
{"pre": "we have been impressed by the success of active learning for nlp tasks # otherefr ; # refr. [SEP] the text classification [SEP] [SEP]", "cit": "for re, we use aimed, previously used to train protein interaction extraction systems ( # refr ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "several studies # otherefr ; # refr have used comparable corpora to extract transliteration pairs. [SEP] the cross - lingual setting. [SEP]", "cit": "other interesting approaches such as # refr rely on temporal distributions of entities. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "some approaches have utilised the visual attributes of objects # otherefr, # refr, and on the source language descriptions # otherefr. [SEP]", "cit": "some approaches have utilised the visual attributes of objects # otherefr ; # refr, relied on an external corpus to predict the relationships between objects [SEP]"}
{"pre": "in this paper, we describe the stanford dependency parser ( nivre and # refr, a preliminary implementation of the stanford dependency parser # otheref [SEP]", "cit": "5 since several studies have indicated that representations of syntax and aspects of syntactic dependency formalism differ in their applicability to support information extraction tasks # refr, [SEP]"}
{"pre": "in the experiments described in detail, this paper is based on the assumption that the words themselves can be represented unambiguously as sequences of candidates or sequences of", "cit": "as known from work on unsupervised part - of - speech tagging # refr, the size of the window in which words will be found similar to [SEP]"}
{"pre": "wsd methods can be roughly categorized into ( elementary ) methods that are based on distributional information rather than capture contextual information. # refr, [SEP] the", "cit": "some researchers achieved improvements by expanding the disambiguated query words with synonyms and some other information from wordnet # otherefr ; # refr [SEP]"}
{"pre": "in addition to exploiting fine - grained topic models, we can find some hypernym data, a hyperparameters # otherefr ; #", "cit": "the seed selection was not fine - tuned ( i. e., it was not adjusted to improve performance ), so it might well be [SEP]"}
{"pre": "in addition, we provide a comparison to well - known pseudoprojective parsing # otherefr ; # refr. [SEP] the problem of [SEP] non", "cit": "the projectivization algorithm # refr iteratively moves each nonprojective arc upward in the tree until the whole tree is projective. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "model accuracy ( f1, e ) ( f - j ) ) ) ) ( f1 ( f2 ) ) ) ) ) ) )", "cit": "unsupervised latent variable models # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the case of english, you have to use meanings as well as dictionaries for word sense disambiguation # otherefr, and [SEP] the", "cit": "differently from the activity of creation and editing of projects, only the final part of the work involved in the integration of processors is accomplished via the [SEP]"}
{"pre": "in addition, graph - based methods have been shown to be highly effective at detecting the ambiguous senses of the target words # otherefr ; [SEP]", "cit": "the results for this setting are shown in table 2, where we also compare with the top - performing systems from the semeval competition, [SEP]"}
{"pre": "id participant cmu - uka carnegie mellon university, usa # otherefr limsi limsi limsi limsi limsi", "cit": "to lower the barrier of entry for newcomers to the field, we provided moses, an open source toolkit for phrase - based statistical [SEP]"}
{"pre": "in a different case of referring expression # otherefr ; # refr, a number of referring expressions have been made by running the properties of [SEP]", "cit": "several types of information about domain entities, such as gradable properties # refr and physical location, are best captured by real - valued attributes. [SEP]"}
{"pre": "we present a novel approach that outperforms turboparser # otherefr,? 2 ), and? 1 ( i. e.,?", "cit": "see also # refr for more discussions. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for the wsj, high accuracy parsing models have been created, some of them using extensions to classical pcfg parsing such as lexicalization # other", "cit": "however, as demonstrated in charniak # otherefr and # refr, a pcfg which simply takes the empirical rules and probabilities off [SEP]"}
{"pre": "for example, patwardhan and riloff # otherefr consider an ie approach where the ie approach taken by # refr who use [SEP]", "cit": "the experiments described below were performed on a version of the proteus system as prepared for muc - 3, the third message understanding conference \\ [ [SEP]"}
{"pre": "in es00 ( s2 ) s ta, the similarity measure is calculated by a dependency parser which is based on the intuition that it is [SEP]", "cit": "wsd system sense # otherefra \\ ] ; \\ [ # refr \\ ] ) for carrying out wsd on the basis of distributional [SEP]"}
{"pre": "we show that the model for surrounding context can be improved by using dependency information rather than strictly relying on the success of constituency parsing # otheref", "cit": "the algorithm operates similarly to the em algorithms used for grammar induction # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "there have been several studies in sentiment analysis # refr, especially in determining the sentiment of words and the document is often assumed that there are studies [SEP]", "cit": "the applications of sentiment analysis range from classifying positive and negative movie reviews ( pang, lee, and # refr to opinion question - answering # [SEP]"}
{"pre": "in this work, we are interested in sentiment analysis on twitter because of its limited tweet tweets # refr. [SEP] sentiment classification # otherefr", "cit": "many systems and approaches have been implemented to automatically detect sentiment on texts ( e. g., news articles, web reviews and web blogs [SEP]"}
{"pre": "a probabilistic model for assigning the probability p is considered as a probability sum over the words of the sentence, as in previous work on dependency parsing [SEP]", "cit": "this includes parsing and relation extraction # refr, entity labeling and relation extraction # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we conducted experiments on the wall street journal section of the penn treebank, except for constituencybased models using a transition based parser # otheref", "cit": "# refr introduced a transition based nonprojective parsing algorithm that has a worst case quadratic complexity and an expected linear parsing time. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "for non - projective parsing, the inside - outside algorithm has been successfully applied to problems, such as parsing # refr and head - automaton grammars #", "cit": "splitting techniques have also been exploited to speed up parsing time for other lexicalized formalisms, such as bilexical context - free grammars and [SEP]"}
{"pre": "it has been observed that the use of syntactic priming effects is crucial for many natural language processing tasks, including question answering # otherefr ; [SEP]", "cit": "the results have demonstrated the existence of priming effects in corpus data : they occur for specific syntactic constructions # otherefr, consistent with the experimental [SEP]"}
{"pre": "we use the stanford parser # refr to parse the utterances. [SEP] sentences, we tokenized the tokens that contain the stanford parser # otherefr", "cit": "we use the stanford core nlp suite # otherefr ; # refr to annotate each document with pos and ner tags, parse trees [SEP]"}
{"pre": "in this work, we assume the reader to # refr,. [SEP] the current discourse - level decoder ( pdtb ), a rule - based", "cit": "recently, however, we presented docent # otherefr ; # refr, a decoder based on local search that translates full documents. [SEP] [PAD]"}
{"pre": "dependency trees have been used in a variety of nlp applications, such as dependency parsing # otherefr, word sense disambiguation # refr,", "cit": "dependency parsing has been actively studied in recent years # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in order to obtain the training data for the whole sentence with the presence of a treebank, we followed the second prepositional phrase [SEP] [SEP]", "cit": "including the use of syntactic information has yielded improvements in accuracy in speech recognition # otherefr and machine translation # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "most of the previous work on normalization focused on microblog normalization, i. e., language modeling as a preprocessing step of textual entailment #", "cit": "methods such as those of han and baldwin # otherefr, # refr or han et al # otherefr are unsupervised but they [SEP]"}
{"pre": "the penn treebank # refr was used the first post - processing of a simple lexicalized treebank ( ptb ) to obtain the pp -", "cit": "semantically annotated corpora riezler et al # otherefr grammar to the parsing of the penn treebank # refr by exploiting various techniques for [SEP]"}
{"pre": "it is well - known that projective parsing algorithms for nonprojective structures have been proposed # refr. [SEP] the model of mcdonald et [SEP] [SEP] [SEP]", "cit": "there has been extensive work on data - driven dependency parsing for both projective parsing # refr ; paskin, 2001 ; yamada and matsum [SEP]"}
{"pre": "named entity recognizers # otherefr ; # refr ) can be trained on gold labeled data and then tested on gold standard documents and [SEP] languages", "cit": "tries have previously been used in both supervised # otherefr and unsupervised # refr named entity recognition. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper, we focus on the hpsg grammar formalism, an underspecified representation of a hpsg treebank, as an underspec", "cit": "depth of representation and transformation of information internally, the [ incr tsdb ( ) ] database records analyses in three different formats, viz. [SEP]"}
{"pre": "for the training of the smt system, we use the open source jane toolkit # refr. [SEP] the class model of moses # otheref", "cit": "the standard models integrated into our jane hierarchical systems # refr ; huck et al 2012c ) are : phrase translation probabilities and lexical smoothing probabilities [SEP]"}
{"pre": "the first one to consider is the phrase - based translation model # otherefr ; # refr. [SEP] and # otherefr [SEP] [SEP] [SEP]", "cit": "for example, the model of # refr uses an itg constraint and beam - based viterbi decoding for tractability, but is still [SEP]"}
{"pre": "the conll 2011 shared tasks on coreference resolution using the ontonotes corpus # refr were an extension of the ontonote [SEP] system # other", "cit": "a small portion of this corpus from the newswire and broadcast news genres (? 120k ) was recently used for a semeval [SEP]"}
{"pre": "wikipedia wikipedia wikipedia wikipedia wikipedia wikipedia wikipedia entity classes can be used as a source of hyponymy relations # refr. [SEP] the hyponymy relation", "cit": "hyponymy relations were extracted from definition sentences # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the only existing senseval - 3 parallel corpora have been made before in the 2007 coarse sense of a target language ( in [SEP]a ) corpus,", "cit": "an effort to alleviate the training data bottleneck is the open mind word expert ( omwe ) project # refr to collect sense - tagged data from [SEP]"}
{"pre": "in this work, we describe how we used the functional annotations from the penn treebank # otherefr, which are some interesting [SEP] the annotations", "cit": "most relevant to this paper is work that seeks to find the appropriate concept in a hierarchy for an argument of a specific relation # otherefr [SEP]"}
{"pre": "this family of techniques has met with success in semisupervised named entity classification # otherefr ; # refr, 11 parts - of - speech [SEP]", "cit": "evaluation is against held - out conll shared task data # otherefr ; # refr, spanning 19 languages. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use bleu # refr as the tuning metric. [SEP] the weights of the transducer to maximize the bleu # otherefr. [SEP] the", "cit": "ter and bleu # refr scores are calculated over all the sentences in the training set. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used bleu # refr, which is the moses score # otherefr. [SEP] the current bleu score # refr [SEP] the current", "cit": "the performance of the systems was measured by bleu # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in fact, the factorization approach has been successfully applied on the source and target languages, e. g., # refr. [SEP] this approach to", "cit": "although scfgs were initially introduced for machine translation as a stochastic word - based translation process in the form of the inversion - transduction grammar # other [SEP]"}
{"pre": "it is worth noting that the former model does not make any projective dependency structure ( henceforth ) can be trained with the [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "they use a variant of eisner? s generative model c # refrb ; eisner, 1996a ) for reranking and extend [SEP]"}
{"pre": "we used the stanford named entity recognizer # refr to extract named entities from the wikipedia list. [SEP] features, we processed, [SEP] the expressions [SEP]", "cit": "we used open nlp pos tagger, standford ner # refr and maltparser # otherefr to label / tag sentences. [SEP]"}
{"pre": "in addition, discriminative weighting methods were proposed to assign appropriate weights to the sentences from training corpus # refr or the phrase pairs of phrase pairs of phrase", "cit": "for example, triggerbased lexicon model # refr and context - dependent translation selection # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in our system, we use an integer linear programming framework # otherefr ; # refrb ) which has been successfully used for coreference resolution", "cit": "besides the mention - pair model, two other commonly used models are the entity - mention model # otherefr ; # refr and ranking models [SEP]"}
{"pre": "randlm 0. 2 # refr stores large - scale n - gram lms within the randomized data structures. [SEP] ( randlm ) for language models", "cit": "recent work # refrb ) has demonstrated that randomized encodings can be used to represent n - gram counts for lms with signficant space [SEP]"}
{"pre": "one common approach is to begin with unlabeled, but clustered event - specific documents, and extract common word patterns as extractors # otherefr [SEP]", "cit": "the majority of previous work relies on ad - hoc clustering algorithms # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the preposition sense disambiguation task of prepositions # refr provided the semeval 2007 task ( i. e., a training set", "cit": "this sense inventory formed the basis of the semeval - 2007 task of preposition word sense disambiguation of # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "several methods have been proposed to address the problem of improving word alignment quality by using various language models # otherefr ; # refr. [SEP] the", "cit": "figure 1 : an example of inaccurate translation and word alignment. and # refr ), which also introduce many word alignment errors. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "in a related paper # refr, we describe how analogical relations could be extracted from wordnet, and an approach that induces conjunctive features [SEP]", "cit": "building on a recent proposal in this direction by # refr, we propose a generic method of this sort, and we test it on a set [SEP]"}
{"pre": "we use a structured perceptron # refr since it is a black - box component for training # otherefr. [SEP] the weights themselves are [SEP]", "cit": "when training is finished, the weight vectors from all iterations are averaged together. # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr developed an unsupervised method that collects statistics from non - native speakers because it has observed only been studied ( e. g. [SEP] [SEP] [SEP]", "cit": "classification - based approaches to argumentative zoning typically use a sequence classifier such as a maximum - entropy markov model or conditional random field # other [SEP]"}
{"pre": "most of the work on sentiment analysis consider either the document # otherefr, or a binary classification # refr, or a positive [SEP] [SEP] [SEP]", "cit": "despite the large amount of recent work on sentiment analysis and opinion mining, much of it has focused on supervised methods ( e. g., [SEP]"}
{"pre": "to date, evaluations of automatic text simplification have been # otherefr ; # refr, and using the transfer rules from a raw text. [SEP]", "cit": "their model is based on quasi - synchronous tree substitution grammar ( qtsg ) # refr and integer linear programming. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used the stanford parser # refr to parse the source domain and the stanford parser # otherefr. [SEP] the training set. [SEP] [SEP] [SEP]", "cit": "the stanford parser # refr was used for pos tagging and parsing. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this has been used in prior work ( e. g., # refr ), to model the sentiment expressed in the twitter, and its social", "cit": "response prediction there has been significant work addressing the task of response prediction in news articles # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in recent years, coreference resolution researchers have also conducted a major nlp task, e. g. # otherefr ; # refr [SEP]", "cit": "the system of # refr uses the node distance in wordnet ( with an upper limit of 4 ) as one component in the distance measure that [SEP]"}
{"pre": "we use brown clusters # otherefr induced by rcv1 corpus # refr as features for chunking # otherefr. [SEP] the word", "cit": "the studies in # otherefr ; # refr reveal improvements when using the brown clustering algorithm # otherefr to extract useful features. [SEP] [PAD]"}
{"pre": "in epistle, ( a ) the subject of a sentence consists of a1, a set of nodes ( b ) and words, as follows", "cit": "# refr provides a good summary of early work in weight - based analysis, as well as a weight - oriented approach to attachment decisions based on [SEP]"}
{"pre": "an alternative learning model that can overcome this problem performs coreference resolution based on entity - mention pairs # otherefr ; ng and # [SEP] [SEP]", "cit": "aone and bennett # otherefr ; ng and # refr ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in order to measure the quality of discourse relations, we used the discourse parser # refr. [SEP] annotations provided by the penn discourse treebank ( pdt", "cit": "reported and direct speech are certainly important in discourse # refr ; we do not believe, however, that they enter discourse relations of the type that [SEP]"}
{"pre": "in this paper, we describe the relationship between the definition of the partial treebank parser # refr, an hpsg treebank - style analyses for", "cit": "there has been a number of research projects to efficiently develop richly annotated corpora with the help of parsers, one of which is called a [SEP]"}
{"pre": "for example, the cdec decoder # refr supports the context - free - reordering / finitestate - translation framework described by dyer and [SEP]", "cit": "these techniques can be broadly divided into pre - ordering techniques, which first parse and reorder the source sentence into the target order before translating # [SEP]"}
{"pre": "langid systems appear in the context of text, e. g., # otherefr ; # refr, and as [SEP] a source name", "cit": "there is widespread misconception of language identification being a? solved task?, generally as a result of isolated experiments over homogeneous datasets with [SEP]"}
{"pre": "while many variants have focused on the incorporation of normalization and other forms of local contexts # otherefr ; # refr, it is not well suited", "cit": "however, a pronunciation model # refr would be needed to find the mapping between g8, 2day and 4ever to great, [SEP]"}
{"pre": "the english sentences were parsed using a state - of - the - art statistical parser # refr. [SEP] # otherefr trained on the [SEP]", "cit": "the success of statistical methods in particular has been quite evident in the area of syntactic parsing, most recently with the outstanding results of # refr and [SEP]"}
{"pre": "many approaches have been developed, including inductive logic programming # otherefr, and methods for bootstrapping # refr ). [SEP] the patterns [SEP] [SEP]", "cit": "many ie systems use extraction patterns or rules to identify the relevant information # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, we plan to incorporate the propbank - style semantic role labelling task, i. e., to annotate the sentence [SEP] [SEP]", "cit": "the state - of - the - art in semantic role labelling has now advanced so much that a number of studies have shown that automatically inferred semantic [SEP]"}
{"pre": "as a promising approach to keyphrases ( i. e., candidate ) is largely unexplored as a source of text [SEP] ( [SEP]", "cit": "# refr etc. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the second approach is to use minimum error rate training # refr, a technique for training in which a translation model is represented as a weighted linear maximum", "cit": "we use a hierarchical phrasebased decoder # otherefra ) which directly generates word lattices from recursive translation networks without any intermediate hypergraph representation # [SEP]"}
{"pre": "we tagged the material using thorsten brants # refr. [SEP] a corpus of 39 ( tnt ), a hidden markov model tag [SEP] [SEP]", "cit": "but if larger training corpora are available, significant disambiguation is possible : with a 1 m word training corpus # otherefr the tnt [SEP]"}
{"pre": "chinese text was segmented using the stanford segmenter # refr. [SEP] stanford segmenter # otherefr. [SEP] features [SEP] the stanford segmenter [SEP]", "cit": "our linguistic features are adopted from # otherefr and # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the first, reordering models are defined over baseline, e. g. reordering in smt # refr. [SEP] the source language to [SEP]", "cit": "both systems make heavy use of linear mixtures to create refined translation and language models, mixing across sources of corpora, genre and translation direction # refr [SEP]"}
{"pre": "in a new application of speech processing ( e. g., # refr ), the optimal ordering of the subcategorization frames ( e.", "cit": "the backbone of our sentence planner is a grammar with subcategorization information which we collected from the lexicon created by korhonen and brisc [SEP]"}
{"pre": "lin? s distributional similarity score # refr was calculated using the modified version of the s distributional similarity measure introduced by # otherefr. [SEP] [SEP]", "cit": "# refr, lenci and benotto # otherefr identified hypernyms in distributional spaces. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in chinese word segmentation, character - based segmentation techniques are combined with sequential labeling models # otherefr ; # refr. [SEP] the problem [SEP] the", "cit": "pointwise mutual information # otherefr ; # refrb ) and it is a measure of the mutual dependence of two strings and reflects the [SEP]"}
{"pre": "in the lexicon of # refr, the authors invoke an unsupervised ( semi - ) model to identify the polarity of a word. [SEP] [SEP] [SEP] [SEP]", "cit": "several approaches have been devised for building such lexicons # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "statistical significance in bleu differences was tested by paired bootstrap re - sampling # refr. [SEP] the paired bootstrap resampling method [SEP], [SEP], [SEP]", "cit": "the improvement is statistically significant with 95 % confidence using pairwise bootstrapping of 1, 000 test sets randomly sampled with replacement # refr. [SEP] [PAD] [PAD]"}
{"pre": "in a real - world approach, you need to user? s utterance when you need to be specified in the user......", "cit": "in addition, the next time you speak to that user, you need to adapt to new information you have gained about them # refr. [SEP] [PAD]"}
{"pre": "# refr. [SEP] ccg ( henceforth ) a log - linear model for french, and a parsing of german [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "# refr has translated the german tiger corpus # otherefr into a ccg - based treebank to model word order variations in german [SEP]"}
{"pre": "while standard features for polarity have been manually crafted ( e. g., # refr ), and # otherefr ), [SEP]", "cit": "# refr generate a lexicon of patient polarity verbs ( ppvs ) that impart positive or negative states on their patients. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, their use in nlp tasks, such as text classification # otherefr, text classification # refr, and pos tagging # [SEP]", "cit": "similarly language specific feature sets were later explored for mono - lingual genre classification experiments in german # refr and russian # otherefr. [SEP] [PAD]"}
{"pre": "crowdsourcing services such as amazon mechanical turk has been used for various nlp tasks in recent years # otherefr ; # refr, [SEP]", "cit": "in recent years, there have been an increasing number of studies # otherefr ; # refr using crowdsourcing for data annotation. [SEP] [PAD]"}
{"pre": "this system uses three corpora of verb clustering : 1 ) the argument classification task # otherefr, ( ii ) a large multilingual corpus of", "cit": "recent research has found that even automatically - acquired verb classifications can be useful for nlp applications # otherefr ; # refr. [SEP] [PAD] [PAD]"}
{"pre": "we conducted experiments on the test set, which we performed very high accuracy on the development set, and the second - order parser described by # [SEP]", "cit": "the two main approaches to dependency parsing are transition based dependency parsing # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the past, several papers have proposed their use in natural language processing tasks, including part - of - speech tagging # otherefr, [SEP]", "cit": "for this purpose, we use the maximum entropy modeling with inequality constraints # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use tnt # refr, a freely available tagger # otherefr. [SEP] the tnt tagger # otherefr used [SEP]", "cit": "networks # otherefr 97. 05 hmm # refr 96. 48 easiest - first 97. 10 full bidirectional 97. 15 [SEP] [PAD] [PAD]"}
{"pre": "we evaluate our model on the semeval - 2007 noun dataset # refr, both defined in ( gi # otherefr and the semev", "cit": "research community wide efforts in the semeval - 2007 task 4 ( gi # refr, the semeval - 2010 task 8 # other [SEP]"}
{"pre": "in this paper, we evaluate the performance of automatic metrics using the pyramid metric # refr and rouge # otherefr. [SEP] [SEP] [SEP] [SEP]", "cit": "prior studies have shown that paired tests for significance are indeed able to discover considerably more significant differences between systems than non - paired tests, in which [SEP]"}
{"pre": "this bayesian approach has been used to induce good hmms in part - of - speech taggers # refr, in which a priori grammar can [SEP]", "cit": "dirichlet priors can be used to bias hmms toward more skewed distributions # refr, which is especially useful in the weakly supervised setting considered here. [SEP]"}
{"pre": "indeed, several methods for calculating the expected counts are proposed by # otherefr, and # refr, among others. [SEP] the product of word", "cit": "notice that q here does not approximate the entire translation process, but only 2 # refr have successfully used treeautomaton determinization to exactly marginal [SEP]"}
{"pre": "empty categories have been studied in recent years for several languages, mostly in the context of reference resolution and syntactic processing for english, such as in [SEP]", "cit": "since empty categories do not exist in the surface form of a language, they are often deemed elusive and recovering ecs is even figuratively called [SEP]"}
{"pre": "# refr used a set of features derived from a discourse treebank, but training a test corpus. [SEP] results. [SEP] results. [SEP] results (", "cit": "in previous work # refr, we reported on a method for empirically validating global discourse units, and on our evaluation of algorithms to identify these units [SEP]"}
{"pre": "dependency trees have been used in a variety of nlp applications, including relation extraction # refr, relation extraction # otherefr. [SEP] this [SEP]", "cit": "# refr propose an integrated statistical parsing technique that augments parse trees with semantic labels denoting entity and relation types. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, it is used in smt as a feature in minimum error training # refr and for rescoring lattices of translation hypotheses [SEP] [SEP] [SEP]", "cit": "we used z - mert # refr to optimise the set of feature weights on the? newstest2011? development set. [SEP] [PAD]"}
{"pre": "in addition, an automatic dictionary definitions can be used to an existing database, e. g., # refr, or to provide a [SEP] dictionary", "cit": "researchers at new mexico state university have built an automatic algorithm \\ [ # refr \\ ] for locating and disambiguating enus terms ( head nouns [SEP]"}
{"pre": "in this paper we evaluate the system on a multilingual dependency treebank, which was evaluated in the conll 2007 shared task on dependency parsing [SEP]", "cit": "for more information about the setup, see # refr in this paper, i will summarize the main findings from the conll 2007 shared task, [SEP]"}
{"pre": "# refr showed that the performance of a sentiment classifier is outperformed the best of its context in the same sentiment of tweets. [SEP] the same sentiment", "cit": "# refr treated 50 twitter tags and 15 smileys as sentiment labels and a supervised sentiment classification framework was proposed to classify the tweets. [SEP] [PAD]"}
{"pre": "this approach is similar to the one used by # refr except that it uses a measure of answer classification. [SEP] classification. [SEP] classification as a classification", "cit": "we thus wondered if it was possible to use existing english corpora, in this case the data used in ( li and # refr, to [SEP]"}
{"pre": "some of the work in this area has been demonstrated, for example, by # refr, who present a classifier that spans of text written from a", "cit": "we use a lexicon of subjective and positive / negative sentiment expressions # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition to the well - known hierarchical systems, we also use a competitive phrase - based system # refr. [SEP] the [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "they are wordbased lrm and phrase - based lrm, which mainly focus on local reordering phenomena, and hierarchical phrase - based lr [SEP]"}
{"pre": "# refr used maximum entropy model in order to find word repetitions, while they use a bigram model to find the optimal set of good indicators,", "cit": "proposals using dynamic programming ( dp ) are given in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, we plan to use the multilingual te - 2. 1 data # refr, a single english - language model was used for [SEP]", "cit": "the english corpus was then translated to all other languages # otherefr ; # refr ), trying to generate sentence - parallel translations. [SEP] [PAD]"}
{"pre": "meanwhile, translation grammars have grown in complexity from simple inversion transduction grammars # otherefr and have increased in size by including more synchronous tree fragments [SEP]", "cit": "meanwhile, translation grammars have grown in complexity from simple inversion transduction grammars # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr used cognate identification in the source - side bitext and the translation of the resulting cognates. [SEP]. [SEP]. [SEP] the [SEP]", "cit": "previous research has shown that using cognates can yield better word alignments # otherefr ; # refr, which in turn often means higher - [SEP]"}
{"pre": "while some methods focus on predicting a complete formal representation of texts # otherefr ; # refr, others have been attempted to improve the performance of", "cit": "maximum entropy model of rules # otherefr, while the second is inspired by tree kernel methods and extracts common subtrees from pairs of parse [SEP]"}
{"pre": "we use the similarity measure described in # refr. [SEP] similarity # otherefr. [SEP] similarity w ( w. [SEP] a sequence of pos [SEP]", "cit": "# refr construct a graph to encourage similar n - grams to be tagged similarly, resulting in moderate gains in one domain, but no gains on [SEP]"}
{"pre": "figure 6 : dependency relations extracted from the bllip parser. 1. 1 # refr trained biomedical domain # otherefr showed that the charnia", "cit": "parsing technologies have improved considerably in the past few years, and high - performance syntactic parsers are no longer limited to pcfg - based frameworks [SEP]"}
{"pre": "seeds are used to harvest as a way of the top - level pattern ( see, e. g., # refr ). [SEP] the [SEP]", "cit": "a substantial body of work has been done in attempts to harvest bits of semantic information, including : semantic lexicons # refr, concept lists # [SEP]"}
{"pre": "this measure draws from the user model that can be used for scoring the performance of the coherence # otherefr, which can be based on the", "cit": "to alleviate this issue here, we followed the distribution similarity approach, which has been widely applied in the automatic generation of gold standards ( gss [SEP]"}
{"pre": "because lexical information is highly sensitive to domain variation, approaches that can identify vcs, scfs and sps in corpora have become increasingly popular, [SEP]", "cit": "these three of types of information have proved useful for natural language processing # otherefr, semantic role labeling # refr, and word sense disambig [SEP]"}
{"pre": "because they cannot capture the meaning of longer phrases properly, compositionality in semantic vector spaces has recently received a lot of attention # otherefr [SEP]", "cit": "# refr present a recursive technique to build compositional meaning of phrases from their constituents, where the nonlinear composition operators are learned by neural networks. [SEP] [PAD]"}
{"pre": "# refr propose an intrinsic metric based on clustering of senses from a wordnet - based wsi system. [SEP] the latter ( [SEP] [SEP] [SEP] [SEP]", "cit": "while the issue distinguishing between related senses is a recognized issue for word sense disambiguation # otherefr ; # refr, which uses supervised training [SEP]"}
{"pre": "the data was parsed with the # refr parser and the information - theoretic # otherefr. [SEP] the patterns [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "reg research goes back at least to the 1980s ( appelt, grosz, joshi, mcdonald and others ), but the field [SEP]"}
{"pre": "instead of using the gold standard features, we adopt the method of # refr applied to our notion of similarity score. [SEP] the similarity score of [SEP]", "cit": "one of the most important approaches is # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "a plethora of prior work learns bilingual lexicons from monolingual and comparable corpora with many signals including distributional, temporal, and topic similarity # [SEP]", "cit": "# refr, for example, mine parallel text from comparable corpora. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this study, we use the reranker proposed by # refr. [SEP] the predicate - argument structure to get around 80 % [SEP] the semantic", "cit": "we used the chinese semantic role labeler of wu and # refr for source side srl, which uses the liblinear # otherefr [SEP]"}
{"pre": "in natural language processing, entropy # otherefr ; # refr. [SEP] this entropy framework ; however, like that the entropy of [SEP] [SEP] [SEP]", "cit": "this paper provides evidence for # refr entropy rate principle, which predicts that the entropy of a sentence increases with its position in the text. [SEP] [PAD]"}
{"pre": "# refr report results on the opus subtitle corpus using the expectation maximization ( em ) algorithm. [SEP] ( em ) algorithm. [SEP] [SEP]", "cit": "several methods exist for deciphering 1 : 1 substitution ciphers : # refr solve 1 : 1 substitution ciphers by formulating the dec [SEP]"}
{"pre": "# refr used a supervised machine learning approach to classify emotion classification on tweets annotated tweets. [SEP] documents. [SEP] documents, in which they use machine learning", "cit": "we therefore experiment with multiple such conventions with apparently similar meanings? here, emoticons ( following # refr ) and twitter hashtags? [SEP]"}
{"pre": "we use the algorithm of # refr to obtain the antecedent for pronouns. [SEP]. [SEP] features, the algorithm could be exploited in [SEP] [SEP] [SEP]", "cit": "in fact, ng and # refra ) challenged the motivation for the inclusion of such detectors, reporting no improvements, or even worse performance. [SEP]"}
{"pre": "then, the documents have been parsed using the the the the the the the the the the the the the the the the the the the the", "cit": "on the rst - dt # otherefr, the best performing system is # refr, who report an f score of 55. 71 for [SEP]"}
{"pre": "for example, error correction methods have been used for spelling correction # otherefr, # refr. [SEP] this approach was proposed to [SEP]", "cit": "languageindependent systems have been evaluated on persian # otherefr and on arabic and english # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "almost all previous research on japanese dependency structure analysis dealt with dependency structures in written text # otherefr ; # refr ; yamada and matsum", "cit": "the conventional statistical model # refr uses only the relationship between two bunsetsus to estimate the probability of dependency, whereas the model in this study [SEP]"}
{"pre": "we use the giza + + toolkit # refr to learn word alignment for decoding, and adopt the grow - diag - final - and heuristic to", "cit": "both the conditional model of denero et al # otherefr operate in a, as does the phrase - based decoding framework of # refr [SEP]"}
{"pre": "in the biomedical domain, anaphora resolution has been studied in recent years, e. g., # otherefr ; # refr, and", "cit": "the feature combinations play an essential role in obtaining a classifier with state - of - the - art accuracy for several nlp tasks ; recent examples [SEP]"}
{"pre": "# refr used a random walk model defined by introducing the semantic orientation of positive or negative. [SEP]. [SEP]. [SEP] words in order to determine the", "cit": "one such line of research is the well - studied problem of identifying the polarity of individual words # otherefr ; # refr. [SEP] [PAD] [PAD]"}
{"pre": "# refr presented an unsupervised method for extracting relations from corpora. [SEP] unannotated data. [SEP]. [SEP] the methods proposed to deal with [SEP]", "cit": "finally, our previous work # refr proposed composing new relations out of chains of previously extracted relations. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the memory - based tagger # refr trained on the wall street journal corpus ( wsj ) corpus. [SEP] ( sections 19 - 21", "cit": "many approaches for pos tagging have been developed in the past, including rule - based tagging # otherefr, memory - based learning # refr [SEP]"}
{"pre": "we use the subjectivity lexicon of # refr, 2 which contains approximately 8000 words which may be used to express opinions. [SEP] the lexicon.", "cit": "# refr present a two - step process to recognize contextual polarity that employs machine learning and a variety of features. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "phrase structures # otherefr ; # refr. [SEP] a japanese dependency tree ( x, y ) h m, a [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "several researchers have explored ds and ps simultaneously to enhance the quality of syntactic parsing # otherefr and tree - to - string machine translation # [SEP]"}
{"pre": "we use mxpost tagger # refr and in order to provide partof - speech tags for the text. [SEP] the tags of the verbs,", "cit": "maximum entropy models based on this principle have been widely used in natural language processing, e. g. for tagging # refr, parsing # other [SEP]"}
{"pre": "in this paper, we focus on determiner usage, commonly used in post - correction # otherefr ; # refr. [SEP] [SEP] [SEP] [SEP]", "cit": "just as tools such as blast # refr are useful in the development of machine translation systems, our system can produce accurate summaries of the corrections made [SEP]"}
{"pre": "in fact, much research has been carried out on the extraction and disambiguation of collocations # refr. [SEP] this is performed by [SEP] [SEP] [SEP]", "cit": "a comprehensive list of ams is given # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in japanese, the dialogue act corpus is often considered as an important problem, often has been shown to be useful for many natural language processing tasks,", "cit": "in cooperation with this initiative, japanese discourse research initiative has started in japan in may 1996, supported by japanese society for artificial intelligence # otheref [SEP]"}
{"pre": "significance of such models has been tested in other areas of language processing # otherefr ; # refr. [SEP] ( bootstrap resampling ) [SEP] [SEP]", "cit": "to test whether a performance difference is statistically significant, we conduct significance tests following the paired bootstrapping approach # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "jiang et al # otherefr ; # refr. [SEP] the word - based model # otherefr trained on a large amount of fine [SEP]", "cit": "inspired by the sub - word tagging method introduced in # refr, we propose a structure - based stacking model to fully utilize heterogeneous word structures to [SEP]"}
{"pre": "in related research, matsuzaki et al # otherefr introduced latent variables to learn finergrained distinctions of treebank categories for machine translation including", "cit": "there are other successful investigations to impose soft syntactic constraints to hierarchical phrase - based models by either introducing syntaxbased rule features such as the prior derivation [SEP]"}
{"pre": "# refr applied levenshtein distance to irish gaelic dialects with remarkable success, and nerbonne t al. # other [SEP]", "cit": "# refr applied levenshtein distance to irish dialects. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "computational work on the computational analysis of poetry focused on quantifying poetic devices such as the detection of poetry focused on the wasteland and creativity", "cit": "# refr quantify various aspects of poety, including style and sentiment, and use these features to distinguish professional and amateur writers of contemporary [SEP]"}
{"pre": "in the muc conferences, the message understanding conferences ( muc ) # refr, a named entity recognizer # otherefr # other [SEP] [SEP] [SEP]", "cit": "discourse references have been the subject of attention in both the message understanding conference # refr and the automatic content extraction program # otherefr. [SEP] [PAD]"}
{"pre": "we use pointwise mutual information ( pmi ) # refr to weight the features. [SEP] the features are based on the decision to measure the mutual", "cit": "we normalize the overall co - occurrence count of the headword pair c12 by the unigram counts of the individual headwords c1 and [SEP]"}
{"pre": "id institution balagur yandex school of data analysis # otherefr mes - * munich / edinburgh / stuttgart # refr omn [SEP]", "cit": "id institution balagur yandex school of data analysis # otherefra ) dcu - fda dublin city university # refra ) dc [SEP]"}
{"pre": "in particular, clusters which contain the top - 1 / 1 / 1 - 1 - 1the system is defined by # otherefr, #", "cit": "# refr phrase coreference resolution as a graph clustering problem : they first perform pairwise classification and then construct a graph using the derived confidence values as [SEP]"}
{"pre": "for english, we used the stanford parser # refr. [SEP] english ( section 2 ). [SEP] the penn treebank # otherefr to [SEP]", "cit": "the main aspects of our policy are as follows : verb conjugation : information about verb conjugation is added to each intermediate node related to the verb ( [SEP]"}
{"pre": "the highest scoring according to the score in table 1 is 2, and we used as a score of p. 8 with the cky algorithm #", "cit": "to improve parsing flexibility in deterministic parsing, our top - down parser uses beam search algorithm with dynamic programming # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "table 1 : the accuracy of the charniak - johnson parser # refr. [SEP] english parser # otherefr. [SEP] the selftraining [SEP]", "cit": "we included some of the features from the parser reranking work of # refr : the height of the parse tree and the number of right [SEP]"}
{"pre": "# refr used morphological analyzer for arabic dialects for arabic. [SEP] languages by taking into consideration. [SEP] different arabic dialects. [SEP] languages, [SEP]", "cit": "for example, # otherefr ; # refr proposed a system including a morphological analyzer and a generator for arabic dialects # otherefr [SEP]"}
{"pre": "building on timeml # otherefr ; # refr identify temporal relationships in free text, but don? t focus on fact extraction. [SEP] [SEP]", "cit": "hence, the joint model resembles # refr extended by section 5? s temporal constraints. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "erkan and radev # otherefr, # refr introduced approaches for unsupervised extractive summarization that rely on the application of graph [SEP] text", "cit": "edge matching techniques similar to those of # refr are used. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "thrax? s paraphrase extraction mode is simple to use, and yields state - ofthe - art syntactically informed sentential paraphr [SEP]", "cit": "synchronous treeadjoining grammars # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition to the regular space e. g. k - best lists, we also introduce the model as described in # refr. [SEP] [SEP] [SEP]", "cit": "the approach has been shown to give improvements over the map classifier in many areas of natural language processing including automatic speech recognition # otherefr ; [SEP]"}
{"pre": "in # refr a number of methods are tested on the centering algorithm. [SEP] the starting point in the experiments of cf. [SEP]a [SEP]a", "cit": "there is less consensus on the preference order : # otherefr ; # refr or right - to - left # otherefr. [SEP] [PAD]"}
{"pre": "for longer documents, with requisite longer summaries, the notion of salience degenerates, and the summary becomes just an incoherent collection of sentences [SEP]", "cit": "1tmvever, unlike # refr # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "although there have been many studies on this topic analysis # otherefr ; # refr, it is necessary to make use of multiple documents for summar", "cit": "we used the dependency parser proposed by imamura et al # refr to acquire the dependency tree. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr. [SEP] a related approach to this problem, parsing is based on a chart and parsing strategy which can be used in a string of input", "cit": "in nlp, # refr presents a method for repairing failed parses in a relatively efficient way based on the fact that, after a [SEP]"}
{"pre": "# refr showed that surprisal calculated from a probabilistic earley parser correctly predicts wellknown processing phenomena that were believed to emerge from structural ambiguities,", "cit": "a recent theory of sentence processing, surprisal theory # refr, combines several of these aspects into one single concept, namely the surprisal of [SEP]"}
{"pre": "in recent years, the task of automatically preposition sense disambiguation has been around 36 ( wsj ) and training classifiers ( see # refr.", "cit": "synonym extraction # otherefr, lexical substitution # refr and paraphrasing # otherefr are related to collocation correction in the [SEP]"}
{"pre": "# refr use part - of - speech information and verb syntactic relations. [SEP] the former for thesaurus construction. [SEP] application. [SEP] distributionally", "cit": "this problem is addressed by riloff and shepherd # otherefr, # refr and more recently by widdows and dor [SEP]"}
{"pre": "named entity recognition ( ner ) # refr can be used for classification and named entity classification. [SEP] tasks, it has been shown that in particular [SEP]", "cit": "this is one of the main causes for the recent growing interest on developing language? independent nerc systems, which may be trained from small training [SEP]"}
{"pre": "the dependency trees are converted to tree structures # refr. [SEP]. [SEP] the word sequence labeling process requires training data. [SEP] the sentence [SEP] effort to", "cit": "in order to get the dependency relation of the training corpus, we re - implement a beam - search style monolingual dependency parser according to # [SEP]"}
{"pre": "morphological disambiguation there has been a lot of work on arabic pos tagging and morphological disambiguation # otherefr ; # refr. [SEP] ( [SEP]", "cit": "morphological disambiguation there has been a lot of work on arabic pos tagging and morphological disambiguation # otherefr ; # refr. [SEP] [PAD] [PAD]"}
{"pre": "in previous work, we proposed a method that uses participantto - participantto - frame mappings to learn event chains, including all of events, temporal", "cit": "all of the techniques so far proposed for this task share a common sub - task : given an event or partial chain of events, predict other [SEP]"}
{"pre": "we follow # refr in representing zero pronouns in an nptool as a classification task, and their method is further discussed. [SEP]. [SEP]", "cit": "in fact, pos tags given to pre - defined morphemes are useful for applications of morphological analysis, such as dependency parsing # otherefr [SEP]"}
{"pre": "the same claim is made in the spirit of the 2007 english lexical sample task ( propbank ), and the prop [SEP] framenet project ( [SEP]", "cit": "erk and # refr has adopted framenet with good results. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "among others, multilingual content synchronization has been recently proposed as an ideal framework for the exploitation of clte components and the integration of semantics and [SEP]", "cit": "cross - lingual textual entailment # otherefr that consists in deciding, given two texts t and h written in different languages ( respectively [SEP]"}
{"pre": "while natural language processing for english in social media has attracted considerable attention recently # otherefr ; # refr, there has not been much work [SEP]", "cit": "recent work # otherefr ; # refr has proposed lexical normalization of tweets which may be useful as a preprocessing step for the upstream tasks like [SEP]"}
{"pre": "# refr showed that the performance of a parser on edit distance representation. [SEP] parsing accuracy ( transcribed conversational speech. [SEP]. [SEP] % ) is", "cit": "work in statistically parsing conversational speech # refr has examined the performance of a parser that removes edit regions in an earlier step. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "italicized text is used to indicate fragments that are semantically identical. valid intersections that follows the basic framework of previous unsupervised fusion systems # other [SEP]", "cit": "the set - theoretic notions of intersection ( along with union ) have been employed to describe variants of sentence fusion tasks in previous work # refr but [SEP]"}
{"pre": "the second set of features is a hierarchical reranker # otherefr ; # refr. [SEP] the larger space of possible link inference. [SEP]", "cit": "given the current infrastructure, other training methods ( e. g., maximum conditional likelihood or mira as used by # refr ) can also [SEP]"}
{"pre": "one uses confusion network decoding to combine translation systems as described in # otherefr and # refr. [SEP] the source [SEP] to capture two [SEP] the", "cit": "there have been several works by # otherefr ; # refr ; we followed two approaches [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the resulting dependency grammar ( english ) is a very important component of parser that is capable of building a machine translation system for automatically [SEP] [SEP] [SEP] [SEP]", "cit": "we have argued in # otherefr that lfg f - structures can be parsed for in a completely context - free fashion, except [SEP]"}
{"pre": "note that this is analogous to the product model by # refr except that the table 1 can be used. [SEP]. [SEP]. [SEP]. [SEP] filtering", "cit": "training on evaluating on wsj section 22 evaluating on questionbank wsj sections 02 - 21 f1 uas las pos f1 uas las pos [SEP]"}
{"pre": "in text analysis, models of local coherence have been proposed for automatic segmentation of text - to - text segmentation # otherefr ; # refr [SEP]", "cit": "another line of related work is discourse analysis in natural language processing : discourse segmentation # otherefr ; # refr splits a document into a linear [SEP]"}
{"pre": "in recent work, we have implemented a corpus of approximately 38 %'training trees for testing \" parse \" and parse \" [SEP] \" [SEP] [SEP] [SEP]", "cit": "the cutting criteria employed in grammar specialization either require carefully manually tuning, or require more complicated statistical techniques # refr ; automatically derived cutting criteria, however [SEP]"}
{"pre": "in a study of agreement on non - discrete classes, # refr found that the best results were obtained by agreement of disagreement on the perplexity", "cit": "based on previous work # refr, we hypothesized that low - frequency words are associated with subjectivity. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr used noun phrases in the field of automatic keyphrase extraction as a candidate selection. [SEP]ing. [SEP] the two types of [SEP]", "cit": "we propose a new apcaption, footnote, and reference lines. proach, which extracts candidates according to the regular expression rules discussed [SEP]"}
{"pre": "the state - of - theart joint models include reranking approaches # otherefr ; # refr, and single - model approaches # [SEP]", "cit": "they effectively alleviate the error propagation, because segmentation and tagging have strong interaction, given that most segmentation ambiguities cannot be resolved without considering the surrounding [SEP]"}
{"pre": "corresponding manipulations in the form of tree transformations for dependency - based parsers have recently gained more interest # otherefr ; # refr but are [SEP]", "cit": "corresponding manipulations in the form of tree transformations for dependency - based parsers have recently gained more interest # refr but are still less studied, partly [SEP]"}
{"pre": "there has been recent work on extracting semantic class members from the web # otherefr ; # refr ). [SEP] this ( s [SEP] [SEP] [SEP]", "cit": "we then apply bootstrapping # refr on the noun and adjective graphs by selecting 10 seeds for visual and non - visual nouns and adjectives [SEP]"}
{"pre": "with linear run - time complexity, they were commonly regarded as a faster but less accurate alternative to graph - based chart parsers # otheref [SEP]", "cit": "we apply the early update strategy # refr, stopping parsing for parameter updates when the goldstandard state item falls off the agenda. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "hyponymy relations can play a crucial role in various nlp systems, e. g., machine translation # otherefr, and hyper", "cit": "hyponymy relations can play a crucial role in various nlp systems, and there have been many attempts to develop automatic methods to acquire hypo [SEP]"}
{"pre": "the first group ( esv ) of approaches towards predicting the precision on the overall position of correct identification, it [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "examples of technologies which could be applied include semantic role labeling, # refr deep syntactic parsing, # otherefr, in order to obtain a [SEP]"}
{"pre": "paraphrase acquisition is mostly done at the sentence - level, e. g., # otherefr ; # refr, which is [SEP]", "cit": "the techniques proposed have a strong relationship to the type of text corpus used 3this verse from apollinaire? s nuit rhe [SEP]"}
{"pre": "in addition, there are several supervised learning methods which make use of available resources such as parallel data # otherefr, and [SEP] well [SEP] [SEP]", "cit": "in comparison to the early approach of yarowsky et al. # otherefr in which pos are directly transferred, subject to heuristic filtering [SEP]"}
{"pre": "for example, on the wmt 2006 shared task was held at the workshop on statistical machine translation # otherefr and machine translation [SEP] [SEP] [SEP]", "cit": "table 3 : data sets for different language pairs. the wmt 2006 shared task on machine translation # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr use a bayesian network to perform wsd which can be used for parameter estimation, was shown to improve the performance of [SEP] models in table", "cit": "these include a variety of bayesian classifiers # otherefr, and augmented mixture models # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in particular, we plan to use the fntbl database # refr. [SEP] manual annotations, a manually created lexicon for which contains [SEP] [SEP] [SEP]", "cit": "framenet # refr already provides a few small scripts, but does not currently encode the complex scenarios that we would like ; a vastly expanded [SEP]"}
{"pre": "we rescore the lattices with integrated lm - based translation with cube pruning # refr. [SEP] the hypergraph rescoring algorithm, [SEP] the cube -", "cit": "recent work has explored two - stage decoding, which explicitly decouples decoding into a source parsing stage and a target language model integration stage # refr [SEP]"}
{"pre": "this type of model has been used by, among others, # otherefr ; # refr, # otherefr. [SEP] [SEP] [SEP] [SEP]", "cit": "practically all data - driven models that have been proposed for dependency parsing in recent years can be described as either graph - based or transitionbased ( [SEP]"}
{"pre": "this approach was soon followed by other researchers # otherefr ; # refr. [SEP] this problem of learning a reranking framework [SEP] [SEP] [SEP]", "cit": "the challenge of learning translations from monolingual data is of long standing interest, and has been approached in several ways # otherefr ; # [SEP]"}
{"pre": "for instance, using linear combinations # otherefr ; # refra ; albrecht and hwa, 2007b ) or a variety of [SEP]", "cit": "however, some of them measured the reliability of metric combinations in terms of their ability to discriminate between human translations and automatic ones ( human likeness [SEP]"}
{"pre": "online methods # refr, are effective to optimize a small number of parameters. [SEP] the decoder. [SEP] a semi - supervised algorithm. [SEP] a structured", "cit": "# refr improved smt performance by online adaptation of scaling factors # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "to date, rl has been used mainly for learning dialogue policies for slot - filling applications such as restaurant recommendations # otherefr, appointment [SEP]", "cit": "to date, rl has been used mainly for learning dialogue policies for slot - filling applications such as restaurant recommendations # otherefr ; # [SEP]"}
{"pre": "we use the publicly available state - of - theart kernel method described in # refr, which is a component of the ddie [SEP] ( [SEP]", "cit": "the system that we used in this shared task combines various techniques proposed in our recent research activities for relation extraction ( re ) # refr. 1 [SEP]"}
{"pre": "in spoken dialogue systems, the pitch accent structure grammar is defined as a basis for the above, and the structure of the utterance [SEP] l2 \\", "cit": "in # refr, given / new and topic structure are used to control intonational variation. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "daum? e iii and # refr, daume? and # otherefr. [SEP] this work. [SEP] this problem by bayesian [SEP] [SEP]", "cit": "iii and # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "almost all text normalization tasks for languages other than japanese # otherefr, # refr, go et al. # otherefr ) [SEP] [SEP]", "cit": "the social text serves as a very valuable information source for many nlp applications, such as the information extraction # otherefr, summarization [SEP]"}
{"pre": "forest reranking methods have been proposed, which can be averaged to achieve state - of - the - art performance on phrase - structure parsing #", "cit": "to address this, # refr formulated constituency parsing as approximate bottom - up inference in order to compactly represent an exponential number of outputs while [SEP]"}
{"pre": "in recent years, several concerns understanding conferences # otherefr # refr have been proposed. [SEP] the availability of ie. [SEP] text [SEP] [SEP] [SEP]", "cit": "a response to these problems came with the creation of shared tasks, such as the muc [ # refr ] which included a co - reference subt [SEP]"}
{"pre": "# refr compiled a set of 90 unseen adjective - noun bigrams using the same 30 adjective - noun combinations. [SEP] adj [SEP]", "cit": "for the seen adjective - noun bigrams, we used the data of # refr, who compiled a set of 90 bigrams [SEP]"}
{"pre": "for example, the main problem for incorporating long - distance dependencies is that they are more accurate generative models # refr. [SEP] the [SEP] [SEP] [SEP] [SEP]", "cit": "improvements in word - toword alignments were achieved through verb group classification as described in ( de # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the features include : a collection of readability metrics # otherefr, ( dr and # refr. [SEP] the word distribution of [SEP] sentences [SEP]", "cit": "two consistently high - performing systems for this task are the ku # refr and unt # otherefr systems. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use a ibm model 1 # otherefr ; # refr. [SEP] equation ( 5 ) algorithm. [SEP] ( b ) [SEP] [SEP] [SEP] [SEP]", "cit": "most existing techniques for combining multiple alignment tables can combine only two alignment tables at a time, and are based on heuristics # otherefr, [SEP]"}
{"pre": "for instance, # refr have suggested using ilp for dependency parsing in nlp, and dependency parsing # otherefr. [SEP] the inference problem", "cit": "for example, consider a dependency parser that uses the maximum spanning tree algorithm # otherefr or its integer linear program variants # refr to make [SEP]"}
{"pre": "clarke et al # otherefr describe approaches for learning semantic parsers from sentences paired with logical forms # refr. [SEP] a variable model to jointly", "cit": "# refr, wong and mooney # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "previous approaches to the srl task have made use of a full syntactic parse of the sentence in order to define argument boundaries and to determine the [SEP]", "cit": "previous approaches to the srl task have made use of a full syntactic parse of the sentence in order to define argument boundaries and to determine the [SEP]"}
{"pre": "dialogue acts are used to describe the function or role of an utterance in a discourse, and have been applied to the analysis of mediums of [SEP]", "cit": "# refr performed joint parsing and semantic role labelling ( srl ), using the results of a probabilistic srl system to improve the accuracy of [SEP]"}
{"pre": "particularly, the latter made team? 09 task people reference faust? 12 - 3c # otherefr bmi @ asu? 12 [SEP]", "cit": "this paper presents our approach ( referred to as bioevent ) for protein - level complex event extraction, developed for the genia task # refr [SEP]"}
{"pre": "we rescore the lattices with cube pruning # refr and use cube pruning # otherefr with cube pruning. [SEP] the k - best parsing [SEP]", "cit": "recent innovations have greatly improved the efficiency of language model integration through multipass techniques, such as forest reranking # refr, local search # [SEP]"}
{"pre": "in the context of natural language processing ( nlp ), text generation has been used successfully used to such tasks such as paraphrase generation #", "cit": "the model itself, however, does not produce importance scores, i. e., we assume that the scores are produced by a separate process [SEP]"}
{"pre": "as regards i ), recently there has been an increase in the number of papers dealing with nominalized predicates # otherefr # refr # [SEP]", "cit": "automatic, accurate and wide - coverage techniques that can annotate naturally occurring text with semantic argument structure play a key role in nlp applications such [SEP]"}
{"pre": "significant improvements have been made in the field of language processing in general, and improved learning techniques have pushed the state of the art in coreference [SEP]", "cit": "it can seem to be a very hard problem # otherefr or one that is relatively easy # refr. ( iv ) the knowledge bottleneck [SEP]"}
{"pre": "semantic role labeling is the process of annotating the predicate - argument structure in text with se -? this research was partially supported by the ar [SEP]", "cit": "in # refr, we reported on a first attempt to overcome this problem by combining semantic role labels produced from different syntactic parses. [SEP] [PAD] [PAD]"}
{"pre": "# refr used similar crf and svm classifiers to classify sentences in newswire text. [SEP] features of newswire text # otherefr used [SEP] features", "cit": "a misinterpretation of the bioscope paper # otherefr led us to believe that five of the nine full articles in the training data [SEP]"}
{"pre": "to resolve this issue, we propose a new method that leverages the use of semantic similarity to determine the attachment between a candidate relation [SEP] [SEP] [SEP]", "cit": "this is also called semantic integration, e. g., # otherefr, reference grounding, e. g., # refr [SEP]"}
{"pre": "for example, # refr used boosting to train a classifier trained on the wall street journal corpus. [SEP] already annotated with a boosting technique. [SEP] [SEP]", "cit": "although the bagging and boosting techniques have known to be effective for improving the performance of syntactic parsing # refr, in this section we focus on [SEP]"}
{"pre": "most of the previous msc approaches rely on sentence compression or syntactic parsers # otherefr ; # refr. [SEP] the textrank [SEP] the text", "cit": "furthermore, as a standalone sentence compression system it yields state of the art performance, comparable to # refr discriminative model and superior to hedge trim [SEP]"}
{"pre": "leuven # refr, tees - 2. 1 # otherefr. [SEP] kernel expansion # otherefr. [SEP] kernel [SEP] [SEP] [SEP]", "cit": "final results on test data on submission of the output from the test data, our system achieved a slot error rate ( ser ) of 0. [SEP]"}
{"pre": "this method, described in # refr, was used to create 30 % of documents for the training material, and test sentences. [SEP] [SEP] [SEP] [SEP]", "cit": "early efforts to perform automatic topic segmentation of speech input without the aid of asr systems have been promising # refr, but have yet to exploit [SEP]"}
{"pre": "we have used the idea of an existing taxonomy to extract collocations such as thesaurus acquisition # otherefr and network [SEP] dictionary senses #", "cit": "this latter aspect is not implemented yet, but will be added in the future, as it is a necessary component for easy navigation # refr. [SEP]"}
{"pre": "we use bleu # refr as the geometric mean of the n - gram precisions in the ibm model 4 and bleu [SEP] the [SEP] [SEP]", "cit": "in our experiments, weights are tuned towards uncased bleu # refr or the combined metric ter - bleu # otherefr. [SEP] [PAD]"}
{"pre": "the english and the czech data are from the 2003 naacl shared task # refr. [SEP] the phrase table including the log - linear combination [SEP] [SEP]", "cit": "for the latter case, the extensions concerning the language model heuristics similar to ( vilar and # refr have also been included. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "following evaluations in machine translation as well as previous work in sentence compression # otherefr ; # refr, we evaluate system performance using f metrics [SEP]", "cit": "a number of diverse approaches have been proposed for deletion - based sentence compression, including techniques that assemble the output text under an n - gram factorization [SEP]"}
{"pre": "id participant cmu carnegie mellon university # otherefr cu - bojar charles university - bojar # refr cu - dep [SEP]", "cit": "metric ids participant amber national research council canada # otherefr meteor cmu # refr sagan - sts famaf, unc, argentina [SEP]"}
{"pre": "we only describe a new application of a hpsg grammar and that is implemented in the ltag project # refr. [SEP] system [SEP]a [SEP] [SEP]", "cit": "the two core phases are the tree selection and 2a more detailed escription iscontained in # refr. the combination phase. [SEP] [PAD]"}
{"pre": "we also plan to experiment with bayesian methods that utilize information extracted from documents # otherefr ; # refr. [SEP] ( 1 ) [SEP] [SEP] [SEP]", "cit": "# refr studied the impact of query types on summary length of search results. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used the same split as # refr. [SEP] ( w ) = p ( w | w )? [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "although large amounts of unlabeled data are known to improve semi - supervised parsing # refr, the best unsupervised systems use less data than is available for [SEP]"}
{"pre": "the model we use is similar to that of # refr. [SEP] the conditional probability of a certain lexical functional grammar is a derivation ; as described in", "cit": "the second approach # otherefr ; # refr defines the probability of a parse tree as the probability that a certain shiftreduce stochastic parsing automaton [SEP]"}
{"pre": "to address this, anaphoricity determination has been the two main subtasks of coreference resolution : i ) local and global re [SEP] ( e", "cit": "recently, anaphoricity determination has been evaluated in the context of coreference resolution, with results showing that training an anaphoricity classifier to [SEP]"}
{"pre": "in # refr, a shallow nlg system is discussed in. [SEP] ( a 2 ) for both input and a shallow semantic grammar [SEP] [SEP] [SEP]", "cit": "tg / 2 has been described originally in [ busemann, 1996 ; # refr ] as a template - based generator. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we incorporate all our new features into a linear model and learn weights for each using the online averaged perceptron algorithm # otherefr with a [SEP]", "cit": "we used mira # refr to learn the feature weights. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used the kenlm toolkit # refr to train a 5 - gram language model on the target language model score. [SEP] [SEP] [SEP] [SEP] the [SEP]", "cit": "table 17 : counts of unique n - grams ( m for millions ) for the 5 orders in the unconstrained language model the large language model was [SEP]"}
{"pre": "# refr used the notion of semantic relatedness between words in a graph to measure of word similarity in two concepts : for the comparison of their relatedness.", "cit": "unlike some approach like # refr, which performs well on some datasets but poorly on others, combing the vsms from heterogeneous sources is more [SEP]"}
{"pre": "we used the l - bfgs optimisation algorithm # otherefr, which converges fast training of l1 (? a1 ) l2,", "cit": "a detailed description of crfs can be found in # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "first, the effects of selectional preferences has been well studied # otherefr ; # refr. [SEP]. [SEP] this work has shown that [SEP]", "cit": "recently, # refr presented a model of eye movement control in reading that directly models the process of identifying the text from visual input, and makes [SEP]"}
{"pre": "in a similar spirit, # refra ) applied the techniques on pubmed citation text and has been shown to be an efficient shift - reduce [SEP] retrieval", "cit": "exceptions include work by van durme and lall # otherefr and # refr, aimed at different problems than that explored here. [SEP] [PAD]"}
{"pre": "to find the optimal parse, we used the self training set, which was trained on the wsj section of the penn treebank and use it", "cit": "the approaches proposed by # refra ) and sagae and tsujii # otherefr can be classified as ensemble? based methods. [SEP]"}
{"pre": "we show that the model for both tasks, such as syntactic parsing # otherefr, and lexicalized pcfg parsing ( unlexicalized", "cit": "we viewed this as equivalent to the more elaborate, smoothed unknown word models that are common in many pcfg parsers, such as # other [SEP]"}
{"pre": "# refr suggested that mt metrics can increase the performance of the search task of mt systems. [SEP] a minimum error rate training procedure. [SEP] the [SEP]", "cit": "we suspect that the newer rypt metric # refr, which directly makes use of human adequacy judgements of substrings, would obtain better human [SEP]"}
{"pre": "most previous work on bilingual lexicon induction focuses on several language pairs, including : french - english # otherefr, # refr, wikipedia [SEP] [SEP]", "cit": "most previous approaches that address bilingual lexicon extraction from comparable corpora are based on the standard approach # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "we can compute this expectations that maximizes the expected in the hypothesis space, we can often use as a dynamic programming ( li and # refr. [SEP]", "cit": "in combination with appropriate semirings, these packed representations can be exploited to compute many values of interest for machine learning, such as best parse [SEP]"}
{"pre": "# refr use visual features for capturing topic models, and predict the contribution of twitter messages. [SEP] the documents by incorporating topic model into [SEP] features into", "cit": "some efforts have tackled tasks such as automatic image caption generation # otherefr, or automatic location identification of twitter users # refr. [SEP]"}
{"pre": "in addition, while the system described in # refr does not perform well on the wsj corpus. [SEP] ( 1 ) it [SEP] ), [SEP]", "cit": "we experiment with four learners commonly employed in language learning : decision list ( dl ) : we use the dl learner as described in # refr, [SEP]"}
{"pre": "in contrast, # refr use statistical parsers to induce a parse of childes with a set of childes on their [SEP] features, [SEP] assumptions", "cit": "in this and all following tables, traditional developmental metrics are shaded. been implementations of completely automated assessments of ipsyn # refr and d - level [SEP]"}
{"pre": "artificial ungrammaticalities have been used in various nlp tasks # otherefr the idea of an automatically generated ungrammatical treebank [SEP]", "cit": "various strategies exist to build robustness into the parsing process : grammar constraints can be relaxed # otherefr, the input sentence can itself be transformed [SEP]"}
{"pre": "we follow the approach of using goldwasser and roth, 2003 ; # refr. [SEP]a ; zhu et al., 2010b ) [SEP]", "cit": "along this line, recent work by # refr and liang et al # otherefr relax supervision to require only annotated answers rather than full logical [SEP]"}
{"pre": "for instance, # refr show that the mwes in the chunking task can be seen as a verb - prepositional phrase attachment. [SEP]", "cit": "several other researchers have proposed a number of computational techniques that deal with the discovery of mwes : # refr for verb - particle constructions, pear [SEP]"}
{"pre": "in a first step, we use a feature set of language pairs to predict strings # otherefr ; # refr. [SEP] features [SEP] [SEP] [SEP]", "cit": "this issue has been addressed by recent work that shows that current natural language processing techniques can be applied to automate the computation of these metrics, [SEP]"}
{"pre": "for instance, the field of statistical parsing has been a long tradition of natural language processing # otherefr ; # refr. [SEP] this approach is", "cit": "like the methods developed by # refr and cortes et al # otherefr our technique incorporates finite automata, but uses a direct thresholdcount [SEP]"}
{"pre": "most attempts to perform this task have engineered various feature sets, augmenting words with topic or content models # otherefr ; # refr, [SEP]", "cit": "pang and lee # otherefr discusses the large range of features engineered for this task, though several recent studies focus on feature learning # [SEP]"}
{"pre": "in this senseval - 2, the best performing system # refr achieved an accuracy of 69. 4 %. 41 %. [SEP] research [SEP] the", "cit": "the idea of using supervised machine learning for wsd is not new and was used for example in ( ng and # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "we use the stanford part - of - speech tagger # refr to identify the text that contain all words that are grammatical and then used to perform", "cit": "we use mxterminator # otherefr to split sentences in the captions ( in many instances, nothing is done in this step bec [SEP]"}
{"pre": "we use minimum error rate training # refr to tune the feature weights to maximize the system? s bleu score on development set, to optimize the", "cit": "the recent advances in statistical machine translation have been achieved by discriminatively training a small number of real - valued features based either on # otheref [SEP]"}
{"pre": "for example, forest reranking # otherefr ; # refr is commonly used in parsing. [SEP] the forest reranking. [SEP] [SEP]", "cit": "as a derivation of the forest reranking for parsing # refr, this strategy reranks on the pruned word lattice, which potentially [SEP]"}
{"pre": "in line with several participants of the sts 2012 challenge, such as # otherefr ; # refr, sts is here modeled as a support [SEP]", "cit": "it is the same task proposed in # refr.? the typed - similarity sts task : given two semi - structured records t1 and t [SEP]"}
{"pre": "several recent papers # otherefr ; # refr use syntactic constraints on the target annotations obtained from the web. [SEP] textual information [SEP] [SEP] the [SEP]", "cit": "two example systems implementing this paradigm are textrun - ner # otherefr and reverb # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "another approach, which we may consider in the future, would be to annotate a small subset of the training examples with full ccg derivations [SEP]", "cit": "recently, there has been a burgeoning interest in developing machine - learning approaches for semantic parsing # otherefr ; # refr, but [SEP]"}
{"pre": "we used the dataset by # refr. [SEP] the opinion polarity ( objective ) of subjectivity and polarity ) sentences of documents. [SEP] subjectivity [SEP]", "cit": "following # refr, who used word and bigram features to model an author? s sentiment, and kogan et al # otherefr [SEP]"}
{"pre": "we use a syntactic dependency parser # refr. [SEP] english ( dependency ) to train a dependency parser on the penn treebank [SEP] dependency trees of each", "cit": "semantic role labeling received considerable attention in the conll shared tasks for syntactic dependency parsing in 2006 and 2007 we also ran maltparser by training [SEP]"}
{"pre": "neural language models # otherefr # refr. [SEP] this representation of neural network language models ( rnn ) for machine translation, [SEP] [SEP] [SEP]", "cit": "feedforward nnlms # otherefr ; # refr and recurrent nnlms # otherefrb ) have been shown to yield both per [SEP]"}
{"pre": "so far, cross - lingual textual entailment # otherefr, and ii ) machine translation evaluation datasets # refrb ). [SEP] textual", "cit": "so far, cross - lingual textual entailment # otherefr, and ii ) machine translation ( mt ) evaluation datasets # refr. [SEP]"}
{"pre": "the work of # refr is also somewhat related to our work. [SEP] this approach to attempts to automatically induce hyponyms from corpora. [SEP] text", "cit": "as a way of moving towards this result, our motivating observation is a simple one, and one that has been explored in other areas ( see [SEP]"}
{"pre": "the standard approach can be applied to comparable corpora with a small number of languages rather than english words, and it is plausible for many other languages #", "cit": "the implementation of the standard approach can be carried out by applying the following three steps # refr ; chiao and zweigenbaum, 2002 ; [SEP]"}
{"pre": "the smt system was tuned on the newstest10 with minimum error rate training ( mert ) # refr using the bleu # otheref", "cit": "we aligned words in our parallel data using the widely used tool giza + + # refr ; however, the standard growing heuristic resulted in very [SEP]"}
{"pre": "paraphrase generation has been addressed related, for example, by others have been proposed to tackle the task of paraphrase generation # otheref", "cit": "paraphrasing has attracted a growing interest from the research community in a broad range of tasks such as language generation # refr, machine translation # [SEP]"}
{"pre": "in order to extract paraphrases, # refr proposes to be more general than others, external knowledge, such as the contexts source for the target", "cit": "then grammar rules for morphological disambiguation, syntactic parsing and noun phrase detection are applied based on finite - state automata technology, kurd # refr [SEP]"}
{"pre": "this result suggests that the models of word meaning are highly related to the main focus on the task of lexical substitution # otherefr, and has", "cit": "# refr propose an exemplar - based approach, in which the meaning of a word in context is represented by the activated exemplars that are [SEP]"}
{"pre": "in the? news 2009 machine transliteration shared task?, an approach modeled after the joint n - gram language model, which achieved the best", "cit": "although joint modeling has shown to be effective in various nlp and computer vision applications # otherefr ; # refr, our choice of using [SEP]"}
{"pre": "in this paper, we show that the proposed parser is based on the simple ( non - recursive, even 3 ), the parser of clark and", "cit": "unfortunately the number of possible derivations grows exponentially with the length of the sentence, and computing the exact mpp is np - hard # refr. [SEP]"}
{"pre": "while reranking has benefited many tagging and parsing tasks # otherefr including semantic role labeling # refr, it has not yet been [SEP]", "cit": "scissor is implemented by augmenting # refr head - driven parsing model ii to incorporate the generation of semantic labels on internal nodes. [SEP] [PAD]"}
{"pre": "we used the swedish treebank as the output of the conll 2009 shared tasks # refr. [SEP] this graph to [SEP] the passive - [SEP] training", "cit": "several state - of - the - art statistical parsers, including mate - tools # refr, berkeleyparser # otherefr are used [SEP]"}
{"pre": "we employ the second - order crf - based model of # refr, which is an extension of monolingual ddd algorithm for bilingual [SEP] languages.", "cit": "our experimental setup is the same as # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the second order edgefactored representation is the first introduced by # refr, which computes the score of arcs in the representation of a graph defined over", "cit": "the motivation for this graph expansion step is similar to that motivating the move from first - order to higher - order dependency path feature types ( e [SEP]"}
{"pre": "cavnar? s part of speech ( pos ) tagger # refr and the freely available cross - lingual lexical sample ( which is based on", "cit": "adams and resnik # refr describe a client - server system using dunning? s n - grams based algorithm # otherefr for a [SEP]"}
{"pre": "in recent years, several dialogue systems have been developed # otherefr ; # refr. [SEP] this approach improves dialogue performance. [SEP] this [SEP] [SEP]", "cit": "many researchers have tackled this problem by developing asr confidence measures based on utterance - level information and dialogue - level information # otherefr [SEP]"}
{"pre": "the features are the same as those in # refr. [SEP] the hierarchical lexicalized reordering model of tillmann and zhang # otherefr [SEP]", "cit": "these clusters mirror parts - of - speech quite effectively # refr, without requiring linguistic resources. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "mst # refrb ) and transition - based # otherefr dependency parsing models are based on both languages, and suffer from this type of dependency", "cit": "parsers for graph - based parsers, we used the projective first - order ( mst1 ) and secondorder ( mst2 ) variants [SEP]"}
{"pre": "2. 2. 1 phrase table training we used the publicly available pharaoh decoder # refr to translate the english into training and learn [SEP] [SEP]", "cit": "2. 1. 3 phrase model training for some pbt systems a forced alignment procedure was applied to train the phrase translation model as described in [SEP]"}
{"pre": "there have been many studies on efficient tweetnlp tool # otherefr ; # refr, sentence processing based. [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "feature description lexical - word count - degree of polysemy average number of wordnet senses per word - mean word length average number of characters [SEP]"}
{"pre": "we use the giza + + toolkit # refr to estimate the alignment probabilities. [SEP]. [SEP] bleu points # otherefr placed [SEP] [SEP]", "cit": "this idea was previously proposed by # otherefr ; # refr although the the objectives differ. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "to date, evaluations of automatic compressions have been # otherefr ; # refr, and statistical machine translation # otherefr. [SEP] the", "cit": "indeed, a variety of models have been successfully developed for this task ranging from instantiations of the noisy - channel model # otherefr ; [SEP]"}
{"pre": "# refr used a semi - supervised lexicalized parser to parse unknown words in the grammar. [SEP] well. [SEP] phenomena they use the morphological [SEP] subject", "cit": "the goal of the la method we describe # refr is to assign correct lexical type ( s ) to a given unknown word. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "similar to the tasks of wide - coverage parsing # otherefr ; # refr, it is related to our work. [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "work on employing packing techniques not only for parsing and transfer, but also for generation and stochastic selection is currently underway ( see # refr ). [SEP]"}
{"pre": "li and # refr report significant improvements in translation quality. [SEP] the ibm model 4 for machine translation, and show that this simple lm yields stateof", "cit": "it is therefore desirable to have dedicated servers to load parts of the lm3? an idea that has been exploited by # otherefr ; [SEP]"}
{"pre": "they introduce a novel hybrid approach to ner model named entity recognition # otherefr ; # refr. [SEP] the whole of a twitter sequence for [SEP]", "cit": "the social text serves as a very valuable information source for many nlp applications, such as the information extraction # otherefr, summarization [SEP]"}
{"pre": "in addition, we also show that the model described in detail by # refr is an svmtool5 # otherefr can be applied to", "cit": "stress is an attribute of syllables, but syllabification is a non - trivial task in itself # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr and rooth et al # otherefr describe a model that allows separating the task of noun - noun morphology of verb and the base", "cit": "a sel ) arate paper # refr looks in detail at the model is performance for particular categories of mori ) hology, in particular, [SEP]"}
{"pre": "for instance, the current state - of - the - art resources such as wordnet # otherefr, framenet # refr or berkeley frame", "cit": "in rule 14, we use framenet # refr to determine whether med / situation should be assigned to an np, npi. [SEP] [PAD] [PAD]"}
{"pre": "this is in contrast to the basic idea of using transfer rules, for example, in the target language transfer system as well as translation units # refr", "cit": "it has already been shown # refr that a head transducer model with hand - coded structure can be trained to give better accuracy than a comparable transfer [SEP]"}
{"pre": "this model is similar to the one described in # refr. [SEP]. [SEP] ( 1 ) is a data structure that is a two - stage sentence", "cit": "we parse the test data with an unlabelled projective dependency parser # refr and drop the order information to obtain the input to our sentence realiser [SEP]"}
{"pre": "in the rst discourse treebank ( rst - dt ) # refr, the penn discourse treebank # otherefr are used to model [SEP] [SEP]", "cit": "to demonstrate the functionality of our system without relying on still imperfect discourse parsing, we use the rst - parsed wall street journal corpus as input [SEP]"}
{"pre": "in this paper we report on the reranking domain adaptation task # otherefr and # refr. [SEP] the approach of using the rerank", "cit": "some work done on domain adaptation could be applied to genre adaptation, such as incorporating available in - domain corpora in the smt model : either [SEP]"}
{"pre": "we can use approximate decoding # refr with a dp - based decoder that can be used for decoding. [SEP] if the search space of scfg does", "cit": "the algorithms are central to large - scale machine translation systems due to their efficiency and tendency to produce high - quality translations # otherefr ; [SEP]"}
{"pre": "brown clustering has been used extensively in supervised nlp tasks such as parsing # otherefr, dependency parsing # refr, question answering # other [SEP]", "cit": "however, only immediately adjacent words are taken into account as recognized e. g. by # refr, sagae and gordon # otherefr [SEP]"}
{"pre": "# refr use latent semantic analysis to find synonym relatedness between terms. [SEP] documents. [SEP] documents. [SEP] the documents in a document. [SEP] [SEP]", "cit": "we proposed to use low dimensional term vectors for inducing the translation probabilities between terms # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refrb ) and chan et al. # otherefr smt system, respectively. [SEP] the wsd problem of wsd [SEP] [SEP]", "cit": "independent of these lexical substitution tasks, the connection between word senses and word translation has been explored in chan et al # otherefr and # [SEP]"}
{"pre": "in this paper, we focus on the particular system of # refr. [SEP] a new features on the single reference and rerank [SEP] the [SEP] [SEP]", "cit": "various algorithms have been applied for reranking in nlp applications # otherefr ; # refr, including parsing, name tagging and machine [SEP]"}
{"pre": "we used an off - the - shelf system, called reverb # refr, a relation extractor for relation extraction. [SEP] text [SEP] [SEP] [SEP]", "cit": "many other previous work have been proposed to construct a knowledge base, including relation expressions # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the berkeley framenet project # refr has been developing a lexicon for english and chinese, and a lexicon that has been built around [SEP] [SEP] [SEP] [SEP]", "cit": "one of the most popular, semantic role labels # otherefr or those predicates that are part of particular semantic frames # refr. [SEP] [PAD] [PAD]"}
{"pre": "this paper describes a simple yet novel method for constructing correspondences in charniak # otherefr, # refr. [SEP] - [SEP] [SEP] [SEP] [SEP]", "cit": "we will not describe the last two layers ( see # refr for a description of the phrase structure algorithm ), but will briefly describe the word [SEP]"}
{"pre": "shift - reduce parsing applies naturally to ccg # refr, and the left - to - right, incremental nature of the training. [SEP] the [SEP]", "cit": "in addition, high accuracy can be maintained by using a model which utilises a rich set of features for making each local decision # refr. [SEP]"}
{"pre": "however, such features are beneficial for a number of coreference systems, including some of lexical features, syntactic features # otherefr ; # refr", "cit": "state - of - the - art approaches include both learningbased # otherefr ; # refr and deterministic models # otherefr. [SEP] [PAD]"}
{"pre": "li and # refr report that despite the availability of a sentence - aligned parallel corpus in both languages. [SEP] ( english and chinese ) [SEP] [SEP] [SEP]", "cit": "we further evaluated our alignments in an end - toend chinese to english translation task using the publicly available hierarchical pipeline joshua ( li and # [SEP]"}
{"pre": "we use the standard split of ctb 5. 0 as in several tasks, since it is fast and much less than [SEP] research [SEP] [SEP] [SEP]", "cit": "following # refr, we split the chinese treebank 5 into training set, development set and test set. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "a joint probability model was first introduced by # refr. [SEP] the probability mass on the target side of a bilingual corpus. [SEP] a word [SEP] a", "cit": "in recent years, various phrase translation approaches # refr have been shown to outperform word - to - word translation models # otherefr. [SEP] [PAD]"}
{"pre": "for example, the main task of anaphora resolution is that it is that coreference resolution is a critical component of many nlp applications, including", "cit": "one of the reasons for the low recall is because target anaphoric pronouns in the bio domain are neutralgender and third - person pronouns [SEP]"}
{"pre": "in the second experiment, the boundary detection is often pairs as the training data of the observed known as the observed vocabularies # otherefr", "cit": "another common practice is to introduce some statistics - based measures, such as boundary entropy # refr and accessor variety # otherefr, which [SEP]"}
{"pre": "probabilistic models are trained by means of integer linear programming # otherefr or # refr. [SEP] - 1 i log - linear models are [SEP] [SEP]", "cit": "discriminative log - linear models are now becoming a de facto standard for probabilistic disambiguation models for deep parsing # otherefr ; # refr [SEP]"}
{"pre": "we used bootstrap resampling # refr to measure significance on the mixed test set, and estimate for each n - gram lm. [SEP] the [SEP] [SEP]", "cit": "differences of more than 0. 51 bp are statistically significant at the 0. 05 level using bootstrap resampling # otherefr ; # refr [SEP]"}
{"pre": "in # refr, we proposed a model based on a standard maximum entropy model, which is based on the? grow - diag - final? [SEP]", "cit": "we also train a class - based language model # refr on two million english sentences selected from the parallel corpus. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used a version of the semantic similarity measure described in # refr. [SEP] the wordnet hierarchy to count whether a word is a noun or not", "cit": "se? # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this idea has been developed and applied to a wide variety tasks, including morphological analysis # otherefr ; # refr. [SEP] ( [SEP] ) [SEP]", "cit": "for example, several early works # otherefr ; # refr demonstrate transfer of shallow processing tools such as part - of - speech taggers [SEP]"}
{"pre": "in this paper, we take a similarity measure ( lin? s? # refr and lin ( s? # otherefr ) as the [SEP]", "cit": "we generated two co - occurrence models using window sizes? 1 and? 4 because we observed different natures of the models.? 1 window [SEP]"}
{"pre": "the spell checking metaphor # otherefr ; # refr is also used as a preprocessing step to detect word type and grammatical error detection. [SEP]", "cit": "# refr use finite state methods to perform french sms normalisation, combining the advantages of smt and the noisy channel model. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "in addition, before the cohesion of the head - dependent phrasal cohesion, the tree transducer of # refr, and is the tree - to -", "cit": "several studies have reported alignment or translation performance for syntactically augmented translation models # otherefr ; # refr and these results have been promising. [SEP]"}
{"pre": "by contrast, explicit syntax approaches seek to directly model the relations learned from parsed data, including models between source trees and target trees # other [SEP]", "cit": "approaches include word substitution systems # otherefr, phrase substitution systems # refr, and synchronous context - free grammar systems # otherefr, [SEP]"}
{"pre": "the features include : a maximum sentence length of 80, grow - diag - final - and symmetrization of giza + + alignments, [SEP]", "cit": "we calculate our features using the kenlm toolkit # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the use of such techniques can be found in # otherefr ; # refr. [SEP] the agglomerative clustering algorithm, which improves the [SEP]", "cit": "nevertheless, the full document text is present in most systems, sometimes as the only feature # refr and sometimes in combination with otherssee for instance [SEP]"}
{"pre": "in the field of statistical parsing, various probabilistic models have been proposed where different models use different models use different models use different models, such as hidden", "cit": "in this form, the distinction between our two models is sometimes referred to as? joint versus conditional? # refr rather than? generative versus discriminative [SEP]"}
{"pre": "in pos tagging, some studies using pos tags were tested by # otherefr ; # refr for pos tagging. [SEP] rel renaming [SEP] [SEP]", "cit": "in addition, we used the conll2009 data sets with the training, development, and test splits used in the shared task # other [SEP]"}
{"pre": "we used the algorithm of # refr to create a dependency parser. [SEP] the information of the dependency relations. [SEP] the wordnet similarity [SEP] the [SEP]", "cit": "for the thesaurus construction we used < verb, case, noun > triplets extracted from japanese newspaper articles # otherefr ) [SEP]"}
{"pre": "# refr use graph - based attribute selection algorithm to select relations among them. [SEP] the attributes of decision trees. [SEP] [SEP] [SEP] [SEP] the expressions.", "cit": "dutch data were taken from the d - tuna corpus ( koolen and # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "corresponding manipulations in the form of tree transformations for dependency - based parsers have recently gained more interest # otherefr ; # refr but are [SEP]", "cit": "this can be seen in state - of - the - art constituency - based parsers such as collins # otherefr, and # [SEP]"}
{"pre": "particularly, the latter made team? 09 task people reference faust? 12 - 3c # otherefr ccp - btmg? [SEP]", "cit": "detection of negation cues and negation scope at conll # otherefr, bionlp # refr and the negation and speculation in nlp [SEP]"}
{"pre": "to capture lexical information, we follow # refr and use maximum entropy based lexicalized reordering model to predict the shift - reduce [SEP] features. [SEP]", "cit": "in particular, we integrate the models into a phrase - based system which uses bracketing transduction grammars # otherefr for phrasal translation # [SEP]"}
{"pre": "# refr proposed a method that uses distributional similarity to these properties. [SEP] the order of word vectors. [SEP] the similarity of two words. [SEP] the", "cit": "some used # otherefr ; # refr ; the others utilized only part of speech information, e. g., widdows # [SEP]"}
{"pre": "furthermore, since research in the related task of sentence compression has benefited from the availability of training data # otherefr ; # refr, [SEP]", "cit": "previous work does produce some examples written by humans, though these are used during evaluation, not for learning ( a large corpus of fusions # [SEP]"}
{"pre": "a similar approach has been advocated for gender attribution in social media such as gender classification # refr, where the gender is to annotate twitter messages [SEP]", "cit": "researchers such as # refr have considered this point, but by comparing the classification accuracy based on the volume of batch data available per author ( in [SEP]"}
{"pre": "binarization choice can also improve parsing efficiency # refr. [SEP] ( ctb ). [SEP] ( ctf ) [SEP] ( ctf ) [SEP]", "cit": "please refer to # refr for more details. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this was overcome by a probabilistic model which provides probabilities of discriminating a correct parse tree among candidates of parse trees in a log - linear model or [SEP]", "cit": "this was overcome by a probabilistic model which provides probabilities of discriminating a correct parse tree among candidates of parse trees in a log - linear model or [SEP]"}
{"pre": "in this paper, we apply a dynamic programming algorithm # refr to extract parallel sentences from a aligned parsed parallel corpus. [SEP] ( 1 ) [SEP]", "cit": "in the field of machitm translation, there is a, growing interest in corl ) lls - i ) ased al ) [SEP]"}
{"pre": "in the field of eomputationa. 1 linguistics, mutual information \\ [ # refr \\ ],? 2 \\ [ church and [SEP]", "cit": "as mentioned above, the mdi2b model is closely related to the ibm2 model # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for example, in the japanese text is a simplified version of japanese morphological analyzer # refr, where a morphological analyzer is used to [SEP] the expressions of", "cit": "in order to organize many different variants of functional expressions, we have designed a morphological hierarchy with nine abstraction levels # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "stsg grammar rules contain pairs of tree fragments called elementary trees # otherefr ; # refr. [SEP] this formalism ; cohn et [SEP] [SEP]", "cit": "we compared the gibbs sampling compressor ( gs ) against a version of maximum a posteriori em ( with dirichlet parameter greater than 1 ) and a [SEP]"}
{"pre": "the most common approach to deriving dependency relations for parses has been to reranker # refr. [SEP] the [SEP] of the [SEP] linguistic structure of", "cit": "the difference between depeval # otherefr applied to the output of the reranking parser of # refr, whereas in be # [SEP]"}
{"pre": "this is a widespread approach in mt system combination # otherefr ; # refr ; confusion networks were used. [SEP] if they depend on positional information", "cit": "this is a widespread approach in mt system combination # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in recent years, nombank # otherefr, nombank # refr, nombank # otherefr have been used to train a [SEP]", "cit": "nominal srl also typically draws on feature sets that are similar to those for verbs, i. e., comprising mainly syntactic and lexical - [SEP]"}
{"pre": "it performs cubic time parsing for arc - factored models # otherefr ; # refra ) and biquadratic time for higher order [SEP]", "cit": "penn - ym penn - s ctb - 5 parser uas las toks / sec uas las toks / sec uas las toks / [SEP]"}
{"pre": "machine translation # otherefr ; van # refr ; or as an application which can use the predictions of wsd systems developed for semeval", "cit": "a completely different approach is taken by the nrc - smt system # refr, that uses a statistical machine translation approach to tackle the cl [SEP]"}
{"pre": "we use pointwise mutual information ( pmi ) # refr to weight the contexts, and select the top 1000 pmi contexts for each query [SEP]", "cit": "the mutual information between two terms # refr can be calculated using equation 2. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "motivated by the phrase pair extraction methods of smt # otherefr, we focus on the connected components, or simply components, [SEP] [SEP] [SEP]", "cit": "we evaluate the translation quality using case - insensitive bleu metric # otherefr without dropping oov words, and the feature weights are tuned [SEP]"}
{"pre": "nonparametric bayesian methods produce state - of - the - art performance on this task # otherefra ; # refr. [SEP] the [SEP] [SEP] [SEP] [SEP]", "cit": "one line of research uses np bayes methods on whole tree structures, in the form of adaptor grammars # otherefra ; # refr, in [SEP]"}
{"pre": "we use a sentence segmentation program # otherefr and a pos tagger # refr to segment the tokens surrounding into sentences. [SEP] the text [SEP]", "cit": "our first model ( ma - me ) is based on disambiguating the ma output in the maximum entropy ( me ) framework # refr. [SEP] [PAD]"}
{"pre": "for the non - projective parsing, we use a discriminative reranker, which is a simple technique originally introduced by # refr and used the [SEP]", "cit": "reranking the output of a k - best parser has been shown to improve upon the best results of a stateof - the - art [SEP]"}
{"pre": "we parse the data with the collins parser # refr. [SEP] this framework : t. [SEP] the word sequence, t, the pos - tags [SEP]", "cit": "in order to objectively evaluate our representation, we derived it from two different sources : constituency parse trees ( generated with our implementation of # refr [SEP]"}
{"pre": "this can be used to train a word aligner # otherefr and monolingual lexicalized tree adjoining grammar ( ltag ) #", "cit": "measures of cross - language relatedness are useful for a large number of applications, including cross - language information retrieval # otherefr ; # refr [SEP]"}
{"pre": "in the context of machine translation, it is often difficult to translate sentences that contain many factors, such as pronominalison # otherefr", "cit": "systematic research into explicitly discourse - related problems has only begun very recently in the smt community # otherefr with work on topics such as [SEP]"}
{"pre": "in contrast, most previous work on sentiment analysis in social media does not consider these kinds of problems # otherefr ; # refr [SEP] [SEP] [SEP]", "cit": "prior work on subjectivity analysis mainly consists of two main categories : subjectivity of a phrase or word is analyzed regardless of the context # other [SEP]"}
{"pre": "the similarity between two words can be computed using a similarity measure in distributional similarity # refr. [SEP]. [SEP] the cosine ( w2 ) in [SEP]", "cit": "when the context profiles are probability distributions, we usually utilize the measures on probability distributions such as the jensen - shannon # otherefr ; # [SEP]"}
{"pre": "the event annotation extended the guidelines and the ge - nia annotation guidelines # otherefrb ; # refr. [SEP] a cross - validation framework [SEP]", "cit": "table 1 : effect of the type generalisations for expanding possible instances # otherefr using the models with the same configuration for seven other available [SEP]"}
{"pre": "# refr used semisupervised learning to train a semi - supervised crf model, which is closely related to word segmentation features and pos tagging. [SEP] features", "cit": "several other variants of crf model has been proposed in the machine learning literature, such as the generalized expectation method # otherefr, which introduce [SEP]"}
{"pre": "in the domain of machine learning, several nlg systems have been applied to the task of natural language generation # otherefr, and to [SEP]", "cit": "systems can plan such choices with a model of dialogue dynamics that predicts which utterances will fulfill communicative goals successfully and efficiently # otherefr ; # [SEP]"}
{"pre": "in this paper, we propose an approach to solve this problem, using the algorithm presented in # refr. [SEP] the algorithm. [SEP] the algorithm of", "cit": "ambiguity is the task of building up multiple alternative linguistic structures for a single input # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in # refr, pre - ordering is cast as a permutation problem and solved by a model that estimates the probability of reversing the relative order [SEP]", "cit": "a well - known strategy consists of preordering the german sentence in an english - like order by applying a set of manually written rules to its [SEP]"}
{"pre": "in a proposal of the treatment of ellipsis # otherefr ; # refr, the antecedents of the quantifier scoping [SEP] already [SEP]", "cit": "vp ellipsis has received a great deal of attention in theoretical and computational linguistics # otherefr ; # refr ; dalrymple, [SEP]"}
{"pre": "we use a model based on the graph representation of # refr, which considers the importance of a document as a sentence. [SEP] a representation of the", "cit": "earliest such work relied on tf * idf weights # refr, later approaches included heuristics to identify summary - worthy bigrams # otheref [SEP]"}
{"pre": "several approaches have been proposed to address this problem, including semi - supervised learning # otherefr ; # refr, multi - sequence labeling # other", "cit": "the problem of producing multiple sequence alignment, especially in the context of sentence alignments, has been extensively studied in nlp # refr. [SEP] [PAD] [PAD]"}
{"pre": "furthermore, we use features that are inspired by recent work in statistical natural language generation # refr. [SEP] those proposed by hebrew # other [SEP]", "cit": "another thread investigates snlg scoring models trained using higher - level linguistic features to replicate human judgments of utterance quality # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "textrank # refr is a graph - based ranking model that takes as input text and uses pagerank as features to compute the ranking model. [SEP]", "cit": "textrank # refr, # otherefr is specifically designed to address this problem, by using an extractive summarization technique that does not [SEP]"}
{"pre": "the spoken language translator ( speech ) tool # refr is a spoken language translator that is a spoken language translator that allows for the user", "cit": "these points will be discussed in the context of the spoken language translator ( slt ) ( rayner, # refr, a customizable [SEP]"}
{"pre": "we use mxpost tagger # refr and the freely available crf - based tagger for english and chinese. [SEP] english [SEP] the crf [SEP] the", "cit": "the chinese text was tagged using the mxpost maximum - entropy part of speech tagging tool # refr trained on the penn chinese treebank 5. [SEP]"}
{"pre": "in a related paper # refr, we present a general approach to identifying paraphrases. [SEP] adjectives that are general, in general, although", "cit": "this type of similarity is reminiscent of relational analogies investigated in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the rte challenge has successfully employed a variety of techniques including regression # otherefr, machine translation # refr, and probabilistic tree edit distance #", "cit": "the line of work on probabilistic tree - edit distance models bears a strong connection to this work # otherefr ; # refr. [SEP] [PAD] [PAD]"}
{"pre": "the existence of ccg parsers # otherefr ; # refrb ) involve the use of log - linear models. [SEP] [SEP] [SEP] [SEP]", "cit": "# refr and toutanova et al # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr minimum error rate training # otherefr. [SEP] ( mert ) procedure is the most commonly used method for training feature weights in statistical", "cit": "random restarts and random walks # refr are commonly used to combat the fact the search space is highly non - convex, often with multiple minima [SEP]"}
{"pre": "for this we use the stanford parser # otherefr ; # refr, in our case, the pos tagging model is [SEP]. [SEP] [SEP] [SEP]", "cit": "in order to derive syntactic information, we use the charniak / johnson reranking parser # refr combined with a constituent - to - [SEP]"}
{"pre": "we use the similarity measure # refr. [SEP] the sense of a lexical gap between a word senses and its corresponding sense in a [SEP] similarity [SEP] [SEP]", "cit": "eventually, the sense supported by those patterns which are semantically closer to the context in question is selected as the most likely one ( see, among [SEP]"}
{"pre": "this exactness assumption, however, rarely holds in practice since exact inference is often intractable in many important problems such as machine translation # otheref [SEP]", "cit": "we also show how perceptron learning with beam - search # otherefr can be extended to handle the additional ambiguity, by adapting the? [SEP]"}
{"pre": "och et al [ 1999 ]? s alignment template model can be reframed as a phrase translation system ; yamada and knight [ 2001 [SEP]", "cit": "details of this model are described by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "dual decomposition ( dd ) # refr offers an attractive framework for combining these two types of parsers. [SEP] a [SEP] [SEP] [SEP] effort [SEP] [SEP] [SEP]", "cit": "dual decomposition # otherefr has recently become popular in the community # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition to the translation model, it is also true to the word sense disambiguation process # refr. [SEP] the context in which the translation process", "cit": "this discrepancy between unigrams versus n - grams was first described in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in a second approach to arabic morphology has been to describe using finite - state morphological analyzers, # refra ), a finite - state transducer", "cit": "there are several variations of this method that produce the same effect # refrd ), with different penalties in the size of the resulting transducer or [SEP]"}
{"pre": "in # refr, we proposed a method that uses topic coherence as features to classify documents as topic distributions over topics. [SEP] the document ( [SEP] )", "cit": "one application of these methods has been to remove incoherent topics before generating labels for topics # refr ; aletras and stevenson, 2013 [SEP]"}
{"pre": "to measure word similarity, we used the gold standard part - of - speech tags # refr. [SEP] the wup similarity package on [SEP] [SEP] [SEP]", "cit": "for example, textual similarity enables relevant documents to be identified for information retrieval # otherefr, lexical simplification # refr, and web search result [SEP]"}
{"pre": "supervised learning of taggers have been applied to part - of - speech # otherefr, unsupervised part - ofspeech tagging # refr and [SEP]", "cit": "recent work by # refr builds a dictionary for a particular language by transferring annotated data from a resource - rich language through the use of word alignments [SEP]"}
{"pre": "such pos tagging work has been plentiful and includes efforts to induce pos tags without labels # otherefr ; ( e. g.", "cit": "in the context of unsupervised pos tagging models, modeling this distinction greatly improves results # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the experiments reported in # refr, we used punctuation # otherefr for which contains a sentence segmentation model, henceforth ). [SEP]", "cit": "other applications have included japanese sentence analysis # otherefr, genre detection # refr, bilingual sentence alignment # otherefr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "normalizing text can traditionally be approached using three well - known nlp metaphor # refr. [SEP] the problem of normalizing sms messages [SEP] [SEP] [SEP] [SEP] microb", "cit": "recent work also focuses on normalizing the twitter messages, which is generally considered a more challenging task. # otherefr adopted the noisy - channel [SEP]"}
{"pre": "the training of our model is loosely related to the hmm model ( ibm model ) based on the hidden markov model ( hmm ), which has a", "cit": "in related fields of nlp lately dirichlet priors have been investigated, e. g. # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "figure 1 : a sentence from the sentential alignment. ( rte ) of the sentence, we use to determine the most important relation between a", "cit": "alignment weights were learned using manually annotated rte development sets ( see # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "character classification before describing the adaptation algorithm, we use cti5 together with pos tags, word segmentation, pos, pos, lemmas, and pos", "cit": "this character - by - character method was first proposed by # otherefr, and a number of discriminative sequential learning algorithms have been exploited, [SEP]"}
{"pre": "we pos - tagged the corpus using tnt tagger # refr and used a statistical tagger and a trigram [SEP] morphological information. [SEP] [SEP]", "cit": "for pos tagging and lemmatization, we combine genia ( with its built - in, occasionally deviant tokenizer ) and tnt # [SEP]"}
{"pre": "in natural language processing, automatically acquired preference models have been shown to aid a number of tasks, including textual entailment # refr [SEP] and [SEP] [SEP]", "cit": "information about the presence or absence of entailment between two sentences has been found to be beneficial for a range of nlp tasks such as word [SEP]"}
{"pre": "the referring expressions challenge has been addressed in the last decade, and has been made it in nlg # refr. [SEP] the intrinsic evaluations of these", "cit": "based on the gricean quantity maxim # otherefr, # refr and gardent # otherefr, this principle holds that descriptions [SEP]"}
{"pre": "for german, we use rftagger # refr. [SEP] 100, which pos tags constituents are parsed using rftagger # otheref [SEP]", "cit": "for german, the pos and morphological tags were obtained from rftagger # refr which provides morphological information such as case, number and gender for [SEP]"}
{"pre": "# refr have shown that perfect hash functions can be used to create a phrase table, while maintaining hashtags are filtering for language models. [SEP]", "cit": "# refr use significance tests to eliminate poor candidates from phrase tables for smt. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "to address this, we propose to use the term, we first apply a set of minimal rules to a string - to - tree system # refr", "cit": "this work was developed mainly in the context of a syntactic - dependency - based tree - to - tree translation system described in # refr. [SEP] [PAD]"}
{"pre": "the only exception is in # refr, where the authors try to maximize the bleu score on a single sentence. [SEP]. [SEP]. [SEP].", "cit": "probabilistic generative models like ibm 1 - 5 # otherefr, and leaf # refr define formulas for p ( f | e ) or p [SEP]"}
{"pre": "such recognition comes from the ideas that crucial progress may derive from decomposing the complex rte task into basic phenomena and from solving each basic phenomenon [SEP]", "cit": "# refr identified 20 categories of common - sense knowledge that are prevalent in rte. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the problem of metaphor modeling is gaining interest within nlp, with a growing number of approaches exploiting statistical techniques # otherefr ; # refr [SEP]", "cit": "figure 1 : organisation of the hierarchical graph of concepts following previous semantic noun classification experiments # otherefr ; # refr, we use the grammatical [SEP]"}
{"pre": "we use the msd dataset introduced by # refr. [SEP] the semantic formula recommended for the sentence similarity measure. [SEP] similarity package by 3, with", "cit": "this fact was also realized by the organizers of the pilot semantic textual similarity task at semeval - 2012 ( see section 5 ), [SEP]"}
{"pre": "gyro builds on approaches developed for syntactic smt # otherefr ; de # refr. [SEP] [SEP] [SEP] [SEP] representations into [SEP] [SEP] [SEP] [SEP]", "cit": "typical solutions involve constraints on the space of permutations, as in multi - document summarisation # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "germanet we decided to choose a lexicalsemantic net for the german sentence ( cf. # refr ). [SEP] ( ii ) [SEP] [SEP] [SEP]", "cit": "for german, we address this issue by introducing two further types of features into our model based on the germanet resource # refr. [SEP] [PAD] [PAD]"}
{"pre": "the grammar is implemented in the grammar feature - based lexicalized hpsg grammar # otherefr, and the grammars described in detail in # refr", "cit": "i have implemented the algorithm in prolog and coded the hpsg feature structure in the way described using profit # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper, we focus on the passive - aggressive algorithm # otherefr, # refr, and are good - suited # [SEP] [SEP] [SEP]", "cit": "in future, we intend to investigate the effect of more sophisticated cohesion measures, including the use of thesaural information from domainindependent sources and [SEP]"}
{"pre": "in recent years, several approaches have been developed specifically for learning such as maximum entropy # otherefr, conditional random fields # refr, [SEP] [SEP]", "cit": "parameter estimation was performed with the limited memory variable metric algorithm # refr implemented in the megam package. 7 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the only difference between the accuracy of svmtov1 was that while the use of 1the pos tagger was trained on the basis [SEP] [SEP]", "cit": "the most common non - fatal problems ( type one ) involved the well - documented adjunct attachment site issue, in particular for prepositional phrases [SEP]"}
{"pre": "we use stratified shuffling test # refr to determine the significance of results. [SEP]. [SEP]. [SEP]ly each rhaps or he l [SEP] [SEP]", "cit": "table 5 shows a 0. 4 percent f - score improvement over the baseline for that section, which is statistically significant at p < 0. [SEP]"}
{"pre": "ensemble learning # otherefr ; # refr showed a successful way of the quality of semantic lexicons for the wsd task # otheref [SEP]", "cit": "the research most closely related to ours is an ensemble - based method for automatic thesaurus construction # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "thus much work developed in the literature has focused on designing robust projection algorithms such as graph - based projection with label propagations # otherefr [SEP]", "cit": "from the perspective of applying deep networks in natural language processing systems, there are a number of works in the literature # otherefr ; # [SEP]"}
{"pre": "tfs # refr also offered type constraints and relations and to our knowledge was the first described in detail in # otherefr. [SEP] a [SEP] [SEP]", "cit": "the reader interested in further practical aspects of our system is referred to # otherefr and tfs # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "paraphrasing has been addressed previously, for example, on sentence compression # otherefr ; # refr, and paraphrasing # otheref", "cit": "paraphrasing has also been used in the evaluation of machine translation system output # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "interfacing extractive summarization with a sentence compression module could improve the conciseness of the generated summaries and render them more informative # refr. [SEP]", "cit": "# refr first extract sentences, then remove redundant phrases, and use ( manual ) recombination rules to produce coherent output. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in 2006, the shared task was multilingual dependency parsing, where participants had to train a single parser on data from thirteen different languages # otheref", "cit": "let us first look at unlabeled attachment scores to compare results that can be achieved with harmonized annotation in contrast to the ones that we can see [SEP]"}
{"pre": "quasi - synchronous grammar makes no restrictions on the form of the target monolingual grammar, though dependency grammars have been used in most previous applications of [SEP]", "cit": "their model is based on quasi - synchronous grammar # refr and integer linear programming. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "almost all text normalization tasks for languages other than japanese # otherefr, # refr, aw et al. # otherefr ). [SEP]", "cit": "among the literature of text normalization # otherefr, # refr employed the noisy channel model to find the most probable word sequence given the observed [SEP]"}
{"pre": "in the past, subsections of the penn treebank # otherefr have been annotated for english, and has been used for several [SEP] [SEP] text", "cit": "reader since readability prediction was initially primarily designed to identify reading material suited to the reading competence of a given individual, most of the existing data [SEP]"}
{"pre": "in this paper, we describe the joint inference framework proposed by # refr, which was an extension of the joint inference framework used in coreference resolution", "cit": "compared to other structured prediction frameworks such as markov logic networks # refr, searn provides high modeling flexibility but it does not requiring taskdependent approximate [SEP]"}
{"pre": "we use a statistical model to classify names, and names, which are described in # refr. [SEP] the features of the algorithm, in which [SEP]", "cit": "the 11 binary history - views used by mene is binary features are very similar to those used in bbn is nymble / ld [SEP]"}
{"pre": "it can not only maintain the strength of phrase translation in traditional phrase - based models # otherefr ; # refr, but also characterize the [SEP]", "cit": "in hierarchical phrase - based smt systems, due to the flexibility of rule matching, a huge number of hierarchical rules could be automatically learnt [SEP]"}
{"pre": "to overcome the shortage of manually aligned data, # refr introduced a statistical machine translation model that combines syntactic transformations from the original work and paired [SEP] [SEP]", "cit": "sentence simplification can also serve to preprocess the input of other tasks, such as summarization # otherefr, semantic role labeling # [SEP]"}
{"pre": "we use the same problem as # refr. [SEP] ( i. e., j ) of text, graphs, and define a similarity [SEP] [SEP]", "cit": "segmentation is a useful intermediate step in such applications as subjectivity analysis # refr, automatic summarization # otherefr and others. [SEP] [PAD] [PAD]"}
{"pre": "acknowledging this complexity, coreference systems, either learning - based # otherefr ; # refr ; rahman and ng, 2011b [SEP]", "cit": "many of the individual features we employ in the fi - nal feature set have appeared in other coreference systems ( bjo? # refr. [SEP]"}
{"pre": "in recent years, popular topic models such as latent dirichlet allocation # otherefr have received much attention in recent years, but have also been [SEP]", "cit": "# refra ) use topic models to learn document - level translation probabilities. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "thus, some research has been focused on deriving different word - sense groupings to overcome the fine? grained distinctions of wn # otheref [SEP]", "cit": "thus, some research has been focused on deriving different word - sense groupings to overcome the fine? grained distinctions of wn ( hearst [SEP]"}
{"pre": "# refr use syntactic information on the target concept of lexico - syntactic patterns. [SEP] the unsupervised relation. [SEP] distributional representation. [SEP] the hyperny", "cit": "# refr uses conjunction and appositive annotations in the vector representation. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr use a vector space model with simple vectors derived vectors from their parts vectors. [SEP] distributional vectors. [SEP] vectors : e. g. [SEP]", "cit": "to do so, we make use of a simple vector - based multiplicative model of compositionality, as proposed by # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "this stands in contrast to a competing approach # otherefr, which segments the input string into substrings that are transduced independently, and # refr", "cit": "a similar conditional latent - variable model has been applied to the task of lemmatization and generation of morphological forms # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this includes work in the framework of rst # otherefr ; # refr, sdrt # otherefr. 3 the task is challenging [SEP]", "cit": "this includes work in the framework of rst # otherefr, graph - bank # refr, the pdtb # otherefr. 3 [SEP]"}
{"pre": "in addition, we compared the performance of two existing wsd systems : the semeval - 2010 task ( 1 ) # refr and the [SEP]", "cit": "in the semeval word sense induction and disambiguation task # otherefr ; # refr, all of the submissions in 2007 created [SEP]"}
{"pre": "in # refr, we evaluate the performance of the vector space model on the task of word sense discrimination of swbd wsd. [SEP] a random", "cit": "however, this induction step has proven to be greatly challenging, in the most recent shared tasks, induction systems either appear to perform poorly or fail [SEP]"}
{"pre": "information extraction ( ie ) systems generally consist of a textrunner system, as compared to a binary classification task, as used by # refr [SEP]", "cit": "information extraction # otherefr, # refr, califf and mooney # otherefr ) to extract role fillers for events. [SEP]"}
{"pre": "there has been a growing interest in corpus - based approaches which retrieve possible verbs from large corpora # otherefr, # refr, # other [SEP]", "cit": "as an alternative to the resource - intensive manual classifications, automatic methods such as classification and clustering are applied to induce verb classes from corpus data, [SEP]"}
{"pre": "# refr used a random walk algorithm to estimate the similarity between two terms that are co - occur with similar to the cosine similarity of the similarity of", "cit": "this measure is known to perform well in identifying similar words on the graph of wordnet # refr and a related measure, the hitting time [SEP]"}
{"pre": "the only exception to this was motivated by previous work in machine translation. # refr describe an unsupervised alignment technique for machine translation. [SEP] itgs [SEP]", "cit": "at the intersection of these lines of work, discriminative itg models have also been proposed, including one - to - one alignment models # refr [SEP]"}
{"pre": "stanford dependency parser # otherefr ; # refr. [SEP] the expressions of sentences in the training. [SEP] this simple model, which [SEP] the decisions", "cit": "it was parsed with the stanford parser # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in # refr a method for learning phrase movements structures. [SEP] a word along with its parent. [SEP] itg. [SEP] itg. [SEP] it", "cit": "a small number of efforts has been dedicated to the simultaneous learning of the probabilities of phrase translation pairs as well as hierarchical reordering, e. [SEP]"}
{"pre": "we use bleu # otherefr and ter # refr as an evaluation metric for machine translation. [SEP] the procedure of the [SEP] it [SEP] it", "cit": "we used bleu? 4 # otherefr, meteor ( v. 1. 3 ) # refr to evaluate the texts at document level [SEP]"}
{"pre": "in # refr, different ways to combine the information of the input to the same test for our dataset. [SEP] the same corpus, we propose the", "cit": "a few methods have been proposed, based mostly on the conventions of uncertainty sampling, where the learner queries the instance about which it has the least [SEP]"}
{"pre": "# refr showed that for a ellipsis that finding and antecedents are related in the same manner. [SEP] phenomena must be resolved by an analysis of", "cit": "it is argued that the approach improves on previous proposals to integrate ellipsis resolution and scope underspecification # refr in that application processes like anaph [SEP]"}
{"pre": "nuggeteer # refr. [SEP] the challenges to q based on a single score. [SEP] text based on the matching problem of learning a [SEP]", "cit": "however, the recent introduction of pourpre, an automatic evaluation metric for the nugget - based evaluation methodology # refr, fills this [SEP]"}
{"pre": "the best system # refr achieved an f - score of 91. 1, 76. 1. 1 % when comparing two different training examples in the", "cit": "the approach of the top system # otherefr was to fit the model to minimize cost over sentences, while the secondbest system # refr [SEP]"}
{"pre": "to obtain dependency trees, we parsed the source sentences using the stanford parser # refr. [SEP] & tsnlp tool # otheref [SEP] [SEP]", "cit": "assessing the quality of a learning algorithm? s output and selecting high quality instances has been addressed for supervised algorithms # otherefr ; # refr [SEP]"}
{"pre": "recently, # refr tried the marcu and wong model constrained by a word alignment and a probability distribution over the phrase pair. [SEP] a word alignment", "cit": "# refr proposed a new conditional model structure that does not cause large and small phrases to compete for probability mass. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in recent years, there has been a growing interest in automating the extraction of semantic parsing systems # refr. [SEP] this approach [SEP] [SEP] this problem", "cit": "for semantic analysis, we used the assert toolkit # refr that produces shallow semantic parses using the propbank conventions. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the only difference between the system and1 - on the accuracy of verbs are presented in ( see # refr for a preliminaryd lexicon ). [SEP]", "cit": "high ambiguity, entangled nodes, and asymmetry have already been emphasised in ( hearst and shu # refr as being an obstacle to the [SEP]"}
{"pre": "figure 1 : similarity measure used in the experiments between two words, the well - known and english corpora to be similar to the method presented in #", "cit": "in his work on distributional similarity # refr designed a parser to identify grammatical relationships between words. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr. [SEP] human tagging of a morphological analyzer for russian, czech, and illustrated that it has a lot of interest [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "to improve tagging for morphological errors, one should investigate which linguistic properties are being incorrectly tagged ( cf. sub - tagging in # refr and what [SEP]"}
{"pre": "in recent years, the task of automatically providing lexical substitutions in context # refr received much attention. [SEP] this work has been done when the task [SEP]", "cit": "the task to generate lexical substitutions in context # refr, i. e., to replace words in a sentence without changing its meaning, has [SEP]"}
{"pre": "we do not attempt to implement all the corpus pre - processing and co - occurrence extraction routines that it would require to be of general use, [SEP]", "cit": "dinu et al # otherefr show, for example, that well - performing, simplified variants of the method in # refr, that [SEP]"}
{"pre": "we are also evaluating the performance of the mfs in semcor # refr, and we present a balanced, semantically annotated dataset, with all content", "cit": "in order to determine the sub - hierarchies that should be used for vl and nj, we used statistics provided by semcor, a sense tagged [SEP]"}
{"pre": "commandtalk # otherefr, circuit fix - it shop # refr, and the interface between a spoken language, on the interface [SEP] [SEP] [SEP]", "cit": "commandtalk # refr, circuit fix - it shop # otherefr are spoken language systems but they interface to simulation or help facilities rather than [SEP]"}
{"pre": "in table 1, # refr used the bllip parser training a discriminative reranker to parse the output of a stochastic parser. [SEP] parsing model", "cit": "we used charniak? s maximum entropy inspired parser and their reranker # refr for target grammar parsing, called a generative parser ( [SEP]"}
{"pre": "# refr used random walks over a graph to determine the semantic relatedness between words, using the personalized pagerank algorithm proposed to compute the weights on a", "cit": "the most similar work to ours is # refr in which the authors derive a graph structure from the inter - article links in wikipedia pages, and [SEP]"}
{"pre": "in addition to domain mainstays such as support vector machines and maximum entropy models, we find increased application of joint models # otherefr [SEP]", "cit": "this paper presents the umass entry to the bionlp 2011 shared task # refra ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we evaluate the performance of these models by measuring topic similarity, and similarity measures using tf - idf # otherefr, and the graph [SEP]", "cit": "it is important to discover the latent topics when summarizing a document collection, because sentences in an important topic would be more important than those talking about [SEP]"}
{"pre": "in the case of dependency parsing, previous work has used coarse - to - fine strategies where simpler first order models are used to prune unlikely [SEP]", "cit": "there are several attempts at incorporating arbitrary tree - based features but these involve either solving an ilp problem # refr or using computa - ( [SEP]"}
{"pre": "in addition, we plan to incorporate pos information, mainly differ in the case of japanese morphological analysis. # otherefr ; # refr [SEP] [SEP]", "cit": "# refr reported the accuracy of their parser as 88. 48 and 95. 09 5since a gold derivation can logically be obtained if gold categories [SEP]"}
{"pre": "previous work has shown that senseval - 3 # otherefr, or # refr as well as maximum entropy models ( see also e. g", "cit": "the wsd system used here is based on the model that achieved the best performance on the senseval - 3 chinese lexical sample task, outperform [SEP]"}
{"pre": "# refr use a more general language model to discover sociolinguistic languages. [SEP] the twitter text, an off - theshelf framework [SEP]", "cit": "a series of papers has documented the interactions between social media text and social variables such as age # otherefr, race # refr, and [SEP]"}
{"pre": "despite the huge potential that automatically induced visual features could represent as a new source of perceptually grounded 3http : / / www. vlfe [SEP]", "cit": "despite the huge potential that automatically induced visual features could represent as a new source of perceptually grounded 3http : / / www. vlfe [SEP]"}
{"pre": "the statistical parsing models that have been proposed, such as those described in # refr, collins # otherefr, but not as many [SEP] the", "cit": "many stochastic parsing models use linguistic intuitions to find this minimal set, for example by restricting the statistical dependencies to the locality of headwords of [SEP]"}
{"pre": "multi - tape two - level morphology # otherefr, # refr ). [SEP] the prosodic onstraints oanalyze ~ [SEP] [SEP]", "cit": "multi - tape two - level morphology # otherefr ; # refr, et. seq. ) addresses various issues in the domain of non [SEP]"}
{"pre": "we use tnt # refr, a second order markov model tagger. [SEP] the sequence n - gram model, introduced by [SEP] the [SEP] [SEP]", "cit": "we compare our results to a similar experiment conducted in their work, where they trained a tnt tagger # refr on several treebanks [SEP]"}
{"pre": "dual decomposition ( dd ) # refr offers an attractive framework for combining these two types of parsers. [SEP] a [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "recently # refr, martins et al # otherefr have shown that dual decomposition or lagrangian relaxation is an elegant s fedcb ( a [SEP]"}
{"pre": "recent work in statistical parsing has shown that the yield better performance in both parsing # otherefr and learning methods ( see # refr for tsg", "cit": "previous work on tag and tig induction # otherefr has addressed the problem using language - specific heuristics and a maximum likelihood estimator, which [SEP]"}
{"pre": "the patterns were automatically constructed by # refr. [SEP] the patterns in order to discover hypernyms, i. e., [SEP] [SEP] [SEP] [SEP]", "cit": "a widely cited method is that of # refr, who argues that specific lexical relations are expressed in well - known intrasentential lexico [SEP]"}
{"pre": "in order to obtain the linguistically plausible right - corner transform representation of incomplete constituents, the corpus is subjected to another, pre - process [SEP] [SEP]", "cit": "for a constituent? of rank n we have : dist = max { dist ( x ) : x in? }, + n 8an [SEP]"}
{"pre": "# refr and callison - burch et al # otherefr improved english translation by pivoting through lemmatization. [SEP] the source language parap", "cit": "context is often defined as local linguistic features such as surrounding words and their part - of - speech, but some works have experimented with more [SEP]"}
{"pre": "we tokenized and part - of - speech tagged the tweets with the carnegie mellon university ( cmu ) twitter nlp tool [SEP]", "cit": "early research on tsa showed that the challenging vocabulary made it harder to accurately tag tweets ; however, # refr report on using a pos tagger [SEP]"}
{"pre": "in the case of sentiment analysis, recent work has focused on detecting emotions such as anger, joy, sadness, sadness, fear, and", "cit": "linguistic style and human characteristics using stylistic # otherefr, identification of interactional style # refr, and recognizing deceptive language # other [SEP]"}
{"pre": "we used the open source toolkit jane # refr, which is freely available for the moses toolkit. [SEP] bleu score [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "but we recently showed that using phrases during search gives better coverage of translation, better future cost estimation and lesser search errors # refra ) than [SEP]"}
{"pre": "the attribute grammar is a very simple and lexicalized tree adjoining grammar ( the category ) of which includes the structure of a sentence [SEP] [SEP]", "cit": "notes ~ cf. / abney 1986 /, / berwick 1987 /, / # refr /, / kashket 1987 /, [SEP]"}
{"pre": "in the case of text retrieval, spelling correction, coreference resolution, has been studied mostly employed to determine the relevant concepts of the internet", "cit": "recently there has been lot of work addressing the problem of annotating text with links to wikipedia entities # otherefr ; # refr. [SEP] [PAD]"}
{"pre": "this can be done automatically with unparsed corpora # otherefr, # refr, from parsed corpora such as marcus et al [SEP]", "cit": "of particular importance to statistical parsers is the investigation of frequencies for verb subcategorizations such as # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we therefore implemented a large treebank1, using the moses3 # otherefr with the default tree fragments used by # refr. [SEP]", "cit": "efficiently identifying useful features for tree kernel methods. # refr [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "since this algorithm remains inexact in the multidimensional case, much of the recent work on mert has focused on extending och? s algorithm [SEP]", "cit": "minimum error rate training # otherefr, summarization # refr, and phonetic alignment # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we evaluated the translation quality using the bleu metric # refr. [SEP] bleu # otherefr. [SEP] the optimization criterion, which compares [SEP]", "cit": "for each language pair, we trained standard phrase - based smt systems in both directions # otherefr tools and evaluated using bleu # [SEP]"}
{"pre": "related work on the automatic classification of temporal information status # otherefr ; # refr is the core of the current time expressions that are related to", "cit": "# refr looked beyond the core temporal expressions and into prepositional phrases that contained temporal relations, i. e. before, during, etc [SEP]"}
{"pre": "in contrast, most of the work on sentiment analysis in opinion mining has focused on reviews # otherefr ; # refr. [SEP] the [SEP] opinion", "cit": "sentencelevel subjectivity classification # otherefr ; # refr ) is the research in text most closely related to our work. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "# refr and fazly et al # otherefr. [SEP] features in order to extract the similar context of the ones. [SEP] features of", "cit": "we used the data set created by # refr, which consists of 13 english expressions ( mainly v + pp or v + np ) that can [SEP]"}
{"pre": "in addition to the well - known tree kernel ( stk ) evaluation, # refr have shown that a large increase in performance [SEP] [SEP] [SEP] [SEP]", "cit": "one example are the semantics - aware metrics of gim? enez and m ` arquez # otherefr and # refr, which [SEP]"}
{"pre": "we used the stanford parser to get dependency parses of the source side of the training data, and show that our baseline parser is related to [SEP]", "cit": "in order to compute syntactic features, we analyzed source sentences using state of the art, tree - bank trained constituency parsers # otheref [SEP]"}
{"pre": "in addition, # refr used support vector machine ( svm ) to create a classifier trained on a data set created by first - order to determine the", "cit": "this includes finding question answer pairs # otherefr, ranking answers # refr etc. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the choices can be found in # refr. [SEP] thesauruses, while much attention has been proposed recently. [SEP] this work in the construction", "cit": "syntactic co - occurrences have often been used in work on lexical acquisition # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in # refr a framework for hierarchical translation is proposed for automatical phrasebased translation. [SEP] a mechanism that uses the head of a derivation [SEP] it", "cit": "early examples of this work include # refr ; more recent models include # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we tested whether statistical significance tests for the results on the stratified shuffling test # refr. [SEP]. [SEP] ( 1 ) 2 [SEP] the results [SEP]", "cit": "# refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "much of previous research investigated the use of dictionary network # otherefr, # refr, adreevskaia and bergler # other [SEP]", "cit": "there are few previous works closest to ours. # refr build connotation lexicons that list words with connotative polarity and connotative [SEP]"}
{"pre": "# refr, green et al. # otherefr. [SEP] the log - linear model of # otherefr. [SEP] a distribution over [SEP]", "cit": "in statistical constituent parsing, many investigations devise treebank transformations that allow the parsing models to access morphological information higher in the tree # otheref [SEP]"}
{"pre": "in # refr, the framework is applied to the training set for the classification of phrase - structure trees presented in # otherefr. [SEP] [SEP]", "cit": "for german we re - implemented the feature templates of # refr which is the state - of - the - art feature set for german. [SEP] [PAD]"}
{"pre": "yet, tree - based translation often underperforms phrase - based translation in language pairs with short range reordering such as arabic - english translation [SEP]", "cit": "huck et al # otherefr add new rules into the hiero system, # refr apply the tree adjoining grammar formalism to [SEP]"}
{"pre": "vn classes were proven beneficial for semantic role labeling ( srl ) # refr, semantic parsing # otherefr. [SEP] the [SEP] [SEP] [SEP] [SEP]", "cit": "vn is built on a refinement of the levin classes, the intersective levin classes # refr, aimed at achieving more coherent classes both semantically and [SEP]"}
{"pre": "in nlp, several methods have been proposed to cope with lexicons # otherefr, # refr, and \\ [ church, 1990 \\", "cit": "among the attempts to enrich lexical information, many have been directed to the analysis of dictionary definitions and the transformation of the implicit information to explicit knowledge [SEP]"}
{"pre": "this measure has been tested in other areas of human evaluations # refr, but agreement analysis, summarisation is often bleu that correlate well with human", "cit": "it is not surprising then that stable averages of quality judgements, let alne high levels of agreement, are hard to achieve, as has [SEP]"}
{"pre": "in this paper, we describe a new approach to german lfg parsing, a language based on lfg grammars # refr. [SEP] [SEP] [SEP] [SEP]", "cit": "in the context of the pargram project, a number of high quality, broad - coverage grammars for several languages have been produced over the years [SEP]"}
{"pre": "to avoid the problem, many methods have been proposed, including methods based on the classification of the ontology construction \\ [ # refr \\ [SEP] [SEP] [SEP]", "cit": "using bilingual dictionaries for mapping words or senses of a language to english counterparts is not new # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for example, # refr used a graph similarity measure to obtain similarity for the similarity of the wordnet hierarchy. [SEP] terms. [SEP]. [SEP] it", "cit": "following existing work # otherefr ; # refr, we built a peer similarity graph containing about 40. 5 million nodes and 1. 33 [SEP]"}
{"pre": "we use a maximum entropy trigram tagger # refr to model. [SEP] the word sequence. [SEP] features consists of 97. 2 the word for", "cit": "it will also be relevant to apply advanced statistical models that can incorporate various useful information to this task, e. g., the maximum entropy [SEP]"}
{"pre": "the initial state contains terminal items, whose labels are the pos tags given by the parser of # refr.. [SEP] if they did not [SEP] the", "cit": "for reasons given in # refr, items are inferred bottom - up right - to - left. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "although many systems that address dialogue systems, e. g. # otherefr ; # refr, have been applied to the task of dialogue systems", "cit": "an obvious candidate is the incremental approach # otherefr ; # refr which allows the system to process partial user inputs, back - channels, [SEP]"}
{"pre": "there have been several subsequent studies, e. g., # otherefr ; # refr. [SEP] the opinion aspectual text # otheref", "cit": "some researchers also proposed to use topic modeling to identify implicit topics and sentiment words # otherefr ; # refr ; li et al, 2010 [SEP]"}
{"pre": "the meteor metric ( denkowski and # refr uses monolingual alignment between the probability two translations of a matching component and a? [SEP]? [SEP]?", "cit": "to this primary system all other hypotheses are aligned using the meteor # refr alignment and thus the primary system defines the word order. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "we use a phrase - based statistical machine translation system consisting of 2000 2 # refr. [SEP] the same lexico - syntactic paraphrases [SEP] [SEP]", "cit": "it is inspired by the work on reformulation, e. g., # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the optimization is performed using the mert algorithm # refr with the bleu score # otherefr as the objective function. [SEP]. [SEP] [SEP]", "cit": "minimum error - rate training ( mert ) # refr was the first approach in mt to directly optimize an evaluation metric. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the nlp community has recently seen a surge of interest in language processing tasks # otherefr, and information extraction # refr. [SEP] [SEP] [SEP]", "cit": "in recent work, collaborative knowledge bases ( ckb ) like wikipedia have been used in ir for judging the document relevance by computing the semantic [SEP]"}
{"pre": "event coreference ( event ) and ( event coreference ) are : in ( 1 ) iii ) we give a mention that is a cluster in", "cit": "although it has not been extensively studied in comparison with the related problem of entity coreference resolution, solving event coreference has already proved its usefulness [SEP]"}
{"pre": "recursive neural networks ( e. g., # refr ), in terms of the vectors of a parsed corpus, and a noun [SEP] [SEP]", "cit": "the k = 200 - best parses at the top cell of the chart are calculated using the efficient algorithm of # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "we report bleu # otherefr, meteor # refr and ter # otherefr scores for the same task. [SEP] the [SEP] [SEP] [SEP]", "cit": "table 2 lists the bleu # otherefr and meteor # refr scores of both systems. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the case of unsupervised dependency parsers, we apply the post - processing of the tokens as defined by # refr. [SEP] the tokens of the", "cit": "7the performance of cohen and smith # otherefr, like the performance of # refr, is greater than what we report, but those [SEP]"}
{"pre": "sentence simplification has been previously applied to text simplification # otherefr ; # refr and sentence fusion # otherefr. [SEP] the [SEP] [SEP] [SEP]", "cit": "in later years, there has been more interest in problems such as sentence compression # otherefr, text simplification # refr and sentence fusion # [SEP]"}
{"pre": "for english, we use the reranker described in # refr. [SEP] the dependency analyzer of each predicate to denote the features of each predicate #", "cit": "related research includes # refr and kawahara and kurohashi # otherefr where statistical information between verbs and case elements is collected on the [SEP]"}
{"pre": "in 2008, the conll 2008 shared task # refr was on joint parsing and semantic role labeling, but the best systems # otherefr were", "cit": "the results from conll shared tasks in 2005 and 2008 # otherefr ; # refr, further show that srl pipeline may be one [SEP]"}
{"pre": "so far, research in automatic opinion recognition has primarily addressed learning subjective language # otherefr, and discriminating between positive and negative language # refr [SEP]", "cit": "research on the automatic classification of movie or product reviews as positive or negative # otherefr ; # refr ) is perhaps the most similar to [SEP]"}
{"pre": "we use minimum error rate training # refr to tune the feature weights to maximize the system? s bleu score on the development set, tuned dev", "cit": "these constituent matching / violation counts are used as a feature in the decoder? s log - linear model and their weights are tuned via minimal error [SEP]"}
{"pre": "we use the stanford parser # refrb ), which consists of about two different types of sentences : sentences being extracted from the same training and [SEP]", "cit": "all the syntax based features are computed from the constituency trees produced from the stanford parser # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in previous work, we showed how to collapse decision trees ( in particular on the dialogue management ) of the dialogue system output ( see # refr for", "cit": "this generator is based on data from the stochastic sentence planner sparky # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "lexicon constructed by combining the lexicon provided by combining mpqa lexicon # refr with a lexicon constructed lexicon, the lexicon of connotation lexicons we [SEP]", "cit": "for english we seed the bootstrapping process with the strongly subjective terms from the mpqa lexicon3 # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the classification approach has been used to deal with the most common grammatical mistakes made by esl learners, such as article and preposition errors # [SEP]", "cit": "it is seen, for example, in # otherefr, # refr, and # otherefr, among others. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "we demonstrate that despite recent successes in discriminative character transduction using indicator features # otherefr ; # refr, our generative hybrid performs surprisingly well [SEP]", "cit": "we utilize a transliteration model # refr, trained from pairs of english person names and corresponding foreign language names, extracted from wikipedia. [SEP] [PAD]"}
{"pre": "in addition, by selecting character n - grams, one can also introduce a lexicon that has been shown to be useful in various tasks such as information", "cit": "however, to compare with related work, we will also adopt boundary f - measure fb = 2rbpb / ( rb + pb ), [SEP]"}
{"pre": "naturally, our current work on question answering for the reading comprehension task is most related to those of # otherefr ; # refr. [SEP] [SEP]", "cit": "our feature representation was designed to capture the information sources that prior work # otherefr ; # refr used in their computations or rules. [SEP] [PAD]"}
{"pre": "the context of a word can be described by the sentence in which it occurs # otherefr ; # refr. [SEP] the context [SEP] the [SEP]", "cit": "they hypothesise that a word and its translation tend to appear in similar lexical context # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the second metric we use is the standard method of # refr, which uses an unlexicalized treebank ( henceforth, could be modified", "cit": "# refr show that annotators tend to start with the decisions with the most certainty, and delay the? hard? decisions as much as possible [SEP]"}
{"pre": "wiktionary has been used extensively for lexical semantics # otherefr, semantic processing # refr, and word sense disambiguation # other [SEP] [SEP]", "cit": "previously, there have been several independent efforts of combining existing lsrs to enhance their coverage w. r. t. their breadth and depth, [SEP]"}
{"pre": "most approaches that extract paraphrases from parallel texts employ some type of pattern matching : sentences with the same meaning are assumed to share many n [SEP]", "cit": "# refr extract subsentential translation pairs from comparable corpora using the log - likelihood - ratio of word translation probability. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "latent - variable pcfgs ( l - pcfgs ) are a highly successful model for natural language parsing # refr. [SEP] [SEP] [SEP] [SEP]", "cit": "in this paper we derive a spectral algorithm for learning of latent - variable pcfgs # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "previous work on parser performance and domain variation by # refr showed that by training a parser on the penn - ii treebank and testing on the penn", "cit": "# refr presents a tree - based method for reconstructing ldd dependencies in penn - ii trained parser output trees. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "integer linear programs have already been successfully used in related fields including semantic role labelling # otherefr, relation and entity classification # refr. [SEP] [SEP]", "cit": "integer linear programs have already been successfully used in related fields including semantic role labelling # otherefr and dependency parsing # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "we use the stanford chinese parser ( ctb ) and pos tagging model # refr for chinese, which is trained on the penn treebank # other", "cit": "the parsers are : the berkeley parser with gold pos tags as input ( berk - g ), the berkeley product parser with two grammars [SEP]"}
{"pre": "only recently, the integration of nlp applications such as information retrieval # otherefr, and machine translation # refr. [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "the general idea is that words are related by the definition they appear in, in a complex network that must be semantic in nature ( this has [SEP]"}
{"pre": "this model is trained with the margin - infused relaxed algorithm # otherefr ; # refr. [SEP] - sat we present a mechanism [SEP] [SEP] [SEP]", "cit": "penn treebank was previously used to train and evaluate various dependency parsers # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "clte has as main applications content synchronization and aggregation in different languages # otherefr ; # refr. [SEP] this approach was proposed a [SEP] [SEP]", "cit": "the cross - lingual textual entailment ( clte ) task consists in determining the type of directional entailment ( i. e. forward [SEP]"}
{"pre": "the basic concept of the approach has been described by # refr. [SEP] this approach. [SEP] the whole corpus. [SEP] the whole corpus. [SEP] [SEP]", "cit": "following models were applied : n - gram posteriors ( zens and # refr, sentence length model, a 6 - gram lm and ibm [SEP]"}
{"pre": "we used the same split as # refr. [SEP] ( i ) we pr ( p ) as follows : q ( w ; w [SEP] [SEP] [SEP]", "cit": "the decoding problem for a broad range of these systems ( e. g., # refr ) corresponds to the intersection of a ( weighted ) [SEP]"}
{"pre": "in this paper, we focus on the graph - based mstparser # otherefr, which is based the second - order parser of mcdonald", "cit": "since arc - standard is bottom - up, we remove all features using the head of stack elements, and also add the right child features of [SEP]"}
{"pre": "in this paper, we show that the reranking parser described in # refr outperforms the bilingual parsing task of multiple languages. [SEP] ( daume", "cit": "we further simplify inference in our model by working in a reranking setting # otherefr ; # refr, where we only consider the [SEP]"}
{"pre": "although a number of papers that reduce the number of features have found been explored in previous work # otherefr ; # refr, we evaluate the", "cit": "while these extractions are inferior to the abstracts, they are attainable by our model, a quality found to be advantageous in discriminative training for [SEP]"}
{"pre": "several methods have been proposed with regard to aligning parallel corpora # otherefr ; # refr. [SEP] this problem by pivot [SEP] the same", "cit": "several approaches rely on bilingual parallel data # otherefr ; # refr, while others leverage distributional methods on monolingual text corpora # otheref [SEP]"}
{"pre": "incidentally, the above attributes are the same as those used by the conventional stochastic dependency parsing methods # otherefr ; # refr. [SEP] the", "cit": "incidentally, the above attributes are the same as those used by the conventional stochastic dependency parsing methods # otherefr ; # refr. [SEP] [PAD]"}
{"pre": "joint methods have been used in rhetorl # otherefr ; # refr. [SEP] text coherence # otherefr noticed to [SEP] text [SEP] text", "cit": "there have been some studies that have used discourse structures locally to optimize the order of selected sentences # otherefr ; # refr. [SEP] [PAD] [PAD]"}
{"pre": "syntax - based statistical machine translation ( smt ) models # refr capture long distance reorderings by using rules with structural and linguistical information [SEP]", "cit": "syntax - based statistical machine translation # otherefr ; # refr capture long distance reorderings by using rules with structural and linguistical information [SEP]"}
{"pre": "in japanese, the main problems of japanese these methods is the subject of a particular verbal semantic role labelings which were later puted by [SEP] [SEP]", "cit": "several methods have been proposed with regard to this problem # otherefr # refr # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the pos information used in this framework to train the pos tagger of # refr. [SEP] dictionaries # otherefr [SEP] [SEP] [SEP]", "cit": "however, running vanilla forward - backward - em leads to mediocre results, due to various properties of the training method # refr. [SEP]"}
{"pre": "# refr use a similar approach for combining multiple translation models in a log - linear framework. [SEP] the reranker of # otherefr [SEP]", "cit": "multiple solutions are also used for reranking # otherefr, and system combination # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "dave et al. # otherefr, yu and # refr, wiebe and riloff # otherefr ). [SEP] [SEP]", "cit": "other research efforts analyze opinion expressions at the sentence level or below to recognize opinions, their polarity, and their strength # otherefr, yu [SEP]"}
{"pre": "we have recently extended this approach to various degrees of verbs by relying on the verb classification task, as defined by the use of the verb classifications #", "cit": "table 5 : cluster quality by origin # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we report results on the bleu # refr, meteor # otherefr. [SEP] the tuning procedure, using the exact string comparison [SEP] ble [SEP]", "cit": "parameter settings we tune our system toward approximate sentence - level bleu # refr, 3 and the decoder is configured to use cube pruning # other [SEP]"}
{"pre": "several approaches assume a tree structure to the nl, mr, or both # otherefr ; ge and # refr, and mooney [SEP] [SEP]", "cit": "several approaches assume a tree structure to the nl, mr, or both ( ge and # refr, and often in - [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "probabilistic synchronous tag # otherefr ; # refr is a probabilistic tree adjoining grammar # otherefr. [SEP] the probability l [SEP] (", "cit": "a proposal in \\ [ # refr \\ ] relates to probabilistie parsing. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "almost all previous research on japanese dependency structure analysis dealt with dependency structures in written text # otherefr ; # refr. [SEP] this kind of [SEP]", "cit": "however, since some methods for detecting sentence boundaries have already been proposed # otherefr ; # refr, we assume that they can be detected [SEP]"}
{"pre": "in our case, the algorithm is chosen for projective decoding ; we use the dependency analysis of # refr. [SEP] the [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "given the lattice and gs,? s, lattice parsing is a straightforward generalization of the standard arc - factored dynamic programming algorithm from # refr [SEP]"}
{"pre": "the patterns we use are similar to those proposed by # refr. [SEP] the patterns. [SEP] the hyponymy relation ( e. g.,", "cit": "we have already made a first approach on the extraction of relational triples from text, where, likewise # refr, we take advantage of textual patterns [SEP]"}
{"pre": "# refr used mdl in hebrew. [SEP] a word segmenter based on a tf - idf model, and [SEP] [SEP] [SEP] [SEP]", "cit": "its connection to lexical acquisition was first uncovered in behavioral studies, and early applications focused mostly on applying mdl to induce word segmentation that results in [SEP]"}
{"pre": "for example, # refr describes a system that can be used for extracting homograph and character sequences. [SEP] text. [SEP] text [SEP] text [SEP] text", "cit": "for example, # otherefr and # refr used spaces to recognise tables in free text. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "different techniques to widen the search space have been described # otherefr ; # refr. [SEP] the search space using minimum bayes risk [SEP] [SEP]", "cit": "# refr present an mbr decoding that makes use of a mixture of different smt systems to improve translation accuracy. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "brent, 1991, 1993 ; # refr. [SEP], 1993 ; briscoe and carroll, 1997 ; manning, 1993 [SEP],", "cit": "brent, 1991, 1993 ; ushioda et al, 1993 ; briscoe and carroll, 1997 ; manning, 1993 [SEP]"}
{"pre": "some of the features employed include parts of speech # otherefr, word stems, and synonyms # refr. [SEP], [SEP] [SEP] [SEP] [SEP]", "cit": "university of amsterdam # otherefr meteor carnegie mellon university # refr amber, bleu - nrc national research council of [SEP]"}
{"pre": "for example, dubey and keller # otherefr use punctuation, and other linguistically annotated corpora, which are well - studied [SEP],", "cit": "the meritof an edge is its inside probability times a prior p ( lhs ) times a lookahead probability # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "unbalanced corpora are common in a number of different tasks, such as emotion detection # otherefr, sentiment classification # refr, and annotation [SEP] [SEP]", "cit": "what? s more, reducing the annotation effort is the goal of this paper but not building a high recall classifier such as # refr and amb [SEP]"}
{"pre": "additionally, we use 50, 000 sparse, binary - valued features based on adjacent arcs and second - order context - order context - order models trained", "cit": "others have introduced alternative discriminative training methods # otherefr ; # refr, in which a recurring challenge is scalability : to train many features [SEP]"}
{"pre": "in contrast, other work has learnt strategies to produce relational facts from text # otherefr ; # refr, and [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "work done during an internship at google research. gine typically returns # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in a vast body of related work, automated methods of sentence generation have been explored in the past # otherefr ; # refr and [SEP] [SEP]", "cit": "we believe that out experiments will give insight into new models of text generation, which is aimed at modeling the process of producing natural language texts, [SEP]"}
{"pre": "note that unlike monolingual parsing is related to the previous work of # refr, who show that their combination is a good fit for pcfg parsing", "cit": "our model leverages multiple automatically learned latent variable grammars, which differ only in the seed of the random number generator used to initialize the em learning [SEP]"}
{"pre": "we parse the data with the # refr parsers trained on the british national corpus # otherefr. [SEP] the [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "even though the lexicon is derived from machine readable dictionaries and contains a \\ ] a. rge number of senses for many words, [SEP]"}
{"pre": "language understanding has been well studied in the context of question / answering # otherefr ; # refr, and machine learning # other [SEP] [SEP] [SEP]", "cit": "language understanding has been well studied in the context of question / answering # otherefr ; # refr, entailment # otherefr, [SEP]"}
{"pre": "the measure pk # refr to use the average length of lexical items. [SEP] a text relative to segment by maximizing the probability distribution of text. [SEP]", "cit": "another class of approaches is based on a generative model of text, for instance hmms # otherefr and bayesian topic modeling # refr ; [SEP]"}
{"pre": "we use mstparser # refr and maltparser # otherefr to train the mst model, and show that a discriminatively trained model", "cit": "for example the passive - aggressive algorithm was adapted to chunking # otherefr, parsing # refrb ), learning preferences # otheref [SEP]"}
{"pre": "textual entailment ( e. g., # refr ) is a framework that has been applied in several natural language processing tasks, [SEP] [SEP] [SEP]", "cit": "for example, two high - accuracy systems are those described in # refr, achieving 60. 4 % accuracy with no task - specific information, [SEP]"}
{"pre": "we have already discussed a very powerful tool for discourse relations # refr in order to support explicit timex links between them, and a more [SEP] [SEP]", "cit": "for searching in pdt, a client - server based system called pml - tq has been developed ( pml - tree query ; pajas and? [SEP]"}
{"pre": "ulc ( gim? nez and m? # refr is an arithmetic mean of mt evaluation metrics that incorporates several semantic information into the translation", "cit": "ulc ( gim? enez and m ` a # refr incorporates several semantic features and shows improved correlation with human judgement on translation quality [SEP]"}
{"pre": "# refr used a supervised backoff model to predict compound words. [SEP], which in a word - to - word sequence, and then [SEP] [SEP]", "cit": "while this approach works when translating between languages with limited morphology such as english and french, it has been found inadequate for morphologicallyrich languages like arabic [SEP]"}
{"pre": "this process is thoroughly explained in # refr. [SEP] distributional similarity the text t2 system ( t. [SEP] t ) in this work : [SEP] [SEP]", "cit": "however, given that posts are generally very short, noisy and lacking in context, traditional nlp approaches tend to perform poorly over social media data [SEP]"}
{"pre": "# refr propose a sense model for wsi which assumes word sense disambiguation and lexical ambiguity resolution together with a bayesian model. [SEP] the target word", "cit": "recently, we have also witnessed that wsi is cast as a topic modeling problem where the sense clusters of a word type are considered as underlying [SEP]"}
{"pre": "for english, we use the parser described in # refr. [SEP] # otherefr. [SEP] the word identities for each of the pair of [SEP]", "cit": "projectivity can be relaxed in some parsers # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "rte # refr. [SEP] machine translation vsms aim to address the problem of student response analysis. [SEP] and generation [SEP] ( qe ). [SEP]", "cit": "rtms achieve very good performance in judging the semantic similarity of sentences # otherefrb ) than the state - of - the - art [SEP]"}
{"pre": "in this section we describe how we have extended it is based on the transfer module in the multilingual setting ( openccg transfer framework ) framework #", "cit": "at first glance, our approach is very similar to the semantic transfer approach presented in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the method of # refr to find the best of each phrase, and use it as a weight vector w. [SEP] the probability distribution of", "cit": "in this paper, the phrase - based machine translation system is utilized # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in recent years, several computational models of latent semantic analysis have been used # otherefr ; # refr to determine the strength of word [SEP] [SEP]", "cit": "pos tags don? t help lsa either, as has already been observed by # otherefr ; # refr for other tasks. [SEP] [PAD]"}
{"pre": "# refr use linguistically syntax trees to derive syntactic information into the source string to handle syntactic. [SEP] complex tree. [SEP]. [SEP] the source [SEP]", "cit": "the past two years have witnessed the rapid development of linguistically syntax - based translation models # otherefr ; # refr, which induce tree [SEP]"}
{"pre": "the approach of # refr showed that the best performance in the former is the same reason about. [SEP]. [SEP]. [SEP] % of the [SEP] [SEP]", "cit": "we improve on # refr by adding normalization and viterbidecoding. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "to our knowledge, the first to use of the coreference resolution system is an extension of the joint - probability model proposed by # refr. [SEP]", "cit": "# refr used several kernel functions in learning. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in fact, the paraphrase generation task can be used for tasks, such as paraphrase recognition # otherefr, machine translation [SEP]", "cit": "in recent years, there has been an increasing interest in the task of paraphrase generation # otherefr ; # refr. [SEP] [PAD] [PAD]"}
{"pre": "for example, # refr addressed the problem of detecting summaries of detecting and evaluated the reports reported in table 1. [SEP] characteristics of [SEP]. [SEP] research", "cit": "for example, zechner # otherefr examined summarization of multiparty dialogues and # refr examined summarization of meeting recordings. [SEP]"}
{"pre": "much research effort has been made to address the binary classification problem # otherefr ; # refr, but is still an attractive solution, as it", "cit": "review texts are automatically filtered to leave only subjective sentences ( motivated by the results described in # refr ) ; the mean number of words per review [SEP]"}
{"pre": "the n - gram models were built using the irstlm toolkit # otherefr, using the berkeley language model # refr, and the berkeley", "cit": "we use the berkeley language model package # refr with absolute discounting # otherefr ) which includes a backoff strategy to lower - order [SEP]"}
{"pre": "we evaluated translation quality using the bleu metric # refr. [SEP] bleu # otherefr. [SEP] the bleu - 4 [SEP] [SEP] [SEP]", "cit": "as commonly used in statistical machine translation, we evaluated the translation performance by bleu score # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr use latent semantic analysis to find synonymy states in a bilingual word representations. [SEP] a word embeddings induced by a latent semantic space of", "cit": "similar to the model presented here, klementiev et al. # otherefr and # refr learn bilingual embeddings using word alignments. [SEP]"}
{"pre": "this is similar to the scheme used by # refr and is similar in relation extraction # otherefr. [SEP] relations. [SEP] relations [SEP] relations [SEP]", "cit": "these are quite powerful approaches but have very high computational requirements ( cf. # refr ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr and biran et al. # otherefr explored statistical methods for sentence simplification and simplification to improve the learning process. [SEP] sentences [SEP]", "cit": "text simplification has applications for children, language learners, people with disabilities # otherefr, and can be beneficial as a preprocessing step for other [SEP]"}
{"pre": "in the field of natural language processing, ner has been well studied and the nlp community, e. g., # otherefr [SEP]", "cit": "on the other hand, al has been successfully used in a number of natural language applications such as text classification # otherefr, named entity [SEP]"}
{"pre": "# refr. [SEP] a statistical representation of the verbs that a verb is - noun combinational phrase ( verbs ) and the verb [SEP] [SEP] [SEP] [SEP]", "cit": "in english, e. g., the two aspect constructions perfective and progressive can be seen as realizing the basic contrast of the action viewed [SEP]"}
{"pre": "in \\ [ # refr \\ ] a system that uses a set of context - free grammar and a set of component words'is described [SEP] [SEP]", "cit": "alternatively, a syntactic filter is applied to the parse tree and any noun phrases for which coreference with the relative pronoun is syntactically legal ( [SEP]"}
{"pre": "# refr pointed out that the number of languages does not make the difficult even for highly ambiguous readings of the ambiguous form ambiguous word [SEP]. [SEP].", "cit": "3it should be noted that important subsequent research, e. g. by # otherefr ; # refr, used the ratnapark [SEP]"}
{"pre": "we use a hidden variable model # otherefr and sequence model ( hmm ) # refr to find the sentence that is content. [SEP] [SEP] [SEP]", "cit": "to achieve readable summaries, the extracted sentences must be appropriately ordered # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "less general approaches based on matching have been proposed in # refr and # otherefr. [SEP] the latent variable approach is [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "still, this is an issue only for short sentences. ments for the ibm - 3 has been shown to often be practicable # [SEP]"}
{"pre": "we use the xerox part - of - speech tagger # refr and the pos tagger of # otherefr. [SEP] this information [SEP]", "cit": "among others, it can be composed with transducers that encode :? correction rules for the most frequent tagging errors which are automatically generated # otheref [SEP]"}
{"pre": "in spoken dialogue systems, incremental systems have been used for incremental dialogue systems # otherefr ; incremental speech recognition and # refr. [SEP] [SEP] [SEP]", "cit": "dialogue systems that process incrementally produce behavior that is perceived by human users to be more natural than systems that use a turn - based approach # [SEP]"}
{"pre": "nonetheless, it is common practice to use the top - performing features in transition - based dependency parsing # otherefr ; # refr. [SEP] this", "cit": "the time column show how many seconds per sentence each parser takes. 7 approach uas las time zhang and clark # otherefr 93. 8 [SEP]"}
{"pre": "to combine grammar - based paraphrasing with lexical and phrasal alternatives gleaned from multiple reference sentences, our approach takes advan - 1 [SEP]", "cit": "earlier, barzilay and lee # otherefr and # refr developed approaches to aligning multiple reference translations in order to extract paraphr [SEP]"}
{"pre": "we can use a very simple weighted string - todependency tree substitution algorithm # refr as follows : the restriction of the tree transducer - - -", "cit": "furthermore, it is known [ see, for example, # refr ] that for every weighted string automaton a with states s, we can construct [SEP]"}
{"pre": "we employ the method of # refr, which is based on the edit distance method we used the english monolingual dependency parse ( english ) [SEP] the", "cit": "instead, we use the unsupervised transliteration mining system of # refr that takes a list of word pairs for training and extracts transliteration [SEP]"}
{"pre": "in this paper, we discuss the ( 1 ) for the ( n - best, the - best ( algorithm, the hereafter referred to hereafter hereafter", "cit": "4this setup used 3 - and 6 - round state - split grammars from # refr, the former used to compute a heuristic for the latter [SEP]"}
{"pre": "transitivity was also used as an information source in other fields of nlp : taxonomy induction # otherefr, and unsupervised relation discovery # [SEP]", "cit": "joint inference has been applied successfully 10percentages for? unknown? are omitted here. to other nlp problems # otherefr ; # [SEP]"}
{"pre": "cross - lingual annotation projection # otherefr, dependency parsing # refr or temporal relation prediction # otherefr. [SEP] the source [SEP] [SEP]", "cit": "the alternative we propose is primarily motivated by the research on annotation projection # otherefr ; s? # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr used dirichlet priors to estimate p ( wi | ti ) for model estimation, which is a hidden markov model is used. [SEP]. [SEP]", "cit": "for example, the task of pos tagging is to recover the appropriate sequence structure given the input word sequence # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr used latent semantic analysis to find affixes. [SEP] the word stems from the prefixes. [SEP] a word [SEP] it morphological [SEP] it", "cit": "the wordframe model # refr uses inflection - root pairs, where unseen inflections are transformed into their corresponding root forms. [SEP] [PAD] [PAD]"}
{"pre": "the annotation of events and event relations in natural language texts has been addressed in the context of a wide - coverage project in the encyclopedias", "cit": "sputlink is based on james allen? s interval algebra # otherefr and # refr who both added a closure component to an annotation environment [SEP]"}
{"pre": "we used the stanford ner tagger # refr to determine if the label word they are selected by an information binary classification task. [SEP] ( 1 [SEP]", "cit": "for syntactic analysis we use the stanford parser # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "there have been many studies on the automatic acquisition of lexical properties for english, e. g., # otherefr ; pereira,", "cit": "precursors to this work include # refr, ( brown et al. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "there have been some recent attempts on the reordering problem within psmt # otherefr ; # refr, with respect to translation reordering [SEP]", "cit": "# refr proposed the use of function word reordering to improve alignments. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "it is generally formulated as a semantic role labeling # otherefr ; # refr. [SEP] the argument structure of predicates as the predicate plays [SEP] [SEP]", "cit": "it is generally formulated as a semantic role labeling # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the ibm model 1 # otherefr and the hidden markov model ( hmm ) alignment model # refr. [SEP] the word movement of the", "cit": "then, we would use an word alignment model # otherefr ; # refr, with source s = xp,..., x [SEP]"}
{"pre": "in fact, the state - of - the - art machine learning models # otherefr ; # refr are trained on the muc - [SEP] [SEP]", "cit": "many researchers have recently explored machine learning - based methods using considerable amounts of annotated data provided by, for example, the message understanding conference and automatic [SEP]"}
{"pre": "in the first step, we use the clustering algorithm # refr. [SEP] vs. [SEP] vs. [SEP] vsms of word sense disambiguation # other", "cit": "a number of previous approaches to name discrimination have employed ideas related to context vectors. # refr proposed a method using the vector space model to disambig [SEP]"}
{"pre": "for part - of - speech tagging we include results from the stanford pos tagger # refr, and parse treebanks # otheref [SEP] [SEP]", "cit": "the system of christodoulopoulos et al # otherefr was based upon an lda type model which included both contexts and other conditionally [SEP]"}
{"pre": "statistical methods for automatic named entity recognition # otherefr ; # refr, and multi - engine machine translation # otherefr. [SEP] [SEP] [SEP]", "cit": "on the other hand, we scored lower on all - caps than bbn is identifinder in the muc - 7 formal evaluation for reasons which [SEP]"}
{"pre": "in addition to the baseline, we also rani - mrl - 2013 datasets with the highest f - score # refr [SEP] thesaurus [SEP]", "cit": "# refr extended the method of lau et al. to incorporate knowledge of the expected domains of new wordsenses, but did not conduct a rigorous [SEP]"}
{"pre": "bracketed corpora # otherefr ; # refr. [SEP] the negra corpus # otherefr 15. 9 [SEP] boundaries [SEP] [SEP] [SEP] [SEP]", "cit": "there are few statistical parsing algorithms that rely only on plain lexical features # refr however, as other algorithms, one needs to decide where to pr [SEP]"}
{"pre": "we use the visual world - widecoverage statistical language model, and demonstrated in # refr. [SEP] linguistic structure prediction # otherefr [SEP] [SEP]", "cit": "creating language describing the scene in a basic template - driven way, utilizing attribute detections # otherefr or likely verbs from a language model # [SEP]"}
{"pre": "this kind of supertagger has been shown to be very effective in various tasks such as mt, syntactic parsing # otherefr [SEP] ( [SEP]", "cit": "# refr and langkilde - geary # otherefr, respectively, though the former is limited to sentences of length 20 or [SEP]"}
{"pre": "the monolingual corpora are available for the multilingual dictionaries making process # otherefr, # refr, is currently underway to develop a syntactic", "cit": "figure 1 : fipscoview : system architecture. tic parsing # otherefr and syntax - based machine translation # refr, the on [SEP]"}
{"pre": "# refr use statistical methods for subjectivity analysis. [SEP] the opinionfinder pairs. [SEP] the two words in this paper. [SEP] features [SEP] the", "cit": "detecting the polarity of words is the fundamental problem for most of sentiment analysis tasks # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, the dialog state tracking challenge ( dialog ) system # refr can benefit from dialog state tracking ( dialog ) to predict the dialog state tracking", "cit": "for further details, please refer to the dstc handbook # refrb ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in a second experiment, we provide a comparison of different ( i ) for the two components : semantic inference, which are the [SEP] [SEP] [SEP] [SEP]", "cit": "nevertheless, simple lexical level entailment systems pose strong baselines which most complex entailment systems did not outperform # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "current state - of - the - art sense clustering are typically reported in # refr. [SEP] the wordnet similarity to be a mixture of two [SEP]", "cit": "for language learners, a fine - grained set of word senses may help in learning subtle distinctions, while coarsely - defined senses are probably [SEP]"}
{"pre": "while many models of text coherence have been developed in recent years # otherefr, # refr, soricut and marcu # other [SEP]", "cit": "however, structured features have only been applied to a handful of nlp tasks such as semantic role labeling # otherefr, syntactic parsing [SEP]"}
{"pre": "thereafter, we employ the ctk # otherefr to compute the similarity between two upsts, and the tree kernels, and ( ii )", "cit": "moreover multi - source knowledge can benefit kernel calculation, such as using dependency information to dynamically determine the tree span # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the emergence of linguistic knowledge in language processing such as part - of - speech tagging # otherefr, syntactic variation # refr, [SEP] [SEP] [SEP]", "cit": "more recently, lu # otherefr, # refr and chen and zechner # otherefr have measured syntactic competence in speech scoring [SEP]"}
{"pre": "in this paper we show how we discuss the general framework of yamada and matsumoto # otherefr, # refr, and the general", "cit": "as # refr pointed out, there is a strong connection between parsing and deduction. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper, we focus on the following feature sets :? a target language model trained on smoothed n - gram language model trained on smoothed data", "cit": "work by # refr, van durme and lall # otherefr considered the problem of building very large language models via the use of [SEP]"}
{"pre": "we used minimum error rate training ( mert ) # refr to tune the feature weights for the log - linear model. [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "the alignment is carried out by giza + + # refr and then we symmetrized the word alignment using the grow - diag - final [SEP]"}
{"pre": "the'lexical transfer component of the system is implemented in the trec - 2the natural language generation system # refr to encode the information of [SEP]", "cit": "in order to solve this problem, start deploys \" s - rules \" # refr, which are reversible syntactic / semantic transformational rules that [SEP]"}
{"pre": "in addition, we provide a detailed overview of the experience of word sense disambiguation task # otherefr ; # refr. [SEP] this [SEP] [SEP]", "cit": "to tackle this problem, we use framenet # refr to generalize event triggers so that semantically similar triggers are clustered in the same frame. [SEP] [PAD]"}
{"pre": "in nlp, rush et al # otherefr applied dual decomposition, and dual decomposition to inference # refr. [SEP] this problem to its", "cit": "finally, in other recent work, # refr describe dual decomposition approaches for other nlp problems. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in a similar vein, # refr use a corpus of paired documents from the same date consists of five different ( annotate window ). [SEP] the", "cit": "word usage similarity ( usim : # refr ) is a relatively new paradigm for capturing similarity in the usages of a given word independently of [SEP]"}
{"pre": "more recently, # refr describe a sequential planning approach, but this approach is limited to simpler than simple ones. [SEP] non - deterministic decision trees,", "cit": "we also considered the visual salience of objects, and the type of spatial relation involved, since recent studies indicate the potential relevance of these features # [SEP]"}
{"pre": "the model parameters,? 1,.,? l,???, i = 1,? i log? (? ) p (", "cit": "note that the inside - outside approach can be combined with any maximum entropy estimation procedure, such as those evaluated by # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "the second hypothesis, that the distribution with respect to context and to context - sensitive similaritys, we apply a probabilistic model based on the assumption that", "cit": "probabilistic latent variable frameworks for generalising about contextual behaviour # otherefr and # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the documents were parsed using the stanford parser # refr. [SEP] stanford parser # otherefr. [SEP] this preprocessing plays a role in [SEP] [SEP]", "cit": "to generate the features for each of the mention pairs a proprietary jdpa tokenizer is used for parsing the document and the stanford parser # refr [SEP]"}
{"pre": "we used bootstrap resampling # refr to measure significance on the mixed test set, and we computed the bootstrap resampling with p < 0. [SEP]", "cit": "statistical significance is computed using paired bootstrap resampling # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper we will present the challenges in the analysis community # refr for the bionlp - st 2009 shared task # otherefr [SEP]", "cit": "several related works have also been published within the framework of the bionlp? 09 shared task on event extraction # otherefr, where [SEP]"}
{"pre": "in addition, the representation of the lexicons described in this paper ( see # refr for an overview of the different kind of multi - word [SEP]", "cit": "hence, efforts are being devoted nowadays to machine translation tools involving these two languages # refr, although they are still scarce. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "particularly, the latter made team? 09 task people reference faust? 12 - 3c # otherefr umass? 12 - 1 [SEP]", "cit": "even if we could manage to obtain highly accurate automatically detected 1in the context of event extraction # otherefr ; # refr. [SEP] [PAD] [PAD]"}
{"pre": "shieber # otherefr recently argued that probabilistic synchronous tree adjoining grammars ( shieber and # refr have the right combination [SEP]", "cit": "mapping between source and target texts is achieved by an extension to the tag formalism known as synchronous tag, introduced by shieber and # refr [SEP]"}
{"pre": "in this paper, we describe the system that we participated in the * sem 2013 task # refr. [SEP] ( semantic textual similarity ) [SEP] ( sts", "cit": "the core semantic textual similarity shared task of * sem 2013 # refr is to generate a score in the range 0 - 5 for a pair of [SEP]"}
{"pre": "we used the minimum error rate training ( mert ) # refr to tune the feature weights for the log - linear model. [SEP] [SEP] [SEP] [SEP]", "cit": "bilingual word alignments are trained and combined from two sources : giza # refr and maximum entropy word aligner # otherefr. [SEP] [PAD] [PAD]"}
{"pre": "# refr used syntactic features, defined as part of speech ( pos ) tags. [SEP] features derived from context features to detect subjectivity. [SEP] subject", "cit": "# refr report experiments with belief tagging, which in many ways is similar to factuality detection. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr use semi - supervised learning to detect ordering of noun - ordering. [SEP] the generalization ability of the clause restructuring, which can be [SEP] [SEP]", "cit": "determining methods for ordering modifiers prenominally and investigating the factors underlying modifier ordering have been areas of considerable research, including [SEP]"}
{"pre": "we obtained symmetric word alignments of training data by first running giza + + # otherefr in both directions and then applying refinement rule? grow", "cit": "however, past work either relies solely on monolingual source - side models # otherefr, or limited modeling of the target side # refr [SEP]"}
{"pre": "in addition, the decoder in addition to the decoder, we also propose a state - of - the - art phrase - based translation system, which", "cit": "we used the joshua decoder ( li and # refr as the baseline hiero system. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use adaptor grammars # refr, a number of nlp tasks that involve the probability of a target word and its collocations. [SEP] [SEP] [SEP]", "cit": "here we use the adaptor grammar package described in johnson et al # otherefr and # refr with? out of the box? default settings [SEP]"}
{"pre": "this work has been inspired by the observation of # refr and # otherefr, who show that word meaning is, [SEP] if, [SEP] [SEP]", "cit": "in the human language acquisition literature, grimshaw # otherefr and # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, there exist a lot of work on automatically constructing polarity lexicons # otherefr ; # refr. [SEP] the word [SEP] subjectivity", "cit": "# refr proposed a method for identifying word polarity of adjectives. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this section we evaluate the performance of the semi - supervised algorithm # refr. [SEP]a ) a local maximum entropy classifier, based [SEP] [SEP] [SEP]", "cit": "to overcome this issue a novel class of approaches have been proposed # otherefr ; # refr that exploit global and local features. [SEP] [PAD] [PAD]"}
{"pre": "in a study of the disambiguation of a bilingual corpus, # refr propose a method to align the same parallel sentences that can be used to disambig", "cit": "comparable corpora can be used to determine which word associations suggest which translations of the word # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "supertagging has since been effectively applied to other formalisms, such as parsers # otherefr, # refr, and [SEP] [SEP] [SEP]", "cit": "when used to predict the probability of the possible regents of each preposition in each sentence, it achieved an accuracy of 79. 4 % [SEP]"}
{"pre": "in this paper we present a phrase - based translation system which generates a word alignment on a word alignment structure, pharaoh # [SEP] [SEP] [SEP]", "cit": "many strategies have been proposed to integrate morphology information in smt, including factored translation models # otherefr, and using porter stems and [SEP]"}
{"pre": "in relation extraction, kernel methods have been used successfully in relation extraction # refr. [SEP] textual entailment # otherefr. [SEP] this [SEP] kernel", "cit": "the problem of relation extraction was later formulated as a classification problem : # refr proposed to solve this problem using maximum entropy models using lexical, syntactic [SEP]"}
{"pre": "in order to efficiently compute the hypergraph packed forest, we used a hypergraph representation proposed by # refr. [SEP] the hypergraph representation of a", "cit": "since its first appearance in # refr, the cube pruning ( cp ) algorithm has quickly gained popularity in statistical natural language processing. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "iii and marcu, 2004 ), # otherefr, # refr, # otherefr. [SEP] kernel expansion and statistical machine learning techniques", "cit": "iii and marcu, 2004 ), # otherefr or # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for instance, the current syntactic relation of japanese predicate - argument structures # otherefr ; # refr have the same problem as prop - bank [SEP]", "cit": "in particular, for languages such as japanese, anaphora resolution is crucial for resolving a phrase in a text to its referent since phrases, [SEP]"}
{"pre": "# refr describe an approximate algorithm for constructing a streaming algorithm for the constructing vector - based matrix operations, which has been shown to be effective in nl", "cit": "to build this system, we exploit recent developments in the area of approximation, randomization and streaming for large - scale nlp problems # refr. [SEP]"}
{"pre": "the polarity orientation of a word w is defined as follows o # otherefr : similarity ( w i ( w i, r ) =?", "cit": "wiebe # otherefr uses # refra ) style distributionally similar adjectives in a cluster - and - label process to generate sentiment [SEP]"}
{"pre": "previous work has noted the existence of either a large corpus of news documents # otherefr, or automatically learning relations # refr. [SEP] [SEP] [SEP]", "cit": "we follow an open ie approach # refr and use dependencies to identify the elements. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in particular, we have developed an automated nlg system that incorporates minibatches1 # otherefr ; # refr. [SEP] [SEP] features [SEP]", "cit": "many of the tasks which have been successfully crowdsourced involve judgments which are similar to those performed in everyday life, such as recognizing unclear writing [SEP]"}
{"pre": "the k - best algorithm, with the k - best parsing algorithm of jime, is described in # refr. [SEP] the lazy algorithm of", "cit": "it is basically an adaptation of one of the k - best parsing algorithms by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used a phrasebased statistical machine translation system similar to # refr. [SEP] this approach by using the technique of # otherefr. [SEP] [SEP]", "cit": "phrase scoring was computed using good - turing discounting # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in statistical machine translation, several language models have been proposed that allow for the storage of language models # otherefr ; # refr. [SEP] the", "cit": "some years ago, there was a clear tendency in smt to use huge lms trained on hundreds on billions # otherefr of words [SEP]"}
{"pre": "the simplest of these # refr is the phrasebased ( r ) alignment model described in detail. [SEP] the likelihood of the translation units [SEP] a [SEP]", "cit": "1this method of phrase pair extraction was originally described by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "twitter? 86p # refr introduced two new approaches, which heavily depended on the generated microblogs. [SEP] the posts. [SEP] the tweets [SEP]", "cit": "there have been many studies on how to extract and utilize such information on tweets # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the physical model of # refr, this model has only been considered to be noun - verb classification, as it has only been the main focus", "cit": "many category induction experiments start by trying to categorize words, and # refr categorize word usages, a combination of a word and its [SEP]"}
{"pre": "the algorithm moves all dimensions at the same time, as proposed by # refr, can deal with an ambiguity. [SEP]. [SEP] the expressions. [SEP]", "cit": "reference domains # otherefr ; # refr are theoretical constructs, which are basically sets of entities presupposed at each use of res. [SEP] [PAD]"}
{"pre": "ng and # refr report results on the same test set, which are compared with the results reported by different ( bruce and [SEP] ( ng [SEP] [SEP]", "cit": "bayesian learning # otherefr, exemplar based learning ( ng and # refr, decision list # otherefr, etc.. [SEP] [PAD]"}
{"pre": "in other papers, the automatic generation modules include agent, the dialogue system developed at the university of idf # refr. [SEP]text # otheref", "cit": "a client may connect to the server and open up a dialogue ( see figure 1 in # refr ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, we use a sophisticated statistical model of discourse segmenter, namely rhetorical structure theory, lexically, and the discourse grammar, can", "cit": "applications in which is is crucial are textto - speech systems, where is helps to improve the quality of the speech output # refr, and [SEP]"}
{"pre": "al has already been applied to several nlp tasks, such as document classification # otherefr, and information extraction # refr. [SEP] [SEP] [SEP]", "cit": "indeed, active learning has been found to provide considerable gains in corpus annotation # refr & # otherefr, and can be a model for [SEP]"}
{"pre": "we used minimum error rate training ( mert ) # refr to tune the decoder for feature weights. [SEP]. [SEP]. [SEP] the decoder [SEP] [SEP]", "cit": "in practice, when training the parameters of an smt system, for example using the discriminative methods of # refr, the cost for skips [SEP]"}
{"pre": "in fact, pos tags given to twitter are assigned using twitter? s arktwee, as we recently presented a way of [SEP] filtering [SEP] [SEP]", "cit": "twitter contains a vast amount of information, including first stories and breaking news # refr, fingerprints of public opinions # otherefr. [SEP] [PAD] [PAD]"}
{"pre": "we use 3500 sentences from conll # otherefr sentences ) and tagged with pos tags ( 4 ) tags ( 14 ) 1 [SEP] (", "cit": "precision and recall rates were 92. 4 % on the same data used in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "sentiment scoring is tackled in both computational linguistics # otherefr ; yu and # refr. [SEP] ( yu and m ) [SEP] ( [SEP] [SEP]", "cit": "there has recently been a dramatic surge of interest in sentiment analysis, as more and more people become aware of the scientific challenges posed and the scope [SEP]"}
{"pre": "in addition, their method can be applied to linearchain crfs # otherefr ; # refr. [SEP] this objective due to the generalized [SEP]", "cit": "in fact, many attempts have recently been made to develop semi - supervised sol methods # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used the dataset by # refr. [SEP] the british national corpus ( bnc ), as part of the acl anthology ( e [SEP] [SEP]", "cit": "the corpus will be used to test and adapt modern nlp tools on historical data, and will be of interest to other current corpus - based [SEP]"}
{"pre": "in # refr, we proposed a method for adapting the phrase table of phrase tables. [SEP] in order to a tuple? s tables, [SEP] [SEP]", "cit": "most of them have been proposed in order to make translation systems perform better for resource - scarce domains when most training data comes from resourcerich domains [SEP]"}
{"pre": "in our experiments, we used the senseval - 3 english lexical sample task # refr consisting of five different wsd systems. [SEP] the [SEP] system", "cit": "2. 1. 3 extracting senses preliminary experiments on 10 nouns of senseval - 3 english lexical - sample task # refr ( s3ls [SEP]"}
{"pre": "# refr used unification formalisms such as lexicalized representation. [SEP] ( 1 ) are represented as a representation of disjunctive structures in terms that", "cit": "moreover, incorporating disjunctive information into internal representation makes parsing more efficient # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the context of spoken dialogue systems, # refr present a framework that allows the user to obtain the user input. [SEP] if the user is [SEP]", "cit": "# refr use logistic regression models to predict the stability and accuracy of incremental speech recognition results to enhance performance without causing delay. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "pleonastic its have been detected using heuristics ( e. g., # refr ) and learning - based techniques such as rule learning # [SEP]", "cit": "they are well - known indicators and constraints for coreference and are taken from previous work # otherefr ; # refr ; lee et al [SEP]"}
{"pre": "three recent papers in this area are church and hanks # otherefr, # refr, and smadja and mckeown # other [SEP]", "cit": "it also differs from previous proposals on lexical acquisition using statistical measures uch as # otherefr ; # refr which either deny the prior existence [SEP]"}
{"pre": "in order to extract such links, we followed a technique that builds on a representation of the words from the source language sentence to a [SEP] in [SEP]", "cit": "# refr describes a method for learning translation relationship between words from bilingual corpora. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the field of natural language processing, barzilay and lee have been used for wsi # otherefr [SEP] the [SEP] application of [SEP]", "cit": "the authors in # refr extend the generative model by lda by many parallel feature representations. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the stanford pos tagger # refr for pos taggers. [SEP] the penn treebank, and use the pos tagger of [SEP] [SEP]", "cit": "when building probabilistic models for tag sequences, we often decompose the global probability of sequences using a directed graphical model # otherefr or a conditional [SEP]"}
{"pre": "for example, the well - known morphological nalysis software ( though, # refr ), can be directly performed. [SEP]. [SEP]. [SEP].", "cit": "rules are applied recursively and nondeterministically, somewhat in the style of # refr, taking advantage of prolog is unification mechanism to [SEP]"}
{"pre": "for example, there are a number of robust semantic processing systems # otherefr ; # refr which contain incremental parsers that pass on partial [SEP]", "cit": "when the parser builds a potential referring expression ( e. g. any np ), it is immediately passed on to the advisor, the [SEP]"}
{"pre": "we train a trigram language model with kneser - ney smoothing # refr. [SEP] smoothing # otherefr constructed from the training data [SEP]", "cit": "much of this work has taken advantage of smoothing techniques to overcome problems associated with data sparseness # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we also compare our results against the paired bootstrap resampling method # refr. [SEP] # otherefr used a paired bootstrap resampling technique to compare", "cit": "on newstest2009, this result is statistically significant with 95 % confidence according to the bootstrap resampling method described by # refr. [SEP] [PAD]"}
{"pre": "in this paper, we show that for the reranking parser reported in # otherefr ; # refr, can be used to automatically obtain", "cit": "this process was performed using a parser made available by eugine charniak and brown university # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the probabilistic model we use here has been shown to be effective in smoothing # otherefr ; # refr. [SEP] the conditional probability distribution p (", "cit": "this model is reminiscent of conditional models in mt that perform stepwise generation of one string or structure from another? e. g., string alignment [SEP]"}
{"pre": "this was done while the bleu score # refr was used as a criterion. [SEP] the translation quality of the translation quality. [SEP]. [SEP] the", "cit": "such comparisons are done either at lexical level # refr, or at linguisticallyricher levels using paraphrases # otherefr. [SEP] [PAD]"}
{"pre": "decode ( ` i,??,??? ) ; # refr. have shown high performance on this task # otherefr. [SEP]", "cit": "we also add them as features in a discriminatively - trained phrase - based mt system, using standard techniques to train their weights # otheref [SEP]"}
{"pre": "in event extraction, common approaches use a variety of syntactic features # otherefr ; # refr. [SEP] this approach is shown to be [SEP] [SEP]", "cit": "the uturku system of bjo? # refr was the winner of the ge task in 2009. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we demonstrate the performance benefits of different statistical learning based on the approach of # refr. [SEP] the approach of erk and pad? [SEP] [SEP] [SEP] [SEP]", "cit": "however, researchers have demonstrated that cosine is not the best relevance metric for other applications, so we evaluated two other topical similarity scores : jacquar [SEP]"}
{"pre": "syntactic category refinement our work also relates to work in syntactic category refinement in which pos categories and parse tree non - terminals are refined in order to [SEP]", "cit": "syntactic category refinement our work also relates to work in syntactic category refinement in which pos categories and parse tree non - terminals are refined in order to [SEP]"}
{"pre": "existing work in abstractive summarization has been quite limited and can be categorized into two categories : # otherefr # refr # otheref [SEP]", "cit": "there are several ways of generating an abstract sentence # otherefr ; # refr ) ; however, most of them rely heavily on the syntactic [SEP]"}
{"pre": "# refr compiled a set of 90 unseen adjective - noun bigrams using the same 30 adjectives. [SEP] adj [SEP] [SEP] [SEP] [SEP]", "cit": "using the web to overcome data sparseness has been attempted before # refr ; however, there are issues : misspellings, typographic errors [SEP]"}
{"pre": "there has been a lot of research in determining the sentiment of words and constructing polarity dictionaries # otherefr ; # refr. [SEP] this problem", "cit": "there have been several subsequent efforts to model within - sentence valence shifts, including compositional grammar # otherefr, matrix - vector products across the [SEP]"}
{"pre": "# refr observed that much of the relation between concepts in the named entities are the entity - entity not between the entities of the entities of the text", "cit": "there are approaches which do not need any human intervention or sophisticated text processing, but learn based on redundancy of the input dataset and some well grounded [SEP]"}
{"pre": "in addition to the clearest window size on the availability of large corpora, we also use a new version of word window that can be used for", "cit": "semantic classification has proved useful in a range of application areas, such as information extraction # otherefr, acquim'tion of domain knowledge [SEP]"}
{"pre": "we use the japanese verb ~ tern \\ [ # refr \\ ]. [SEP]'~ m ~ m ~ m ~ m ~ m ~ \\ [", "cit": "then, classification rules were crafted by hand, or detected from relation - tagged examples by a machine learning technique # otherefr ; [SEP]"}
{"pre": "we evaluated translation quality using bleu # refr and ter # otherefr. [SEP] the word error rate ( wer ) to measure [SEP] [SEP] [SEP]", "cit": "the second and the third columns contain the average bleu score # refr on the top three results on the development and test sets. [SEP] [PAD] [PAD]"}
{"pre": "several authors have used supertags, an additional factored smt framework for mt # refr, that has since it more robustly [SEP] the", "cit": "our approach is slightly different from # refr and # otherefr, who mainly used the supertags on the target language side, english [SEP]"}
{"pre": "integer linear programming ( ilp ) has recently been applied to several classification tasks, including relation extraction # refr, semantic role labeling # otherefr", "cit": "we take a similar approach that has been previously used for entity / relation recognition # refr, and model this inference procedure as solving an ilp [SEP]"}
{"pre": "proposed approaches to modelling nc semantics have used semantic similarity # otherefr ; gi # refr and paraphrasing # otherefr. [SEP] [SEP]", "cit": "proposed approaches to modelling nc semantics have used semantic similarity # otherefr ; # refr and paraphrasing # otherefr. [SEP] [PAD] [PAD]"}
{"pre": "an excellent version of the model that we have used the same dop features ( version 2. 1 ) =? n = 1.? n [SEP]", "cit": "moreover, # refr show how a tree kernel can be applied to dop1 is all - subtrees representation. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr use machine translation for multilingual sentiment analysis. [SEP] the cross - lingual subjectivity analysis. [SEP] natural language processing ( nlp )", "cit": "similarly, # refr propose a method based on machine translation to generate parallel texts, followed by a cross - lingual projection of subjectivity labels [SEP]"}
{"pre": "bayesian inference methods have become popular in natural language processing # refr. [SEP] this approach to nlp, they have successfully applied to machine translation # other", "cit": "bayesian inference has been widely used in natural language processing # refr ; blunsom et al2009 ; ravi and knight, 2011 [SEP]"}
{"pre": "the choice of p as # otherefr fits this bill, but many other choices can be made regarding pref, such as # refr. [SEP]", "cit": "to do this, we modified the exact pcfg parser of # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "while these approaches have been shown to be successful # otherefr ; # refr in the past, the statistical framework has been limited [SEP] [SEP] [SEP]", "cit": "when comparing our results to the results of # refr, who pursue a multi - level segmentation aproach using conditional random fields optimizing over the [SEP]"}
{"pre": "we used the charniak - johnson parser # refr for english, and we used the charniak parser # otherefr to parse the", "cit": "alternatively, our work could be integrated into a full - sentence parser by using our feature representations directly in a discriminative cfg parser # otheref [SEP]"}
{"pre": "we train the averaged perceptron algorithm # otherefr with beam search # refr as in early update # otherefr. [SEP] the inex [SEP]", "cit": "beam search incremental parsers # otherefr ; # refr provide very competitive parsing accuracies for various grammar formalisms ( cfg, ccg [SEP]"}
{"pre": "the use of monolingual language models has been well studied in the nlp community, e. g. # otherefr ; # refr [SEP]", "cit": "google research papers report on a distributed infrastructure that is used to train on up to two trillion tokens, which result in language models containing [SEP]"}
{"pre": "the main idea here is that we developed in the context of a natural language text processing system # refr. [SEP] text understanding conference [SEP] characteristics [SEP] characteristics", "cit": "the approach taken here for navy messages, which uses suhlanguage s leetional patterns for disambiguation, was developed, esign [SEP]"}
{"pre": "kernel functions are very effective at modeling diverse linguistic phenomena by implicitly representing data in high dimensional spaces, e. g. # otherefr ; [SEP]", "cit": "more recently, kernel functions, which implicitly represent data in some high dimensional space, have been employed to study and further improve many natural language systems [SEP]"}
{"pre": "we use a variant of the algorithm defined by # refr for ner. [SEP] the laws algorithm. [SEP] the laws order to fit of the data.", "cit": "in the future, we will research more effective text mining techniques for contextual extraction # otherefr at the same time increasing the amount of annotated [SEP]"}
{"pre": "concrete consequences of this general nlp task, notably the aim of grefenstette and sadrzadeh # otherefr ; # refr.", "cit": "concrete consequences of this general abstract setting and applications to empirical data are under active study # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used the stanford ner tagger # refr to determine whether a noun or its labeling is a specific domain. [SEP]. [SEP] it appears in [SEP]", "cit": "as in # refr we apply our approach to a linear chain conditional random field # otherefr using the mallet toolkit with default parameters. [SEP]"}
{"pre": "# refr used a pos - tagger to obtain the right dictionary for words by first predicting the morphological relations between words in a sentence. [SEP] [SEP]", "cit": "the whole word morphologizer # refr uses a pos - tagged lexicon as input, induces morphological relationships without attempting to discover or identify morphemes [SEP]"}
{"pre": "relation instances, then, are represented by indicatorargument pairs # refr. [SEP] sentences by using document types or tokens. [SEP] documents ( e.", "cit": "examples include using bootstrapping to amplify small seed sets of example outputs # otherefr ; # refr, leveraging existing databases that overlap with [SEP]"}
{"pre": "the propbank project has been designed as an active development of a powerful technology for computational lexicon building on syntactic structure # otherefr, semantic [SEP]", "cit": "in previous work using the propbank corpus, # otherefr for predicting semantic roles based on the framenet corpus # refr. [SEP] [PAD] [PAD]"}
{"pre": "the task of semantic textual similarity # refr was defined as a common solution in the semeval - 2010 task [SEP] a new [SEP] of identifying relations", "cit": "rel setup is informed by recent semantic relation tasks # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used giza + + # refr on the corpus to train the lm weight the finalized nist. [SEP] - 2 to - word n -", "cit": "finally, we use mert training # refr to learn feature weights for the decoder. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in particular, the problem of post - processing is defined as the headed decision tree ( e. g., # refr ). [SEP] the", "cit": "to show that the influence of punctuations on parsing is independent of specific parsing algorithms, we conduct experiments using three parsers, each representing [SEP]"}
{"pre": "we used the dmv implementation from # refr. [SEP] this strategy. [SEP] this strategy. [SEP] it takes the original idea of an agent, following", "cit": "for instance, models addressing the acquisition of grammatical constructions and their meaning # refr typically learn from symbolic input. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use a hierarchical clustering algorithm # refr to obtain the strength of for agreement of an inter - annotator agreement. [SEP] a single concept. [SEP]", "cit": "these methods are the information retrieval inspired precision - recall # otherefr ; # refr and krippendorff? s?, a [SEP]"}
{"pre": "in this work, we describe results from the open - source syntax augmented machine translation ( samt ) toolkit # refr applied to the monolingual [SEP]", "cit": "in subsequent work, the approach has been extended to incorporate linguistic annotation on the target side ( as in samt # refr ) or on both [SEP]"}
{"pre": "in addition, we computed the predicted precision and recall scores by the predicted b3n4 # otherefr and the stanford coreference [SEP] system", "cit": "an entity is the group of all the mentions referring to the same person in the text ( recasens and # refr. http : [SEP]"}
{"pre": "in contrast, recent work in unsupervised part - of - speech tagging uses em # refr, and unsupervised learning of pos taggers. [SEP] features #", "cit": "recent work has made significant progress on unsupervised pos tagging # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for example, # refr describe coarse parsing for a simple, and a parsing algorithm that is presented in figure 2, where the basic idea is used", "cit": "in the recent vine pruning approach # otherefr, significant speedup is gained by leveraging structured information via a coarse - to - fine [SEP]"}
{"pre": "for instance, # refra ) find that the coverage of a sense is determined by the meaning of the word? s meaning task is a [SEP]", "cit": "the teams of ( hsh ) # refr, clac # otherefr participated with two unsupervised approaches. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in natural anguage generation, different generation tasks often interact with each other in a complex way, which is hard to integrate pipeline architecture [SEP] the pipeline", "cit": "# refr, reiter & dale # otherefr ), and has been successfully used to combine standard preprocessing tasks such as part - [SEP]"}
{"pre": "in information extraction, for example, utilizing manually - created rules or resources are used for learning in a new domain # otherefr [SEP]. #", "cit": "supervised learning of relation - specific extractors ( e. g., # refr ), and?? open. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this is in contrast to methods for the case of translation models that rely on the fact that the translation is rather uncommon can be found in french [SEP]", "cit": "the approach started with the so - called ibm models # refr, implementing a set of elementary operations, such as movement, duplication and translation, [SEP]"}
{"pre": "# refr show that for the use of query logs, their approach is much harder to disambiguate the set of sets of types represented by the type", "cit": "# refr use distributional statistics to determine the probability that a wordnet - derived inference rule is valid in a given context. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for productive constructions, they are largely inspired by syntax - augmented # refr. [SEP] the inferred multi - word expressions relying on the part of speech (", "cit": "in contrast with representations like that of # refr, in which concepts are distributed over several lexical entries, a tree - rewriting representation such as the [SEP]"}
{"pre": "# refr use a morphological analyzer to disambiguate arabic morphological disambiguation. [SEP] arabic ( mada ) for arabic, a pos tagger. [SEP]", "cit": "these solutions include morphological analysis # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, we plan to use the ideological similarity measure # refr, which is the first measure of text - til between adjacent segments in the", "cit": "knowledge - lean approaches distributional models of content have appeared with some frequency in research on text segmentation and topic - based language modeling # refr ; beef [SEP]"}
{"pre": "# refr presents an algorithm that reranks using part - of - speech tags for the translation model. [SEP]. [SEP], of collins and *", "cit": "the actual translations were produced with a greedy decoder # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the idea of using a polarity of a verb or subjectivity in a sentence - level polarity is often used as an important problem # other [SEP] tasks", "cit": "over the years researchers have developed various approaches to identify polarity of words # otherefr, sentences # refr even documents # otherefr. [SEP]"}
{"pre": "in a second experiment, we used the stanford constituent parser # refr to parses with a lfg parser. [SEP] if the constituent [SEP] it tends", "cit": "as the table shows, the openccg scores are quite competitive, exceeded only by # refr extensively hand - crafted system as well as [SEP]"}
{"pre": "by contrast, explicit syntax approaches seek to directly model the relations learned from parsed data, including models between source trees and target trees # other [SEP]", "cit": "many other models translate discontiguous phrases, and the size of their extracted rulesets is such a pervasive problem that it is a recur [SEP]"}
{"pre": "# refra ) used part - of - speech information and image labelling for content. [SEP] text ( nns ). [SEP] the [SEP] of [SEP]", "cit": "topic modelling is now widely used in natural language processing # otherefr, image labelling # refra ) and visualisation of document collections # other [SEP]"}
{"pre": "our method to constrain the translations using tm fuzzy matches is similar to # otherefr, except that the word alignment between e? and f [SEP]", "cit": "for example, # otherefr showed that reusing these translations as large rules in a hierarchical system # refr can be beneficial when the fuzzy [SEP]"}
{"pre": "syntax - based statistical machine translation ( ssmt ) has achieved significant progress during recent years, with two threads developing simultaneously : the synchronous parsing - [SEP]", "cit": "syntax - based statistical machine translation # otherefr and the tree - to - string ( tts ) transducer # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "in # refr a pre - reordering system is used to model reorderings in pos tags. [SEP] the source sentence to a target sentence to", "cit": "rottmann and vogel # otherefr and # refr used rules to reorder the source side and store different possible reorderings in [SEP]"}
{"pre": "in addition, the definition of the muc - 6 challenge # otherefr # refr which outperforms a number of systems in which were available after [SEP]", "cit": "in a previous attempt to define predicate - argument structure, semeval, the effort was abandoned because so many constructs would require detailed attention and [SEP]"}
{"pre": "we used bleu # refr, ter # otherefr to evaluate the translation quality. [SEP] bleu score. [SEP] the [SEP] [SEP] [SEP] [SEP]", "cit": "we run the decoding using the baseline feature weights and a weight for a cache feature and compute the ( case - insensitive ) bleu # refr [SEP]"}
{"pre": "in contrast, factored translation models # otherefr ; # refra ) use morphological features and syntactic information in the source [SEP]. [SEP] [SEP]", "cit": "bojar and kos # otherefr or # refr.. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "there has been a sizable amount of research on opinion summarization # otherefr ; # refr. [SEP] [SEP] textrank # otheref", "cit": "one major paradigm of review summarization is aspect - based summarization, which is based on identifying aspects and associating opinion sentiment with them. [SEP]"}
{"pre": "there has been research on utilizing manually aligned corpus to assist automatic word alignment, and obtains encouraging results on alignment error rate. # otherefr [SEP]", "cit": "there have been several research papers on using mturk to help natural language processing tasks, # refr used mturk to evaluate machine translation [SEP]"}
{"pre": "# refr and bos # otherefr derive semantic graph processing from a large unannotated corpus to deal with an underspecified representation for", "cit": "the semantic format is dependencyminimal recursion semantics # otherefr as a compact and easily readable equivalent to robust minimal recursion semantics ( rm [SEP]"}
{"pre": "we used datasets distributed for the 2006 and 2007 conll shared tasks # otherefr ; # refr. [SEP] this data [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "the evaluation datasets correspond to the test sets from the conll shared tasks on dependency parsing # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "we use crfs as well as # refr. [SEP] ( w0 ) : w ( w i ) = argmax e { w [SEP] (", "cit": "many machine learning approaches have been proposed # otherefr ; wu and # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the publicly available coreference resolution system of stanford corenlp # refr to perform well for each of the errors. [SEP] errors, a", "cit": "this yields a formal foundation for previous work on link - based error analysis # otherefr and complements work on transformation - based error analysis # [SEP]"}
{"pre": "weak supervision is also a popular option for re : mintz et al # otherefr ; # refr. [SEP] this approach. [SEP] [SEP] [SEP]", "cit": "since then, the approach grew in popularity # otherefr ; # refr ; nguyen and moschitti, 2011 ; sun et al [SEP]"}
{"pre": "in this work, we aim to consider the text as a post - processing step, as well as this method [SEP] ( [SEP] ) to [SEP] [SEP]", "cit": "most works construe the problem in the metaphors of either machine translation # otherefr ; # refr, or automated speech recognition # other [SEP]"}
{"pre": "we use a hierarchical phrase - based translation system called max - margin # refr. [SEP] the grammars m1 are similar to the generalization of och?", "cit": "smt systems based on synchronous context free grammars # otherefr ; # refr have recently been shown to give competitive performance relative to phrase - [SEP]"}
{"pre": "the model of # refr goes beyond that of # otherefr and now as it captures the semantic representations between dialogue and discourse entities were modeled as", "cit": "in ( huet and # refr unsupervised models were proposed that use stochastic alignment and latent dirichlet allocation respectively, but these models infer a flat concept [SEP]"}
{"pre": "transliteration methods typically fall into two categories : generative approaches # otherefr that try to produce the target transliteration given a source [SEP]", "cit": "this has been shown both in supervised settings # refr and unsupervised settings # otherefr describes an unsupervised training of a constrained conditional model ( ccm [SEP]"}
{"pre": "we use a general framework of the parallel phrase extraction # refr. [SEP] the dp - based methods decreases on a graph - based approach that requires exhaustive", "cit": "the german v - o pairs were extracted from a syntactic analysis of the hgc carried out using the bitpar parser # refr. [SEP] [PAD] [PAD]"}
{"pre": "an appealing approach to such textual inferences is to explicitly transform t into h, using a sequence of transformations # otherefr ; # refr. [SEP]", "cit": "in addition, it includes a search algorithm which finds an optimal sequence of transformations for any given t / h pair # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "in the second step, the output is pos - tagger, in contrast, from # refr, and we explicitly apply a conditional random [SEP] filtering", "cit": "recently, there has been an explosion of interest in conditional random fields # otherefr for solving structured output classification problems, with many successful applications [SEP]"}
{"pre": "in our experiments, we use sifat ( me ) # refrb ) and evaluate the summaries of two different query types of summaries. [SEP] [SEP]", "cit": "to evaluate our system, we use the pyramid evaluation method # refr at sentence level. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we follow the framework of # refr in formulating chunking as a classification task, where the search space is represented as a sequence labeling task,", "cit": "left - to - right and rightto - left orderings have been often investigated in sequential labeling tasks # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in a second approach, the approach is to train a discriminative model # otherefr ; # refr. [SEP] features in a structured perceptron #", "cit": "alignment with giza + + # otherefr and the berkeley aligner # refrb ) are supported. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we also used the publicly available software moschitti # otherefr with the svm - light - tk toolkit # refr for automatic structural [SEP]", "cit": "kpet stands for the path - enclosed tree ( pet ) kernel # refr. w is a multiplicative constant used for the pet kernel. [SEP] [PAD]"}
{"pre": "most of the early works in cognate identification has been considered by either build upon lexico - syntactic patterns # otherefr ; # refr,", "cit": "previous work in cognate identification has largely focused on identifying cognates in pairs of languages # otherefr ; # refr, with a few [SEP]"}
{"pre": "we note that the proposed method is related to previous work in chinese microblogs # otherefr ; # refr. [SEP] the problem [SEP] [SEP]", "cit": "figure 2 : resolution acc @ k accuracy # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "most of the previous work on normalization focused on word normalization, we consider a simple variant of normalization, which has been shown to be effective in [SEP]", "cit": "there has been a lot of interest in recent years on? normalization? of social media such as twitter, but that work defines normalization much more [SEP]"}
{"pre": "in the latter case, the algorithm has been used for parameter estimation # otherefr, and other tree - based models # refr. [SEP] [SEP]", "cit": "2available under the eclipse public licence from http : / / www. graphviz. org / string automata tree automata dag automata compute [SEP]"}
{"pre": "7 # refr extended cube pruning as the semiring challenge. [SEP] (? ) by leveraging memory ; it can be used for the exact computation", "cit": "another differentiation technique, implemented within the semiring, is given by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the japanese, the unknown word is usually represented by using a maximum entropy approach # refr. [SEP] ( me ) and the unknown [SEP] [SEP] [SEP]", "cit": "# refr studied japanese word segmentation using me models. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the literature, syntactical constraints are used for lexicalized reordering models # otherefr ; # refr, and in # other [SEP] [SEP]", "cit": "this paper describes a decoding algorithm for a syntax - based translation model # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "state - of - the - art statistical machine translation systems based on a log - linear framework are parameterized by {?,? },,,", "cit": "state - of - the - art statistical machine translation systems based on a log - linear framework are parameterized by {?,? },, [SEP]"}
{"pre": "much work has been done related to word sense disambiguation # otherefr, and sentiment analysis # refr. [SEP] this work [SEP] the presence of", "cit": "there has been previous work on assigning polarity values to senses of words taken from word - net # otherefr, # refr ). [SEP] [PAD]"}
{"pre": "for instance, the ibm model - 1, hmm - to - word alignment models # otherefr ; # refr, have been used in the", "cit": "ibm model 1 # otherefr and the hmm alignment model # refr are cascaded to form the baseline model for alignment. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "past approaches to sentence compression include a noisy channel formulation # otherefr, a pure discriminative model # refr, and an integer linear programming formulation #", "cit": "another future direction is to extend our ilp formulations to more sophisticated models that go beyond word deletion, like the ones proposed by # refr. [SEP]"}
{"pre": "bilingual lexicon extraction from comparable corpora has received considerable attention since the 1990s # otherefr ; # refr ; dagan et al, 1995 ;", "cit": "# refr verified this assumption between english and german. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in particular, abstraction mechanisms ( e. g., # refr have been applied to a number of languages. [SEP]. [SEP] the problem of tag", "cit": "for example, an infinite intersection with a regular set having the form of a triple - counting language or a string matching language # refr would suff [SEP]"}
{"pre": "graph - based label propagation methods have recently shown they can outperform the state - of - the - art in several natural language processing # otheref [SEP]", "cit": "graph - based label propagation methods have recently shown they can outperform the state - of - the - art in several natural language processing # otheref [SEP]"}
{"pre": "in # refr, a phrase - based translation model was used to predict the consistency between source and target languages. [SEP], [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "for instance # refr extract rules from n - best lists of alignments for a syntax - augmented hierarchical system. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "discriminative log - linear models # otherefr ; # refr are a form of discriminative training framework, which can be used for parameter estimation, [SEP]", "cit": "the prevalent translation model in modern systems is a conditional log - linear model # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for unsupervised pos tagging, we use the online perceptron algorithm # refr since we can be used for parameter estimation, by our fast and training.", "cit": "one sees this clear trend in the supervised nlp literature? examples include the perceptron algorithm for tagging # otherefr, mira for [SEP]"}
{"pre": "we adopt the weighted marginal relevance algorithm # refr as our testbed, in figure 1. [SEP] ( 1 ) we do not provide a definition of [SEP]", "cit": "much work has been done for generic multidocument summarization # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "there have been two general lines of research : the first one derives the nc semantics from the semantics of the nouns it is made of # other [SEP]", "cit": "recently, the idea of using fine - grained paraphrasing verbs for nc semantics has been gaining popularity # otherefr # refr. [SEP]"}
{"pre": "the first system uses a log - linear combination of a rule - based statistical mt model, a rule - based system and a rule - based [SEP]", "cit": "since the work of # refra ), statistical post - editing ( spe ) has become a very popular technique in the domain of hybrid mt [SEP]"}
{"pre": "verb classes have proved useful in various # otherefr, word sense disambiguation # refr, and subcategorization acquisition # otherefr.", "cit": "this idea provided the computational linguistics community with criteria for the definition and the classification of verb semantics ; it has subsequently resulted in the research of the [SEP]"}
{"pre": "we use a sentence alignment model as described in # refr. [SEP]. [SEP] ( 5 ) = to e. g. [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "in 2005, however, several independent efforts # otherefr ; # refr demonstrated that discriminatively trained models can equal or surpass the alignment [SEP]"}
{"pre": "while recognizing # otherefr ; # refr. [SEP] the current approaches for this task, we use these features as a [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "# refr defines an attribution as having a source span, a cue span, and a content span : source is the span of text that indicates [SEP]"}
{"pre": "we use the same kernels for our experiments, e. g. # refr. # otherefr. [SEP] kernel computation and svms lightly", "cit": "the experiments were carried out with the svm - light - tk software available at http : / / ai - nlp. info. uniroma [SEP]"}
{"pre": "we use the english side of the parallel corpus # refr. [SEP] training data was parsed using the grammars english and german. [SEP] [SEP] [SEP] [SEP]", "cit": "coverage precision grammar of english # refr and a lexical functional grammar parser # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in 2012, the 2012 sts task was complete in the 2012 conference # otherefr ( s? # refr. [SEP] the sts task of [SEP]", "cit": "this paper presents the two systems for automated measuring of semantic similarity of short texts which we submitted to the semeval - 2012 semantic text similarity [SEP]"}
{"pre": "thus, we can deduce that subjectivity contexts should be disambiguated in an gloss vector space that can be obtained by using such features from the [SEP]", "cit": "there has been a large and diverse body of research in opinion mining, with most research at the text # otherefr or word # refr [SEP]"}
{"pre": "iii, 2007 ; # refr. [SEP] the svm classifier # otherefr. [SEP]. [SEP] the representation of data in the multi - domain dataset", "cit": "additional examples include congressional floor debate records ( e. g. political party, speaker, bill ) # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used the following similarity measure : lin ( wu and # refr to compute the degree of semantic relations between two concepts in word pairs, [SEP] [SEP]", "cit": "we experiment with the knowledge - based measures implemented in the wordnet : : similarity package # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this work, we aim to precisely replicate human edited phrases # otherefr ; # refr. [SEP] this work was done [SEP] [SEP] [SEP] [SEP]", "cit": "this work is also similar in aim to a component of the parsing and language modeling work of # refr, which used right - binarization [SEP]"}
{"pre": "in statistical machine translation, it is common to see a recent example search # otherefr ; # refr. [SEP] this approach is to use local", "cit": "we create a forest of possible synchronous derivations ( cf. # refr ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in recent years, several system combination methods have been proposed to combine the outputs of multiple mt systems # refr. [SEP] a derivation forest in [SEP] [SEP]", "cit": "# refrb ) partially resolved the problem by constructing a large network in which each hypothesis was treated as a skeleton and the multiple networks were merged [SEP]"}
{"pre": "the last two systems were evaluated using bleu # otherefr and meteor # refr12. [SEP], on a held - out set [SEP] [SEP]", "cit": "# refr propose additional, tunable features in the phrase table to indicate the origin of phrase translations. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this is related to the work of # refr, who train generation models of visual objects such as linear combinations of generated descriptions of objects, and [SEP]", "cit": "# refr describe a system with multiple hand - written templates. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used the similarity measure ( wu and # refr, lcsr ), defined the similarity between two words in the corresponding verbs [SEP] [SEP] [SEP] [SEP]", "cit": "for instance, the leacock - chodorow metric # otherefr finds the shortest path between two concepts and 6http : / [SEP]"}
{"pre": "the subgradient update for the ` 1 - ` 2 regularization term is done in line 11 and then for the loss in line 12. 6 unlike", "cit": "well - known examples include mert # refr, mira # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the last years have seen a boost of work devoted to the development of unsupervised learning for nlp tasks # otherefr ; # refr. [SEP]", "cit": "these include ccm # otherefr, ( u ) dop based models # refr, an exemplar based approach # otherefr which we [SEP]"}
{"pre": "in this paper, we focus on the treebank grammar ( tsg ) # refr, and remove the structures of rules. [SEP], in order", "cit": "for further discussion, and for the proof of the order independence s e # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in recent years, there has been an increased interest in the efficiency of dialogue systems in the domain of dialogue systems # otherefr ; # refr", "cit": "to achieve incrementality, most dialogue systems employ an incremental chart parser ( cf. # refr etc. ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "another approach, which we may consider in the future, would be to annotate a small subset of the training examples with full ccg derivations [SEP]", "cit": "this has been successfully applied in combinatorial categorial grammar # otherefr, as it tightly couples compositional semantics with syntax # refr ; as cc [SEP]"}
{"pre": "this framework scales to large data, and to the task of automatically derive bilingual wsd algorithms # refr. [SEP] the [SEP] unsupervised [SEP] [SEP] [SEP] [SEP]", "cit": "# refr first considered unsupervised ensembles by combining four state of the art word sense disambiguation systems using a simple voting scheme with much success. [SEP] [PAD]"}
{"pre": "the only difference between the system and the system optimization of disambiguation is that it is generally formulated as a single learning problem can be used by #", "cit": "furthermore, it has been previously applied to word sense discrimination successfully, returning the best results among a number of other measures # refr. [SEP] [PAD] [PAD]"}
{"pre": "# refr resort to automatic analysis of multi - word mwes to constituency parsing. [SEP] the preprocessing plays an important role in natural language processing.", "cit": "recently, # refr proposed integrating the multiword expressions directly in the grammar without pre - recognizing them. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this work, we assume a general parallel corpus in which each sentence pair are non - terminal symbol x and y conditioned on the other [SEP] [SEP]", "cit": "in recent years, statistical machine translation # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "previous work has addressed the problem of generating locative expressions, employing a multi - modal dialogue architecture # otherefr ; # refr. [SEP] [SEP]", "cit": "previous research on cooperative responses has noted that summary strategies should vary according to the context # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the srilm toolkit # otherefr to train the lm for language model estimation, and perform decoding using the srilm toolkit # refr", "cit": "church et al # otherefr looked at golomb coding and # refr used tries in a distributed setting. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for instance, to measure the syntactic similarities between the source and target languages, # refr found that that both reference and those that that that that that", "cit": "we use three different kinds of metrics : dr - stm semantic tree matching, a la # refr, but over drs instead of over constituency [SEP]"}
{"pre": "output : gold standard topic label for each of the lda topics for tw. 1 : for each topic i? { 1, 2,. [SEP]", "cit": "to alleviate this issue here, we followed the distribution similarity approach, which has been widely applied in the automatic generation of gold standards # otheref [SEP]"}
{"pre": "# refr present a model for compositionality based on vector spaces # otherefr. [SEP] representations. [SEP] the vectors of representing [SEP] vectors for [SEP]", "cit": "a concrete instantiation of this theory was exemplified on a toy hand crafted corpus by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "kernel functions are very effective at modeling diverse linguistic phenomena by implicitly representing data in high dimensional spaces, e. g. # refr. [SEP] features [SEP]", "cit": "# refr? the work was mainly done when the author was a visiting student at i2r and che et al # otherefr for [SEP]"}
{"pre": "in this work, we evaluate the performance of the simple metrics used by # refr. [SEP] the word sense disambiguation. [SEP] a latent variable [SEP]", "cit": "to represent the semantics of scus and candidate substrings of target summaries, we applied the latent vector model of # refr. 1 guo and [SEP]"}
{"pre": "# refr describes a method for clustering words according to their frequencies in english syntactic contexts. [SEP] different ways. [SEP] different from a single word [SEP] it", "cit": "another application of hard clustering methods # otherefr, # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr show that for pcfg parsing, unlexicalized pcfg over the penn treebank could be used to produce grammars automatically induce a", "cit": "as shown in # refr, the ability of pcfg models to disambiguate phrases crucially depends on the expressiveness of the symbolic backbone they [SEP]"}
{"pre": "in the second evaluation, the precision of the precision and recall scores are reported in # refr, f - measure # otherefr [SEP] [SEP] [SEP]", "cit": "we implemented the formula for both the expected values and the log - likelihood values as described by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we run our beam search approach on the same cipher and report better results without using an additional word sense disambiguation [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "complete automation of the key discovery process remains an active area of research # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr proposed to use an exponential hash to build larger corpora for lms, and show significant improvements in machine translation quality. [SEP], [SEP], [SEP]", "cit": "this fact, along with the observation that machine translation quality improves as the amount of monolingual training material increases, has lead to the introduction of [SEP]"}
{"pre": "previous work has shown that ensemble - based methods can be applied to a wide variety of natural language processing tasks # otherefr, machine translation #", "cit": "for the base learner, we use kriya # refr, an in - house hierarchical phrase - based machine translation system, to produce multiple [SEP]"}
{"pre": "in fergus, bangalore and rambow # otherefr used a probabilistic tree - to - tree transducer - to - tree tagger", "cit": "recently, specific probabilistic tree - based models have been proposed not only for machine translation # otherefr ; # refr, and language modeling # [SEP]"}
{"pre": "domain adaptation is widely recognized as a technique which can significantly improve domain adaptation # otherefr ; # refr. [SEP] ( daume. [SEP] [SEP]", "cit": "as expected, when an indomain corpus is used both for training as well as for optimizing the log - linear parameters, the peform [SEP]"}
{"pre": "this area of research recently has received a significant amount of attention # otherefr ; # refr ; lu et al., 2008 ; jones [SEP]", "cit": "this area of research recently has received a significant amount of attention # otherefr ; # refrb ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "several authors have noted how pos tagging performance is sensitive to cross - domain shifts # otherefr, methods such as feature bagging # refr,", "cit": "several authors have noted how pos tagging performance is sensitive to cross - domain shifts # otherefr ; # refr, and while most authors have [SEP]"}
{"pre": "# refr revisited koppel? s work using only the 200 most frequent character bigrams, and achieved 65. 6 % accuracy, with [SEP]", "cit": "the same experimental setup is assumed by # refr, who are mostly interested in testing the hypothesis that an author? s choice of words in a [SEP]"}
{"pre": "the features include : a maximum entropy classifier, trained on native english text # otherefr ; # refr. [SEP] [SEP] [SEP] [SEP] [SEP] features [SEP]", "cit": "# refr compared a range of learning algorithms for the task of correcting errors made by non - native writers, including an averaged perceptron algorithm # [SEP]"}
{"pre": "de - facto and zhang develop a semisupervised approach to deriving a lexicon from a list of lexico - syntactic patterns # refr. [SEP] [SEP]", "cit": "the reconciliation engine which presents the second part of the elicitation engine is detailed on previous papers # refr # otherefr. [SEP] [PAD]"}
{"pre": "many pasa methods have been studied on the naist text corpus # otherefr, and the predicate - argument structure analysis # refr. [SEP]", "cit": "many pasa methods have been studied on the naist text corpus # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "secondly, we only consider the relation between the syntactic and the target expressions, which have been shown to be useful in a number of nlp applications", "cit": "perhaps there is a legitimate role here for metalinguistic judgments after all, in which participants are asked to express their preference between expressions ( see [SEP]"}
{"pre": "extensible dependency grammar ( xdg ) is a new grammar formalism based on the extensible dependency grammar ( xdg ) # refrb ),", "cit": "we build upon the extensible dependency grammar ( xdg ) # refr model and its cp implementation in oz # otherefrc ). [SEP] [PAD]"}
{"pre": "typos, 2 ), that vs.? non - nominal constituent? have been done when it is possible to induce a verb [SEP] [SEP] [SEP]", "cit": "# refr mine inter - linearized data from the web and infer typological features for? low - density? languages, i. e. languages [SEP]"}
{"pre": "we use the following baseline ( 4 ) : p ( ci = |??? | t? )? ( t? |? [SEP] [SEP]", "cit": "these results also support the broader and farreaching claim that natural language problems in a resource - poor language can be solved using a knowledge source [SEP]"}
{"pre": "while many approaches have been developed, in this literature, they are still applied to a variety of tasks, such as improving performance [SEP] characteristics # other", "cit": "this setup is often used to gather data from users who believe they are interacting with an automated system # otherefr ; # refr. [SEP] [PAD]"}
{"pre": "for rule extraction we use moses # otherefr implementation of ghkm # refr, which although is conventionally used to extract syntax - augmented [SEP]", "cit": "for rule extraction we use moses # otherefr ; # refr, which although is conventionally used to extract syntax - augmented scfgs from [SEP]"}
{"pre": "the nli task consists of 1. 2. 2 of two languages / language identification / nli / language identification software modules clan / [SEP]", "cit": "the details about the tasks are described by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in this paper, we focus on the following four recent reference methods : # otherefr ; # refr for training the negated [SEP] [SEP] [SEP]", "cit": "previous evaluation studies suggest that the original corpus sentence is not always the only optimal realisation of a given linguistic input # otherefr ; # [SEP]"}
{"pre": "the main idea that a translation estimation from comparable corpora has been studied by # refr, and has recently developed to support vector machines # otheref [SEP]", "cit": "a different method is proposed by # refr, who use latent semantic analysis on a combined collection of texts written in two languages. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "we used the mxpost tagger # refr for english and the base forms. [SEP] the tagger of # otherefr for german, and", "cit": "english part of speech # otherefr, and max imum entropy # refr, to select just a few. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the swedish corpus is a swedish treebank which was created in the ancora corpus ( bnc ), an english - [SEP] system [SEP] [SEP] [SEP]", "cit": "pad? and lapata # otherefrb ) projected annotation from english to german, and # refr implemented a complete pipeline for english? swedish [SEP]"}
{"pre": "most of the previous work on named entity recognition mainly focus on named entity recognition ( ner ) # refr, which is a sequential model that is trained", "cit": "many of the previous studies of bio - ner tasks have been based on machine learning techniques including hidden markov models ( hmms ) # refr, [SEP]"}
{"pre": "for example, # refr used part - of - speech tags to add features based on the pos tags of the penn treebank tags to the and", "cit": "our feature set is taken from # otherefr ; # refr and models the relation arguments, the surface distance between the relation arguments, and [SEP]"}
{"pre": "2. 2. 2 semantic - similarity sieves we first extend the above system with two new sieves that exploit semantics from wordnet, [SEP]", "cit": "this extends a similar approach by # refr that merges only the attributes of mentions ( such as gender, but not all pairwise features ) [SEP]"}
{"pre": "4the idea of implementing word class predictions for hebrew ( e. g., # refr ), and others have been [SEP] [SEP] [SEP]", "cit": "we have used a toolkit developed at at & t bell laboratories # refr which manipulates weighted and unweighted finite - state machines ( acceptor [SEP]"}
{"pre": "previous work in smt includes that, for example, the models as well as joint probability models # otherefr ; # refr, and [SEP]", "cit": "specifically, we use kriya # refr - our in - house hiero - style system for training and decoding. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this is well illustrated by the collins parser # refr, scrutinized by bikel # otherefr, where several factors are [SEP] ( 1 )", "cit": "for the czech data, we used the predefined training, development and testing split of the prague dependency treebank # otherefr, and [SEP]"}
{"pre": "# refr used syntactic features on the basis of sla theory that posits that l1 features may be reflected in some form of characteristic errors or [SEP]", "cit": "# refr are also motivated by a linguistic hypothesis, namely that syntactic errors in a text are influenced by the author? s l1. [SEP] [PAD]"}
{"pre": "we use two versions of the bitext systems : the source - pivot and target - side of the europarl corpus, [SEP] [SEP] [SEP]", "cit": "the idea was introduced in # refr, and is described in more detail in # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the log - linear model # refr, a distribution over the sentence pairs are extracted using the log - linear model # otherefr. [SEP] [SEP]", "cit": "discriminative training has been used mainly for translation model combination # refr and with the exception of # otherefr, has not been used to directly [SEP]"}
{"pre": "so far, research in automatic opinion recognition has primarily addressed learning subjective language # otherefr, and discriminating between positive and negative language # refr [SEP]", "cit": "so far research in automatic opinion recognition has primarily addressed learning subjective language # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the first approach divides the association measure is to use statistical data with a unigram specification # refr. [SEP] this approach that employs a comparison of [SEP]", "cit": "the work described in # refr and smadja # otherefra. b ) is along the same lines as ours, though he uses a [SEP]"}
{"pre": "crowdsourcing can allow inexpensive and rapid data collection for various nlp tasks # otherefr ; # refr. [SEP] the availability of parallel corpora", "cit": "without these resources, researchers have resorted to developing their own small, ad hoc datasets # otherefr ; # refr, and have often [SEP]"}
{"pre": "the recordings of the transcribed recognition of semantically similar words can be used to select the number of clusters, e. g. words in the same [SEP]", "cit": "so far we have used a weighted string edit distance matcher and experimented with di erent substitution weights including ones based on measures of statistical similarity [SEP]"}
{"pre": "to solve the lexical gap problem, most researchers focused on translation - based approaches since the relationships between words # otherefr ; # refr. [SEP]", "cit": "in addition, some researchers also explored the matrix factorization techniques for other nlp tasks, such as relation extraction # otherefr and question answering [SEP]"}
{"pre": "in this paper, we focus on the sentiment analysis of tweets written by drawing on sentence polarity # otherefr ; yu and # refr [SEP] [SEP]", "cit": "in the second category, subjectivity of a phrase or word is analyzed within its context # otherefr ; yu and # refr ; nas [SEP]"}
{"pre": "thus, they can be used for semi - supervised learning # otherefr ; # refr and multilingual sentiment analysis # otherefr. [SEP]", "cit": "supervised techniques have been proved promising and widely used in sentiment classification # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "proposed approaches to modelling nc semantics have used semantic similarity # otherefr ; # refr. [SEP] this relation labeling # otherefr could also be", "cit": "proposed approaches to modelling nc semantics have used semantic similarity # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in order to obtain a linguistically plausible rightcorner transform representation of words, the corpus can be computed automatically in the corpus, [SEP] [SEP] [SEP]", "cit": "following recent work by # refr on using hmms to build representations, we estimate parameters for a fully - connected hmm with 100 latent states over [SEP]"}
{"pre": "proceedings of the conference on empirical methods in natural guage processing tasks, including anaphora resolution # refr, prepositional phrase attachment. [SEP] [SEP]", "cit": "for example, # refr learned hyponymy relationships by collecting words in lexico - syntactic expressions, such as? np, np, and [SEP]"}
{"pre": "in the last two decades, machine learning - based methods have been applied to coreference resolution # otherefr ; ng and # refr. [SEP]", "cit": "in a typical machine learning - based coreference resolution system # otherefr ; ng and # refr, a statistical model is learned from training [SEP]"}
{"pre": "2. 2. 1. 1 smt system uses the same irc - h corpus for twitter - based mturk to obtain the results", "cit": "similar work on evaluating mt output # refr has asked turkers to rank more than two choices, but in order to keep our evaluation as straightforward [SEP]"}
{"pre": "sentiment analysis research has been performed to distinguish the authors? polarity # otherefr : # refr to sentence - level # otherefr. [SEP]", "cit": "different feature weighting methods, including binary weighting, term frequency, and tf? idf have been adopted in past sentiment analysis studies ( e. [SEP]"}
{"pre": "in addition, several studies have shown that the anaphora resolution of anaphora resolution has a potential antecedent for tasks like bridging resolution [SEP] text [SEP] text", "cit": "but in abstract anaphora, english prefers demonstratives to personal pronouns and definite articles # refr. 1 demonstra - 1this is [SEP]"}
{"pre": "the penn treebank # refr has more than a hundred phrase structure treebank # otherefr. [SEP]ly reletagger, [SEP] [SEP] [SEP]", "cit": "# otherefr ; marcus, kim, # refr, is aimed at a complex annotation of ( a part of ) the czech national [SEP]"}
{"pre": "these problems involve more dynamic classification targets and different performance expectations # refr. [SEP], one could be relevant for each of the current use of a spoken", "cit": "# refr observed that such disfluencies are just as common in monologues as in dialogues even though there is no need for the [SEP]"}
{"pre": "we include results for a multilingual model, where the primary part of a grammar are from the original ibm model # otheref [SEP] [SEP] [SEP] [SEP]", "cit": "for example, klein and manning? s # otherefr dependency model with valence ( dmv ) could be imple - 1un [SEP]"}
{"pre": "there have been several proposed methods for incorporating long - distance reordering model # otherefr, and word - based models # refr. [SEP] [SEP]", "cit": "table 9 : comparison of our approach with using only the gigaword corpus method p r f - score best05 # refr ) 0. [SEP]"}
{"pre": "in # refr, we showed that for a certain nlp task, such as pos tagging ( chunking ) is a sequence labeling task. [SEP]", "cit": "# refra ), computing approximate association scores like pointwise mutual information # otherefrb ; goyal and daume. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "an important practical challenge for the field of nlp research is that included in the computational linguistics community # otherefr, for which [SEP] the [SEP]", "cit": "from the side of the language engineering there are initiatives for describing standards and # refr present such an initiative, the isle project, which is [SEP]"}
{"pre": "there have been many studies on sentiment analysis # otherefr, # refr, and many others have proposed to identify a sentence polarity # other [SEP]", "cit": "the general approach is to summarize the semantic polarity ( i. e., positive or negative ) of sentences / documents by analysis of the orientations [SEP]"}
{"pre": "in another related work, # refr propose to use a similar method for bootstrapping an english ( to see table 1 ). [SEP] the mutual information", "cit": "active learning for g2p perhaps most closely related to our work are the papers of # refr and dwyer and kondrak # other [SEP]"}
{"pre": "# refr defines degrees of non - projectivity in terms of the maximum number of intervening constituents in the projection of a syntactic head and shows that [SEP]", "cit": "while this? surface dependency approximation? # refr may be acceptable for certain applications of syntactic parsing, it is clearly not adequate as a basis for [SEP]"}
{"pre": "nonparametric bayesian methods produce state - of - the - art performance on this task # otherefra ; # refr. [SEP] the [SEP] [SEP] [SEP] [SEP]", "cit": "maximum marginal decoding # refr can then be used to get the map estimate of the probability distributions over the alignment positions for each sentence from the samples [SEP]"}
{"pre": "expressions determined by wsms several recent works, including lin # otherefr, # refr, baldwin et al # otherefr, [SEP]", "cit": "recent works, including that of lin # otherefr, # refr, biemann and giesbrecht # otherefr, show [SEP]"}
{"pre": "the problem can be solved by a bipartite graph matching algorithm # otherefr ; # refr, which improves the quality of parallel sentences in a [SEP]", "cit": "in this framework, the source language, let? s say english, is assumed to be generated by a noisy probabilistic source. 1 most of [SEP]"}
{"pre": "in this paper, we propose an application of decision trees to mt, which is the most common noun phrase [SEP]. # refr [SEP] the [SEP] [SEP]", "cit": "previous work on defining subtasks within statistical machine translation has been performed on, e. g., noun - noun pair # refr and named [SEP]"}
{"pre": "suppose that the source sen - 13if this condition is removed, and the simpler case for the translations are found in samt # refr. [SEP]", "cit": "while others have worked on combining rules from multiple syntax - based systems # otherefr, we are not aware of any other work that seeks [SEP]"}
{"pre": "in such cases, neither global features # refr nor aggregated contexts # otherefr can help. [SEP] the kernels are [SEP]. [SEP]. [SEP] [SEP]", "cit": "another promising direction is the use of syntactic trees, feature sequences and pairs of instances, e. g. # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use brill? s tagger # refr to pos - tag the text chunker. [SEP] this timex2 is trained on [SEP] [SEP]", "cit": "all corpora were stemmed # otherefr and part - of - speech tagged # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the last decade, the cube pruning algorithm has been shown to reduce the complexity of # refr. [SEP] it has been the [SEP]ing of the", "cit": "cp has applications in tree and phrase based machine translation # otherefr ; # refr, parsing # otherefr, and in general in [SEP]"}
{"pre": "the recent semeval wsi tasks # otherefr ; # refr have provided a standard framework for evaluating wsi systems, with [SEP] [SEP]", "cit": "third, this evaluation makes the simplifying assumption of one sense per instance ; however, # refr note that the relations between senses may cause a single [SEP]"}
{"pre": "we note that our model is equivalent to the one presented by # refr, with the following nlp pipelines from the sequential model of # other", "cit": "we follow a long line of research in nlp that addresses search problems using # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the max - b? me model # refr to calculate the similarity score between the mt output and the reference translation. [SEP] [SEP] [SEP] the", "cit": "however, there is little agreement on what types of knowledge are helpful : some suggestions concentrate on lexical information, e. g., by the [SEP]"}
{"pre": "in the case of dependency parsers, # refr introduced a class of dependency parsers, including the first - order tree, spanning tree, spanning", "cit": "although it is possible to parse non - projective structures in quadratic time under a model in which each dependency decision is independent of all the others # [SEP]"}
{"pre": "most of the annotation approaches rely on training corpora for the task of anaphora resolution # otherefr ; # refr. [SEP] the annotation [SEP] t", "cit": "referee, a tcl / tk program for coreference annotation # refr, is better in this respect in that it writes the annotations to [SEP]"}
{"pre": "# refr, and li and abe # otherefr studied how to find an optimal abstraction level of an underspecification which has been [SEP] [SEP]", "cit": "thk means that rgpsg parses can always be verified efficiently, while gpsg parsee cannot, in gener ~ h # refr [SEP]"}
{"pre": "for example, # refr used a similar method for estimating the correctness of synonymy and a relation using an external resource. [SEP] the [SEP] [SEP]", "cit": "kendall? s tau coefficient (? k ) is commonly used ( e. g., # refr to compare rankings, and looks at [SEP]"}
{"pre": "this has led to a vast amount of research on mining natural language processing # otherefr ; # refr, and is the goal of [SEP] [SEP]", "cit": "although this analysis suggests that language identification and smt output detection # refr may be useful additions to the pipeline, we regard this as reasonably high [SEP]"}
{"pre": "we used bleu # refr, which is based on the moses decoder # otherefr. [SEP] the grammars of the grammars of source [SEP]", "cit": "we also report the result of our translation quality in terms of both bleu # refr and ter # otherefr against four human reference translations [SEP]"}
{"pre": "we use the giza + + toolkit # refr to train the phrase - based statistical machine translation ( smt ) system to train the translation model", "cit": "for acquiring a pbm, we followed the approach described by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "recently, incremental sigmoid belief networks ( isbns ) has been widely studied for word alignment and has been studied in # refr. [SEP] [SEP] [SEP] [SEP]", "cit": "iii and marcu, 2005 ), parsing # otherefr and word alignment # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "ilp has been used extensively for text - to - text generation # otherefr ; # refr, and dependency parsing # other [SEP] [SEP] [SEP]", "cit": "both martins and smith # otherefr and # refr build models that jointly extract and compress, but learn scores for sentences ( or phrases [SEP]"}
{"pre": "the first is usually focus on exploiting automatic generated labeled data from the target language ( slm ) # refr, the second is on [SEP]. [SEP]", "cit": "in detail, a word - based decoding is used, which adopts a loglinear framework as in # refr with only two features, translation model [SEP]"}
{"pre": "in particular, we focus on improving the sparsity of rare rules as defined by the number of features on the data, and the pos tagger developed", "cit": "the sentence label update is performed using what # refr call a pointwise collapsed gibbs sampler. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in recent years several techniques have been developed for sentiment analysis # refr ). [SEP] text categorization techniques to identify subjective nouns and objective documents # other [SEP]", "cit": "riloff and # refr state that? it is [ very hard ] to obtain collections of individual sentences that can be easily identified as subjective [SEP]"}
{"pre": "figure 1 : system combination of multiple systems and confusion networks were used by # refr. [SEP] the approach of treating it as a function of the hypothesis", "cit": "most closelyrelated is work by # refr, who proposed a way to generate diverse translations by varying particular? traits,? such as translation length [SEP]"}
{"pre": "this has led to the development of various data - driven grammar formalisms, such as hpsg # otherefr, and # refr. [SEP]", "cit": "thus, for instance, it has been a typical practice in ls - gram to distribute syntactic and semantic information over an analysis and a refinement grammar [SEP]"}
{"pre": "the features are the same as those in # refr. [SEP] the text t ( h ) h ( t. [SEP] ) h ( t. [SEP]", "cit": "note that we tune the phrase - based smt feature weights using mert # refr once in the beginning, and use the same weights across [SEP]"}
{"pre": "it has been shown that the standard approach can be used to rank the n - best output of a discriminative reranker # refr. [SEP] the", "cit": "for the last set of experiments, we used the probabilistic model described in # otherefr ( model 2 ), and the tree kernel # [SEP]"}
{"pre": "in the bionlp 2009 shared task on event extraction, participants constructed event extraction systems using a variety of common data [SEP] features # otherefr", "cit": "recently, biomedical text mining tools have evolved from extracting simple binary relations between genes or proteins to a more expressive event representation # refr. [SEP] [PAD] [PAD]"}
{"pre": "tinguish the verb classes ~ in exploring these quesuoate the meaning of verbs is important for a wide range of nlp tasks, such", "cit": "# refr showed that multiple listings could in some cases be interpreted as regular sense xtensions, and defined intersective levin classes, which [SEP]"}
{"pre": "we use the ppdb paraphrase database # otherefr, which is related to our model, include features extracted paraphrases [SEP] [SEP]", "cit": "ppdb we use lexical features from the paraphrase database ( ppdb ) # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in several recent proposals # otherefr ; # refr, statistical and machine learning techniques were used to extract classifiers from hand - tagged corpus. [SEP]", "cit": "despite making such an assumption, this proves to be among the most accurate techniques in comparative studies of corpus - based word sense disambiguation methodologies ( [SEP]"}
{"pre": "we wish to apply this direct, bayesian approach to learn better translation rules for syntaxbased statistical mt # otherefr ; # refr, as [SEP]", "cit": "deterministic annealing # otherefr is is used in our system to speed up the training process, similar to # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr argue that the first of a word is an mwe in its ability to identify its ability to distinguish the same polarity ( i. e", "cit": "# refr explore empirical models of compositionality for noun - noun compounds and verb - particle constructions. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we evaluate our system on the aid f1 measure # refr, which is calculated on the test set. [SEP] system ( m2 ) [SEP] [SEP]", "cit": "for the latter, each induced cluster is first mapped to the gold scf frame that annotates the highest number of verb instances this induced cluster also [SEP]"}
{"pre": "the maximum spanning tree algorithm1 was recently introduced as a viable solution for nonprojective dependency parsing # refrb ). [SEP] the k - best", "cit": "the dp algorithms are generally variants of the cky bottom - up chart parsing algorithm such as that proposed by # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "while transfer learning was proposed more than a decade ago # otherefr ; # refr, and its application in relation extraction is still unexplored [SEP]", "cit": "however, to the best of our knowledge, there is almost no work on adapting relation extraction # otherefr ; # refr and distant supervision [SEP]"}
{"pre": "discourse segmentation has been an active area of research # otherefr ; # refr. [SEP] the grounding of sentence segmentation # otherefr [SEP]", "cit": "lexical cohesion is an idea that topicallycoherent segments display compact lexical distributions # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "ahlswede et al, 1986, on the webster is seventh new collegiate dictionary ; # refr, on the collins english [SEP]", "cit": "while dep has been described in general terms before # otherefr ; # refr, this paper draws on our experience in parsing the collins german [SEP]"}
{"pre": "morphological analysis and disambiguation of arabic # otherefr, # refr, and grammar # otherefr. [SEP] this information by [SEP] [SEP] [SEP]", "cit": "4. 1. 2 mada # refr perform morphological disambiguation using a morphological analyzer. # otherefr augment this with lemma disambiguation [SEP]"}
{"pre": "while our system is related to the task of summarizing speech conversations, we compare it to other clusters of summarizing speech summaries, [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "while these features have been found to work well for generic extractive summarization # refr, we use additional features for capturing the more specific sentence [SEP]"}
{"pre": "the senses of a word may be subjectivity in a sentence # otherefr ; # refr. [SEP] subjectivity sense disambiguation # otheref", "cit": "we therefore incorporate subjectivity word sense disambiguation ( swsd ) as defined in # refr into lexical substitution. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "current approaches employ various machine learning techniques for this task, such as inductive logic programming in earlier systems # otherefr ; # refr. [SEP] [SEP]", "cit": "it is also possible to self - train a semantic parser without any labeled data # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the experiments are performed on tagging accuracy with a small amount of data from tagged the wall street journal corpus using the brill tagger # [SEP] [SEP]", "cit": "almost all of the work in the area of automatically trained taggers has explored markov - model based part of speech tagging \\ [ jelinek [SEP]"}
{"pre": "several rte systems have been tested on the same rte task # otherefr ; # refr. [SEP] the distributional similarity of w [SEP] [SEP]", "cit": "such similarities are not present in standard lexical resources like wordnet or dekang lin? s thesaurus # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "in 2005, however, several independent efforts # otherefr ; # refr demonstrated that discriminatively trained models can equal or surpass the alignment [SEP]", "cit": "in 2005, however, several independent efforts # refr demonstrated that discriminatively trained models can equal or surpass the alignment accuracy of the standard models [SEP]"}
{"pre": "in addition, most event extraction systems are targeted in a sentiment extraction pipeline of particular events # otherefr ; # refr. [SEP] this [SEP] [SEP]", "cit": "there has also been work on event trend detection # otherefr generated a calendar of events mentioned on twitter. # refr proposed structured retrieval of [SEP]"}
{"pre": "we use the following features :? pos tagger # otherefr, a rule - based pos tagger # refr trained on pos [SEP] [SEP]", "cit": "we trained on the training set of prop - bank supplemented with the brown corpus, resulting in a test accuracy on the test set of propbank [SEP]"}
{"pre": "in this paper, we utilize an information extraction ( wu and # refr ) method to extract the depth of word forms. [SEP] sentences in [SEP] [SEP]", "cit": "the semantic similarity between words is computed based on wu and palmer? s measure ( wu and # refr using wordnet # otherefr. [SEP]"}
{"pre": "to test the paraphrase generation task, we use the corpus of # refr. [SEP] sentences of paraphrases drawn from the training material.", "cit": "7e. g., # refr and glickman et al # otherefr report? values around 0. 6 for paraphr [SEP]"}
{"pre": "# refr describe a statistical model for spelling correction. [SEP] orthographic cues for orthographic information retrieval and substitution of phonemes.", "cit": "there has also been some work on computational approaches to characterizing rhymes # refr and global properties of the rhyme network # otherefr [SEP]"}
{"pre": "from these papers followed two largely independent lines of research, respectively dubbed formally syntax - based machine translation # otherefr ; # refr and [SEP]", "cit": "from these papers followed two largely independent lines of research, respectively dubbed formally syntax - based machine translation # otherefr and linguistically syntax [SEP]"}
{"pre": "some of them are frequency, point - wise mutual information # otherefr, distributed frequency of object using verb - object # refr, similarity of", "cit": "they do not fall cleanly into mutually exclusive classes, but populate the continuum between the two extremes # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "a number of verb classifications have been built on other hand, including framenet # otherefr and framenet # refr. [SEP] [SEP] [SEP] [SEP]", "cit": "a number of verb classifications have been built to support natural language processing # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "several statistical parsers have been implemented in various grammar formalisms # otherefr ; # refr. [SEP] the reading time w? [SEP] [SEP] [SEP]", "cit": "many other complexity metrics have been suggested as mutually contributing to reading difficulty ; for example, entropy reduction # otherefr, and split - syntactic [SEP]"}
{"pre": "while transfer learning was proposed more than a decade ago # otherefr, and information extraction # refr, the field of ontology [SEP]o [SEP] [SEP]", "cit": "alternatively, researchers have developed sophisticated probabilistic models to alleviate the effect of noisy data # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "revision learning # otherefr ; # refr. [SEP] this simple model by adding a shift ( henceforth ) a two pos tagger for [SEP]", "cit": "the revision model of # refr applies a second classifier for deciding whether the predictions of a base learner are accurate. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we evaluate using bleu - 4 # refr and meteor # otherefr. [SEP] the training procedure. [SEP] the training procedure introduced by [SEP] the", "cit": "the experiments were evaluated using bleu # refr and meteor # otherefr12. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "it has been successfully applied to a wide variety of tasks, including dependency parsing # otherefr, relation extraction # refr, and machine translation #", "cit": "our unsupervised approach follows a self training protocol # otherefr ; # refr ; reichart and rappoport, 2007b ) enhanced with [SEP]"}
{"pre": "to measure fixedness, we use lin # otherefr - 2 # refr to measure the strength of meaning of thesaurusity, [SEP]", "cit": "like lin # otherefr, we generate lexical variants of the target automatically by replacing either the verb or the noun constituent by a semantically similar [SEP]"}
{"pre": "in this work, we use dependency tree kernel # refr, which is a component of the current relation between pairs of entities. [SEP] this [SEP] [SEP]", "cit": "previous work # otherefr ; # refr has traditionally relied on extensive human involvement ( e. g., hand - annotated training instances, [SEP]"}
{"pre": "3. 2. 3 target expression tree substitution grammar ( as defined in # refr ) is a finite state transducer. [SEP] ( fst ) [SEP] [SEP]", "cit": "as argued in kaplan and kay # otherefr, # refr, karttunen et al # otherefr, and elsewhere, [SEP]"}
{"pre": "most previous work on normalization of social media text focused on word substitution # otherefr ; # refr. [SEP] the noisy non - standard [SEP] [SEP]", "cit": "most previous work on normalization of social media text focused on word substitution # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the supervised approach is based on an unsupervised learning algorithm that allows to reduce the parameters of the former approach of # refr. [SEP] features in [SEP] features", "cit": "me have been also applied to wsd # otherefr ; sua? # refr, and as meta - learner in # otheref [SEP]"}
{"pre": "morphological features : automatically extracted from morphological treebanks # otherefr ; # refr. [SEP] this corpus, we use the morphological information throughout our", "cit": "a promising avenue may be the approach by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "connectors have been shown to be effective in other context related works as well # refr. [SEP] this intuition is the same as it [SEP] for the", "cit": "a common approach for sentiment detection is to use a labelled lexicon to score sentences # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the transducer? s rewrite operation sequence model ( osm ) # refr. [SEP] the linear sequence of each word as a sequence of actions.", "cit": "commonly used models such as hmms, n - gram models, markov chains, probabilistic finite state transducers and pcfgs all fall in the [SEP]"}
{"pre": "the similarity measure is based on the measure described in # refr. [SEP] similarity between homogeneity and the homogeneity of homogeneity and the wordnet similarity between the", "cit": "homogeneity within each of the corpora is important here since we may find that the results reflect sections within one of the corpora which are unlike other sections [SEP]"}
{"pre": "this result suggests that the performance of the neural network model outperforms the state - of - the - art distributional models # otherefr ; # refr", "cit": "previous approaches use taskspecific information, by either relying on a # otherefr, or by treating analogy detection as a supervised learning task # [SEP]"}
{"pre": "we trained the model using the structured perceptron # refr and the online perceptron algorithm # otherefr. [SEP] ( 1 ) averaging l1", "cit": "one sees this clear trend in the supervised nlp literature? examples include the perceptron algorithm for tagging # refr, mira for dependency parsing [SEP]"}
{"pre": "we use the stanford pos tagger # refr to obtain the pos tags for the pos tags of the training data. [SEP] ( with the pos tag", "cit": "previous authors have used numerous hmm - based models # otherefr, and cyclic dependency networks # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, researchers have recently explored learning semantic parsers for map natural language sentences to formal representations # otherefr ; ge and # refr.", "cit": "recent work in learning semantics has focused on mapping sentences to meaning representations ( e. g., some logical form ) given aligned sentence / meaning [SEP]"}
{"pre": "# refr use a sophisticated algorithm to estimate the frequencies of a larger word, but use a measure of the precision of recall of the probabilities that [SEP]", "cit": "table 1 : maximum likelihood esti : lnates freq ( c, v, r ) is the number of ( n, v, [SEP]"}
{"pre": "while transfer learning was proposed more than a decade ago # otherefr, and has been that it has been useful to learn [SEP] features from a", "cit": "a third approach, weak supervision, performs selfsupervised learning of relation - specific extractors from noisy training data, heuristically generated by matching database [SEP]"}
{"pre": "in japanese, the relationship between a predicate is usually represented by using the levin ratio of the predicate # refr. [SEP] arguments [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "hence, diathesis alternations have been the topic of interest for a number of researchers in the field of automatic verb classification, which aims [SEP]"}
{"pre": "we use the french treebank # refr and the german treebank # otherefr. [SEP]. [SEP]. [SEP] the em plays a finite -", "cit": "the grammar was trained using the algorithm of # refr using 3 rounds of split / merge / smooth2. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the first question, which we discuss in this work, is the field is related to the application of annotation systems presented in # refr. [SEP] [SEP]", "cit": "although the interpretation of quantifiers and negation is a traditional research area in computational linguistics # otherefr, their generation is much less studied # [SEP]"}
{"pre": "the most common algorithm for combining the hmm alignment with a maximum entropy model with a limited amount of features # otherefr, and the use of", "cit": "4from # otherefr. and sahmm # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the most common algorithm for aligning the parse trees is obtained from the chinese and in the chinese - english and has the largest [SEP] english [SEP] #", "cit": "second, # otherefr, who require 400 cpu hours to re - align 330k chinese - english sentence pairs ( anonymous, p. [SEP]"}
{"pre": "to facilitate comparisons with previous work # otherefr ; # refr, we model the similarities between the phrases ( or words ) of the source language", "cit": "the scfg formalism # otherefr was repopularized for statistical machine translation by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used mxpost # refr and in order to extract the part of speech tags for the tokens. [SEP] the tokens of the tokens [SEP] for each", "cit": "2a maximum - entropy - based part of speech tagger was used # refr without the adaptation to the biomedical domain.. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "to date, most approaches to the bionlp event extraction task # refr ; kim et al, 2011a ) use a single model to [SEP]", "cit": "this resembles approaches that merge different classifiers # refr or attempt to estimate confidence of models # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, the genia event extraction task was performed by the bionlp st 2009 # refr, and the stanford event extraction [SEP] [SEP] [SEP]", "cit": "particularly, the latter made team? 09 task people reference faust? 12 - 3c # refr umass? 12 - 1c # [SEP]"}
{"pre": "# refr find that web counts can be used to rank candidate items. [SEP] the same fixed n - gram counts relative frequencies, [SEP] the [SEP] [SEP]", "cit": "the results are compared against two state of the art approaches : a supervised machine learning model, semantic scattering # otherefr, and a web [SEP]"}
{"pre": "in recent years, several machine learning techniques have been developed for automatically acquired inference rules for information extraction # otherefr ; # refr. [SEP] the", "cit": "one approach which was used for evaluating automatically acquired rules is to measure their contribution to the performance of specific systems, such as qa # otheref [SEP]"}
{"pre": "this approach is inspired from the notion of discourse relation generation # otherefr, # refr, and dialogue acts # otherefr. [SEP] [SEP]", "cit": "our evaluation of the dialogue modeller and verbalizer components described in # refr shows that both accuracy and fluency of generated dialogues are not worse [SEP]"}
{"pre": "graph - based label propagation methods have recently shown they can outperform the state - of - the - art in several natural language processing ( nlp [SEP]", "cit": "further, unlike other graph - propagation algorithms # refr, our approach is inductive. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr use machine learning techniques to identify hedges in general domainspecification, and that support vector machines are contextually [SEP] cues [SEP] [SEP] [SEP]", "cit": "for example, online product and movie reviews have provided a rich context for analyzing sentiments and opinions in text # otherefr for a recent [SEP]"}
{"pre": "discriminative parsing has been investigated before, such as in johnson # otherefr, # refr, and, most recently, in this work, [SEP]", "cit": "recent work # otherefr ; # refr describes log - linear glms applied to pcfg representations, but does not make use of dependency [SEP]"}
{"pre": "we use a word alignment model similar to those proposed by # refr. [SEP] the class of phrases to ensure that a word sequence alignment is a mixture", "cit": "it is important because a wordaligned corpus is typically used as a first step in order to identify phrases or templates in phrase - based machine [SEP]"}
{"pre": "previous work on nlg systems that address more than one user group employs different versions of a system for each different user group # otherefr [SEP]", "cit": "nlg systems tend to be very domain - specific and data - driven systems that seek to simultaneously optimize both content selection and surface realisation have [SEP]"}
{"pre": "statistical translation methods can be divided into word - based # otherefr, phrase - based # refr and lexical methods # otherefr systems [SEP]", "cit": "for example, we can use such a translation model to help complete target ext being drafted by a human translator # refr. [SEP] [PAD] [PAD]"}
{"pre": "however, the? too few of the hierarchical modeling work in unsupervised parsing has focused on the problem of inducing hierarchical structure # otherefr ; [SEP]", "cit": "our work fits well with several recent approaches aimed at completely unsupervised learning of the key aspects of syntactic structure : lexical categories # otherefr, [SEP]"}
{"pre": "current approaches have been evaluated in various ssl techniques, including inductive logic # otherefr, formal and statistical machine translation # refr. [SEP] [SEP]", "cit": "other works # otherefr ; # refr try to alleviate the annotation effort by only taking sentence and logical form pairs to train the models. [SEP]"}
{"pre": "sp have been proven to help many natural language processing tasks that involve attachment de -? partial of this work was done when the first author visiting [SEP]", "cit": "lapata et al investigate the correlations between the co - occurrence counts ( ct ) c ( q, a ), or smoothed counts with the [SEP]"}
{"pre": "unsupervised training methods have also been proposed in the past for related problems in decipherment # otherefr ; # refr ; ravi and [SEP]", "cit": "translation model : machine translation is a much more complex task than solving other decipherment tasks such as word substitution ciphers # otherefrb [SEP]"}
{"pre": "in addition to the regular distance model, our approach also relates to work in # refr, in which the authors propose to incorporate such features to capture", "cit": "artificial intelligence of the hungarian academy of sciences and university of szeged. lexical substitution does not rely on explicitly defined sense inventories # [SEP]"}
{"pre": "we used mecab as a morphological analyzer and a morphological analyzer # refr for english, and we use the japanese ner [SEP] [SEP] [SEP] features [SEP] [SEP]", "cit": "we applied an em - style word clustering algorithm in # refr to 600 millionweb pages and clustered 1 million nouns into 500 classes. [SEP] [PAD] [PAD]"}
{"pre": "in japanese, the unknown word guessing is used for unknown words by # refr. [SEP]. [SEP] the prefix probabilities. [SEP] unknown [SEP] [SEP] [SEP]", "cit": "one is to find unknown words from corpora and put them into a dictionary # otherefr ; # refr ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "several researchers # otherefr ; # refr, have already shown that measures of synonym tests ( see, e. g., # other", "cit": "the contexts in which a target word appears can be extracted in terms of a window of cooccurring ( content ) words surrounding the target # [SEP]"}
{"pre": "it is based on that, because its lexicon, it has been shown that incorporating various semantic tasks, including word sense disambiguation, [SEP] [SEP] [SEP]", "cit": "for example, in summarization, barzilay and elhadad # otherefr and # refr focus on multiword noun phrases. [SEP]"}
{"pre": "we then show that the proposed a discriminative dependency parser # refr outperforms the state - of - the - art parsing algorithm of [SEP]. [SEP] the [SEP]", "cit": "this is equivalent to minimum bayes risk decoding # refr, which is used by cohen and smith # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr addressed the problem of identifying the same entities as utilized citation context and showed improvements. [SEP] ( p ). [SEP] (? [SEP] [SEP] [SEP]", "cit": "citation context has been explored in several studies # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "text similarity has been extensively studied in nlp applications such as pos tagging # otherefr, word sense disambiguation # refr, and text [SEP]", "cit": "a variety of segmentation granularities, or atomic units, exist, including segmentations at the morpheme # otherefr, sentence ( e [SEP]"}
{"pre": "the task of preposition prediction is closely related to previous work on preposition errors # otherefr ; # refr. [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "the determiner system builds on the ideas described in # refrc ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the experiments presented in # refr, we evaluate the performance of our model on the task of anaphora resolution. [SEP]. [SEP] [SEP] [SEP] [SEP]", "cit": "a form of multi - objective optimization was applied to coreference by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for example, the effects of verbs can be used to identify alternations # otherefr ; # refr. [SEP] the associated verb [SEP] [SEP] [SEP]", "cit": "first, using linguistic results on the semantics of french nps # otherefr, we identified predicate - argument configurations that cannot be matched by a [SEP]"}
{"pre": "we used the moses phrase - based smt system # refr. [SEP] the current alignment of hierarchical phrase pairs. [SEP] the current word alignment [SEP]", "cit": "raw parallel data need to be preprocessed in the modern phrase - based smt before they are aligned by alignment algorithms, one of [SEP]"}
{"pre": "in this paper we present a method that performs robust parsing on newswire texts # refr. [SEP] text chunker # otherefr. [SEP] [SEP]", "cit": "# refr proposed a linguistically motivated approach based on syntactic information to semi - automatically refine a list of hedge cues. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the textual portion of the documents is cleaned of html, tokenized, split into sentences and part - ofspeech tagged using the tnt tag [SEP]", "cit": "in addition to using the manually constructed 37, 000 - word lexicon included in the erg, we accommodate unknown words by mapping pos tags produced by [SEP]"}
{"pre": "we evaluate the output of two machine translation systems : bleu # refr and meteor # otherefr. [SEP]a [SEP] 1 [SEP] [SEP] [SEP] [SEP]", "cit": "the results were evaluated using the bleu metric # refr with the original sentences as reference ; they indicate a higher suitability of the new formemes [SEP]"}
{"pre": "we use averaged perceptron training # refr from crfsuite # otherefr. [SEP] ( daume. [SEP] ( daume [SEP] [SEP] [SEP]", "cit": "therefore, here, we use terp? s inference algorithms that find low cost edit sequences but use a discriminative learning algorithm based on the percept [SEP]"}
{"pre": "other work has learnt semantic analyses from text in the context of interactions in computational environments # otherefr ; and from raw text alone # [SEP]", "cit": "# refr and liang et al # otherefr replace semantic annotations in the training set with target answers which are more easily available. [SEP] [PAD] [PAD]"}
{"pre": "in the experiments reported in this section, we show how i state - of - the - art pronoun generation systems # refr are very competitive with the", "cit": "# refr ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "many corpus based statistical methods have been proposed to solve this problem, including supervised learning algorithms # otherefr, semi - supervised learning algorithms # refr", "cit": "yarowsky # refr presented, for the rst time, the possibility that unlabeled examples can be used for wsd. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in # refr, a maximum entropy model is used to predict the probability of a word order of a word order n - gram word sequence, as", "cit": "syntax information has been used for reordering, such as in # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in contrast, approaches to nlg have been trained on the penn treebank corpus # otherefr, # refr ), and have recently [SEP]", "cit": "subsequent work explored ways of exploiting linguistically annotated data for trainable generation models # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use an off - the - shelf twitter part - of - speech tagger # refr trained on the tweets written from twitter sentences with a twitter", "cit": "recent progress on building nlp tools for twitter # otherefr ; # refr makes it possible to investigate an approach to summarizing twitter events which [SEP]"}
{"pre": "the approach which we have awareed that is the fact defined by the model, allows us to construct a combinatory categorial grammar that allows [SEP]", "cit": "one is to use elementary categories, such as np or s, in encoding both syntactic types and logical forms # otherefr ; # refr [SEP]"}
{"pre": "incremental top - down and left - corner parsers have been shown to effectively # otherefr ; # refr, and we will use incremental [SEP]", "cit": "recent work continues to advocate surprisal in particular as a very useful measure for predicting processing difficulty # refr, and the measure has been derived using [SEP]"}
{"pre": "figure 2 : probability p ( t ) = | '. c., we use tbl ) robbed stupid backoff [SEP] [SEP] [SEP]", "cit": "as one of those noun phrase chunking techniques, we propose a method for incorporating richer contextual information as well as patterns of constituent morphemes within [SEP]"}
{"pre": "we use the same as # refr. [SEP] kernel expansion, which is an efficient parameter estimation algorithm for decision trees. [SEP] the svm [SEP] [SEP] [SEP]", "cit": "on the other hand, automatic feature engineering of syntactic or shallow semantic structures has been carried out by means of structural kernels, e. g. [SEP]"}
{"pre": "we used the same dataset as # refr. [SEP] the french negation features. [SEP] the rerank process to different languages. [SEP] the wordnet [SEP]", "cit": "in the future, we plan to investigate the use of semantic similarity from distributional and other sources # otherefr, babelnet # refr [SEP]"}
{"pre": "we used the comlex lexicon # refr for english verb lexicon # otherefr for verb lexicon constructed a lexicon. [SEP] dictionary ( l ).", "cit": "we based our pos table lookup on nyu is comlex # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "many methods for knowledge extraction have been proposed to deal with the issue of specific senses, such as thesaurus extraction # otherefr, [SEP]", "cit": "other synonym resolution work is fully supervised # otherefr ; # refr, training models using manually constructed sets of synonyms. [SEP] [PAD] [PAD]"}
{"pre": "there have been several attempts in the literature of learning parsers for semantic parsers # otherefr ; # refr, but the availability of training", "cit": "in these settings, existing systems can produce correct meaning representations with f1 scores approaching 0. 9 # otherefr ; # refr. [SEP] [PAD]"}
{"pre": "several methods have been proposed with regard to aligning sentences # otherefr ; # refr, aljs ~ nlng words # otheref [SEP]", "cit": "several methods have been proposed with regard to aligning sentences # otherefr, aljs ~ nlng words # refr and acquiring rules from [SEP]"}
{"pre": "in nlp, rf classifiers have been used for : language modelling # otherefr and semantic parsing # refr. [SEP] features [SEP] this [SEP] [SEP]", "cit": "such shallow features have been proven effective in a number of nlp applications including : named entity recognition # refr, multilingual named entity transliter [SEP]"}
{"pre": "we use the forced alignment ( grow - diag - final # refr as an extension of the restrictions ) to the decoder. [SEP] it [SEP] it [SEP]", "cit": "research efforts to increase search efficiency for phrase - based mt # refr have explored several directions, ranging from generalizing the stack decoding algorithm # other [SEP]"}
{"pre": "there have been several attempts to develop methods for automatically learning fine - grained opinion lexicons # otherefr ; # refr. [SEP] the [SEP]", "cit": "because of the practicality of this structured summary format, it has been adopted in several previous studies # otherefr ; # refr as well [SEP]"}
{"pre": "reconcile is a modular software platform that abstracts a pairwise coreference resolution component of machine learning - based coreference resolution systems # other [SEP] if two", "cit": "we incorporate lexicalized feature sets into two different coreference architectures : reconcile # refr, a pairwise coreference classifier, and sieve # [SEP]"}
{"pre": "in addition, most of the translation model # otherefr ; # refr, which treats translation lexicons as a binary [SEP] the source [SEP] it", "cit": "the first algorithm is similar to competitive linking # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "to overcome the huge potential syntactic patterns, we used the patterns automatically extracted by # refr. [SEP] the patterns automatically extracted by training the subtree [SEP] the", "cit": "those patterns can be manually created # refr, chosen via automatic bootstrapping # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition to domain adaptation, we also perform the source - target phrase as well as the baseline systems # refr. [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "previous research on domain adaptation for smt includes data selection and weighting # otherefr ; # refr, mixture models # otherefr, [SEP]"}
{"pre": "on the other hand, # refr extend the original alignment model to translation of source sentences. [SEP] the target language sentence to be translated [SEP] [SEP] [SEP]", "cit": "previous works have attempted to handle morphology, decompounding and regularization through lemmatization, morphological analysis, or unsupervised techniques # otherefr [SEP]"}
{"pre": "# refr presented a method that combines a similarity measure based on the depth of the relative frequencies of two verbs and the path ( wu and [SEP] [SEP]", "cit": "we compute argument similarity using wordnet # otherefr and the measure proposed by wu and # refr which is based on path length. [SEP] [PAD]"}
{"pre": "this basic architecture of the system is similar to that of # refr. [SEP] ( i. e., subcategorization frames ) are [SEP] [SEP]", "cit": "information extraction ( ie ) ( # refr ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "binarizing the syntax trees for syntax - based machine translation is an instance, # refr. [SEP]. [SEP] this binarization allows [SEP] [SEP]", "cit": "in the worstcase, a binarized grammar with a source arity of s will require at most ( 2s + 1 ) free [SEP]"}
{"pre": "besides the mention - pair model, two other commonly used models are the entity - mention model # refr and ranking model # otherefr. [SEP]", "cit": "in recent years, markov logic has been widely used in natural language processing problems # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "continuous semantic space representations have proven successful in a wide variety of nlp and ir applications, such as document clustering # otherefr [SEP] [SEP] [SEP]", "cit": "in the context of lexical semantics, vsms provide a natural way of measuring semantic word relatedness by computing the distance between the corresponding vectors, which [SEP]"}
{"pre": "for instance, the discontinuous grammar rules may be discovered with tree structures # otherefr ; # refr. [SEP] this method so that the shiftreduce", "cit": "a related idea for discontinuous phrase structure is the reversible splitting conversion of # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in recognition of this need, a number of recent information extraction # otherefr ; # refr. [SEP] the event [SEP] [SEP] the event [SEP] [SEP]", "cit": "finally, we make use of the event analyses created by systems that participated in the bionlp shared task, made available to the research community [SEP]"}
{"pre": "in bibliography entries # refr, a given field ( author, title, etc. ) should be filled by at most one substring of the input", "cit": "the second dataset is the reference part of the cora information extraction dataset. 1 this 1the cora ie dataset has been used in se [SEP]"}
{"pre": "the same technique has been applied to the task of statistical machine translation ( smt ) presented by # refr. [SEP] the training corpus to a sentence", "cit": "separate 5 - gram language models were built from the target side of the two data sets and then they were interpolated using weights chosen to minimise the [SEP]"}
{"pre": "in an early version of the system, # refr generated paraphrases using an f1 - measure that incorporates the target lexicalized meaning representations.", "cit": "in an earlier study of the utility of automatic metrics with penn treebank ( ptb ) surface realization data # refr, we observed moderate correlations [SEP]"}
{"pre": "this has been shown to be effective for helping to improve performance # otherefr ; # refr. [SEP] the algorithm is [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "surprisal has received a lot of attention in recent literature due to nice mathematical properties # otherefr ; # refra ). [SEP] [PAD] [PAD]"}
{"pre": "in a related work, # refr use reading1 in the context of a query - dependent query model to determine the presence of a word. [SEP]", "cit": "in the skillsum project # refr, used to generate literacy test reports, a set of choices regarding output ( cue phrases, ordering and punct [SEP]"}
{"pre": "# refr have recently highlighted the importance of teasing apart the different aspects of a word by a word? different? different? different? frameworks.", "cit": "these include bag - of - words co - occurrence vectors, possibly mapped to lower dimensionality with svd or other techniques # otherefr and many [SEP]"}
{"pre": "we use a hierarchical phrase - based translation grammar # otherefr ; # refr, which is a synchronous context free grammar ( scfg ).", "cit": "while the original hiero approach works with a single nonterminal label ( x ) ( besides the start nonterminal s ), more recent work [SEP]"}
{"pre": "the lexicalized reordering model was trained by jane # refra ), which was used as a feature in the translation process. [SEP] the [SEP]", "cit": "jane? s phrase extraction can optionally supply this information from the training data. # refr and # otherefr employ similar techniques and provide [SEP]"}
{"pre": "the decision list # otherefr, # refr, and lesk # otherefr have been applied to wsd. [SEP] [SEP] [SEP] [SEP]", "cit": "some of them have been fully tested in real size texts # otherefr, # refr, # otherefr ). [SEP] [PAD] [PAD] [PAD]"}
{"pre": "morphology acquisition has been integrated by many researchers in the past by only et al. # otherefr, # refr, and # otheref [SEP]", "cit": "some morphology discovery algorithms learn relationships between words by comparing the orthographic or semantic similarity of the words # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the edinburgh submission for wmt 2010 - 10 # refr. [SEP] the former for all languages, though we used a raw [SEP] [SEP] [SEP]", "cit": "nova? k # otherefr obtained an improvement of 0. 22 bleu with no distortion penalty ; whereas # refr enhanced by 0 [SEP]"}
{"pre": "unsupervised dependency parsing has seen rapid progress recently, with error reductions on english # otherefr, and better and better results for other languages # refr", "cit": "variations of the algorithm presented in page and brin # otherefr have been used in keyword extraction and extractive summarization # refr, [SEP]"}
{"pre": "# refr extract a set of 90 % relative frequencies of 8 million words, and selected from 90 % of the british national corpus. [SEP] documents [SEP]", "cit": "for this reason, using the web has proved successful in several other fields of nlp, e. g., machine translation # otheref [SEP]"}
{"pre": "crfs have been successfully applied to a variety of tasks including named entity recognition # otherefr, noun phrase chunking # refr, and [SEP]", "cit": "y are the random variables over the labels of the nodes that are globally conditioned on x, which are the random variables of the observations. # [SEP]"}
{"pre": "we used the features generated by the mira algorithm # refr. [SEP] et al. # otherefr, who used tree parse trees to [SEP]", "cit": "tree - to - string translation rules are generic and applicable to numerous linguistically syntax - based statistical machine translation # otherefr ; # refr [SEP]"}
{"pre": "the parsing schemata are based on the well - known parsing algorithm described in # refra ). [SEP] argue for parsing [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "now consider a standard memoizing proof procedure such as earley deduction # refr or the memoizing procedures described by tamaki and [SEP]"}
{"pre": "we use a support vector machine ( svm ) system with the default polynomial kernel ( ape ) # refr. [SEP] system1 # otherefr", "cit": "named entity extraction a statistical ner system described in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used the default parameters for all systems, and the feature weights were trained with minimum error rate training # refr. [SEP] - rate training [SEP] [SEP]", "cit": "to create a simple translation model, we used the berkeley aligner to align the parallel text from the first assignment, and extracted a phrase table [SEP]"}
{"pre": "the first, the bracketing f1, is defined as? statistically significant ( p < 0. 05 ), using a query [SEP] [SEP] [SEP]", "cit": "most automatic segmentation techniques # refr ; tan and peng, 2008 ; zhang et al, 2related datasets and supplementary material can be accessed from http [SEP]"}
{"pre": "we use the stanford corenlp suite to lemmatize and partof - speech tag each word # otherefr, and resolve core [SEP]", "cit": "we use the following attributes for these constraints : number? we assign number attributes based on : ( a ) a static list for pronouns ; [SEP]"}
{"pre": "# refr use a pos tagger and a chunker to extract noun phrases. [SEP] features from the web and the [SEP] [SEP] it algorithm. [SEP]", "cit": "in statistical keyphrase extraction, many variations for term frequency counts have been proposed in the literature including relative frequencies # otherefr, [SEP]"}
{"pre": "previous work on automatic identification of newswire - style or even more, such as speculation detection, temporal classification, etc., are mostly focused on", "cit": "the first systems were fully hand - crafted # refr without any empirical evaluation on a dedicated corpus. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "to support this, we performed a set of experiments using the maltparser # otherefr, which we trained on the conll - [SEP]", "cit": "the parser used here was malt, which achieves accuracies of 85 % when deriving labelled dependencies on english text # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use 3500 sentences from conll # otherefr ; # refr as features for chunking with 1. 2 the standard bio [SEP] a", "cit": "several representations to encode region information are proposed and examined # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "while several methods have been proposed to date, such this problem # otherefr ; # refr. [SEP] the unsupervised versions of the noisy - channel", "cit": "solutions to the compression task have been cast mostly in a supervised learning setting ( but see # refra ), hori and furui # [SEP]"}
{"pre": "in a similar approach, # refr presents a classifier based on recursive neural networks that allows for the purpose of a classifier trained on [SEP] [SEP] [SEP] [SEP]", "cit": "# refr exploit the simile frame? as x as y? to harvest a great many common similes and their underlying stereotypes from the [SEP]"}
{"pre": "we use dependency relations extracted by the stanford parser # refr and then extract dependency relations from the dependency parse trees. [SEP] a graph defined in each word", "cit": "employing syntactic or dependency relations to aid question answering systems is by no means new # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "for example, # refr developed a system that exploits distributional similarity to a semantic lexicon, and a combination of word similarity and relatedness by comparing it against", "cit": "more recently, # refr showed that it is possible to combine visual representations of word meanings into a joint bimodal representation constructed by using latent topics. [SEP]"}
{"pre": "this has been shown in numerous works on well that semi - supervised learning ( e. g. # refr ), or unsupervised # other [SEP] [SEP]", "cit": "along similar lines, # refr combine a generative model of word alignment with a log - linear discriminative model trained on a small set of hand aligned [SEP]"}
{"pre": "# refr used a phrase based smt system, optimized reordering to translate compounds, and find the total of 21578s, whereas they use", "cit": "we used two decoders, matrax # refr and moses # otherefr, both standard statistical phrase based decoders. [SEP] [PAD]"}
{"pre": "they are particularly attractive for several lexical resources, and syntactical information, but they are not designed to increase the precision, recall, and f [SEP]", "cit": "specifically, our entailment graph is built over the extracted phrases # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the disambiguation task has received much attention in the recent years, and several studies # otherefr ; # refr. [SEP] this approach. [SEP]", "cit": "maximum entropy classifiers have been effective on a variety of nlp problems including preposition sense disambiguation ( ye and # refr, which is somewhat [SEP]"}
{"pre": "the polarity of a word may be dependant on its context # refr. [SEP] subjectivity analysis of the mpqa project # otherefr [SEP]", "cit": "fid is included in the narrative annotation schema of mani # otherefr, but it is not given any particular attention within that framework? [SEP]"}
{"pre": "morphological features are integrated in a statistical model ( log - linear features ) # refr. [SEP] features : p ( w, w, [SEP] [SEP] [SEP]", "cit": "however, obtaining considerable improvements in speech recognition accuracy seems hard, as is demonstrated by the fairly meager improvements # otherefr, and # [SEP]"}
{"pre": "among the latter, there are nlp applications such as the detection of lexical errors # otherefr, textual entailment # refr, textual entail", "cit": "among the latter, there are nlp applications such as the detection of lexical errors # otherefr ; # refr, information retrieval # other [SEP]"}
{"pre": "we are currently implementing a shallow parser for our previous work # refr. [SEP] a german dt that includes a number of predicate classifiers. [SEP] different [SEP]", "cit": "# refr, we employ a full merging between b3 parses and bitpar parses. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we show that the model can be used for projective parsing can be structured by ignoring the shift - reduce algorithm # otherefr, and recently applied", "cit": "such models are commonly referred to as edge - factored since their parameters factor relative to individual edges of the graph # otherefr ; # [SEP]"}
{"pre": "text structuring the insertion task is closely related to the extensively studied problem of sentence ordering. 3 most of the existing algorithms represent text ordering as a [SEP]", "cit": "the experimental results demonstrate that our model is able to significantly outperform the state - ofthe - art coherence model by # refr, reducing the error rate [SEP]"}
{"pre": "weakly supervised corpus - based methods have utilized noun co - occurrence statistics # otherefr, syntactic information # refr, and lexico - syntactic [SEP]", "cit": "another related line of work is automated ontology construction, which aims to create lexical hierarchies based on semantic classes ( e. g., # refr [SEP]"}
{"pre": "co - occurrence frequencies have long been used to resolve linguistic ambiguities # otherefr ; # refr. [SEP] the frequencies [SEP] between two languages [SEP]", "cit": "# refr first articulated the need for? a multilingual corpora based system, which exploits the differences between languages to automatically acquire knowledge about word senses [SEP]"}
{"pre": "# refr describe a joint probability model for alignment, but the need for alignment by allowing the probability mass to the alignment over words. [SEP] it [SEP]", "cit": "# refr reduce its complexity by using only concepts that match the high - confidence giza + + alignments. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in a similar vein, # refr adds the flexibility of generating referring expressions in order to determine the most frequently occurring text. [SEP] it appears to have", "cit": "from early treatments in seminal papers by appelt # otherefr ; # refr, generating referring expressions has become one of the most studied areas [SEP]"}
{"pre": "we also compare statistical significance with paired bootstrap re - sampling # refr. [SEP] paired bootstrap resampling # otherefr. [SEP] the [SEP] [SEP] [SEP]", "cit": "statistical significance test is performed using the bootstrap re - sampling method proposed by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this was overcome by a probabilistic model which provides probabilities of discriminating a correct parse tree among candidates of parse trees in a log - linear model or [SEP]", "cit": "this model is introduced as a reference distribution # otherefr ; # refr of the probabilistic hpsg model ; i. e., the [SEP]"}
{"pre": "reranking approaches have given improvements in accuracy on a number of nlp problems including parsing # otherefr ; # refr, semantic role labeling", "cit": "some variants used explicit spaces # otherefr, and feature vector approaches were proposed in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "reranking has also been successfully employed in syntactic parsing # otherefr ; # refr as well as information extraction systems. [SEP] this [SEP] [SEP]", "cit": "we used the syntactic? semantic parser by # refra ) to annnotate the sentences with dependency syntax # otherefr frameworks. [SEP] [PAD]"}
{"pre": "many alternative methods have been proposed based on the algorithms in machine learning, such as averaged perceptron # otherefr, maximum entropy # refr,", "cit": "they primarily differ in the mode of training ; online or mert - like batch, and in their objectives ; max - margin # otheref [SEP]"}
{"pre": "in smt, greedy decoders have been used by # refr to translate the entire sentence f as a black box to be sentence segmentation. [SEP]", "cit": "for word - based smt, greedy hill - climbing techniques were advocated as a faster replacement for beam search # otherefr ; # refr [SEP]"}
{"pre": "in fact, # refr observed that differences in english? f - score is not very reliable because the reordering is observed over [SEP]. [SEP].", "cit": "however, simple, yet powerful pre - ordering techniques have made this argument a thing of the past # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in addition, we plan to use the svm - based tagger described in # refr. [SEP] this paper, we propose a state - of -", "cit": "nadeau and sekine # otherefr ; # refr and conditional random field # otherefr to ner, which can address these [SEP]"}
{"pre": "we use a freely available3er of hebrew # otherefr which is also removed and part - of - speech ( pos ) tag", "cit": "features our feature set consists of # otherefr bengali pos tagger and # refr hindi pos tagger, as well as ( [SEP]"}
{"pre": "# refr showed that the degree of syntactic chunks in the context of noun compound nouns can be abstracted with naturally occurring in computational models. [SEP].", "cit": "baseline model given the skewed bracketing distribution in our dataset, we implement the following majority baselines : a ) right classifies all phrases [SEP]"}
{"pre": "in particular, we test different variants of the same simple model # otherefr ; # refr as hpsg # otherefr. [SEP] [SEP]", "cit": "other authors have performed surface realization using various grammar formalisms, for instance ccg # otherefr, hpsg # refr, and lf [SEP]"}
{"pre": "some of these problems include lemmatization # otherefr, pos tagging # refr, shallow parsing # otherefr. [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "comparing scores from different metrics can give a very rough indication of some major problems, especially in combination with a part - ofspeech analysis # refr [SEP]"}
{"pre": "we used an early update version of the averaged perceptron algorithm # refr. [SEP] the incremental shift - reduce model. [SEP] the incrementally [SEP] the", "cit": "several incremental parsing methods have been proposed so far # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the feature weights were tuned on a development set by applying minimum error rate training ( mert ) under the bleu criterion # refr. [SEP].", "cit": "recent studies have also confirmed that tuning mt systems against better mt metrics? using algorithms like mert # refr? leads to better system performance # [SEP]"}
{"pre": "in es 1, the performance of wsd has been measured, with the goal of improving the performance of word sense disambiguation # otheref [SEP]", "cit": "in some experiments of syntactic disambiguation # otherefr, # refr, we tried to combine both taxonomical and distributional measures in such a [SEP]"}
{"pre": "# refr use cognate similarity to rank candidate lists for the same language set. [SEP] well - known relationships ( [SEP] ) from [SEP] [SEP] [SEP] [SEP]", "cit": "there is a range of past work that has variously investigated cognate detection # otherefr, and bilingual lexicon induction # refr. [SEP] [PAD]"}
{"pre": "the choice to include two different dependency parsers but only one constituency - based parser is motivated by the study of # refr, as it [SEP]", "cit": "the berkeley parser is a freely available implementation of the statistical training and parsing algorithms described in # otherefr and # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "aside from the many systems that induce trees from gold tags, there are also unsupervised methods for inducing syntactic categories from gold tags # refr [SEP] phenomena [SEP]", "cit": "however, we suspect that the real gains would come from using soft clustering techniques # otherefr ; # refr, inter alia ) and [SEP]"}
{"pre": "we used a multi - threaded version of the giza + + tool # refr. 2 this speeds up the process and corrects an [SEP]", "cit": "for word alignment we used mgiza + + # refr, a multi - threaded implementation of giza + + # otherefr. [SEP]"}
{"pre": "while early work penalized phrase movements without considering reorderings arising from vastly differing grammatical structures across language pairs like arabic - english # other [SEP]", "cit": "the approach ( so called maximum entropy classifier or simply maxent ) is a popular choice # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the supervised evaluation setting, the? f1 score was also performed on the best performing system # refr when the best systems are [SEP] [SEP] [SEP]", "cit": "our method is heavily inspired by previous proposals from v? eronis # otherefr, hyperlex ) and # refr. [SEP] [PAD] [PAD]"}
{"pre": "statistical techniques, both supervised learning from tagged corpora # otherefr, ( ng and # refr, # otherefr, have been investigated.", "cit": "the ino < lel 1 ) 3,, si ; e, l ; ina ( 1. 998 ) was {, rai [SEP]"}
{"pre": "we note that no pitman - yor language models are suitable for modelling within the bayesian framework of # refr, pitman - yo [SEP] [SEP]", "cit": "dirichlet processes # otherefr or their hierarchical variants # refr and generalizations # otherefr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the second extension of monolingual paraphrase is to construct a bilingual pivot language, as well as the pivot language for smt model", "cit": "translation model augmentation with paraphrases # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in a typical setting, it has been shown that incorporating eye - tracking and dependency parses is significantly more accurate than models # refr. [SEP] [SEP]", "cit": "in the domain of incremental language comprehension, especially, there is a substantial amount of computational work suggesting that humans behave rationally # otherefr [SEP]"}
{"pre": "in morphological analysis, the only morphological analysis of arabic dialects has been found in numerous papers by habash and rambow # otherefr ;", "cit": "the data facilitates machinelearned part - of - speech taggers, tokenizers, and shallow parsing units such as chunkers, as exemplified [SEP]"}
{"pre": "in # refr, mixture models were used to optimize the coefficients to the adaptation domain. [SEP] bleu score, which is exactly once in a model", "cit": "in this aspect, previous methods can be divided into two categories : one paid attention to collecting more sentence pairs by information retrieval technology # otheref [SEP]"}
{"pre": "in this paper, we propose an ibm model, which is based on the l2 model, and hence discarding ( s | [SEP] ( i", "cit": "phrase - based models # refr are a widely - used approach for statistical machine translation. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "these include multiple translations of the same text # otherefr, and corresponding articles from multiple news sources # refr. [SEP] textual entailment # other", "cit": "such transformations are typically denoted as? paraphrases? in the literature, where a wealth of methods for their automatic acquisition were proposed # other [SEP]"}
{"pre": "in a related strand of work, # refr show that, for instance,. [SEP] coverage of web - based models yields results that are significantly lower", "cit": "one way to access more information is to exploit surface counts from large corpora like the web # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "for this purpose, we use the subjectivity lexicon of # refr, 2 which contains approximately 8000 words which may be used to express opinions.", "cit": "phraselevel sentiment analysis has been performed in a small number of cases, for example # refr where expressions are classified as neutral or polar before determining [SEP]"}
{"pre": "it is also worth mentioning that if the training data are available on the training data, then it is trained on the training data ( in an [SEP]", "cit": "it has also been noted that it is more difficult to translate into morphologically rich languages, and methods for modeling target - side morphology have attracted interest [SEP]"}
{"pre": "in the field of ie, pattern - based event extraction has been combined with a number of tasks, including named entity recognition # otherefr,", "cit": "current approaches for learning such patterns include bootstrapping techniques # otherefr ; # refr, fully supervised learning approaches # otherefr and other [SEP]"}
{"pre": "wiki : 2 ) a few seed selection for the general sense disambiguation task of word sense disambiguation, and in wiki - 3 [SEP]", "cit": "previous work on sense alignment yielded several alignments, such as wn? wp - en # refr, wn? wkt - en # otheref [SEP]"}
{"pre": "crfs have been successfully used for a variety of nlp tasks # otherefr ; # refr, but we are not aware of [SEP].", "cit": "since the transformation is mostly explained as local substitutions, deletions, and insertions, we treat word transliteration as a sequence labeling problem # other [SEP]"}
{"pre": "# refr segmented text by using the information put corpus as part of the speech tagger in the rst bank # otherefr. [SEP] the information", "cit": "morris and hirst # otherefr and # refr find topic boundaries in the texts by using lexical cohesion. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we chose a dataset that would be enjoyable to reannotate : the movie review dataset of # refr. 3 the dataset consists of [SEP]", "cit": "previous research has shown that enriching the sentiment labels with human annotators?? rationales? can produce substantial improvements in categorization performance # refr [SEP]"}
{"pre": "we used the mstparser # refr for the conll - x shared task. [SEP] if two existing systems are included in the conll -", "cit": "we use a modified version of the edge - factored parser of # refr to predict vdrs over a set of annotated object regions. [SEP] [PAD]"}
{"pre": "we use statistical significance of the results by # refr. [SEP]ly defined as the results. [SEP] by the crf + cfg parser # otheref", "cit": "we use the approximate randomization test # refr for statistical significance of the difference between the basic sequential crf and our second round crf, which has additional [SEP]"}
{"pre": "scfs can be useful for many nlp applications, such as parsing # otherefr, verb clustering # refr, # otherefr [SEP]", "cit": "most existing systems rely on handwritten rules # otherefr ; # refr or simple cooccurrence statistics # otherefr applied to the grammatical [SEP]"}
{"pre": "in the second international chinese word segmentation bakeoff # otherefr, two of the highest scoring systems in the closed track competition were based [SEP]", "cit": "this character - by - character method was first proposed by # otherefr, and latent variable crfs # refr. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the nli system of # refr for the give challenge which it has been shown to be effective for the nli shared tasks. [SEP]", "cit": "the nli shared task 2013 # refr is the first shared task on nli using the common dataset? toefl - 11? # other [SEP]"}
{"pre": "# refr show that for pcfg parsing, unlexicalized pcfg over the penn treebank could be used to produce state of the art", "cit": "as our goal is to create the simplest possible model which can nonetheless model experimental data, we do not make any tree modification designed to improve accuracy [SEP]"}
{"pre": "# refr ). [SEP] the degree of compositionality of expressions in general noun - noun compounds ( verb - noun combinations ) to detect subjectivity.", "cit": "identifying non - compositional # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "text planning : an expression in the isi sentence planning stage is embodied by the text planner ( in the text \\ [ # refr \\ ]. [SEP]", "cit": "independent knowledge via s'pecific but domainindependent knowledge to domain - dependent communication knowledge ( moore and paris is motivation plan operator for motivating replacement [SEP]"}
{"pre": "we do not attempt to identify alternations across verbs or manuals # refr, but compare them with an automatic measure of two semantic roles. [SEP]", "cit": "in related unsupervised tasks, riloff and colleagues have learned? case frames? for verbs # otherefr, while # refr has learned [SEP]"}
{"pre": "we choose the crf learning toolkit wapiti1 # refr to train me classifiers on the wapiti1 list # otherefr. [SEP]", "cit": "table 4 : features for disambiguation with wapiti, example 3? disambiguate independent suffixes we use wapiti # refr, [SEP]"}
{"pre": "in recent years, several lines of work addressed semantic parsing using various formalisms and levels of supervision # otherefr ; # refr. [SEP] the", "cit": "early works # otherefr ; # refr employed inductive logic programming approaches to learn a semantic parser. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the parsing model is the one proposed in # refr, as well as in the dependency treebank of hungarian. [SEP], we [SEP] the [SEP]", "cit": "unlike most previous work on data - driven dependency parsing # otherefr ; # refr, we assume that dependency graphs are labeled with dependency types [SEP]"}
{"pre": "the wu & # refr and wu # otherefr describe a probabilistic synchronous grammar for translation. [SEP]. [SEP], a tm [SEP] [SEP] [SEP] [SEP]", "cit": "with a few exceptions ( wu and # refr, most smt systems are couched in the noisy channel framework ( see figure 1 ). [SEP]"}
{"pre": "in a second approach, # refr used a similar method to detect the context of a particular application of a lexicalized grammatical structure to a particular [SEP]", "cit": "the main source of knowledge the system relies on in this step is a large - scale, reusable lexicon we combined from multiple resources # refr. [SEP]"}
{"pre": "nonetheless, during the last decade, there has been a steady flow of new work on content selection that employed machine learning # otherefr ; [SEP]", "cit": "# refr attempted a statistical approach to content selection using a substantial corpus of biographical summaries paired with selected content, where they extracted rules and [SEP]"}
{"pre": "in addition, we evaluate our joint model on the conll 2008 shared task on joint parsing and semantic role labeling # otherefr, which [SEP]", "cit": "semantic role labeling # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we used transformation - based learning # otherefr, vp chunks ( np ) and vp tags ( np chunker, vp, noun chunker", "cit": "# refr first assigned a chunk tag to each word in the sentence : i for inside a chunk, o for outside a chunk, and type [SEP]"}
{"pre": "we use the wall street journal section of the penn treebank ( ptb ), by # refr and used n - gram statistics for np [SEP]", "cit": "recent annotations by # refra ) added np structure to the ptb. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "there have been many studies on pos taggers # otherefr, # refr, # otherefr. [SEP] this approach. [SEP] [SEP] [SEP]", "cit": "lp has been used successfully for extending pos labels from high - resource languages to low via parallel corpora # otherefr or highto low - [SEP]"}
{"pre": "in # refr, an efficient inside - outside estimation algorithm is applied to the structured perceptron of # otherefr, which has been applied to", "cit": "syntactic model we used two discriminative arcfactored models for labeled dependency parsing : a first - order model, and a second - order model with [SEP]"}
{"pre": "reranking approaches have given improvements in accuracy on a number of nlp problems including parsing # otherefr ; # refr, and machine translation", "cit": "previous work has generally relied on two approaches to representation : explicitly hand? crafted features # otherefr ) or features defined through kernels [SEP]"}
{"pre": "to obtain syntactic dependency structures, we apply the stanford parser # refr on the target words, and we converted the pos tags. [SEP] [SEP] [SEP] [SEP]", "cit": "the richly annotated gigaword data comprises automatic parses obtained with the stanford parser # refr so that we easily have access to the lemma [SEP]"}
{"pre": "in previous work, # refr used the spin work by # otherefr by # otherefr. [SEP] the textrank algorithm. [SEP] a", "cit": "previous work addressed the problem of identifying the polarity of subjective text # otherefrb ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "malt # otherefr, mst # refr, and mate parser # otherefr? trained on the conll 2006 data set. [SEP] [SEP]", "cit": "sagae # otherefr used two different learning algorithms of their graph - based parser to complete a one iteration of co - training, getting [SEP]"}
{"pre": "the conll 2005 shared task on semantic role labeling # otherefr ; # refr, have shown that shallow semantic shallow semantic [SEP] ( srl", "cit": "for srl, high accuracy has been achieved by : # otherefr ; # refr ; toutanova et al, 2005 ; [SEP]"}
{"pre": "# refr showed that surprisal calculated from a probabilistic earley parser correctly predicts wellknown processing phenomena that were believed to emerge from structural ambiguities,", "cit": "in this context, the most common formalization of a word? s information content is its surprisal # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the machine translation community, most state - of - the - art machine translation systems # otherefr ; # refr are designed for [SEP] the", "cit": "the chinese text was segmented with a crf - based chinese segmenter optimized for mt # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "english sentences were parsed with the stanford parser # refr and we used the stanford parser # otherefr. [SEP] [SEP] [SEP] [SEP] features, as", "cit": "? 5 parseval f score of the tree with respect to a tree produced by the stanford parser # refr? 6 right hand side of the [SEP]"}
{"pre": "this approach is similar to the ones described in # refr. [SEP] a higher scheme to annotate in which can be extracted as features, could be", "cit": "we focus more closely on understanding the role of syntax by comparing the use of hand - crafted features and tree kernels # refr, and [SEP]"}
{"pre": "we follow # refr in using the cr system for coreference resolution in a pronoun resolution system by reranking manner. [SEP]. [SEP] the [SEP]", "cit": "# refr ) are actually positive coreference indicators. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the creation of the timeml parser # otherefr and the development of a large amount of parse annotated corpora ( costa - oriented textual corpora )", "cit": "one approach might be to first group events into their narrative containers # refr, for example, grouping together all events linked to the time of a [SEP]"}
{"pre": "# refr used the ratnaparkhi? s supertagger to lexical dependencies for resolving coordination disambiguation. [SEP] it into two [SEP] languages,", "cit": "many previous studies for coordination disambiguation have focused on a particular type of np coordination # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in a second experiment, we use an automatic evaluation of utterance - based on the output produced by scoringing dialogue systems # otheref [SEP] [SEP] [SEP]", "cit": "other times, a wide variety of utterances work well # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "several unsupervised dependency parsing algorithms # otherefr ; # refr have been proposed and achieved high parsing accuracies on several treebanks, due in [SEP]", "cit": "this led to a vast amount of research on unsupervised grammar induction # otherefr ; # refr, which appears to be a natural solution to [SEP]"}
{"pre": "in the biomedical domain, negation has been used in the biomedical domain, e. g. corpus, biomedical text, [SEP], biomedical documents, [SEP]", "cit": "the bioscope corpus consists of three parts : clinical free - texts ( radiology reports ), biological full papers and biological paper abstracts from the gen [SEP]"}
{"pre": "in the last years, a new method has been proposed for generating summaries from the document # otherefr ; # refr. [SEP] [SEP] [SEP] [SEP]", "cit": "another approach, presented by # refr, consists in generating coherent summaries that are shorter than a single sentence. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "subclauses are labeled as? sbar? in the parser tree generated by a commonly used nlp tool, e. g. # refr [SEP]", "cit": "existing approaches consider essay rating as a classification # otherefr or preference ranking problem # refr, where the loss function is the regression loss, [SEP]"}
{"pre": "this is fine grained with the presence of opinion expression, but we find that opinion expressions are not available to http : / / www. [SEP]", "cit": "therefore, we adapt a standard machine learning - based approach to np coreference resolution # otherefr ; ng and # refr for our purposes [SEP]"}
{"pre": "morfessor # refr. [SEP] a mdl system that uses a morphological analyzer to segment segmentation algorithm. [SEP] segmentation algorithm. [SEP] [SEP] [SEP] [SEP]", "cit": "these studies attempt to minimize lexicon complexity # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we follow # refr, who train a classifier for mention np coreference resolution by using the two coreference resolver. [SEP] sentences [SEP] [SEP] [SEP]", "cit": "iii and marcu, 2005 ; # refr ; versley, 2006 ; ng, 2007, inter alia ) use lexical semantic information as [SEP]"}
{"pre": "in the unsupervised evaluation, the system outputs are compared by using v - measure # refr. [SEP] ( v - beta ) [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "clustering techniques have been used successfully for many natural language processing tasks, such as document clustering # otherefr, pitch accent type disambiguation # [SEP]"}
{"pre": "figure 1 : a sentence from english verb in a sentence containing the predicate identification of the argument structure of the source ( part ) and then [SEP] [SEP]", "cit": "srl # otherefr, extraction of predicate - argument structures # refr, automatic extraction of semantic relations # otherefr, among others [SEP]"}
{"pre": "similar to compositional models in monolingual settings # otherefr and multilingual settings ( hermann and # refr, the representation of a set [SEP]", "cit": "in that respect, the work reported in this paper extends the current research on purely statistical data - driven distributional models of cross - lingual semantic [SEP]"}
{"pre": "similar to compositional models in monolingual settings # otherefr and multilingual settings ( hermann and # refr, the representation of a target word", "cit": "without observing any context, the standard models of semantic word similarity that rely on the semantic space spanned by latent cross - lingual concepts in both [SEP]"}
{"pre": "# refr use a semi - supervised approach to ordering the ordering of modifiers for choosing among alternative orders of modifiers for choosing among [SEP]", "cit": "determining methods for ordering modifiers prenominally and investigating the factors underlying modifier ordering have been areas of considerable research, including [SEP]"}
{"pre": "we use the reinforcement learning framework of reinforcement learning ( rl ) # refr to map natural language to an nlp system to an nlp system.", "cit": "# refr, nl utterances fl commands ( in r ) [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the user is you based on the dialogue model of # refr. [SEP] dialogue acts, although the task is. [SEP]. [SEP]. [SEP] [SEP] [SEP]", "cit": "i i i i i i i # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "sentence compression has been considered before in contexts outside of summarization, such as headline, title, and subtitle generation # otheref [SEP]", "cit": "other applications include automatic subtitling # otherefr ; # refr and displaying text on devices with very small screens # otherefr. [SEP]"}
{"pre": "another line of research closely related to our work is the recognition of semantic parsing or semantic role labeling # otherefr ; # refr. [SEP] the", "cit": "recent works have shown that multi - modal semantic representation models outperform unimodal linguistic models on a variety of tasks, including modeling semantic relatedness and predicting [SEP]"}
{"pre": "we used the charniak parser # refr for parsing sentences, and self - training with svm - light # otherefr and test software [SEP]", "cit": "in fact, # refr found a similar technique to be effective? though only in a model with a large feature space (? pcfg + [SEP]"}
{"pre": "the second chinese text segmentation bakeoff # otherefr, toutanova et al # refr and building block compound splitting the [SEP] [SEP]", "cit": "unfortunately, determining the optimal segmentation is challenging, typically requiring extensive experimentation # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this model is then used to generate the set of the target words, which are the first parse, then reranked to the inside - outside", "cit": "a new data - oriented version of morpa ( \\ [ # refr \\ ] ) assigns a priority ordering to the set of morphological decom - [SEP]"}
{"pre": "in addition to the well - known word error rate # otherefr ; # refr. [SEP] the quality of the translation model [SEP] [SEP] [SEP] [SEP]", "cit": "mt quality in the medical translation task is evaluated using automatic evaluation metrics : bleu # otherefr, and cder # refr. [SEP] [PAD]"}
{"pre": "in order to extract web documents from unstructured text in different domains, such as blogs # otherefr, and twitter, [SEP] ( el [SEP]", "cit": "# refr and kinsella et al. # otherefr present methods to identify the location of a user based on his or her tweets [SEP]"}
{"pre": "elongated words and phrases are sometimes enriched by sentiments # refr. [SEP] the word frequencies. [SEP] the same negation in social media. [SEP] [SEP] the", "cit": "it is particularly common in opinionated words # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this approach has been well studied in the context of question answering # otherefr, # refr, and machine translation # otherefr. [SEP]", "cit": "iii and marcu, 2004 ), relation extraction # otherefr ; # refr ; zhang et al, 2005 ; bunescu, [SEP]"}
{"pre": "twitter is widely used for conversations # otherefr ; # refr. [SEP] the twitter messages ; however, [SEP] features [SEP] such as [SEP] features,", "cit": "a related task to ours is that of response generation, as explored by # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "implementations of sorted feature formalisms such as tdl # otherefr, tfs # refr and others have been used for the development and [SEP] this", "cit": "the commission of the european communities through the project lre - 61 - 061 \" reusable gratnmatical resources \", where it has been [SEP]"}
{"pre": "in the case of the current system, the remaining 17 ( a. ) is similar to the bioene, and assesses the aim of [SEP] [SEP]", "cit": "in this paper we address the matter of automatic generation oftechnical documentation # refr by studying the problem of automatically generating documents describing the single step [SEP]"}
{"pre": "we cluster german verbs using features capturing their valency or subcategorisation, following prior work # otherefr ; li and # refr, [SEP]", "cit": "in recent years, a variety of approaches have been proposed for automatic induction of verb classes from corpus data # otherefr ; # refr ; [SEP]"}
{"pre": "we also show how supervised the unsupervised wsd system of # refr, a decision list of the semantic information contained in the senseval - 3 word", "cit": "mt software translated ones ), as it has been shown to perform well with the features described below # refra ). [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we choose to perform all our models as well as the neural networks trained on large data sets, which have used manually - created semi - markov models", "cit": "being able to efficiently exploit features defined over individual words, our model also opens up the possibility for us to exploit alternative representations of words for learning [SEP]"}
{"pre": "therefore, studies have recently resorted to other resources for the enhancement of parsing models, such as large - scale unlabeled data # otherefr [SEP]", "cit": "# refr propose the qg for machine translation ( mt ) problems, allowing greater syntactic divergences between the two languages. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in order to select how the rhetorical structure of the rhetorical goals are not derived from the rhetorical structure theory ( rst ) # refra", "cit": "current models of text structure computational models two general methodologies have been applied to the structuring of explanations : schemas # otherefr \\ ], \\ [SEP]"}
{"pre": "we compare two similarity models : a set of features and a set of features ( i. e. partof - speech ), [SEP] improvements (", "cit": "mira has been used successfully for both sequence analysis # refra ) and dependency parsing # otherefrb ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "parallel corpora have been shown to provide a rich source of constraints for statistical machine translation # otherefr ; # refr. [SEP] this approach is [SEP]", "cit": "a common approach to obtain such material is to look for it on the web. 9 the use of already 8http : / / www. [SEP]"}
{"pre": "in our work we use the dirt collection because it consists of a single treebank corpus # refr. [SEP] well - known [SEP] [SEP] [SEP] [SEP]", "cit": "the rest of the paper is organized as follows : section 2 introduces the inference rule collection 2another line of work on acquiring paraphrases [SEP]"}
{"pre": "the classification approach has been used to deal with the most successful classification of named entity recognition # otherefr ; # refr. [SEP] the classification [SEP]", "cit": "applications of document pair classification include plagiarism detection # otherefr, paraphrase detection # refr or text similarity detection # other [SEP]"}
{"pre": "the second corpus of preposition errors are the subject of verb and subject of verb errors # otherefr ; # refr. [SEP] [SEP]ly,", "cit": "certain constructions, such as english prepositions, are difficult to characterize by grammar rules and thus are wellsuited for machine learning approaches # refr [SEP]"}
{"pre": "starting from being mapped into a document level classification task # otherefr ; # refr, it has been shown that incorporating more and more complex features", "cit": "sentiment analysis includes a variety of different problems, including : sentiment classification techniques to classify reviews as positive or negative, based on bag of words # [SEP]"}
{"pre": "7work such as # refr, martins et al # otherefr, utilize some aspects of the non - local features for parsing, but", "cit": "these include beam search # otherefr, in which arbitrary features can act as constraints on y, and approximate solutions like # refr, in [SEP]"}
{"pre": "for instance, # refr report that removing attribute selection from the web1. [SEP] system. [SEP] training data. [SEP] the data of attribute selection.", "cit": "3for comparison : in the reg challenge 2008, ( which involved a different test set, but the same type of data ), the best [SEP]"}
{"pre": "in nlp, rf classifiers have been used for pos tagging # otherefr, parsing # refr, and machine translation # otherefr.", "cit": "thus, a classifier trained on newswire data and tested on biomedical data will have seen few training examples related to sentences with features? gene? [SEP]"}
{"pre": "in addition to the standard wsd problem, smt systems have made use of a word - aligned bilingual corpus # otherefr ; # refr", "cit": "for example, # refr built classifiers inspired by those used in word sense disambiguation to fill in blanks in a partially - completed translation. [SEP]"}
{"pre": "on one hand, the use of machine learning techniques such as decision trees, has been successfully applied to dialogue act tagging # [SEP] these pairs # [SEP]", "cit": "in the previous research, tbl showed successful performance in many annotation task, e. g. # otherefr, # refr. [SEP] [PAD]"}
{"pre": "we use a dynamic programming technique applied to the search problem # refr. [SEP] if they are polynomial time. [SEP]. [SEP]. [SEP] the source [SEP]", "cit": "in other related work, # refr use several preprocessing strategies on both source and target language to make them more alike with regards to sentence length and [SEP]"}
{"pre": "# refr use an implicit subjectivity analysis in online debate forums and use the stance of political communication. [SEP] features to classify online debate forums", "cit": "the topic was? evolution?, with sides? yes, i believe? vs.? no, i dont believe?. bates [SEP]"}
{"pre": "# refr extract a similar approach, but concentrated on the identification of the nouns using the prepositions. [SEP]a - 3 noun phrases are known", "cit": "for instance, # refr experimented with a random sample of two hundred english verb - particle constructions and showed that as many as two thirds [SEP]"}
{"pre": "in # refr, we proposed a way of incorporating the training features in a classification model. [SEP] kernel ( pke ). [SEP] kernel [SEP] (", "cit": "tree and sequence kernels have been successfully used in many nlp applications, e. g. : parse reranking and adaptation # otheref [SEP]"}
{"pre": "in machine translation, the wellknown paraphrase identification can be used to build upon the one proposed by # refr. [SEP] ( 3 ) much", "cit": "syntactic similarity the algorithm introduced by # refr takes two sentences as input and merges them by top - down syntactic fusion guided by compatible syntactic substr [SEP]"}
{"pre": "we base our experiments on basenp data, using the iob scheme # refr, the np chunker. [SEP] named entity tags [SEP]. [SEP]", "cit": "base noun phrases ( basenps ), broadly? the initial portions of non - recursive noun phrases up to the head? # refr, are [SEP]"}
{"pre": "we used a multi - threaded version of the giza + + tool # refr. 2 this speeds up the process and corrects an [SEP]", "cit": "for the word alignments, we chose mgiza # refr, using seven threads per mgiza instance, with the parallel option, i. e [SEP]"}
{"pre": "in this paper, we evaluate the reliability of the annotation even when annotation guidelines for a new dependency annotation, which provides an easy - to - to", "cit": "brat is distributed with examples from over 20 corpora for a variety of tasks, involving texts in seven different languages and including examples from corpora such [SEP]"}
{"pre": "we use the memory - based tagger # refr trained on the wall street journal corpus ( wsj ) section of the penn treebank and are", "cit": "moreover, automatic feature weighting in the similarity metric of an mb learner makes the approach well - suited for domains with large numbers of features from heterogeneous [SEP]"}
{"pre": "the sentences were parsed using the collins parser # refr and charniak # otherefr. [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "a head percolation table has previously been used in several statistical parsers # otherefr ; # refr to find heads of phrases. [SEP] [PAD] [PAD]"}
{"pre": "for example, # refr demonstrated that such models can be used for reorderings, which can be quite effective in smt by combining them.", "cit": "the absolute improvements of 1. 0 bleu points on average over 1 - best alignments are statistically significant at p < 0. 01 using sign [SEP]"}
{"pre": "we use the stanford corenlp suite to lemmatize and partof - speech tag each word # otherefr, and resolve core [SEP]", "cit": "previous studies identified the presence of recall errors as a main bottleneck for improving performance # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "a typical approach to normalization is to use noisy channel model, as well as a word alignment task # otherefr, and machine translation # refr", "cit": "# refr use a large amount of training data to supervise an fst - based french sms normalizer. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the standard tags encoding for tags of tagset trained the tagger # refr and the base parser for dutch sentences. [SEP] ln [SEP] [SEP]", "cit": "we use a tagging framework which is based on so - called iob tagging, commonly used in the context of phrase chunking tasks # refr [SEP]"}
{"pre": "to make normalization efficient, contrastive estimation # refr proposed a logistic regression model based on the expectation maximization algorithm that takes the regular error model as input", "cit": "recent studies have formalized the task in the discriminative framework # refr, t? = argmax t? gen ( s ) p ( t | [SEP]"}
{"pre": "\\ [ # refr \\ ] offer an alternative method for discovering and using the lexical attachment preferences, based on corpus - based lexical co - occurrence statistics", "cit": "another elated alternative would be to select a single best classification - - for example, using the measure of selectional ssociation proposed in [SEP]"}
{"pre": "it has been applied to a wide variety of tasks, including part of speech tagging # otherefr ; # refr, and syntactic parsing [SEP] [SEP]", "cit": "with the pos extraction method, we first tagged the bnc using an fntbl - based tagger # refr trained over the brown and [SEP]"}
{"pre": "in a different approach, # refr used wordnet similarity to automatically generate the synonyms or sentences. [SEP] ( 2 ) [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "two common techniques for query expansion are blind relevance feedback # otherefr and word sense disambiguation ( wsd ) # refr. [SEP] [PAD] [PAD]"}
{"pre": "# refr used a supervised machine learning approach for sentiment classification. [SEP] features, including sentiment, unigrams, bigrams, etc. [SEP] features", "cit": "while the examination of adjectives is highly important for sentiment analysis ( as shown by # refr who were able to achieve high accuracy even when using [SEP]"}
{"pre": "we used the pos tagger # refr to train the pos tagger of unknown words. [SEP]. [SEP] morphological information. [SEP] the current tagger", "cit": "lower accuracies have been reported in the literature for mandarin pos tagging # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the experiments reported in this paper, we use the pp - attachment disambiguation algorithm # otherefr ; # refr to obtain the results of", "cit": "2. 2. 1 pars ing in recent years, the success of statistical parsing techniques can be attributed to several factors, such as the increasing [SEP]"}
{"pre": "this has led to the development of various data - driven dependency parsers, such as those by yamada and matsumoto # otheref [SEP]", "cit": "some authors propose to solve it by techniques for recovering non - projectivity from the output of a projective parser in a post - processing step # [SEP]"}
{"pre": "in addition to the mt - based method, researchers have also investigated other methods for paraphrase generation, such as the pattern - based methods [SEP]", "cit": "moreover, research on acquisition # otherefr, generation # refr, and recognition # otherefr of paraphrases has been on the [SEP]"}
{"pre": "we propose a linear model framework to define the similarity of the two optimization algorithms : ( 1 ) similarity to minimum bayes risk ( mbr [SEP] [SEP]", "cit": "in particular, our results show a speed - up by two orders of magnitude with respect to the original method of # refr and by a factor [SEP]"}
{"pre": "most of the previous work on sentiment analysis consider to determine the document # otherefr ; # refr. [SEP] [SEP] [SEP] [SEP]ity of documents [SEP]", "cit": "recently, there are some studies on joint sentiment / topic extraction # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the relationship between two parts of speech and text is often modeled as a classification problem, e. g. # otherefr ; # refr [SEP]", "cit": "acd also differs from topic clustering # otherefr ; # refr, though there are superficial similarities. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the c & c tagger # refr and the c tagger # otherefr to provide a wide range of languages. [SEP] features", "cit": "by training the c & c tagger # refr on the gold - standard corpora and our new wikipedia - derived training data, we evaluate the [SEP]"}
{"pre": "following # refr, we use the pcfg approximation to regularized pcfg models. [SEP] this model # otherefr. [SEP] [SEP] [SEP] [SEP]", "cit": "compared to a basic treebank grammar # otherefr ; # refr conditioning information. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the stanford dependency parser # otherefr is a function tagger that uses a constituent parser to obtain syntactic dependencies for words, and then parses", "cit": "to overcome part - of - speech errors and increase recall, we incorporate three sources : ( 1 ) the np heads from a syntactic parse tree [SEP]"}
{"pre": "for example, the briscoe and carroll, 1997 ; # refr has been used to find the good performance of natural anguage [SEP] [SEP]", "cit": "examples include automatic augmentation f wordnet relations # otherefr, and automatic acquisition of subcategorization data from large text corpora # refr. [SEP]"}
{"pre": "in this paper, we focus on intra - sentential discourse relations # otherefr ; # refr, rhetorical structure theory # otheref [SEP]", "cit": "# refr find that a better syntactic parse of a sentence can be derived when the syntax of adjacent sentences is also taken into account. [SEP] [PAD] [PAD]"}
{"pre": "the lexicon can be computed efficiently estimated by optimizing the conditional likelihood that a word alignment can be computed by its translation alignment model # otherefr ;", "cit": "symmetrization can also be realized during alignment model training # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "bod # otherefr, # refra ), semantic interpretation # otherefr ). [SEP] ( full ) [SEP] ( full sentences [SEP] [SEP]", "cit": "# refr and bean et al # otherefr ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "table 5 shows the results for our experiments with the uas of mcdonald et al # otherefr using the parser of # refr. [SEP]. [SEP]", "cit": "koo et al. # otherefr and # refr use unsupervised wordclusters as features in a dependency parser to get lexical dependencies. [SEP]"}
{"pre": "an alternative learning model that can overcome this problem performs coreference resolution based on entity - mention pairs # otherefr ; # refrb ) [SEP]", "cit": "7. 1. 2 cluster - ranking model the cluster - ranking # otherefr, # refr ) and the mention - ranking model # [SEP]"}
{"pre": "corrections to deal with the problem of error detection and correction have been proposed in the literature # otherefr ; # refr. [SEP] [SEP] [SEP] [SEP]", "cit": "as an example, a convenience store environment was developed and a corpus of interaction was collected # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "there has been a growing interest in recognizing non - english # otherefr ; # refr. [SEP] the current work of yarowsky # other", "cit": "the one computational approach that at least claims to consider archaeological decipherment # refr, curiously enough, assumes an alphabetic and purely [SEP]"}
{"pre": "# refr used a factored language model ( flm ) to train a 4 - gram language model on words perplexity of the [SEP] [SEP]", "cit": "an alternate method of embedding words in a continuous space is through tied mixture language models # refr, where n - grams frequencies are modeled similar to [SEP]"}
{"pre": "this result improves the efficiency of # refr, a efficient algorithm which requires only a large corpus of extracted from large documents. [SEP] the training data increases", "cit": "this work expands upon our earlier workshop papers # refra ; goyal et al., 2010b ). [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "some of these new content ( el. ), which is based on the one described in # refr, is another. [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "the mda system developed at xrce # refr uses a formalism inspired from definite clause grammars # otherefr that encodes both the abstract semantic syntax [SEP]"}
{"pre": "the task organizers use the conll - 2013 nlp 2009 # refr. [SEP] system is trained on the well - formed native english error data", "cit": "the second and third experiments are inspired by # otherefr ; # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "the most common practice is to use a nonparametric prior as a translation process # refr. [SEP]. [SEP] the entire sequence of phrases [SEP]. [SEP] it", "cit": "the machine translation literature is littered with various attempts to learn a phrase - based string transducer directly from aligned sentence pairs, doing away with the [SEP]"}
{"pre": "in the sections that follow, for example, in the wsd literature are good in the senseval - 3 english lexical sample task # refr,", "cit": "this is roughly comparable with most frequent sense figures in standard annotated corpora such as semcor # refr and the senseval / semeval data [SEP]"}
{"pre": "since then, many methods have been developed to automatically identify opinion words and their polarity # otherefr, as well as n - gram and [SEP]", "cit": "other datasets are also available, including two polarity datasets consisting of movie reviews # otherefr, and a collection of newspaper headlines annotated [SEP]"}
{"pre": "often, methods for opinion, sentiment, and subjectivity analysis rely on lexicons of subjective # otherefr ; # refr ). [SEP] [SEP]", "cit": "often, methods for opinion, sentiment, and subjectivity analysis rely on lexicons of subjective # otherefr ; # refr ). [SEP] [PAD]"}
{"pre": "we tuned the batch mira algorithm # otherefr to optimize the feature weights for each feature, and optimize the feature weights for each translation model", "cit": "one or both of these limitations have led to recent introduction of alternative optimization strategies, such as minimum - risk # otherefr, structured svm [SEP]"}
{"pre": "# refr applied self - training to pos tagging with self - training, and show that the agreement of disagreement over the same taggers are [SEP] [SEP]", "cit": "# refr reported positive results with little labeled training data but negative results when the amount of labeled training data increases. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "although general dialogue strategies have been proposed to change in the dialogue policies, the presence of word - sense disambiguation systems will result in the context [SEP]", "cit": "in other types of spoken dialogue systems, the user? s subjective judgments about using the system are often considered a primary system performance metric ; e [SEP]"}
{"pre": "in this system, we have demonstrated that redundancy in the extracted data ( despite the noise ) can be leveraged to improve quality, by analyzing global", "cit": "our underlying ie system is described in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "thrax extracts phrase pairs that are labeled with the target language model # refr, which are variations of the target language model. [SEP] [SEP] [SEP] [SEP]", "cit": "we also experiment with relaxing the parses by a method proposed under the label of syntax - augmented machine translation ( samt ), described [SEP]"}
{"pre": "these are the'quasi logical forms'# otherefr, differing from aresolved logical forms'( rlf ) as contextual [SEP] (", "cit": "the details of two versions of the cle quantifier scoping mechanism are discussed by # refr and pereira # otherefr. [SEP] [PAD]"}
{"pre": "undoubtedly, effective disambiguation techniques are of great use in many natural language processing tasks, e. g., machine translation and information retrieving # [SEP]", "cit": "word sense disambiguation has long been one of the major concerns in natural anguage processing area # otherefr ; # refr, whose aim [SEP]"}
{"pre": "in the graph - based model, global optimization methods are used in the framework of # refr. [SEP] a graph - based model # otherefr", "cit": "by extending the firstorder model, mcdonald and pereira # otherefr and # refr exploit second - order features over two adjacent arcs [SEP]"}
{"pre": "in # refr, two versions of wikipedia and semi - supervised machine learning methods are used to extract large te data sets similar to the ones provided [SEP]", "cit": "more specifically, an entailment rule is defined # refr as a directional relation between two sides of a pattern, corresponding to text fragments with variables [SEP]"}
{"pre": "in # refr, the authors romanian corpus consists of five different senses ( per ) and ( per ), but using the method [SEP] a single", "cit": "research by # refr and koeling et al. # otherefr pointed out that a change of predominant sense is often indicative of a change [SEP]"}
{"pre": "we use the model of # refrb ), which is then used to model adaptation on smoothed word vectors ( e. g. [SEP] [SEP] the", "cit": "we tested three commonly - used functions : the bhattacharyya coefficient # otherefr ; # refr, the jensen - shannon divergence [SEP]"}
{"pre": "in error detection, most methods of error analysis have been proposed for detecting corrections # otherefr ; # refr. [SEP], [SEP], [SEP],", "cit": "that corrections are di cult for asr systems is generally explained by the fact that they tend to be hyperarticulated | higher, louder [SEP]"}
{"pre": "several methods have been proposed to use a variety of features, including part - of - speech ( pos ) tags # refr, named entity recognition #", "cit": "# refr employs hundreds of hand - crafted templates as features for decision tree learning. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this method has been successfully applied in many applications # refr. [SEP] ( 1 ) reynarl v denotes the ambiguous word [SEP] subject [SEP] [SEP]", "cit": "the benefits of using grammatical information for automatic wsd were first explored by # refr and resnik # otherefr in unsupervised approaches to disambig [SEP]"}
{"pre": "# refr use a joint probability model for machine translation, which is no longer word forms of a phrase - based model. [SEP] a word [SEP] it", "cit": "limitations of basic word - based models prompted researchers to exploit morphological and / or syntactic / phrasal structure # otherefr, # refr, [SEP]"}
{"pre": "we evaluate our approach on test set sections 2 - 21 of the v - measure # refr and v - beta # otherefr. [SEP] [SEP]", "cit": "specifically, we perform hierarchical agglomerative clustering ( hac ) using ward? s method as the inter - cluster distance, while the distance [SEP]"}
{"pre": "in recent years, conditional random fields # otherefr have shown success on a number of natural language processing ( nlp ) tasks, such as", "cit": "# otherefr, chunked, and labeled with irex 8 named entity types by crfs using minimum classification error rate # refr, [SEP]"}
{"pre": "approaches in this area span methods for simplifying lexis # otherefr ; # refr, syntax # otherefr. [SEP] [SEP] [SEP] the [SEP]", "cit": "in the recent work of # refr, for example demonstrates an approach to increasing readability of texts by learning from unsimplified texts. [SEP]"}
{"pre": "similar to compositional models in monolingual settings # otherefr and multilingual settings ( hermann and # refr, the representation of a set [SEP]", "cit": "the utility of the transfer or annotation projection by means of bilingual lexicons obtained from the clss models has already been proven in various tasks such [SEP]"}
{"pre": "the only broad - coverage precision grammars available for english, recall and f - score is shown in # refrb ). [SEP] [SEP] [SEP] [SEP] [SEP]", "cit": "the manually compiled grammars in our experiment are also intrinsically different to grammars automatically induced from treebanks # otherefr or the various ccg [SEP]"}
{"pre": "this is a generalization of the monolingual metrics used in multi - parallel phrase tables # refr. [SEP] this approach was used to [SEP] the [SEP] [SEP]", "cit": "in contrast to most of the previous approaches to combine the outputs of multiple mt systems # otherefr ; # refr, which are variations over [SEP]"}
{"pre": "woodsend and lapata # otherefr present a discriminative framework where the summary? and the sentences are parsed using the grammatical compression method proposed", "cit": "prior studies often rely heavily on the generic sentence compression approaches # refr for compressing the sentences in the documents, yet a generic compression system may [SEP]"}
{"pre": "och et al [ 1999 ]? s alignment template model can be reframed as a phrase table ; yamada and knight, 2005 [SEP] [SEP]", "cit": "most recent approaches in smt, eg # otherefr ; # refr, use a log - linear model to combine probabilistic features. [SEP] [PAD]"}
{"pre": "most of the applications of comparable corpora focus on discovering translation equivalents to support machine translation, such as bilingual lexicon extraction # otherefr, parallel [SEP]", "cit": "to validate this, we then perform keyword extraction by using a simple tfidf based approach, which has been shown effective for keyword or key [SEP]"}
{"pre": "a number of statistical parsing models have recently been developed for combinatory categorial grammar # otherefr ; # refrb ). [SEP] this [SEP]", "cit": "impressive results have been achieved culminating in the state - of - the - art parser of # refr which has been used as the parser [SEP]"}
{"pre": "the recent approaches in coreference resolution by combining the generic and poon and domingos of the mentions model # otherefr ; #", "cit": "# refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr describe a similar approach to ccg parsing that uses equation ( 1 ) trained on a subset of the wall street journal portion of the penn", "cit": "recent work on a softmax - margin loss function and integrated supertagging via belief propagation has improved this to 88. 58 % # refr [SEP]"}
{"pre": "mu? # refr describe an unsupervised system that makes use of a coreference resolution model with a strong features, and show a strong results in the", "cit": "note that several leading coreference researchers have published books # otherefr ), and delivered tutorials ( e. g., # refr [SEP]"}
{"pre": "the use of dimensionality reduction techniques, for instance latent semantic analysis in # otherefr or examplar - based models # refr. [SEP] the", "cit": "this perspective was first adopted by # otherefr and # refr and then, explored in details in # otherefr. [SEP] [PAD] [PAD] [PAD]"}
{"pre": "this binarization is similar to the one described by # refr. [SEP]. [SEP] ( i. e., a shift - reduce parsing )", "cit": "# refr state? while cfgs can always be reduced to rank two ( chomsky normal form ), this is not the case for [SEP]"}
{"pre": "we trained the model using the averaged perceptron algorithm # refr. [SEP] - bfgs system # otherefr. [SEP] a simplified version of [SEP]", "cit": "here we learn a discriminative hmm model # refr of sentence compression using mira # otherefr, comparable to previously explored models of noun phrase [SEP]"}
{"pre": "in this paper, we compare the results obtained by tree kernels on parse trees ( i. e., re - ranking ) # refr. [SEP]", "cit": "it generalizes a subset tree kernel ( stk ) # refr that maps a tree into the space of all possible tree fragments constrained by the [SEP]"}
{"pre": "# refr used classifiers based on a set of features features features extracted from the hedge classification features of the hedge cues. [SEP] features of hedge classification.", "cit": "other early work focused on semisupervised learning due to a lack of annotated datasets # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "we use the yamcha # refr chunker for the chunking of svm and we adopted the support vector machines. [SEP] kernel svm, in our", "cit": "further details can be found in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this is in fact that supervised and unsupervised approaches are superior features # refr. [SEP] features are those of the mentions of the mentions of [SEP]", "cit": "other hybrid approaches reliant on rule - based and ml are presented by # otherefr and the involvement of machine translation system to boost the [SEP]"}
{"pre": "distributional similarity is being deployed ( e. g., # refr ) in question answering # otherefr. [SEP] text similarity [SEP] [SEP] [SEP] [SEP]", "cit": "some researchers count positional collocations in a sliding window, i. e., the cocounts and soa measures are calculated per relative position # [SEP]"}
{"pre": "the largest current efforts are to create a translation and a subset of the data sets # refr. [SEP] the current format of the [SEP] it appears in", "cit": "on the other hand, graf can be used as a pivot format between other formats # otherefr, e. g. there is [SEP]"}
{"pre": "factored translation has been successfully applied to many language pairs and with diverse types of information encoded in the additional factors, i. a. # [SEP]", "cit": "# refr or toutanova et al # otherefr.. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "analyzing the morphological structure of words can benefit natural language processing ( nlp ) applications from grapheme - to - phoneme conversion # refr, [SEP]", "cit": "character trees have been incorporated into a number of more recently proposed unsupervised morphology induction systems # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "# refr, curran # otherefr improves on the latter by clustering by committee. [SEP] the frequencies of verbs, and the latter by committee", "cit": "# refr used clustering to build an unlabeled hierarchy of nouns. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in the rhetorical structure theory # otherefr and the rhetorical relations rhetorical relations # refr. [SEP] ( rst ) is shown to be", "cit": "this led # refr to present multi - nuclear versions of some nuclear relations from the classic extended classification. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "in order to assess the quality of a linguistically informed corpus, and the reliability of their systems has been conducted by either dividing the data into the", "cit": "aggregation is performed according to heuristics similar to the ones proposed in # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "an alternative learning model that can overcome this problem performs coreference resolution based on entity - mention pairs # refrb ). [SEP] the latter # other", "cit": "there is a large body of literature for coreference resolution based on machine learning # otherefr ; # refr approach. [SEP] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "recently, kernel methods have been applied to relation extraction # otherefr ; # refr. [SEP] kernel methods based on crosslingual data [SEP] [SEP]", "cit": "while many supervised machine learning approaches have been successfully applied to the rdc task # otherefr ; # refr, few have focused on weakly [SEP]"}
{"pre": "this model is trained on the entire data set, but we can treat discriminatively trained models # refr. [SEP] - order models # otherefr", "cit": "mt? s goal is to learn a mapping function, f, from an input sentence, x, into y = ( t, h ) [SEP]"}
{"pre": "this is the main reason because the performance of previous research on this topic, we adopted the experimental settings # otherefr ; [SEP] [SEP] [SEP] [SEP]", "cit": "specifically, an approach that involves incorporating? clusteringbased word representations # otherefr and dependency parsing # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
{"pre": "this has led to active research on broad - scale acquisition of entailment rules for predicates, e. g. # otherefr ; # [SEP]", "cit": "another variant occurs when using binary templates : a template may be represented by a pair of feature vectors, one for each variable # otherefr [SEP]"}
{"pre": "# refr, in particular, the centering theory # otherefr. [SEP]'~ lnng ~ lnng ~ ( as [SEP] [SEP] [SEP]", "cit": "some exceptions are # otherefr ; and ( di # refr, which uses centering theory # otherefr in several ways. [SEP] [PAD]"}
{"pre": "we therefore use the stanford typed dependencies ( de marneffe and # refr. [SEP] dependency representations, i. e., bilou [SEP] [SEP]", "cit": "iii ) stanford style, another alternative scheme in the manner of the stanford dependencies ( de marneffe and # refr, all with a head [SEP]"}
{"pre": "this is similar to the approach taken in # refr. [SEP] recognizing speaker?. [SEP] recognizing speaker?. [SEP] if needed before speaking. [SEP] it", "cit": "experiments in both # otherefr and # refr find no conclusive winner among early fusion, additive late fusion, and multiplicative late fusion. [SEP] [PAD]"}
{"pre": "the features are combined into a log - linear model, and the lowercased implementation of the mert training algorithm # refr. [SEP] [SEP] [SEP]", "cit": "we have build phrase - based systems # otherefr ; # refr, using the standard log linear framework in order to introduce several models explaining [SEP]"}
{"pre": "we focus specifically on pos induction systems, where no prior knowledge is available, in contrast to pos disambiguation systems # otherefr, which [SEP]", "cit": "we focus specifically on pos induction systems, where no prior knowledge is available, in contrast to pos disambiguation systems # otherefr ; # [SEP]"}
{"pre": "we focus on the particular qa of dependency relations # otherefr ; # refr. [SEP] kernel # otherefr. [SEP] kernel [SEP] kernel [SEP]", "cit": "iii and marcu, 2004 ), relation extraction # otherefr ; # refr ; bunescu and mooney, 2005 ; zhang [SEP]"}
{"pre": "the n - gram translation system can be tuned by minimum error rate training # refr. [SEP]. [SEP] the translation quality of the translation [SEP] [SEP] [SEP]", "cit": "besides, the log - linear model # otherefr is employed to linearly interpolate these features for obtaining the best translation according to the formula [SEP]"}
{"pre": "in this paper we focus on the general schemata # refr, where our task is defined when the textual entailment between entity mentions in which", "cit": "cp is phrased in terms of the textual entailment ( te ) paradigm # refr. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"}
